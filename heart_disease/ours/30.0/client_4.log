nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:44:57:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:44:57:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 22:44:57:DEBUG:ChannelConnectivity.IDLE
02/07/2025 22:44:57:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738997097.879423 1773156 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/07/2025 22:44:59:INFO:
[92mINFO [0m:      Received: train message 51e68a24-ebb3-4315-b5c8-1699f9dd3afa
02/07/2025 22:44:59:INFO:Received: train message 51e68a24-ebb3-4315-b5c8-1699f9dd3afa
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours/30.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours']
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.2413487716239615
Epoch 1/64:
  Train Loss: 0.5509437024593353
  Validation Loss: 0.60199373960495
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 2/64:
  Train Loss: 0.5598863661289215
  Validation Loss: 0.602148711681366
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 3/64:
  Train Loss: 0.5559219717979431
  Validation Loss: 0.6022968292236328
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 4/64:
  Train Loss: 0.5511245429515839
  Validation Loss: 0.6024715304374695
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 5/64:
  Train Loss: 0.55805903673172
  Validation Loss: 0.6026313900947571
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 6/64:
  Train Loss: 0.5558522939682007
  Validation Loss: 0.6027752757072449
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 7/64:
  Train Loss: 0.5509562790393829
  Validation Loss: 0.6029097437858582
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 8/64:
  Train Loss: 0.5522525012493134
  Validation Loss: 0.6030634045600891
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 9/64:
  Train Loss: 0.5498885810375214
  Validation Loss: 0.603202760219574
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 10/64:
  Train Loss: 0.5486942827701569
  Validation Loss: 0.6033241152763367
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 11/64:
  Train Loss: 0.5547358095645905
  Validation Loss: 0.6034747362136841
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 12/64:
  Train Loss: 0.5507462024688721
  Validation Loss: 0.6036331653594971
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 13/64:
  Train Loss: 0.5533192753791809
  Validation Loss: 0.6037830710411072
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 14/64:
  Train Loss: 0.5567100942134857
  Validation Loss: 0.6039283871650696
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 15/64:
  Train Loss: 0.551382839679718
  Validation Loss: 0.6040759086608887
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 16/64:
  Train Loss: 0.5513319969177246
  Validation Loss: 0.6042357087135315
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 17/64:
  Train Loss: 0.5514151155948639
  Validation Loss: 0.6043891310691833
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 18/64:
  Train Loss: 0.5578329563140869
  Validation Loss: 0.6045635938644409
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 19/64:
  Train Loss: 0.5638380497694016
  Validation Loss: 0.6047253012657166
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 20/64:
  Train Loss: 0.5452293753623962
  Validation Loss: 0.6048970818519592
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 21/64:
  Train Loss: 0.5539109110832214
  Validation Loss: 0.6050906777381897
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 22/64:
  Train Loss: 0.5608969926834106
  Validation Loss: 0.605263352394104
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 23/64:
  Train Loss: 0.5503678321838379
  Validation Loss: 0.6054331660270691
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 24/64:
  Train Loss: 0.5492047369480133
  Validation Loss: 0.6055892705917358
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 25/64:
  Train Loss: 0.5439286828041077
  Validation Loss: 0.6057531833648682
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 26/64:
  Train Loss: 0.5510067045688629
  Validation Loss: 0.6059221029281616
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 27/64:
  Train Loss: 0.555365800857544
  Validation Loss: 0.6061245203018188
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 28/64:
  Train Loss: 0.5516330003738403
  Validation Loss: 0.6063234210014343
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 29/64:
  Train Loss: 0.5559642016887665
  Validation Loss: 0.606533408164978
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 30/64:
  Train Loss: 0.5479588806629181
  Validation Loss: 0.6067199110984802
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 31/64:
  Train Loss: 0.5447614192962646
  Validation Loss: 0.6068968176841736
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 32/64:
  Train Loss: 0.5523913204669952
  Validation Loss: 0.6070641279220581
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 33/64:
  Train Loss: 0.5413141697645187
  Validation Loss: 0.6072264909744263
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 34/64:
  Train Loss: 0.541085496544838
  Validation Loss: 0.6073604822158813
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 35/64:
  Train Loss: 0.5555812418460846
  Validation Loss: 0.6074835062026978
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 36/64:
  Train Loss: 0.5406235456466675
  Validation Loss: 0.6076571941375732
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 37/64:
  Train Loss: 0.5409023463726044
  Validation Loss: 0.6077927350997925
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 38/64:
  Train Loss: 0.5540299713611603
  Validation Loss: 0.6079294681549072
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 39/64:
  Train Loss: 0.5447119474411011
  Validation Loss: 0.6080664992332458
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 40/64:
  Train Loss: 0.5414365828037262
  Validation Loss: 0.6082095503807068
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 41/64:
  Train Loss: 0.5460366308689117
  Validation Loss: 0.6083661317825317
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 42/64:
  Train Loss: 0.5477869510650635
  Validation Loss: 0.6085296869277954
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 43/64:
  Train Loss: 0.5474952757358551
  Validation Loss: 0.6087263822555542
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 44/64:
  Train Loss: 0.5408502519130707
  Validation Loss: 0.6089200377464294
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 45/64:
  Train Loss: 0.5492657423019409
  Validation Loss: 0.6091057062149048
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 46/64:
  Train Loss: 0.542928546667099
  Validation Loss: 0.6092662215232849
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 47/64:
  Train Loss: 0.5487276613712311
  Validation Loss: 0.6094644069671631
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 48/64:
  Train Loss: 0.5425665080547333
  Validation Loss: 0.6096628308296204
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 49/64:
  Train Loss: 0.5426313877105713
  Validation Loss: 0.6098564863204956
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 50/64:
  Train Loss: 0.5417664647102356
  Validation Loss: 0.6100743412971497
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:45:25:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:27:INFO:
[92mINFO [0m:      Received: evaluate message 014b0dfd-d5f0-44f6-b46a-4b1d4a61384e
02/07/2025 22:45:27:INFO:Received: evaluate message 014b0dfd-d5f0-44f6-b46a-4b1d4a61384e
[92mINFO [0m:      Sent reply
02/07/2025 22:45:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:45:33:INFO:
[92mINFO [0m:      Received: train message 2db7222a-bf19-4a90-b82e-9b3de3f00ecd
02/07/2025 22:45:33:INFO:Received: train message 2db7222a-bf19-4a90-b82e-9b3de3f00ecd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 51/64:
  Train Loss: 0.547547847032547
  Validation Loss: 0.6102884411811829
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 52/64:
  Train Loss: 0.5423046946525574
  Validation Loss: 0.6104864478111267
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 53/64:
  Train Loss: 0.5382012128829956
  Validation Loss: 0.6106749773025513
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 54/64:
  Train Loss: 0.541598379611969
  Validation Loss: 0.6108578443527222
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 55/64:
  Train Loss: 0.5408419668674469
  Validation Loss: 0.6110281944274902
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 56/64:
  Train Loss: 0.5464612245559692
  Validation Loss: 0.6111974716186523
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 57/64:
  Train Loss: 0.547822117805481
  Validation Loss: 0.6113619208335876
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 58/64:
  Train Loss: 0.5418011248111725
  Validation Loss: 0.6115406155586243
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 59/64:
  Train Loss: 0.5411107540130615
  Validation Loss: 0.611741304397583
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 60/64:
  Train Loss: 0.540306806564331
  Validation Loss: 0.6119346022605896
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 61/64:
  Train Loss: 0.5417630970478058
  Validation Loss: 0.612136960029602
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 62/64:
  Train Loss: 0.543201744556427
  Validation Loss: 0.6123183369636536
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 63/64:
  Train Loss: 0.5408177673816681
  Validation Loss: 0.6125308871269226
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 64/64:
  Train Loss: 0.5388958156108856
  Validation Loss: 0.6127374768257141
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
{'train_loss': 0.5388958156108856, 'val_roc_auc': 0.7777777777777778, 'val_accuracy': 0.7692307829856873, 'val_loss': 0.6127374768257141}
 ROC_AUC: 0.7778|| Accuracy 0.7692 || Train Loss: 0.5389
 Val Loss: 0.6127 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5801183137628767
Test ROC-AUC: 0.5914285714285714
Test Accuracy: 0.6222222222222222
test_loss: 0.5801183137628767
test_roc_auc: 0.5914285714285714
test_accuracy: 0.6222222222222222
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.20280426656427153
Epoch 1/64:
  Train Loss: 0.5848420262336731
  Validation Loss: 0.4952091872692108
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.567284494638443
  Validation Loss: 0.49516505002975464
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5843591094017029
  Validation Loss: 0.49509140849113464
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5846883952617645
  Validation Loss: 0.4950161874294281
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5792797207832336
  Validation Loss: 0.4949335753917694
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5808685719966888
  Validation Loss: 0.4948437511920929
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5825673639774323
  Validation Loss: 0.4947581887245178
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5716310143470764
  Validation Loss: 0.49468547105789185
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5738349854946136
  Validation Loss: 0.4946058988571167
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5778448283672333
  Validation Loss: 0.4945245385169983
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5780817866325378
  Validation Loss: 0.49442726373672485
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5772993862628937
  Validation Loss: 0.4943213164806366
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5852433145046234
  Validation Loss: 0.49421218037605286
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5813054144382477
  Validation Loss: 0.49411913752555847
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5670329332351685
  Validation Loss: 0.4940164387226105
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5834323763847351
  Validation Loss: 0.4939251244068146
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.577453076839447
  Validation Loss: 0.49383872747421265
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5776267647743225
  Validation Loss: 0.4937508702278137
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5832925140857697
  Validation Loss: 0.493648886680603
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 20/64:
  Train Loss: 0.5770988166332245
  Validation Loss: 0.493534654378891
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 21/64:
  Train Loss: 0.5780254304409027
  Validation Loss: 0.493439644575119
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 22/64:
  Train Loss: 0.5805244147777557
  Validation Loss: 0.4933471977710724
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 23/64:
  Train Loss: 0.5751168429851532
  Validation Loss: 0.49324899911880493
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 24/64:
  Train Loss: 0.5712311267852783
  Validation Loss: 0.49316272139549255
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 25/64:
  Train Loss: 0.5866968929767609
  Validation Loss: 0.49308067560195923
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 26/64:
  Train Loss: 0.5744422376155853
  Validation Loss: 0.4930051863193512
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 27/64:
  Train Loss: 0.5731212496757507
  Validation Loss: 0.4929187297821045
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 28/64:
  Train Loss: 0.5776046216487885
  Validation Loss: 0.49281829595565796
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 29/64:
  Train Loss: 0.5733670592308044
  Validation Loss: 0.4926998019218445
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 30/64:
  Train Loss: 0.5668534338474274
  Validation Loss: 0.492596834897995
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 31/64:
  Train Loss: 0.5730747580528259
  Validation Loss: 0.49250566959381104
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 32/64:
  Train Loss: 0.5744134187698364
  Validation Loss: 0.4923863112926483
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 33/64:
  Train Loss: 0.5685162246227264
  Validation Loss: 0.49227407574653625
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 34/64:
  Train Loss: 0.5668664574623108
  Validation Loss: 0.49215054512023926
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 35/64:
  Train Loss: 0.5620212405920029
  Validation Loss: 0.492033451795578
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 36/64:
  Train Loss: 0.5744253396987915
  Validation Loss: 0.4918954074382782
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 37/64:
  Train Loss: 0.5848522782325745
  Validation Loss: 0.4917634129524231
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 38/64:
  Train Loss: 0.5727031528949738
  Validation Loss: 0.491638720035553
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 39/64:
  Train Loss: 0.5676580965518951
  Validation Loss: 0.4915256202220917
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 22:45:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:01:INFO:
[92mINFO [0m:      Received: evaluate message 0a4200b0-31e9-4a3e-9f06-965eeecfec6c
02/07/2025 22:46:01:INFO:Received: evaluate message 0a4200b0-31e9-4a3e-9f06-965eeecfec6c
[92mINFO [0m:      Sent reply
02/07/2025 22:46:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:01:INFO:
[92mINFO [0m:      Received: train message bc30735f-99ac-4dcd-b567-f0b3a7778250
02/07/2025 22:46:01:INFO:Received: train message bc30735f-99ac-4dcd-b567-f0b3a7778250
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 40/64:
  Train Loss: 0.5746182799339294
  Validation Loss: 0.491428017616272
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5588628500699997
  Validation Loss: 0.49134835600852966
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.572941243648529
  Validation Loss: 0.49124646186828613
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.5690250098705292
  Validation Loss: 0.4911349415779114
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5747757852077484
  Validation Loss: 0.49100807309150696
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5710095167160034
  Validation Loss: 0.4908953905105591
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5649973750114441
  Validation Loss: 0.49077674746513367
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5689299404621124
  Validation Loss: 0.49066299200057983
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5664380788803101
  Validation Loss: 0.4905500113964081
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.5672301352024078
  Validation Loss: 0.490443617105484
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5802509486675262
  Validation Loss: 0.4903326630592346
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5677173435688019
  Validation Loss: 0.4902348220348358
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5752401649951935
  Validation Loss: 0.49014225602149963
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5696344971656799
  Validation Loss: 0.4900584816932678
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5715477764606476
  Validation Loss: 0.48997315764427185
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5687967538833618
  Validation Loss: 0.48990681767463684
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5785373747348785
  Validation Loss: 0.4898342192173004
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5608720481395721
  Validation Loss: 0.489762544631958
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5749270617961884
  Validation Loss: 0.48967114090919495
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.5647121965885162
  Validation Loss: 0.48958176374435425
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5739073157310486
  Validation Loss: 0.4894934296607971
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5740477740764618
  Validation Loss: 0.4894053637981415
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5705572962760925
  Validation Loss: 0.48931989073753357
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5669069588184357
  Validation Loss: 0.4892396032810211
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5685805678367615
  Validation Loss: 0.48914965987205505
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5685805678367615, 'val_roc_auc': nan, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.48914965987205505}
 ROC_AUC: nan|| Accuracy 0.6154 || Train Loss: 0.5686
 Val Loss: 0.4891 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5796782460477617
Test ROC-AUC: 0.6028571428571429
Test Accuracy: 0.6222222222222222
test_loss: 0.5796782460477617
test_roc_auc: 0.6028571428571429
test_accuracy: 0.6222222222222222
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.09919764005417164
Epoch 1/64:
  Train Loss: 0.5498720109462738
  Validation Loss: 0.604783296585083
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 2/64:
  Train Loss: 0.550998717546463
  Validation Loss: 0.6047800779342651
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 3/64:
  Train Loss: 0.5522814393043518
  Validation Loss: 0.6047892570495605
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 4/64:
  Train Loss: 0.5566566288471222
  Validation Loss: 0.6048121452331543
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 5/64:
  Train Loss: 0.5519030690193176
  Validation Loss: 0.6048630475997925
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 6/64:
  Train Loss: 0.5510934591293335
  Validation Loss: 0.6049262285232544
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 7/64:
  Train Loss: 0.5476089417934418
  Validation Loss: 0.6049818992614746
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 8/64:
  Train Loss: 0.5561476647853851
  Validation Loss: 0.6050421595573425
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 9/64:
  Train Loss: 0.5534730851650238
  Validation Loss: 0.6050984859466553
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 10/64:
  Train Loss: 0.5515784621238708
  Validation Loss: 0.6051690578460693
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 11/64:
  Train Loss: 0.5425091236829758
  Validation Loss: 0.6052255630493164
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 12/64:
  Train Loss: 0.547323077917099
  Validation Loss: 0.6052901148796082
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 13/64:
  Train Loss: 0.5554482638835907
  Validation Loss: 0.6053619384765625
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 14/64:
  Train Loss: 0.5528110861778259
  Validation Loss: 0.6054002046585083
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 15/64:
  Train Loss: 0.5479848384857178
  Validation Loss: 0.605451762676239
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 16/64:
  Train Loss: 0.5564523339271545
  Validation Loss: 0.6055149435997009
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 17/64:
  Train Loss: 0.5533546507358551
  Validation Loss: 0.6055848002433777
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 18/64:
  Train Loss: 0.5489984452724457
  Validation Loss: 0.6056462526321411
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 19/64:
  Train Loss: 0.5524367988109589
  Validation Loss: 0.6056984066963196
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 20/64:
  Train Loss: 0.5555305778980255
  Validation Loss: 0.6057507395744324
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 21/64:
  Train Loss: 0.5538644194602966
  Validation Loss: 0.6058107614517212
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 22/64:
  Train Loss: 0.5397866368293762
  Validation Loss: 0.6058671474456787
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 23/64:
  Train Loss: 0.545457661151886
  Validation Loss: 0.6059353351593018
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 24/64:
  Train Loss: 0.5532592833042145
  Validation Loss: 0.6059949994087219
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 25/64:
  Train Loss: 0.5468910336494446
  Validation Loss: 0.6060494780540466
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 26/64:
  Train Loss: 0.5471200942993164
  Validation Loss: 0.6061062216758728
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 27/64:
  Train Loss: 0.5517041683197021
  Validation Loss: 0.6061582565307617
  Val ROC-AUC: 0.4
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:29:INFO:
[92mINFO [0m:      Received: evaluate message 0fae3b41-2d08-44a6-8f37-09ad7bcae219
02/07/2025 22:46:29:INFO:Received: evaluate message 0fae3b41-2d08-44a6-8f37-09ad7bcae219
[92mINFO [0m:      Sent reply
02/07/2025 22:46:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:30:INFO:
[92mINFO [0m:      Received: train message 77444c9c-eba2-4b87-86e6-499a837c3d61
02/07/2025 22:46:30:INFO:Received: train message 77444c9c-eba2-4b87-86e6-499a837c3d61
  Val Accuracy: 0.46153849363327026
Epoch 28/64:
  Train Loss: 0.5464566946029663
  Validation Loss: 0.6062130331993103
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 29/64:
  Train Loss: 0.5455558598041534
  Validation Loss: 0.6062590479850769
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 30/64:
  Train Loss: 0.5544345676898956
  Validation Loss: 0.6062981486320496
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 31/64:
  Train Loss: 0.5330641567707062
  Validation Loss: 0.6063360571861267
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 32/64:
  Train Loss: 0.542544960975647
  Validation Loss: 0.606374979019165
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 33/64:
  Train Loss: 0.5433155596256256
  Validation Loss: 0.6064181327819824
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 34/64:
  Train Loss: 0.5430630743503571
  Validation Loss: 0.6064398884773254
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 35/64:
  Train Loss: 0.5508152544498444
  Validation Loss: 0.6064844727516174
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 36/64:
  Train Loss: 0.5390153378248215
  Validation Loss: 0.606526792049408
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 37/64:
  Train Loss: 0.5450322031974792
  Validation Loss: 0.606560230255127
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 38/64:
  Train Loss: 0.5393616557121277
  Validation Loss: 0.6066155433654785
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 39/64:
  Train Loss: 0.5429260432720184
  Validation Loss: 0.6066731810569763
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 40/64:
  Train Loss: 0.5417743623256683
  Validation Loss: 0.6067232489585876
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 41/64:
  Train Loss: 0.5481215119361877
  Validation Loss: 0.60678631067276
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 42/64:
  Train Loss: 0.5368118286132812
  Validation Loss: 0.6068192720413208
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 43/64:
  Train Loss: 0.5456132292747498
  Validation Loss: 0.6068775653839111
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 44/64:
  Train Loss: 0.5404623746871948
  Validation Loss: 0.6069105267524719
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 45/64:
  Train Loss: 0.5448254942893982
  Validation Loss: 0.6069596409797668
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 46/64:
  Train Loss: 0.5477260649204254
  Validation Loss: 0.6070205569267273
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 47/64:
  Train Loss: 0.5414183735847473
  Validation Loss: 0.6070567965507507
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 48/64:
  Train Loss: 0.5381124019622803
  Validation Loss: 0.6070939898490906
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 49/64:
  Train Loss: 0.5480083227157593
  Validation Loss: 0.6071184277534485
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 50/64:
  Train Loss: 0.5414883494377136
  Validation Loss: 0.6071476340293884
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 51/64:
  Train Loss: 0.5382689535617828
  Validation Loss: 0.6071629524230957
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 52/64:
  Train Loss: 0.5392259955406189
  Validation Loss: 0.6071939468383789
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 53/64:
  Train Loss: 0.5395613312721252
  Validation Loss: 0.6072253584861755
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 54/64:
  Train Loss: 0.5466956198215485
  Validation Loss: 0.6072574257850647
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 55/64:
  Train Loss: 0.5449991226196289
  Validation Loss: 0.6072875261306763
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 56/64:
  Train Loss: 0.5429403483867645
  Validation Loss: 0.6073014736175537
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 57/64:
  Train Loss: 0.5334763079881668
  Validation Loss: 0.6073125004768372
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 58/64:
  Train Loss: 0.5458119511604309
  Validation Loss: 0.6073236465454102
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 59/64:
  Train Loss: 0.5365240275859833
  Validation Loss: 0.6073467135429382
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 60/64:
  Train Loss: 0.5404553115367889
  Validation Loss: 0.6073557138442993
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 61/64:
  Train Loss: 0.5355954766273499
  Validation Loss: 0.6073617339134216
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 62/64:
  Train Loss: 0.5378426909446716
  Validation Loss: 0.6073710322380066
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 63/64:
  Train Loss: 0.5415659248828888
  Validation Loss: 0.6073921918869019
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 64/64:
  Train Loss: 0.5436563491821289
  Validation Loss: 0.6073889136314392
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
{'train_loss': 0.5436563491821289, 'val_roc_auc': 0.4, 'val_accuracy': 0.46153849363327026, 'val_loss': 0.6073889136314392}
 ROC_AUC: 0.4000|| Accuracy 0.4615 || Train Loss: 0.5437
 Val Loss: 0.6074 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5793486952781677
Test ROC-AUC: 0.6142857142857143
Test Accuracy: 0.6444444444444445
test_loss: 0.5793486952781677
test_roc_auc: 0.6142857142857143
test_accuracy: 0.6444444444444445
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.16802411136040973
Epoch 1/64:
  Train Loss: 0.5611647963523865
  Validation Loss: 0.5542744398117065
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5737956166267395
  Validation Loss: 0.5540400743484497
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5637824535369873
  Validation Loss: 0.5538398027420044
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.5682019293308258
  Validation Loss: 0.5536555051803589
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.555256575345993
  Validation Loss: 0.5534715056419373
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.5668738484382629
  Validation Loss: 0.5533033013343811
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5594241917133331
  Validation Loss: 0.5531115531921387
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5665426254272461
  Validation Loss: 0.5529205799102783
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.5690709054470062
  Validation Loss: 0.5527346730232239
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.5690221190452576
  Validation Loss: 0.552573025226593
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.5578092336654663
  Validation Loss: 0.5524033308029175
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5608374774456024
  Validation Loss: 0.5522189736366272
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5639156997203827
  Validation Loss: 0.5520495176315308
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5646267533302307
  Validation Loss: 0.5519012212753296
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 15/64:
  Train Loss: 0.5569368302822113
  Validation Loss: 0.5517463684082031
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 16/64:
  Train Loss: 0.568854570388794
  Validation Loss: 0.5516055822372437
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:46:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:59:INFO:
[92mINFO [0m:      Received: evaluate message c8c85386-dae9-49f0-ab90-442af19f53a6
02/07/2025 22:46:59:INFO:Received: evaluate message c8c85386-dae9-49f0-ab90-442af19f53a6
[92mINFO [0m:      Sent reply
02/07/2025 22:46:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:46:59:INFO:
[92mINFO [0m:      Received: train message 7478a517-c88d-421c-9604-6550a6e8d045
02/07/2025 22:46:59:INFO:Received: train message 7478a517-c88d-421c-9604-6550a6e8d045
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 17/64:
  Train Loss: 0.5615395307540894
  Validation Loss: 0.55144864320755
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 18/64:
  Train Loss: 0.5679158568382263
  Validation Loss: 0.5512921214103699
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 19/64:
  Train Loss: 0.5535234212875366
  Validation Loss: 0.5511369705200195
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 20/64:
  Train Loss: 0.5667466521263123
  Validation Loss: 0.5509863495826721
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 21/64:
  Train Loss: 0.558702826499939
  Validation Loss: 0.5508258938789368
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 22/64:
  Train Loss: 0.562795102596283
  Validation Loss: 0.5506619215011597
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 23/64:
  Train Loss: 0.5607243776321411
  Validation Loss: 0.5504897832870483
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 24/64:
  Train Loss: 0.5607366561889648
  Validation Loss: 0.5503001809120178
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 25/64:
  Train Loss: 0.5579070448875427
  Validation Loss: 0.5501279830932617
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 26/64:
  Train Loss: 0.5605137944221497
  Validation Loss: 0.5499550700187683
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 27/64:
  Train Loss: 0.5554802715778351
  Validation Loss: 0.5497899651527405
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 28/64:
  Train Loss: 0.5605145692825317
  Validation Loss: 0.5496199131011963
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 29/64:
  Train Loss: 0.562031090259552
  Validation Loss: 0.5494440197944641
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 30/64:
  Train Loss: 0.5585896372795105
  Validation Loss: 0.5492815375328064
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 31/64:
  Train Loss: 0.564122349023819
  Validation Loss: 0.5491173267364502
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 32/64:
  Train Loss: 0.5623891651630402
  Validation Loss: 0.5489622354507446
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 33/64:
  Train Loss: 0.5585167706012726
  Validation Loss: 0.5488150715827942
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 34/64:
  Train Loss: 0.564612627029419
  Validation Loss: 0.5486425161361694
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 35/64:
  Train Loss: 0.5576154291629791
  Validation Loss: 0.548488974571228
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 36/64:
  Train Loss: 0.5567200779914856
  Validation Loss: 0.5483503341674805
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 37/64:
  Train Loss: 0.5618752837181091
  Validation Loss: 0.5482033491134644
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 38/64:
  Train Loss: 0.5584220290184021
  Validation Loss: 0.5480435490608215
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 39/64:
  Train Loss: 0.5613341331481934
  Validation Loss: 0.5479008555412292
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 40/64:
  Train Loss: 0.5569224953651428
  Validation Loss: 0.5477571487426758
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5639464855194092
  Validation Loss: 0.5476003289222717
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.5579937696456909
  Validation Loss: 0.5474566221237183
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.5595926344394684
  Validation Loss: 0.5473102331161499
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5521223843097687
  Validation Loss: 0.5471676588058472
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5582907795906067
  Validation Loss: 0.5470206141471863
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.561040073633194
  Validation Loss: 0.5468575358390808
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5486879646778107
  Validation Loss: 0.5467047691345215
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5507916808128357
  Validation Loss: 0.546550989151001
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.5507314801216125
  Validation Loss: 0.5464061498641968
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5553142726421356
  Validation Loss: 0.5462693572044373
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5477508753538132
  Validation Loss: 0.5461254715919495
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5531470775604248
  Validation Loss: 0.5459819436073303
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5612060725688934
  Validation Loss: 0.5458353757858276
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.550630122423172
  Validation Loss: 0.5457120537757874
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5473422706127167
  Validation Loss: 0.5455883145332336
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5554333031177521
  Validation Loss: 0.5454777479171753
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5551449358463287
  Validation Loss: 0.5453548431396484
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5643517971038818
  Validation Loss: 0.5452431440353394
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5523207187652588
  Validation Loss: 0.5451181530952454
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5581381320953369
  Validation Loss: 0.5449832081794739
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5473527312278748
  Validation Loss: 0.5448563694953918
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5544395744800568
  Validation Loss: 0.5447341203689575
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5526106655597687
  Validation Loss: 0.5446197986602783
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5553561747074127
  Validation Loss: 0.5444765090942383
  Val ROC-AUC: 0.4545454545454546
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5553561747074127, 'val_roc_auc': 0.4545454545454546, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5444765090942383}
 ROC_AUC: 0.4545|| Accuracy 0.6923 || Train Loss: 0.5554
 Val Loss: 0.5445 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5790145814418792
Test ROC-AUC: 0.6285714285714286
Test Accuracy: 0.6
test_loss: 0.5790145814418792
test_roc_auc: 0.6285714285714286
test_accuracy: 0.6
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.17280895588100975
Epoch 1/64:
  Train Loss: 0.5739817917346954
  Validation Loss: 0.5251396894454956
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.5702976882457733
  Validation Loss: 0.5251255631446838
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5820119976997375
  Validation Loss: 0.5251099467277527
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5707049369812012
  Validation Loss: 0.5250924825668335
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5748080313205719
  Validation Loss: 0.5250514149665833
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5666262209415436
  Validation Loss: 0.5250163078308105
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.568032294511795
  Validation Loss: 0.5249647498130798
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.576898843050003
  Validation Loss: 0.5249001383781433
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5642096400260925
  Validation Loss: 0.524854838848114
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5745204091072083
  Validation Loss: 0.5247951745986938
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5691865682601929
  Validation Loss: 0.5247495770454407
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5710306167602539
  Validation Loss: 0.5247054696083069
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.566949725151062
  Validation Loss: 0.5246490836143494
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5738926529884338
  Validation Loss: 0.524578869342804
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.570645660161972
  Validation Loss: 0.5245071649551392
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5657997131347656
  Validation Loss: 0.5244476795196533
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5703131258487701
  Validation Loss: 0.5243857502937317
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.564121663570404
  Validation Loss: 0.5243266820907593
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5624989569187164
  Validation Loss: 0.5242584943771362
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5596518814563751
  Validation Loss: 0.5241826772689819
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5708887279033661
  Validation Loss: 0.5241068601608276
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5679703056812286
  Validation Loss: 0.5240347981452942
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.571514368057251
  Validation Loss: 0.5239746570587158
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5631786286830902
  Validation Loss: 0.5239259600639343
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5670083165168762
  Validation Loss: 0.5238721966743469
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5804692804813385
  Validation Loss: 0.5238272547721863
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5696445107460022
  Validation Loss: 0.5237908959388733
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5740425288677216
  Validation Loss: 0.5237533450126648
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5621269345283508
  Validation Loss: 0.5237172245979309
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5690345764160156
  Validation Loss: 0.5236858129501343
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5679872035980225
  Validation Loss: 0.5236503481864929
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5717404186725616
  Validation Loss: 0.5236161351203918
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5637791454792023
  Validation Loss: 0.5235773921012878
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5753301084041595
  Validation Loss: 0.5235286951065063
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5579988062381744
  Validation Loss: 0.5234898328781128
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5593993961811066
  Validation Loss: 0.5234473347663879
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5621437132358551
  Validation Loss: 0.5233931541442871
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5618082880973816
  Validation Loss: 0.5233535766601562
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5614203214645386
  Validation Loss: 0.5233092904090881
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.567351371049881
  Validation Loss: 0.5232588648796082
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5555558204650879
  Validation Loss: 0.5232007503509521
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5609939396381378
  Validation Loss: 0.5231302976608276
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5643310248851776
  Validation Loss: 0.523055911064148
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5587422251701355
  Validation Loss: 0.5229894518852234
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.572944700717926
  Validation Loss: 0.5229305028915405
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5632861256599426
  Validation Loss: 0.522865891456604
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5666380524635315
  Validation Loss: 0.522811233997345
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5580917298793793
  Validation Loss: 0.5227596163749695
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5609811544418335
  Validation Loss: 0.5227174162864685
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5610705316066742
  Validation Loss: 0.5226678252220154
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5656004548072815
  Validation Loss: 0.5226099491119385
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5598575174808502
  Validation Loss: 0.5225473642349243
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5555396676063538
  Validation Loss: 0.5224980115890503
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5602532923221588
  Validation Loss: 0.5224355459213257
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5639829635620117
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:26:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:28:INFO:
[92mINFO [0m:      Received: evaluate message f3d7c755-8381-44d0-8a63-29ccaefab546
02/07/2025 22:47:28:INFO:Received: evaluate message f3d7c755-8381-44d0-8a63-29ccaefab546
[92mINFO [0m:      Sent reply
02/07/2025 22:47:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:31:INFO:
[92mINFO [0m:      Received: train message 4548fc58-90f3-460c-a866-016ba0f6bd88
02/07/2025 22:47:31:INFO:Received: train message 4548fc58-90f3-460c-a866-016ba0f6bd88
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5223768353462219
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.561013400554657
  Validation Loss: 0.522313117980957
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5639987885951996
  Validation Loss: 0.5222465991973877
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5521801710128784
  Validation Loss: 0.522199809551239
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.557657390832901
  Validation Loss: 0.5221425294876099
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5620886087417603
  Validation Loss: 0.5220842957496643
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5571363270282745
  Validation Loss: 0.5220339894294739
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5572001039981842
  Validation Loss: 0.5219731330871582
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5649572312831879
  Validation Loss: 0.5219200253486633
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.554752379655838
  Validation Loss: 0.521864116191864
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.554752379655838, 'val_roc_auc': 0.08333333333333333, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.521864116191864}
 ROC_AUC: 0.0833|| Accuracy 0.5385 || Train Loss: 0.5548
 Val Loss: 0.5219 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5786861697832744
Test ROC-AUC: 0.6428571428571428
Test Accuracy: 0.6
test_loss: 0.5786861697832744
test_roc_auc: 0.6428571428571428
test_accuracy: 0.6
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.19197981214347237
Epoch 1/64:
  Train Loss: 0.564848780632019
  Validation Loss: 0.5428017377853394
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5640000700950623
  Validation Loss: 0.5427825450897217
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5727898478507996
  Validation Loss: 0.5427196025848389
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5614862143993378
  Validation Loss: 0.5426203012466431
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5750164687633514
  Validation Loss: 0.5425417423248291
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5658974349498749
  Validation Loss: 0.5424741506576538
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5642514228820801
  Validation Loss: 0.5424124598503113
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5631875991821289
  Validation Loss: 0.542339563369751
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5653374493122101
  Validation Loss: 0.5422582626342773
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.575820803642273
  Validation Loss: 0.5421758890151978
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5673944056034088
  Validation Loss: 0.5420796275138855
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5679472982883453
  Validation Loss: 0.5419727563858032
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5681059062480927
  Validation Loss: 0.5418817400932312
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5641815364360809
  Validation Loss: 0.5417903065681458
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5645108819007874
  Validation Loss: 0.5417038202285767
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5660151541233063
  Validation Loss: 0.5415997505187988
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5667542219161987
  Validation Loss: 0.5414910912513733
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5675876140594482
  Validation Loss: 0.5413763523101807
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.561762809753418
  Validation Loss: 0.5412602424621582
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5606177449226379
  Validation Loss: 0.5411539673805237
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5627858638763428
  Validation Loss: 0.5410659313201904
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5650174021720886
  Validation Loss: 0.5409866571426392
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.556388795375824
  Validation Loss: 0.5409119129180908
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5603341162204742
  Validation Loss: 0.540835976600647
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5621680915355682
  Validation Loss: 0.5407642126083374
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5611857771873474
  Validation Loss: 0.5406945943832397
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5628615617752075
  Validation Loss: 0.5406085252761841
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5572014153003693
  Validation Loss: 0.5405218005180359
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.558724582195282
  Validation Loss: 0.5404422879219055
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.56621253490448
  Validation Loss: 0.540376603603363
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.562586635351181
  Validation Loss: 0.540296196937561
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.558673083782196
  Validation Loss: 0.5402234196662903
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5684265196323395
  Validation Loss: 0.5401466488838196
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5625707805156708
  Validation Loss: 0.5400734543800354
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5657420754432678
  Validation Loss: 0.5400119423866272
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5531565845012665
  Validation Loss: 0.5399444699287415
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.550592914223671
  Validation Loss: 0.539862871170044
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5673848986625671
  Validation Loss: 0.5397830605506897
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5519781410694122
  Validation Loss: 0.5396898984909058
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5563997030258179
  Validation Loss: 0.5396063923835754
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 41/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:47:54:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:47:59:INFO:
[92mINFO [0m:      Received: evaluate message 55a09622-ec38-4dd4-9c72-e83d4f4e6c83
02/07/2025 22:47:59:INFO:Received: evaluate message 55a09622-ec38-4dd4-9c72-e83d4f4e6c83
[92mINFO [0m:      Sent reply
02/07/2025 22:48:00:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:01:INFO:
[92mINFO [0m:      Received: train message 31bb28b9-34f0-47c0-bf8f-8947380f6a52
02/07/2025 22:48:01:INFO:Received: train message 31bb28b9-34f0-47c0-bf8f-8947380f6a52
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.565007746219635
  Validation Loss: 0.5395277738571167
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.56218221783638
  Validation Loss: 0.539458692073822
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5616670846939087
  Validation Loss: 0.5394015312194824
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5642974972724915
  Validation Loss: 0.539335310459137
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5586959421634674
  Validation Loss: 0.5392641425132751
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5536180138587952
  Validation Loss: 0.5391989350318909
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5588251352310181
  Validation Loss: 0.5391221642494202
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5613732933998108
  Validation Loss: 0.5390399098396301
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5613479316234589
  Validation Loss: 0.5389695167541504
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5623033046722412
  Validation Loss: 0.5388982892036438
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5565312206745148
  Validation Loss: 0.5388430953025818
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5548577606678009
  Validation Loss: 0.5387609004974365
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5586928427219391
  Validation Loss: 0.5386866927146912
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5599580705165863
  Validation Loss: 0.5386056900024414
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5658352077007294
  Validation Loss: 0.5385094881057739
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5593514144420624
  Validation Loss: 0.5384058952331543
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5586478412151337
  Validation Loss: 0.5383240580558777
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5543208122253418
  Validation Loss: 0.5382509231567383
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5549185872077942
  Validation Loss: 0.538182258605957
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5585983693599701
  Validation Loss: 0.5380911827087402
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5587991178035736
  Validation Loss: 0.5380010604858398
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5625790357589722
  Validation Loss: 0.537906289100647
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5586082339286804
  Validation Loss: 0.5378111600875854
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5614681243896484
  Validation Loss: 0.5377154350280762
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5614681243896484, 'val_roc_auc': 0.7272727272727273, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5377154350280762}
 ROC_AUC: 0.7273|| Accuracy 0.6923 || Train Loss: 0.5615
 Val Loss: 0.5377 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5783149666256375
Test ROC-AUC: 0.6542857142857144
Test Accuracy: 0.6
test_loss: 0.5783149666256375
test_roc_auc: 0.6542857142857144
test_accuracy: 0.6
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.21116177708790929
Epoch 1/64:
  Train Loss: 0.5498394966125488
  Validation Loss: 0.6137988567352295
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 2/64:
  Train Loss: 0.5515357851982117
  Validation Loss: 0.614077091217041
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 3/64:
  Train Loss: 0.5442207157611847
  Validation Loss: 0.6143449544906616
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 4/64:
  Train Loss: 0.5443295240402222
  Validation Loss: 0.6145681738853455
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 5/64:
  Train Loss: 0.539683386683464
  Validation Loss: 0.6147861480712891
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 6/64:
  Train Loss: 0.5456454157829285
  Validation Loss: 0.614981472492218
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 7/64:
  Train Loss: 0.5453514158725739
  Validation Loss: 0.615158200263977
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 8/64:
  Train Loss: 0.5449260175228119
  Validation Loss: 0.6153449416160583
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 9/64:
  Train Loss: 0.5457567274570465
  Validation Loss: 0.6155075430870056
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 10/64:
  Train Loss: 0.5518730282783508
  Validation Loss: 0.6156770586967468
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 11/64:
  Train Loss: 0.541575014591217
  Validation Loss: 0.6158723831176758
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 12/64:
  Train Loss: 0.5393610596656799
  Validation Loss: 0.616058349609375
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 13/64:
  Train Loss: 0.5516389310359955
  Validation Loss: 0.6162177324295044
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 14/64:
  Train Loss: 0.5506755709648132
  Validation Loss: 0.6163822412490845
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 15/64:
  Train Loss: 0.5503067374229431
  Validation Loss: 0.6165487170219421
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 16/64:
  Train Loss: 0.5441931486129761
  Validation Loss: 0.6167134046554565
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 17/64:
  Train Loss: 0.5410851836204529
  Validation Loss: 0.6168819665908813
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.38461539149284363
Epoch 18/64:
  Train Loss: 0.5436763167381287
  Validation Loss: 0.6170485019683838
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.38461539149284363
Epoch 19/64:
  Train Loss: 0.5486241579055786
  Validation Loss: 0.6172340512275696
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.38461539149284363
Epoch 20/64:
  Train Loss: 0.5474816560745239
  Validation Loss: 0.6173929572105408
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.38461539149284363
Epoch 21/64:
  Train Loss: 0.5374757349491119
  Validation Loss: 0.6175307035446167
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.38461539149284363
Epoch 22/64:
  Train Loss: 0.5344610214233398
  Validation Loss: 0.6176931858062744
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.38461539149284363
Epoch 23/64:
  Train Loss: 0.5452711284160614
  Validation Loss: 0.6178505420684814
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 24/64:
  Train Loss: 0.5477026402950287
  Validation Loss: 0.6180148720741272
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 25/64:
  Train Loss: 0.5488688945770264
  Validation Loss: 0.618167519569397
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 26/64:
  Train Loss: 0.5463525652885437
  Validation Loss: 0.61832195520401
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 27/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:29:INFO:
[92mINFO [0m:      Received: evaluate message 72f63055-1a89-4182-9586-006e8bd7064f
02/07/2025 22:48:29:INFO:Received: evaluate message 72f63055-1a89-4182-9586-006e8bd7064f
[92mINFO [0m:      Sent reply
02/07/2025 22:48:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:29:INFO:
[92mINFO [0m:      Received: train message 9d2bf43a-e018-4973-91f4-0c8ec44d05b7
02/07/2025 22:48:29:INFO:Received: train message 9d2bf43a-e018-4973-91f4-0c8ec44d05b7
  Train Loss: 0.5444637537002563
  Validation Loss: 0.6184811592102051
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 28/64:
  Train Loss: 0.540618896484375
  Validation Loss: 0.6186307072639465
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 29/64:
  Train Loss: 0.54298534989357
  Validation Loss: 0.6187743544578552
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 30/64:
  Train Loss: 0.5376231074333191
  Validation Loss: 0.618901789188385
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 31/64:
  Train Loss: 0.5495077669620514
  Validation Loss: 0.619032084941864
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 32/64:
  Train Loss: 0.5333232581615448
  Validation Loss: 0.6191404461860657
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 33/64:
  Train Loss: 0.5327022969722748
  Validation Loss: 0.619269073009491
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 34/64:
  Train Loss: 0.5412936210632324
  Validation Loss: 0.619401216506958
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 35/64:
  Train Loss: 0.5331059247255325
  Validation Loss: 0.6195339560508728
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 36/64:
  Train Loss: 0.5399362444877625
  Validation Loss: 0.6196629405021667
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 37/64:
  Train Loss: 0.5296252220869064
  Validation Loss: 0.619780957698822
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 38/64:
  Train Loss: 0.537900298833847
  Validation Loss: 0.6198716163635254
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 39/64:
  Train Loss: 0.5412282943725586
  Validation Loss: 0.6199663281440735
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 40/64:
  Train Loss: 0.534281462430954
  Validation Loss: 0.6200494170188904
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 41/64:
  Train Loss: 0.5436830222606659
  Validation Loss: 0.6201304793357849
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 42/64:
  Train Loss: 0.544619083404541
  Validation Loss: 0.6202123761177063
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 43/64:
  Train Loss: 0.5403781831264496
  Validation Loss: 0.6203030943870544
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 44/64:
  Train Loss: 0.539743572473526
  Validation Loss: 0.6204025745391846
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 45/64:
  Train Loss: 0.5371414422988892
  Validation Loss: 0.6205059885978699
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 46/64:
  Train Loss: 0.5354792177677155
  Validation Loss: 0.6205905079841614
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 47/64:
  Train Loss: 0.535549521446228
  Validation Loss: 0.6206520199775696
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 48/64:
  Train Loss: 0.5358184278011322
  Validation Loss: 0.6207128763198853
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 49/64:
  Train Loss: 0.543259859085083
  Validation Loss: 0.6207517981529236
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 50/64:
  Train Loss: 0.5393925309181213
  Validation Loss: 0.6208063960075378
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 51/64:
  Train Loss: 0.5388272106647491
  Validation Loss: 0.6208509802818298
  Val ROC-AUC: 0.4
  Val Accuracy: 0.38461539149284363
Epoch 52/64:
  Train Loss: 0.5432251989841461
  Validation Loss: 0.6208828091621399
  Val ROC-AUC: 0.3666666666666667
  Val Accuracy: 0.38461539149284363
Epoch 53/64:
  Train Loss: 0.530733123421669
  Validation Loss: 0.6209522485733032
  Val ROC-AUC: 0.3666666666666667
  Val Accuracy: 0.38461539149284363
Epoch 54/64:
  Train Loss: 0.5361406803131104
  Validation Loss: 0.6210303902626038
  Val ROC-AUC: 0.3666666666666667
  Val Accuracy: 0.38461539149284363
Epoch 55/64:
  Train Loss: 0.5309455096721649
  Validation Loss: 0.621115505695343
  Val ROC-AUC: 0.3666666666666667
  Val Accuracy: 0.38461539149284363
Epoch 56/64:
  Train Loss: 0.5303376764059067
  Validation Loss: 0.6211974024772644
  Val ROC-AUC: 0.3666666666666667
  Val Accuracy: 0.38461539149284363
Epoch 57/64:
  Train Loss: 0.5342019498348236
  Validation Loss: 0.6212361454963684
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.38461539149284363
Epoch 58/64:
  Train Loss: 0.5338298380374908
  Validation Loss: 0.6212700605392456
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.38461539149284363
Epoch 59/64:
  Train Loss: 0.5355336964130402
  Validation Loss: 0.6212844252586365
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.38461539149284363
Epoch 60/64:
  Train Loss: 0.5348430871963501
  Validation Loss: 0.6213187575340271
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.38461539149284363
Epoch 61/64:
  Train Loss: 0.5312575399875641
  Validation Loss: 0.6213497519493103
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.38461539149284363
Epoch 62/64:
  Train Loss: 0.5415132343769073
  Validation Loss: 0.6213744282722473
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.38461539149284363
Epoch 63/64:
  Train Loss: 0.53216353058815
  Validation Loss: 0.6214335560798645
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.38461539149284363
Epoch 64/64:
  Train Loss: 0.5340502560138702
  Validation Loss: 0.6214823722839355
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.38461539149284363
{'train_loss': 0.5340502560138702, 'val_roc_auc': 0.3333333333333333, 'val_accuracy': 0.38461539149284363, 'val_loss': 0.6214823722839355}
 ROC_AUC: 0.3333|| Accuracy 0.3846 || Train Loss: 0.5341
 Val Loss: 0.6215 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5780384182929993
Test ROC-AUC: 0.6628571428571428
Test Accuracy: 0.6
test_loss: 0.5780384182929993
test_roc_auc: 0.6628571428571428
test_accuracy: 0.6
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.17073164309522326
Epoch 1/64:
  Train Loss: 0.5679979622364044
  Validation Loss: 0.5377567410469055
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5688442587852478
  Validation Loss: 0.5377660989761353
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.563884437084198
  Validation Loss: 0.5377352237701416
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5594241321086884
  Validation Loss: 0.5377184152603149
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5641363859176636
  Validation Loss: 0.5377026200294495
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5575751066207886
  Validation Loss: 0.5376964211463928
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5545761287212372
  Validation Loss: 0.5376944541931152
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.559412032365799
  Validation Loss: 0.5376790761947632
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5600410103797913
  Validation Loss: 0.5376801490783691
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5594421625137329
  Validation Loss: 0.5376642942428589
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5680384635925293
  Validation Loss: 0.5376508831977844
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5694452822208405
  Validation Loss: 0.5376080274581909
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5580379366874695
  Validation Loss: 0.537555992603302
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5648292601108551
  Validation Loss: 0.5374912023544312
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5698393881320953
  Validation Loss: 0.5374442338943481
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5676228404045105
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:48:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:57:INFO:
[92mINFO [0m:      Received: evaluate message 5ab1bc7c-9551-4df0-8f47-8b65738c03c9
02/07/2025 22:48:57:INFO:Received: evaluate message 5ab1bc7c-9551-4df0-8f47-8b65738c03c9
[92mINFO [0m:      Sent reply
02/07/2025 22:48:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:48:58:INFO:
[92mINFO [0m:      Received: train message 3bce8096-1999-4afb-a435-a70873aedbbb
02/07/2025 22:48:58:INFO:Received: train message 3bce8096-1999-4afb-a435-a70873aedbbb
  Validation Loss: 0.5374258160591125
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5627981126308441
  Validation Loss: 0.5373969078063965
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5613875985145569
  Validation Loss: 0.5373654365539551
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5607084035873413
  Validation Loss: 0.5373305678367615
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5610501766204834
  Validation Loss: 0.5373042821884155
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5663028359413147
  Validation Loss: 0.5372860431671143
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5546512007713318
  Validation Loss: 0.5372726321220398
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5651826858520508
  Validation Loss: 0.5372581481933594
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5585309565067291
  Validation Loss: 0.5372323989868164
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5605986714363098
  Validation Loss: 0.5372050404548645
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5590676367282867
  Validation Loss: 0.537193775177002
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5580832064151764
  Validation Loss: 0.5371589064598083
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5696285665035248
  Validation Loss: 0.537122368812561
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5603270828723907
  Validation Loss: 0.537088930606842
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5608611404895782
  Validation Loss: 0.5370668172836304
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5704420506954193
  Validation Loss: 0.5370464324951172
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5575062930583954
  Validation Loss: 0.537003219127655
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5548117756843567
  Validation Loss: 0.5369836091995239
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5575548708438873
  Validation Loss: 0.5369439721107483
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5657929182052612
  Validation Loss: 0.5369189977645874
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5670545995235443
  Validation Loss: 0.5369147658348083
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5642327666282654
  Validation Loss: 0.5369189381599426
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5624612867832184
  Validation Loss: 0.5369042754173279
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5605480074882507
  Validation Loss: 0.5368877053260803
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5506541281938553
  Validation Loss: 0.5368536114692688
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.557134360074997
  Validation Loss: 0.5368239283561707
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.557334840297699
  Validation Loss: 0.5367575287818909
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5605113506317139
  Validation Loss: 0.5366925001144409
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5683174133300781
  Validation Loss: 0.5366517305374146
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5588698387145996
  Validation Loss: 0.5366096496582031
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5638926923274994
  Validation Loss: 0.5365571975708008
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5597505867481232
  Validation Loss: 0.536524772644043
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5612742900848389
  Validation Loss: 0.5364862680435181
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5516459047794342
  Validation Loss: 0.5364457964897156
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.558951735496521
  Validation Loss: 0.5364047288894653
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5502325296401978
  Validation Loss: 0.536359429359436
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5526055097579956
  Validation Loss: 0.5363052487373352
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.56021848320961
  Validation Loss: 0.5362607836723328
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5559393763542175
  Validation Loss: 0.536221981048584
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5594409704208374
  Validation Loss: 0.5361549854278564
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5564675629138947
  Validation Loss: 0.536078929901123
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5539003312587738
  Validation Loss: 0.5360013246536255
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5576663613319397
  Validation Loss: 0.5359457731246948
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5518051981925964
  Validation Loss: 0.535892128944397
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5554372072219849
  Validation Loss: 0.5358278155326843
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5553748607635498
  Validation Loss: 0.5357864499092102
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5561763644218445
  Validation Loss: 0.5357447862625122
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5576640665531158
  Validation Loss: 0.53569096326828
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5593403279781342
  Validation Loss: 0.5356304049491882
  Val ROC-AUC: 0.4166666666666667
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5593403279781342, 'val_roc_auc': 0.4166666666666667, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5356304049491882}
 ROC_AUC: 0.4167|| Accuracy 0.5385 || Train Loss: 0.5593
 Val Loss: 0.5356 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.577774523364173
Test ROC-AUC: 0.6771428571428572
Test Accuracy: 0.5777777777777777
test_loss: 0.577774523364173
test_roc_auc: 0.6771428571428572
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.22009528458966088
Epoch 1/64:
  Train Loss: 0.5779010355472565
  Validation Loss: 0.5025739073753357
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.565584659576416
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.502372682094574
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5798086822032928
  Validation Loss: 0.5021761059761047
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.567950427532196
  Validation Loss: 0.5020367503166199
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.5771780908107758
  Validation Loss: 0.5018746256828308
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.5692976117134094
  Validation Loss: 0.5017479658126831
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5776503384113312
  Validation Loss: 0.501618504524231
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5719172358512878
  Validation Loss: 0.5014902353286743
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.57921302318573
  Validation Loss: 0.5013591051101685
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.5658212006092072
  Validation Loss: 0.5012378096580505
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.577743411064148
  Validation Loss: 0.5011313557624817
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5742756724357605
  Validation Loss: 0.5010268092155457
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5756496787071228
  Validation Loss: 0.5009085536003113
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5759840309619904
  Validation Loss: 0.5007957220077515
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 15/64:
  Train Loss: 0.5747552812099457
  Validation Loss: 0.5006780028343201
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 16/64:
  Train Loss: 0.5842710137367249
  Validation Loss: 0.5005642771720886
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 17/64:
  Train Loss: 0.5705269575119019
  Validation Loss: 0.500455379486084
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 18/64:
  Train Loss: 0.5602997541427612
  Validation Loss: 0.5003354549407959
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 19/64:
  Train Loss: 0.5695007741451263
  Validation Loss: 0.5002118945121765
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 20/64:
  Train Loss: 0.574535071849823
  Validation Loss: 0.5000928044319153
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 21/64:
  Train Loss: 0.5642736852169037
  Validation Loss: 0.4999699294567108
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 22/64:
  Train Loss: 0.5727273523807526
  Validation Loss: 0.4998270869255066
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 23/64:
  Train Loss: 0.5702458918094635
  Validation Loss: 0.49968549609184265
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 24/64:
  Train Loss: 0.5695514380931854
  Validation Loss: 0.4995434582233429
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 25/64:
  Train Loss: 0.5751620233058929
  Validation Loss: 0.4993800222873688
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 26/64:
  Train Loss: 0.568292111158371
  Validation Loss: 0.4992155134677887
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 27/64:
  Train Loss: 0.5757774412631989
  Validation Loss: 0.49906086921691895
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 28/64:
  Train Loss: 0.5733800530433655
  Validation Loss: 0.4988988935947418
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 29/64:
  Train Loss: 0.5700812935829163
  Validation Loss: 0.49874037504196167
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 30/64:
  Train Loss: 0.5719391405582428
  Validation Loss: 0.49858608841896057
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 31/64:
  Train Loss: 0.5724479854106903
  Validation Loss: 0.4984424412250519
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 32/64:
  Train Loss: 0.5674972832202911
  Validation Loss: 0.49830710887908936
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 33/64:
  Train Loss: 0.5720483958721161
  Validation Loss: 0.4981812834739685
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 34/64:
  Train Loss: 0.5740147233009338
  Validation Loss: 0.49804314970970154
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 35/64:
  Train Loss: 0.5696008801460266
  Validation Loss: 0.4979187846183777
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 36/64:
  Train Loss: 0.577486127614975
  Validation Loss: 0.4977891147136688
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 37/64:
  Train Loss: 0.5702157318592072
  Validation Loss: 0.49765071272850037
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 38/64:
  Train Loss: 0.5752635300159454
  Validation Loss: 0.4974939227104187
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 39/64:
  Train Loss: 0.5749985575675964
  Validation Loss: 0.4973498582839966
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 40/64:
  Train Loss: 0.570903867483139
  Validation Loss: 0.49721506237983704
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5645130574703217
  Validation Loss: 0.4970667064189911
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.5741018056869507
  Validation Loss: 0.49691861867904663
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.5682686567306519
  Validation Loss: 0.49680718779563904
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5612932443618774
  Validation Loss: 0.4966909885406494
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5718628168106079
  Validation Loss: 0.4965687096118927
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5688637793064117
  Validation Loss: 0.49646443128585815
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5718478858470917
  Validation Loss: 0.49635785818099976
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5771249830722809
  Validation Loss: 0.49624115228652954
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.569974809885025
  Validation Loss: 0.49614593386650085
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5760577619075775
  Validation Loss: 0.49603646993637085
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5641587376594543
  Validation Loss: 0.49591773748397827
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5598111152648926
  Validation Loss: 0.4958037734031677
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.571392148733139
  Validation Loss: 0.4956676959991455
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5645288228988647
  Validation Loss: 0.4955645203590393
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5694322884082794
  Validation Loss: 0.49545782804489136
  Val ROC-AUC: 0.6666666666666666
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:26:INFO:
[92mINFO [0m:      Received: evaluate message 6ab89f32-226c-4a10-816c-e74116538a95
02/07/2025 22:49:26:INFO:Received: evaluate message 6ab89f32-226c-4a10-816c-e74116538a95
[92mINFO [0m:      Sent reply
02/07/2025 22:49:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:28:INFO:
[92mINFO [0m:      Received: train message 10e4b30a-5f69-4f1f-a92c-1d30788b1a82
02/07/2025 22:49:28:INFO:Received: train message 10e4b30a-5f69-4f1f-a92c-1d30788b1a82
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5712679028511047
  Validation Loss: 0.4953412413597107
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.569504976272583
  Validation Loss: 0.4952412545681
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5736441910266876
  Validation Loss: 0.49513766169548035
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.566615879535675
  Validation Loss: 0.49502062797546387
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5677763521671295
  Validation Loss: 0.4949130117893219
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5617026686668396
  Validation Loss: 0.49478504061698914
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5666148066520691
  Validation Loss: 0.49466046690940857
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5696619749069214
  Validation Loss: 0.4945339858531952
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5697117447853088
  Validation Loss: 0.4944092929363251
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5697117447853088, 'val_roc_auc': 0.6666666666666666, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.4944092929363251}
 ROC_AUC: 0.6667|| Accuracy 0.6154 || Train Loss: 0.5697
 Val Loss: 0.4944 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5774837758806016
Test ROC-AUC: 0.6771428571428572
Test Accuracy: 0.5777777777777777
test_loss: 0.5774837758806016
test_roc_auc: 0.6771428571428572
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.22690256457735813
Epoch 1/64:
  Train Loss: 0.5440639555454254
  Validation Loss: 0.6190566420555115
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5363534837961197
  Validation Loss: 0.6191583871841431
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5442545711994171
  Validation Loss: 0.6192373633384705
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5485715270042419
  Validation Loss: 0.6192559599876404
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5443446338176727
  Validation Loss: 0.6192606687545776
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5382159203290939
  Validation Loss: 0.6192797422409058
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5418005287647247
  Validation Loss: 0.6192839741706848
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5426395535469055
  Validation Loss: 0.6192963123321533
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5425120890140533
  Validation Loss: 0.6193310022354126
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5503937005996704
  Validation Loss: 0.619355320930481
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5411153137683868
  Validation Loss: 0.6193832755088806
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5430916547775269
  Validation Loss: 0.6194018721580505
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5398547649383545
  Validation Loss: 0.6194227337837219
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5405353903770447
  Validation Loss: 0.61944979429245
  Val ROC-AUC: 0.6666666666666667
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5483364164829254
  Validation Loss: 0.6194841265678406
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5404279828071594
  Validation Loss: 0.6195201873779297
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5460458695888519
  Validation Loss: 0.6195545196533203
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5434975624084473
  Validation Loss: 0.6195818781852722
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5400755405426025
  Validation Loss: 0.61961430311203
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5467429459095001
  Validation Loss: 0.6196581721305847
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5380833148956299
  Validation Loss: 0.6196891069412231
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5400489866733551
  Validation Loss: 0.6196940541267395
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5434465110301971
  Validation Loss: 0.6197299957275391
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5452421307563782
  Validation Loss: 0.6197593808174133
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5447568893432617
  Validation Loss: 0.6197618842124939
  Val ROC-AUC: 0.6388888888888888
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5407491624355316
  Validation Loss: 0.6197871565818787
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5342168509960175
  Validation Loss: 0.6197981238365173
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5459438264369965
  Validation Loss: 0.6198347806930542
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5459223985671997
  Validation Loss: 0.6198770403862
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5390869081020355
  Validation Loss: 0.6199094653129578
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5459405481815338
  Validation Loss: 0.6199585795402527
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5393745005130768
  Validation Loss: 0.6200329661369324
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5464645624160767
  Validation Loss: 0.6201062202453613
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5443377196788788
  Validation Loss: 0.6201466917991638
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5490700900554657
  Validation Loss: 0.6201783418655396
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5400454699993134
  Validation Loss: 0.6202096343040466
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5440939366817474
  Validation Loss: 0.6202602386474609
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5372384190559387
  Validation Loss: 0.6202907562255859
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.543909877538681
  Validation Loss: 0.6203272938728333
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.542456716299057
  Validation Loss: 0.6203640103340149
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5429325997829437
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:49:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:57:INFO:
[92mINFO [0m:      Received: evaluate message ca16e85b-c0a5-42df-8122-a4fd72541cc3
02/07/2025 22:49:57:INFO:Received: evaluate message ca16e85b-c0a5-42df-8122-a4fd72541cc3
[92mINFO [0m:      Sent reply
02/07/2025 22:49:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:49:58:INFO:
[92mINFO [0m:      Received: train message 62c26f1e-f250-4738-94fb-7482942f6606
02/07/2025 22:49:58:INFO:Received: train message 62c26f1e-f250-4738-94fb-7482942f6606
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.62040776014328
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.5368448495864868
  Validation Loss: 0.6204595565795898
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.5475597083568573
  Validation Loss: 0.6204765439033508
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5317464470863342
  Validation Loss: 0.6205090880393982
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.537318229675293
  Validation Loss: 0.6205114722251892
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5456138551235199
  Validation Loss: 0.6205345988273621
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5338733196258545
  Validation Loss: 0.6205422282218933
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5357324481010437
  Validation Loss: 0.6205763220787048
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.536100447177887
  Validation Loss: 0.6206181049346924
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5392771661281586
  Validation Loss: 0.6206523776054382
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5435729026794434
  Validation Loss: 0.6206795573234558
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5364035069942474
  Validation Loss: 0.6207067966461182
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5386468470096588
  Validation Loss: 0.6207776665687561
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5343194007873535
  Validation Loss: 0.620849072933197
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5376516580581665
  Validation Loss: 0.6209129691123962
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5427452325820923
  Validation Loss: 0.6209675073623657
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5317462533712387
  Validation Loss: 0.6210456490516663
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5283283442258835
  Validation Loss: 0.6211282014846802
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.5380438566207886
  Validation Loss: 0.6212010383605957
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5412003695964813
  Validation Loss: 0.6212629675865173
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5374208390712738
  Validation Loss: 0.6213153004646301
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5360749661922455
  Validation Loss: 0.6213713884353638
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5398419201374054
  Validation Loss: 0.6214299201965332
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5393551290035248
  Validation Loss: 0.6214772462844849
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5393551290035248, 'val_roc_auc': 0.638888888888889, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.6214772462844849}
 ROC_AUC: 0.6389|| Accuracy 0.6154 || Train Loss: 0.5394
 Val Loss: 0.6215 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.577226271894243
Test ROC-AUC: 0.6742857142857143
Test Accuracy: 0.5555555555555556
test_loss: 0.577226271894243
test_roc_auc: 0.6742857142857143
test_accuracy: 0.5555555555555556
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.14205565491920424
Epoch 1/64:
  Train Loss: 0.5665234625339508
  Validation Loss: 0.5234324932098389
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5685550272464752
  Validation Loss: 0.5233777165412903
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5626189410686493
  Validation Loss: 0.5233312845230103
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.5714817047119141
  Validation Loss: 0.5232860445976257
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.5602171123027802
  Validation Loss: 0.5232367515563965
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.5691094100475311
  Validation Loss: 0.5231953859329224
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5725573897361755
  Validation Loss: 0.5231612920761108
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5612286329269409
  Validation Loss: 0.5231367349624634
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.5739852786064148
  Validation Loss: 0.5230934023857117
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.569566398859024
  Validation Loss: 0.523057758808136
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.5671027600765228
  Validation Loss: 0.5230233669281006
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5656707584857941
  Validation Loss: 0.5229920744895935
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5635806620121002
  Validation Loss: 0.5229595899581909
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5627410411834717
  Validation Loss: 0.5229339599609375
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5692459344863892
  Validation Loss: 0.5228938460350037
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5646617412567139
  Validation Loss: 0.5228633880615234
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5682240128517151
  Validation Loss: 0.5228185653686523
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.563740074634552
  Validation Loss: 0.5227845907211304
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5716805160045624
  Validation Loss: 0.522743821144104
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5639117956161499
  Validation Loss: 0.5227011442184448
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5696347951889038
  Validation Loss: 0.5226656198501587
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5629882216453552
  Validation Loss: 0.5226276516914368
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5635341703891754
  Validation Loss: 0.5225890874862671
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5575053095817566
  Validation Loss: 0.522549033164978
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5620793402194977
  Validation Loss: 0.5225120782852173
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5690208971500397
  Validation Loss: 0.5224822163581848
  Val ROC-AUC: 0.3333333333333333
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:22:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:25:INFO:
[92mINFO [0m:      Received: evaluate message cb27c64b-0b54-4368-ac81-b17ee0607de9
02/07/2025 22:50:25:INFO:Received: evaluate message cb27c64b-0b54-4368-ac81-b17ee0607de9
[92mINFO [0m:      Sent reply
02/07/2025 22:50:26:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:27:INFO:
[92mINFO [0m:      Received: train message 1d939aca-a36f-486a-abbd-62be97deb6d1
02/07/2025 22:50:27:INFO:Received: train message 1d939aca-a36f-486a-abbd-62be97deb6d1
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5611221790313721
  Validation Loss: 0.5224406123161316
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5636612772941589
  Validation Loss: 0.5223836898803711
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5685152411460876
  Validation Loss: 0.5223279595375061
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5663318336009979
  Validation Loss: 0.5222682952880859
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5658914148807526
  Validation Loss: 0.5222175717353821
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5596383810043335
  Validation Loss: 0.5221735239028931
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5609107315540314
  Validation Loss: 0.5221177935600281
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5665935575962067
  Validation Loss: 0.5220755338668823
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5569234192371368
  Validation Loss: 0.5220353007316589
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5586738884449005
  Validation Loss: 0.5219933390617371
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5688547194004059
  Validation Loss: 0.521949291229248
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5664785802364349
  Validation Loss: 0.5219065546989441
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5625061392784119
  Validation Loss: 0.5218706130981445
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5597562193870544
  Validation Loss: 0.5218304991722107
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5560366213321686
  Validation Loss: 0.5217882394790649
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5698985159397125
  Validation Loss: 0.5217374563217163
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5577147603034973
  Validation Loss: 0.5217020511627197
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.566790759563446
  Validation Loss: 0.521658718585968
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5647160410881042
  Validation Loss: 0.5216070413589478
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5586143732070923
  Validation Loss: 0.5215626955032349
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5585657358169556
  Validation Loss: 0.5215161442756653
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5592634081840515
  Validation Loss: 0.5214754343032837
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5647798776626587
  Validation Loss: 0.5214247703552246
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5546486675739288
  Validation Loss: 0.5213748216629028
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5612487494945526
  Validation Loss: 0.5213190317153931
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5659235119819641
  Validation Loss: 0.5212731957435608
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5513345152139664
  Validation Loss: 0.5212278366088867
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5617682337760925
  Validation Loss: 0.5211745500564575
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5550413429737091
  Validation Loss: 0.5211232900619507
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5647075772285461
  Validation Loss: 0.5210757851600647
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5545494854450226
  Validation Loss: 0.5210251808166504
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5646903216838837
  Validation Loss: 0.5209811329841614
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5573555529117584
  Validation Loss: 0.5209266543388367
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.550085186958313
  Validation Loss: 0.5208697319030762
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5607984364032745
  Validation Loss: 0.520815908908844
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5589563250541687
  Validation Loss: 0.5207718014717102
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5582237839698792
  Validation Loss: 0.5207265019416809
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5582950413227081
  Validation Loss: 0.5206813812255859
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5582950413227081, 'val_roc_auc': 0.3333333333333333, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5206813812255859}
 ROC_AUC: 0.3333|| Accuracy 0.5385 || Train Loss: 0.5583
 Val Loss: 0.5207 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5769665751192304
Test ROC-AUC: 0.68
Test Accuracy: 0.5555555555555556
test_loss: 0.5769665751192304
test_roc_auc: 0.68
test_accuracy: 0.5555555555555556
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.17681885702813815
Epoch 1/64:
  Train Loss: 0.5561742186546326
  Validation Loss: 0.5839244723320007
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 2/64:
  Train Loss: 0.5528805255889893
  Validation Loss: 0.5840514898300171
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 3/64:
  Train Loss: 0.5606887638568878
  Validation Loss: 0.5841101408004761
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 4/64:
  Train Loss: 0.5548348426818848
  Validation Loss: 0.584145724773407
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 5/64:
  Train Loss: 0.558141827583313
  Validation Loss: 0.5842273831367493
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 6/64:
  Train Loss: 0.5540295839309692
  Validation Loss: 0.5843034982681274
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 7/64:
  Train Loss: 0.5490573048591614
  Validation Loss: 0.5843510031700134
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 8/64:
  Train Loss: 0.5516964197158813
  Validation Loss: 0.584392249584198
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 9/64:
  Train Loss: 0.5517562627792358
  Validation Loss: 0.5844528675079346
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 10/64:
  Train Loss: 0.5415874719619751
  Validation Loss: 0.5844870209693909
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 11/64:
  Train Loss: 0.543110266327858
  Validation Loss: 0.5845339298248291
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 12/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.5557136237621307
  Validation Loss: 0.5845799446105957
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 13/64:
  Train Loss: 0.5533947050571442
  Validation Loss: 0.5846351981163025
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 14/64:
  Train Loss: 0.5432662665843964
  Validation Loss: 0.5846838355064392
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 15/64:
  Train Loss: 0.5623620450496674
  Validation Loss: 0.5847445726394653
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 16/64:
  Train Loss: 0.5471523702144623
  Validation Loss: 0.5847975611686707
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 17/64:
  Train Loss: 0.5472025275230408
  Validation Loss: 0.5848302841186523
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 18/64:
  Train Loss: 0.5478281378746033
  Validation Loss: 0.5848658084869385
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 19/64:
  Train Loss: 0.5650586038827896
  Validation Loss: 0.5848946571350098
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 20/64:
  Train Loss: 0.5548906624317169
  Validation Loss: 0.5849169492721558
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 21/64:
  Train Loss: 0.5519795715808868
  Validation Loss: 0.5849548578262329
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 22/64:
  Train Loss: 0.5520803332328796
  Validation Loss: 0.584994375705719
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 23/64:
  Train Loss: 0.5542581379413605
  Validation Loss: 0.5850474834442139
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 24/64:
  Train Loss: 0.5431610345840454
  Validation Loss: 0.5850948691368103
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 25/64:
  Train Loss: 0.554182380437851
  Validation Loss: 0.5851411819458008
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 26/64:
  Train Loss: 0.5554750263690948
  Validation Loss: 0.5851849317550659
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 27/64:
  Train Loss: 0.5573214590549469
  Validation Loss: 0.5852236151695251
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 28/64:
  Train Loss: 0.5498518645763397
  Validation Loss: 0.5852856636047363
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 29/64:
  Train Loss: 0.5431032180786133
  Validation Loss: 0.5853347182273865
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.23076924681663513
Epoch 30/64:
  Train Loss: 0.5531006157398224
  Validation Loss: 0.5853702425956726
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 31/64:
  Train Loss: 0.5389189124107361
  Validation Loss: 0.5854076147079468
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 32/64:
  Train Loss: 0.5502991378307343
  Validation Loss: 0.5854566693305969
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 33/64:
  Train Loss: 0.5455800294876099
  Validation Loss: 0.5855035185813904
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 34/64:
  Train Loss: 0.5526892840862274
  Validation Loss: 0.5855616927146912
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 35/64:
  Train Loss: 0.5556789636611938
  Validation Loss: 0.5855976939201355
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 36/64:
  Train Loss: 0.5406552851200104
  Validation Loss: 0.5856155753135681
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 37/64:
  Train Loss: 0.5450450778007507
  Validation Loss: 0.5856280326843262
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 38/64:
  Train Loss: 0.5478667616844177
  Validation Loss: 0.5856446623802185
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 39/64:
  Train Loss: 0.5447624325752258
  Validation Loss: 0.585681676864624
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.23076924681663513
Epoch 40/64:
  Train Loss: 0.5502873957157135
  Validation Loss: 0.585719108581543
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 41/64:
  Train Loss: 0.5479260981082916
  Validation Loss: 0.5857601165771484
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 42/64:
  Train Loss: 0.5536277890205383
  Validation Loss: 0.5857831835746765
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 43/64:
  Train Loss: 0.5463754236698151
  Validation Loss: 0.5858162641525269
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 44/64:
  Train Loss: 0.5480346381664276
  Validation Loss: 0.5858464241027832
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 45/64:
  Train Loss: 0.5480614900588989
  Validation Loss: 0.5858831405639648
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 46/64:
  Train Loss: 0.5435788333415985
  Validation Loss: 0.5859150290489197
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 47/64:
  Train Loss: 0.5483105778694153
  Validation Loss: 0.585963249206543
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 48/64:
  Train Loss: 0.535939946770668
  Validation Loss: 0.5860106945037842
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 49/64:
  Train Loss: 0.5507088303565979
  Validation Loss: 0.5860655307769775
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 50/64:
  Train Loss: 0.5472592115402222
  Validation Loss: 0.5861000418663025
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 51/64:
  Train Loss: 0.5454884469509125
  Validation Loss: 0.5861245393753052
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 52/64:
  Train Loss: 0.5430499613285065
  Validation Loss: 0.5861418843269348
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 53/64:
  Train Loss: 0.5411896705627441
  Validation Loss: 0.5861569046974182
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 54/64:
  Train Loss: 0.5483208000659943
  Validation Loss: 0.5861803889274597
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 55/64:
  Train Loss: 0.5425330102443695
  Validation Loss: 0.5861898064613342
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 56/64:
  Train Loss: 0.5441087484359741
  Validation Loss: 0.5862246751785278
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 57/64:
  Train Loss: 0.5500501394271851
  Validation Loss: 0.5862511396408081
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 58/64:
  Train Loss: 0.5459886789321899
  Validation Loss: 0.5862683653831482
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 59/64:
  Train Loss: 0.5375532060861588
  Validation Loss: 0.5862737894058228
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 60/64:
  Train Loss: 0.5481217801570892
  Validation Loss: 0.5862760543823242
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 61/64:
  Train Loss: 0.5426408648490906
  Validation Loss: 0.5862770080566406
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 62/64:
  Train Loss: 0.5467235147953033
  Validation Loss: 0.5862874388694763
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 63/64:
  Train Loss: 0.5449577271938324
  Validation Loss: 0.5862998366355896
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
Epoch 64/64:
  Train Loss: 0.5402137339115143
  Validation Loss: 0.5863056182861328
  Val ROC-AUC: 0.36363636363636365
  Val Accuracy: 0.3076923191547394
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:50:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:56:INFO:
[92mINFO [0m:      Received: evaluate message 19444c6f-c001-4f9b-8030-bf04e58bee4f
02/07/2025 22:50:56:INFO:Received: evaluate message 19444c6f-c001-4f9b-8030-bf04e58bee4f
[92mINFO [0m:      Sent reply
02/07/2025 22:50:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:50:59:INFO:
[92mINFO [0m:      Received: train message c5c2c3d6-0c85-470e-b7b1-ff79c546f1d9
02/07/2025 22:50:59:INFO:Received: train message c5c2c3d6-0c85-470e-b7b1-ff79c546f1d9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
{'train_loss': 0.5402137339115143, 'val_roc_auc': 0.36363636363636365, 'val_accuracy': 0.3076923191547394, 'val_loss': 0.5863056182861328}
 ROC_AUC: 0.3636|| Accuracy 0.3077 || Train Loss: 0.5402
 Val Loss: 0.5863 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5766190237469143
Test ROC-AUC: 0.6971428571428572
Test Accuracy: 0.5777777777777777
test_loss: 0.5766190237469143
test_roc_auc: 0.6971428571428572
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.1270477933417169
Epoch 1/64:
  Train Loss: 0.5497449338436127
  Validation Loss: 0.5871217846870422
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 2/64:
  Train Loss: 0.5602377951145172
  Validation Loss: 0.5872251391410828
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 3/64:
  Train Loss: 0.5438506007194519
  Validation Loss: 0.5873720049858093
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 4/64:
  Train Loss: 0.5604775846004486
  Validation Loss: 0.5874801874160767
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 5/64:
  Train Loss: 0.5501006543636322
  Validation Loss: 0.5875945687294006
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 6/64:
  Train Loss: 0.5496556758880615
  Validation Loss: 0.5877160429954529
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 7/64:
  Train Loss: 0.5493525266647339
  Validation Loss: 0.5878452658653259
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 8/64:
  Train Loss: 0.5528961420059204
  Validation Loss: 0.5879713296890259
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 9/64:
  Train Loss: 0.5463212132453918
  Validation Loss: 0.5881003737449646
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 10/64:
  Train Loss: 0.555194228887558
  Validation Loss: 0.5882256627082825
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 11/64:
  Train Loss: 0.5575677156448364
  Validation Loss: 0.5883650183677673
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 12/64:
  Train Loss: 0.553828090429306
  Validation Loss: 0.5885128378868103
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8461538553237915
Epoch 13/64:
  Train Loss: 0.5542811155319214
  Validation Loss: 0.5886516571044922
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 14/64:
  Train Loss: 0.5399379134178162
  Validation Loss: 0.5887935757637024
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 15/64:
  Train Loss: 0.5496585965156555
  Validation Loss: 0.5889248251914978
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 16/64:
  Train Loss: 0.5473983287811279
  Validation Loss: 0.5890783667564392
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 17/64:
  Train Loss: 0.5494602918624878
  Validation Loss: 0.5892201662063599
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 18/64:
  Train Loss: 0.5489989817142487
  Validation Loss: 0.5893659591674805
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 19/64:
  Train Loss: 0.5472067892551422
  Validation Loss: 0.589500904083252
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 20/64:
  Train Loss: 0.5469596087932587
  Validation Loss: 0.5896233320236206
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 21/64:
  Train Loss: 0.5477766990661621
  Validation Loss: 0.5897392630577087
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 22/64:
  Train Loss: 0.5536680221557617
  Validation Loss: 0.589842677116394
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 23/64:
  Train Loss: 0.555794894695282
  Validation Loss: 0.5899446606636047
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 24/64:
  Train Loss: 0.5483911335468292
  Validation Loss: 0.5900468826293945
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 25/64:
  Train Loss: 0.545767605304718
  Validation Loss: 0.5901673436164856
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 26/64:
  Train Loss: 0.5437445044517517
  Validation Loss: 0.5903099179267883
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 27/64:
  Train Loss: 0.545159250497818
  Validation Loss: 0.5904480814933777
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 28/64:
  Train Loss: 0.5514118075370789
  Validation Loss: 0.5905715227127075
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 29/64:
  Train Loss: 0.5449509024620056
  Validation Loss: 0.5907047390937805
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 30/64:
  Train Loss: 0.5507057905197144
  Validation Loss: 0.5908137559890747
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 31/64:
  Train Loss: 0.5553916394710541
  Validation Loss: 0.5909181833267212
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 32/64:
  Train Loss: 0.5487438142299652
  Validation Loss: 0.591038167476654
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 33/64:
  Train Loss: 0.5487729609012604
  Validation Loss: 0.5911512970924377
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 34/64:
  Train Loss: 0.551369309425354
  Validation Loss: 0.5912910103797913
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 35/64:
  Train Loss: 0.545377790927887
  Validation Loss: 0.5914286971092224
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 36/64:
  Train Loss: 0.5462927520275116
  Validation Loss: 0.5915317535400391
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 37/64:
  Train Loss: 0.5534303188323975
  Validation Loss: 0.5916491746902466
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 38/64:
  Train Loss: 0.5513386428356171
  Validation Loss: 0.59178227186203
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 39/64:
  Train Loss: 0.5434732139110565
  Validation Loss: 0.5919228792190552
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 40/64:
  Train Loss: 0.5495934188365936
  Validation Loss: 0.5920364260673523
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 41/64:
  Train Loss: 0.5557386875152588
  Validation Loss: 0.5921443104743958
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 42/64:
  Train Loss: 0.5482760667800903
  Validation Loss: 0.5922667384147644
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 43/64:
  Train Loss: 0.5385025292634964
  Validation Loss: 0.5923788547515869
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 44/64:
  Train Loss: 0.5422937572002411
  Validation Loss: 0.5924850106239319
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 45/64:
  Train Loss: 0.538845032453537
  Validation Loss: 0.592574417591095
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 46/64:
  Train Loss: 0.5409841537475586
  Validation Loss: 0.5926613211631775
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 47/64:
  Train Loss: 0.5447589159011841
  Validation Loss: 0.5927492380142212
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 48/64:
  Train Loss: 0.5456766486167908
  Validation Loss: 0.5928340554237366
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 49/64:
  Train Loss: 0.5471661686897278
  Validation Loss: 0.5929120182991028
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 50/64:
  Train Loss: 0.5483571588993073
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:51:25:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:31:INFO:
[92mINFO [0m:      Received: evaluate message 3aa8a4f0-3622-4ccb-a8ca-562f30e5fcdd
02/07/2025 22:51:31:INFO:Received: evaluate message 3aa8a4f0-3622-4ccb-a8ca-562f30e5fcdd
[92mINFO [0m:      Sent reply
02/07/2025 22:51:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:51:34:INFO:
[92mINFO [0m:      Received: train message cd0f8b8d-7b94-45dd-aa78-18b01ef77d5e
02/07/2025 22:51:34:INFO:Received: train message cd0f8b8d-7b94-45dd-aa78-18b01ef77d5e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5930169224739075
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 51/64:
  Train Loss: 0.5532963871955872
  Validation Loss: 0.5930981040000916
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 52/64:
  Train Loss: 0.5485713481903076
  Validation Loss: 0.5931891202926636
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.8461538553237915
Epoch 53/64:
  Train Loss: 0.5489687025547028
  Validation Loss: 0.5932848453521729
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 54/64:
  Train Loss: 0.5444809198379517
  Validation Loss: 0.5933696627616882
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 55/64:
  Train Loss: 0.5511170327663422
  Validation Loss: 0.5934689044952393
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 56/64:
  Train Loss: 0.5524778962135315
  Validation Loss: 0.5935624837875366
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 57/64:
  Train Loss: 0.5469397306442261
  Validation Loss: 0.5936708450317383
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 58/64:
  Train Loss: 0.5431933999061584
  Validation Loss: 0.5937762260437012
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 59/64:
  Train Loss: 0.5492534041404724
  Validation Loss: 0.5939032435417175
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 60/64:
  Train Loss: 0.5405332446098328
  Validation Loss: 0.5940303802490234
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 61/64:
  Train Loss: 0.539717048406601
  Validation Loss: 0.5941572189331055
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 62/64:
  Train Loss: 0.5401463508605957
  Validation Loss: 0.5942978858947754
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 63/64:
  Train Loss: 0.5470920205116272
  Validation Loss: 0.5944188237190247
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
Epoch 64/64:
  Train Loss: 0.5482406318187714
  Validation Loss: 0.5945419669151306
  Val ROC-AUC: 0.8055555555555556
  Val Accuracy: 0.8461538553237915
{'train_loss': 0.5482406318187714, 'val_roc_auc': 0.8055555555555556, 'val_accuracy': 0.8461538553237915, 'val_loss': 0.5945419669151306}
 ROC_AUC: 0.8056|| Accuracy 0.8462 || Train Loss: 0.5482
 Val Loss: 0.5945 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5763058265050253
Test ROC-AUC: 0.7085714285714286
Test Accuracy: 0.5111111111111111
test_loss: 0.5763058265050253
test_roc_auc: 0.7085714285714286
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.2235661997929128
Epoch 1/64:
  Train Loss: 0.559108555316925
  Validation Loss: 0.5653565526008606
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.554330974817276
  Validation Loss: 0.5653887987136841
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5559603571891785
  Validation Loss: 0.5654239058494568
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5571613013744354
  Validation Loss: 0.5654603242874146
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5555892288684845
  Validation Loss: 0.5654945969581604
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5477635115385056
  Validation Loss: 0.5655309557914734
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.562703400850296
  Validation Loss: 0.5655645728111267
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5575549006462097
  Validation Loss: 0.5656060576438904
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5597656667232513
  Validation Loss: 0.5656474232673645
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5547570288181305
  Validation Loss: 0.5656812787055969
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5516436994075775
  Validation Loss: 0.5657129883766174
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5518819391727448
  Validation Loss: 0.5657444000244141
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5614540576934814
  Validation Loss: 0.5657786130905151
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.552888810634613
  Validation Loss: 0.5658102035522461
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5585864186286926
  Validation Loss: 0.5658336877822876
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5518818497657776
  Validation Loss: 0.5658549070358276
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 17/64:
  Train Loss: 0.5489676892757416
  Validation Loss: 0.5658683180809021
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 18/64:
  Train Loss: 0.5476422011852264
  Validation Loss: 0.5658796429634094
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 19/64:
  Train Loss: 0.5502108335494995
  Validation Loss: 0.5658884644508362
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 20/64:
  Train Loss: 0.5572077631950378
  Validation Loss: 0.5658910870552063
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 21/64:
  Train Loss: 0.5521001219749451
  Validation Loss: 0.5658993721008301
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 22/64:
  Train Loss: 0.5547828376293182
  Validation Loss: 0.565920889377594
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 23/64:
  Train Loss: 0.5547061562538147
  Validation Loss: 0.5659480094909668
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 24/64:
  Train Loss: 0.5561025142669678
  Validation Loss: 0.5659740567207336
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 25/64:
  Train Loss: 0.5577439963817596
  Validation Loss: 0.5659962892532349
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 26/64:
  Train Loss: 0.5496884286403656
  Validation Loss: 0.5660110712051392
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 27/64:
  Train Loss: 0.549119770526886
  Validation Loss: 0.5660171508789062
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 28/64:
  Train Loss: 0.549974262714386
  Validation Loss: 0.5660187602043152
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 29/64:
  Train Loss: 0.5600215196609497
  Validation Loss: 0.5660250782966614
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 30/64:
  Train Loss: 0.5550262629985809
  Validation Loss: 0.5660396218299866
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 31/64:
  Train Loss: 0.5517996847629547
  Validation Loss: 0.5660557746887207
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 32/64:
  Train Loss: 0.5565765500068665
  Validation Loss: 0.5660640001296997
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 33/64:
  Train Loss: 0.5545384287834167
  Validation Loss: 0.5660671591758728
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 34/64:
  Train Loss: 0.5525799691677094
  Validation Loss: 0.5660733580589294
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 35/64:
  Train Loss: 0.5575868487358093
  Validation Loss: 0.5660755038261414
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 36/64:
  Train Loss: 0.5578900873661041
  Validation Loss: 0.5660824775695801
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 37/64:
  Train Loss: 0.5485534071922302
  Validation Loss: 0.5660822987556458
  Val ROC-AUC: 0.5
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:04:INFO:
[92mINFO [0m:      Received: evaluate message 31018fe4-5c69-4d72-ac2e-cea2d87f23f7
02/07/2025 22:52:04:INFO:Received: evaluate message 31018fe4-5c69-4d72-ac2e-cea2d87f23f7
[92mINFO [0m:      Sent reply
02/07/2025 22:52:05:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:06:INFO:
[92mINFO [0m:      Received: train message 8240c4ed-9790-4619-ba8e-ad7bf0233b89
02/07/2025 22:52:06:INFO:Received: train message 8240c4ed-9790-4619-ba8e-ad7bf0233b89
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.46153849363327026
Epoch 38/64:
  Train Loss: 0.5485722124576569
  Validation Loss: 0.5660761594772339
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 39/64:
  Train Loss: 0.5478379726409912
  Validation Loss: 0.5660921335220337
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 40/64:
  Train Loss: 0.5481949746608734
  Validation Loss: 0.5660998225212097
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 41/64:
  Train Loss: 0.5478546023368835
  Validation Loss: 0.5661081075668335
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 42/64:
  Train Loss: 0.5558638572692871
  Validation Loss: 0.5661177635192871
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 43/64:
  Train Loss: 0.5524089932441711
  Validation Loss: 0.5661210417747498
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 44/64:
  Train Loss: 0.5522340536117554
  Validation Loss: 0.5661320090293884
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 45/64:
  Train Loss: 0.5531139373779297
  Validation Loss: 0.5661435127258301
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 46/64:
  Train Loss: 0.5530456304550171
  Validation Loss: 0.5661558508872986
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 47/64:
  Train Loss: 0.5518563389778137
  Validation Loss: 0.5661702752113342
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 48/64:
  Train Loss: 0.5416152030229568
  Validation Loss: 0.5661913156509399
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 49/64:
  Train Loss: 0.5471571087837219
  Validation Loss: 0.566215455532074
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 50/64:
  Train Loss: 0.5507687330245972
  Validation Loss: 0.5662313103675842
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 51/64:
  Train Loss: 0.5455913841724396
  Validation Loss: 0.5662484169006348
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 52/64:
  Train Loss: 0.5482178330421448
  Validation Loss: 0.5662705302238464
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 53/64:
  Train Loss: 0.5464940965175629
  Validation Loss: 0.5662949681282043
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 54/64:
  Train Loss: 0.5512498021125793
  Validation Loss: 0.5663200616836548
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 55/64:
  Train Loss: 0.5489524602890015
  Validation Loss: 0.5663467645645142
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 56/64:
  Train Loss: 0.5490719079971313
  Validation Loss: 0.5663725733757019
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 57/64:
  Train Loss: 0.5551045835018158
  Validation Loss: 0.5663923025131226
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 58/64:
  Train Loss: 0.5489471852779388
  Validation Loss: 0.5664124488830566
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 59/64:
  Train Loss: 0.5485460758209229
  Validation Loss: 0.5664311647415161
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 60/64:
  Train Loss: 0.548141747713089
  Validation Loss: 0.5664464235305786
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 61/64:
  Train Loss: 0.5531487166881561
  Validation Loss: 0.5664672255516052
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 62/64:
  Train Loss: 0.5463463962078094
  Validation Loss: 0.5664941072463989
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 63/64:
  Train Loss: 0.5506178140640259
  Validation Loss: 0.5665197372436523
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 64/64:
  Train Loss: 0.5548701882362366
  Validation Loss: 0.566541314125061
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
{'train_loss': 0.5548701882362366, 'val_roc_auc': 0.5, 'val_accuracy': 0.46153849363327026, 'val_loss': 0.566541314125061}
 ROC_AUC: 0.5000|| Accuracy 0.4615 || Train Loss: 0.5549
 Val Loss: 0.5665 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5759674807389578
Test ROC-AUC: 0.7114285714285714
Test Accuracy: 0.5111111111111111
test_loss: 0.5759674807389578
test_roc_auc: 0.7114285714285714
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.143575438642074
Epoch 1/64:
  Train Loss: 0.5505658984184265
  Validation Loss: 0.6228312253952026
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 2/64:
  Train Loss: 0.5402059555053711
  Validation Loss: 0.6230045557022095
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 3/64:
  Train Loss: 0.5425712466239929
  Validation Loss: 0.6232019066810608
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 4/64:
  Train Loss: 0.5425394177436829
  Validation Loss: 0.6233845949172974
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 5/64:
  Train Loss: 0.5428347885608673
  Validation Loss: 0.6235535144805908
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 6/64:
  Train Loss: 0.5457389950752258
  Validation Loss: 0.6237202882766724
  Val ROC-AUC: 0.825
  Val Accuracy: 0.7692307829856873
Epoch 7/64:
  Train Loss: 0.5376573801040649
  Validation Loss: 0.6238716244697571
  Val ROC-AUC: 0.825
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5398217141628265
  Validation Loss: 0.6240316033363342
  Val ROC-AUC: 0.825
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5472373366355896
  Validation Loss: 0.6241699457168579
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5391460657119751
  Validation Loss: 0.624314546585083
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5419162511825562
  Validation Loss: 0.6244512796401978
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.54371377825737
  Validation Loss: 0.6245958209037781
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5443145930767059
  Validation Loss: 0.6247231364250183
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.542511373758316
  Validation Loss: 0.6248631477355957
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5340673327445984
  Validation Loss: 0.6250151991844177
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5454467535018921
  Validation Loss: 0.6251589059829712
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5438013672828674
  Validation Loss: 0.6253063082695007
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5425204634666443
  Validation Loss: 0.6254612803459167
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5397295653820038
  Validation Loss: 0.6256190538406372
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5420193672180176
  Validation Loss: 0.6257638335227966
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5529608726501465
  Validation Loss: 0.6259261965751648
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.535565972328186
  Validation Loss: 0.6260776519775391
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5442660450935364
  Validation Loss: 0.6262277960777283
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5424982905387878
  Validation Loss: 0.6263709664344788
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5423764884471893
  Validation Loss: 0.62652987241745
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5416141450405121
  Validation Loss: 0.6266888976097107
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5422687530517578
  Validation Loss: 0.6268509030342102
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5420143306255341
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:52:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:34:INFO:
[92mINFO [0m:      Received: evaluate message 164f0bb0-6b6b-4dba-b81b-a214797e02cd
02/07/2025 22:52:34:INFO:Received: evaluate message 164f0bb0-6b6b-4dba-b81b-a214797e02cd
[92mINFO [0m:      Sent reply
02/07/2025 22:52:35:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:52:35:INFO:
[92mINFO [0m:      Received: train message fd396dcd-5bed-4304-aefc-8638fa03ed5d
02/07/2025 22:52:35:INFO:Received: train message fd396dcd-5bed-4304-aefc-8638fa03ed5d
  Validation Loss: 0.6269974112510681
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5421188175678253
  Validation Loss: 0.6271307468414307
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5386213064193726
  Validation Loss: 0.6272528171539307
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5386645197868347
  Validation Loss: 0.6273779273033142
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.53854039311409
  Validation Loss: 0.6275141835212708
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5390025079250336
  Validation Loss: 0.6276555061340332
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5379136502742767
  Validation Loss: 0.6277954578399658
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5366971790790558
  Validation Loss: 0.6279246211051941
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5464538335800171
  Validation Loss: 0.6280608773231506
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5385232865810394
  Validation Loss: 0.628197193145752
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.542677104473114
  Validation Loss: 0.6283326148986816
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5414376556873322
  Validation Loss: 0.6284701228141785
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5343041718006134
  Validation Loss: 0.6286174058914185
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5328864902257919
  Validation Loss: 0.628768801689148
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5345500409603119
  Validation Loss: 0.6289222836494446
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5402204990386963
  Validation Loss: 0.629075288772583
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5357302129268646
  Validation Loss: 0.6292174458503723
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5344987213611603
  Validation Loss: 0.629347026348114
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5332877933979034
  Validation Loss: 0.6294838786125183
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5266807079315186
  Validation Loss: 0.6296206712722778
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.537775307893753
  Validation Loss: 0.6297613382339478
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5321434140205383
  Validation Loss: 0.6299017071723938
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5372086465358734
  Validation Loss: 0.6300572156906128
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5372314155101776
  Validation Loss: 0.6301990747451782
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5370126068592072
  Validation Loss: 0.6303393244743347
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.533176451921463
  Validation Loss: 0.6304826736450195
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5323441326618195
  Validation Loss: 0.6306187510490417
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5286605507135391
  Validation Loss: 0.6307712197303772
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5323603451251984
  Validation Loss: 0.630926251411438
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5419181287288666
  Validation Loss: 0.6310719847679138
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5290163904428482
  Validation Loss: 0.6312160491943359
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5346981585025787
  Validation Loss: 0.6313639879226685
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5404911935329437
  Validation Loss: 0.6314905881881714
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5311537086963654
  Validation Loss: 0.6315957903862
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5382701754570007
  Validation Loss: 0.6317313313484192
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5372781455516815
  Validation Loss: 0.6318748593330383
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5351032316684723
  Validation Loss: 0.6319995522499084
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5351032316684723, 'val_roc_auc': 0.8, 'val_accuracy': 0.692307710647583, 'val_loss': 0.6319995522499084}
 ROC_AUC: 0.8000|| Accuracy 0.6923 || Train Loss: 0.5351
 Val Loss: 0.6320 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5757141033808391
Test ROC-AUC: 0.7228571428571429
Test Accuracy: 0.5111111111111111
test_loss: 0.5757141033808391
test_roc_auc: 0.7228571428571429
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.20958545010216767
Epoch 1/64:
  Train Loss: 0.5703393518924713
  Validation Loss: 0.5145161747932434
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5688092410564423
  Validation Loss: 0.5144827365875244
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5680595934391022
  Validation Loss: 0.5144331455230713
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5729052126407623
  Validation Loss: 0.5144045352935791
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5655429363250732
  Validation Loss: 0.5143857002258301
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5714231133460999
  Validation Loss: 0.5143679976463318
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5720856785774231
  Validation Loss: 0.5143292546272278
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5734744966030121
  Validation Loss: 0.5142913460731506
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5647394955158234
  Validation Loss: 0.5142707824707031
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5701698064804077
  Validation Loss: 0.5142361521720886
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5675654709339142
  Validation Loss: 0.5141992568969727
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5695457756519318
  Validation Loss: 0.5141763091087341
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5664073824882507
  Validation Loss: 0.5141628980636597
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5733384191989899
  Validation Loss: 0.5141331553459167
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5680851638317108
  Validation Loss: 0.5140972137451172
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5702666640281677
  Validation Loss: 0.5140589475631714
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.569973886013031
  Validation Loss: 0.5140412449836731
  Val ROC-AUC: 0.9090909090909092
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:53:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:04:INFO:
[92mINFO [0m:      Received: evaluate message 28b817d0-5153-4139-acda-a0112705c0fe
02/07/2025 22:53:04:INFO:Received: evaluate message 28b817d0-5153-4139-acda-a0112705c0fe
[92mINFO [0m:      Sent reply
02/07/2025 22:53:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:04:INFO:
[92mINFO [0m:      Received: train message 25ec3d17-0e70-42de-80b6-00ae624db546
02/07/2025 22:53:04:INFO:Received: train message 25ec3d17-0e70-42de-80b6-00ae624db546
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5634804666042328
  Validation Loss: 0.5140266418457031
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5621796548366547
  Validation Loss: 0.5139973163604736
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5707734227180481
  Validation Loss: 0.5139842629432678
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5683355629444122
  Validation Loss: 0.5139775276184082
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5718294680118561
  Validation Loss: 0.5139697790145874
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.571085125207901
  Validation Loss: 0.5139573812484741
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5722855627536774
  Validation Loss: 0.5139384269714355
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5634916126728058
  Validation Loss: 0.5139321684837341
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5652912855148315
  Validation Loss: 0.513922393321991
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5679646730422974
  Validation Loss: 0.5139010548591614
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.556229904294014
  Validation Loss: 0.5138781666755676
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.573328822851181
  Validation Loss: 0.5138413310050964
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5721542835235596
  Validation Loss: 0.5138128995895386
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5654903054237366
  Validation Loss: 0.5137861371040344
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5757623612880707
  Validation Loss: 0.5137587785720825
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5680534243583679
  Validation Loss: 0.5137445330619812
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5678576827049255
  Validation Loss: 0.513718843460083
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.568136990070343
  Validation Loss: 0.5136968493461609
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5621326863765717
  Validation Loss: 0.513691782951355
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5676384568214417
  Validation Loss: 0.5136837959289551
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.563896656036377
  Validation Loss: 0.5136796236038208
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5662797093391418
  Validation Loss: 0.5136885046958923
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5630815029144287
  Validation Loss: 0.5136916041374207
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5621139109134674
  Validation Loss: 0.5137025713920593
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5636067092418671
  Validation Loss: 0.5137081146240234
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5635932385921478
  Validation Loss: 0.5137144327163696
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5618849396705627
  Validation Loss: 0.5137364268302917
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5694797337055206
  Validation Loss: 0.5137583017349243
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5633217096328735
  Validation Loss: 0.5137780904769897
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.56719970703125
  Validation Loss: 0.5138009786605835
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5669854879379272
  Validation Loss: 0.5138121843338013
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5686017572879791
  Validation Loss: 0.5138260126113892
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5674827992916107
  Validation Loss: 0.5138382911682129
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5737814605236053
  Validation Loss: 0.5138505697250366
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5698489248752594
  Validation Loss: 0.513860821723938
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.56135293841362
  Validation Loss: 0.513868510723114
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5741468071937561
  Validation Loss: 0.5138646960258484
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.559781551361084
  Validation Loss: 0.5138686299324036
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5624178946018219
  Validation Loss: 0.51385897397995
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5583103001117706
  Validation Loss: 0.5138612985610962
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5674968063831329
  Validation Loss: 0.5138518810272217
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5620678961277008
  Validation Loss: 0.5138409733772278
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5662588179111481
  Validation Loss: 0.5138384699821472
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5648535490036011
  Validation Loss: 0.51385098695755
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.563489556312561
  Validation Loss: 0.5138510465621948
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5613012313842773
  Validation Loss: 0.5138476490974426
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5626744031906128
  Validation Loss: 0.5138444900512695
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5626744031906128, 'val_roc_auc': 0.9545454545454546, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5138444900512695}
 ROC_AUC: 0.9545|| Accuracy 0.6923 || Train Loss: 0.5627
 Val Loss: 0.5138 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.57545784579383
Test ROC-AUC: 0.7257142857142858
Test Accuracy: 0.5111111111111111
test_loss: 0.57545784579383
test_roc_auc: 0.7257142857142858
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  0.3604888916015625
Dynamic noise multiplier: 0.15501881281352325
Epoch 1/64:
  Train Loss: 0.5845748782157898
  Validation Loss: 0.45919886231422424
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5849721133708954
  Validation Loss: 0.4590755105018616
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5795158445835114
  Validation Loss: 0.45901423692703247
  Val ROC-AUC: nan
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5798726975917816
  Validation Loss: 0.45893698930740356
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5821475684642792
  Validation Loss: 0.45886853337287903
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5831825733184814
  Validation Loss: 0.45878875255584717
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5810095369815826
  Validation Loss: 0.45871421694755554
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5843294262886047
  Validation Loss: 0.4586533308029175
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.582548201084137
  Validation Loss: 0.4586086571216583
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5837251842021942
  Validation Loss: 0.45855167508125305
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5798020958900452
  Validation Loss: 0.45849624276161194
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5745429992675781
  Validation Loss: 0.4584280550479889
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5757611393928528
  Validation Loss: 0.458362877368927
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5875245630741119
  Validation Loss: 0.4582887887954712
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5778341293334961
  Validation Loss: 0.45821258425712585
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5754669606685638
  Validation Loss: 0.4581640064716339
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5828962624073029
  Validation Loss: 0.4581145942211151
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5816903412342072
  Validation Loss: 0.4580709636211395
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5871027112007141
  Validation Loss: 0.458020955324173
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5917991399765015
  Validation Loss: 0.4579602777957916
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5803175270557404
  Validation Loss: 0.4578843414783478
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5728564560413361
  Validation Loss: 0.45781657099723816
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5750332474708557
  Validation Loss: 0.45775115489959717
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5822855830192566
  Validation Loss: 0.4576767683029175
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5816842913627625
  Validation Loss: 0.4575876295566559
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5837972462177277
  Validation Loss: 0.4575115442276001
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5754111111164093
  Validation Loss: 0.45744815468788147
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5793526768684387
  Validation Loss: 0.4574018716812134
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5844537317752838
  Validation Loss: 0.4573480188846588
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5795078873634338
  Validation Loss: 0.45728474855422974
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5797094702720642
  Validation Loss: 0.4572021961212158
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5819852948188782
  Validation Loss: 0.45711350440979004
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.577864021062851
  Validation Loss: 0.4570325016975403
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5829416513442993
  Validation Loss: 0.4569444954395294
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.579892098903656
  Validation Loss: 0.4568559229373932
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5769800841808319
  Validation Loss: 0.45678040385246277
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5764141976833344
  Validation Loss: 0.45670580863952637
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5856507122516632
  Validation Loss: 0.4566519856452942
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5830642580986023
  Validation Loss: 0.456589013338089
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.589541494846344
  Validation Loss: 0.4565090239048004
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5849220454692841
  Validation Loss: 0.4564354121685028
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.568740576505661
  Validation Loss: 0.4563613831996918
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5885171592235565
  Validation Loss: 0.45627743005752563
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5782164931297302
  Validation Loss: 0.4561910033226013
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5849807560443878
  Validation Loss: 0.4561004340648651
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.579355388879776
  Validation Loss: 0.4560092091560364
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5778908431529999
  Validation Loss: 0.4559260308742523
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.580960750579834
  Validation Loss: 0.4558315873146057
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5837076902389526
  Validation Loss: 0.45574381947517395
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5764650404453278
  Validation Loss: 0.45567557215690613
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5857024788856506
  Validation Loss: 0.4556078016757965
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5759584903717041
  Validation Loss: 0.45555058121681213
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5832344889640808
  Validation Loss: 0.45549461245536804
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5767260491847992
  Validation Loss: 0.45544421672821045
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5778470933437347
  Validation Loss: 0.45537951588630676
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5799170434474945
  Validation Loss: 0.45530885457992554
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5829460322856903
  Validation Loss: 0.4552328884601593
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5791667103767395
  Validation Loss: 0.4551551043987274
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.5713196396827698
  Validation Loss: 0.4550721347332001
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5774804949760437
  Validation Loss: 0.4549785852432251
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5748011767864227
  Validation Loss: 0.454876184463501
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5754167437553406
  Validation Loss: 0.45477405190467834
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5733582973480225
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 22:53:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:30:INFO:
[92mINFO [0m:      Received: evaluate message adb5b5f1-0376-4438-9284-c39bb0e458df
02/07/2025 22:53:31:INFO:Received: evaluate message adb5b5f1-0376-4438-9284-c39bb0e458df
[92mINFO [0m:      Sent reply
02/07/2025 22:53:32:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:53:33:INFO:
[92mINFO [0m:      Received: train message 443fef2d-f6ae-48da-9a74-ffe7ce850ff5
02/07/2025 22:53:33:INFO:Received: train message 443fef2d-f6ae-48da-9a74-ffe7ce850ff5
