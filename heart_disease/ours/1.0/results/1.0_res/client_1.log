nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:32:16:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:32:16:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 22:32:17:DEBUG:ChannelConnectivity.IDLE
02/07/2025 22:32:17:DEBUG:ChannelConnectivity.CONNECTING
02/07/2025 22:32:17:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
02/07/2025 22:32:17:INFO:
[92mINFO [0m:      Received: train message bdce5b79-f4d9-45e6-a544-c2b4461d6bf3
02/07/2025 22:32:17:INFO:Received: train message bdce5b79-f4d9-45e6-a544-c2b4461d6bf3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours/1.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours']
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.712692454457283
  Validation Loss: 0.7639992237091064
  Val ROC-AUC: 0.7333333333333334
  Val Accuracy: 0.65625
Epoch 2/64:
  Train Loss: 0.712048813700676
  Validation Loss: 0.7634917497634888
  Val ROC-AUC: 0.7416666666666666
  Val Accuracy: 0.65625
Epoch 3/64:
  Train Loss: 0.711522564291954
  Validation Loss: 0.7630354166030884
  Val ROC-AUC: 0.7416666666666666
  Val Accuracy: 0.6875
Epoch 4/64:
  Train Loss: 0.711042508482933
  Validation Loss: 0.7624490261077881
  Val ROC-AUC: 0.7458333333333333
  Val Accuracy: 0.6875
Epoch 5/64:
  Train Loss: 0.7104595452547073
  Validation Loss: 0.7617684006690979
  Val ROC-AUC: 0.7458333333333333
  Val Accuracy: 0.6875
Epoch 6/64:
  Train Loss: 0.7098745107650757
  Validation Loss: 0.7613450288772583
  Val ROC-AUC: 0.7458333333333333
  Val Accuracy: 0.6875
Epoch 7/64:
  Train Loss: 0.7094311118125916
  Validation Loss: 0.7608931064605713
  Val ROC-AUC: 0.75
  Val Accuracy: 0.6875
Epoch 8/64:
  Train Loss: 0.7090144753456116
  Validation Loss: 0.7604466676712036
  Val ROC-AUC: 0.7583333333333333
  Val Accuracy: 0.6875
Epoch 9/64:
  Train Loss: 0.7085385769605637
  Validation Loss: 0.7598611116409302
  Val ROC-AUC: 0.7625
  Val Accuracy: 0.6875
Epoch 10/64:
  Train Loss: 0.708054319024086
  Validation Loss: 0.7592172622680664
  Val ROC-AUC: 0.7625
  Val Accuracy: 0.6875
Epoch 11/64:
  Train Loss: 0.7076032757759094
  Validation Loss: 0.7585684657096863
  Val ROC-AUC: 0.7625
  Val Accuracy: 0.6875
Epoch 12/64:
  Train Loss: 0.707152783870697
  Validation Loss: 0.7580764889717102
  Val ROC-AUC: 0.7708333333333333
  Val Accuracy: 0.6875
Epoch 13/64:
  Train Loss: 0.7067785412073135
  Validation Loss: 0.757472574710846
  Val ROC-AUC: 0.7708333333333333
  Val Accuracy: 0.6875
Epoch 14/64:
  Train Loss: 0.7063761651515961
  Validation Loss: 0.7568581104278564
  Val ROC-AUC: 0.775
  Val Accuracy: 0.6875
Epoch 15/64:
  Train Loss: 0.7059741169214249
  Validation Loss: 0.7563369274139404
  Val ROC-AUC: 0.7791666666666667
  Val Accuracy: 0.6875
Epoch 16/64:
  Train Loss: 0.7056307792663574
  Validation Loss: 0.7557879090309143
  Val ROC-AUC: 0.7791666666666667
  Val Accuracy: 0.6875
Epoch 17/64:
  Train Loss: 0.705208033323288
  Validation Loss: 0.7552138566970825
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.6875
Epoch 18/64:
  Train Loss: 0.7047740519046783
  Validation Loss: 0.7547069787979126
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.6875
Epoch 19/64:
  Train Loss: 0.7043662220239639
  Validation Loss: 0.7542292475700378
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.7039524763822556
  Validation Loss: 0.7538350224494934
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.7035450637340546
  Validation Loss: 0.7534911632537842
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.7031959593296051
  Validation Loss: 0.7531000375747681
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.7028914093971252
  Validation Loss: 0.7526878118515015
  Val ROC-AUC: 0.7833333333333333
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.7025661170482635
  Validation Loss: 0.752346396446228
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.7023106813430786
  Validation Loss: 0.7520209550857544
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.7020911127328873
  Validation Loss: 0.7517080307006836
  Val ROC-AUC: 0.7916666666666666
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.7018288820981979
  Validation Loss: 0.7512317895889282
  Val ROC-AUC: 0.7916666666666666
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.7014406323432922
  Validation Loss: 0.7506712079048157
  Val ROC-AUC: 0.7916666666666666
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.7010485976934433
  Validation Loss: 0.7501440048217773
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.7006828635931015
  Validation Loss: 0.7497190237045288
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.7003810703754425
  Validation Loss: 0.7493478059768677
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.7001295536756516
  Validation Loss: 0.7490683197975159
  Val ROC-AUC: 0.7833333333333334
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6998344212770462
  Validation Loss: 0.748721182346344
  Val ROC-AUC: 0.7875000000000001
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6994913667440414
  Validation Loss: 0.7483088970184326
  Val ROC-AUC: 0.7916666666666666
  Val Accuracy: 0.75
Epoch 35/64:
  Train Loss: 0.6991305351257324
  Validation Loss: 0.7479512691497803
  Val ROC-AUC: 0.7958333333333334
  Val Accuracy: 0.75
Epoch 36/64:
  Train Loss: 0.698803186416626
  Validation Loss: 0.7475256323814392
  Val ROC-AUC: 0.7958333333333334
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.6984530836343765
  Validation Loss: 0.7470817565917969
  Val ROC-AUC: 0.7958333333333334
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.6981136202812195
  Validation Loss: 0.7466763257980347
  Val ROC-AUC: 0.8
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6977453529834747
  Validation Loss: 0.746261715888977
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6974789351224899
  Validation Loss: 0.745984673500061
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6971940398216248
  Validation Loss: 0.7456446886062622
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6969458758831024
  Validation Loss: 0.7453113198280334
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6966431140899658
  Validation Loss: 0.7450247406959534
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6964070647954941
  Validation Loss: 0.7447960376739502
  Val ROC-AUC: 0.8083333333333333
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6961511522531509
  Validation Loss: 0.7445580959320068
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6959007382392883
  Validation Loss: 0.7443108558654785
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6955935508012772
  Validation Loss: 0.7440235018730164
  Val ROC-AUC: 0.8041666666666667
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6952869743108749
  Validation Loss: 0.7436219453811646
  Val ROC-AUC: 0.8083333333333333
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.6949574202299118
  Validation Loss: 0.743195116519928
  Val ROC-AUC: 0.8083333333333333
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6946724951267242
  Validation Loss: 0.7428051829338074
  Val ROC-AUC: 0.8125
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.6944391429424286
  Validation Loss: 0.7424586415290833
  Val ROC-AUC: 0.8125
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.6942297965288162
  Validation Loss: 0.7421205639839172
  Val ROC-AUC: 0.8166666666666668
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6940222680568695
  Validation Loss: 0.741763710975647
  Val ROC-AUC: 0.8208333333333334
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.6937986463308334
  Validation Loss: 0.7413879632949829
  Val ROC-AUC: 0.825
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6935687065124512
  Validation Loss: 0.7410857677459717
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.6933577060699463/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:32:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:29:INFO:
[92mINFO [0m:      Received: evaluate message c2ca7562-ba9a-4b01-b75b-0af3a8c46f69
02/07/2025 22:32:29:INFO:Received: evaluate message c2ca7562-ba9a-4b01-b75b-0af3a8c46f69
[92mINFO [0m:      Sent reply
02/07/2025 22:32:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:33:INFO:
[92mINFO [0m:      Received: train message 819bc74a-3a18-49e9-8d34-9a68bfa7d517
02/07/2025 22:32:33:INFO:Received: train message 819bc74a-3a18-49e9-8d34-9a68bfa7d517
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)

  Validation Loss: 0.7407815456390381
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6930717378854752
  Validation Loss: 0.7404911518096924
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6928187161684036
  Validation Loss: 0.7400820851325989
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6924895793199539
  Validation Loss: 0.7395424842834473
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.692112386226654
  Validation Loss: 0.7389291524887085
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6917376667261124
  Validation Loss: 0.7383352518081665
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6914128810167313
  Validation Loss: 0.7377623319625854
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.690992683172226
  Validation Loss: 0.7372402548789978
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6906525790691376
  Validation Loss: 0.7367975115776062
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.75
{'train_loss': 0.6906525790691376, 'val_roc_auc': 0.8291666666666666, 'val_accuracy': 0.75, 'val_loss': 0.7367975115776062}
 ROC_AUC: 0.8292|| Accuracy 0.7500 || Train Loss: 0.6907
 Val Loss: 0.7368 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7235990086427102
Test ROC-AUC: 0.6648065476190477
Test Accuracy: 0.625
test_loss: 0.7235990086427102
test_roc_auc: 0.6648065476190477
test_accuracy: 0.625
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.711488887667656
  Validation Loss: 0.755901575088501
  Val ROC-AUC: 0.7
  Val Accuracy: 0.59375
Epoch 2/64:
  Train Loss: 0.7109453976154327
  Validation Loss: 0.7550996541976929
  Val ROC-AUC: 0.7124999999999999
  Val Accuracy: 0.59375
Epoch 3/64:
  Train Loss: 0.7103860229253769
  Validation Loss: 0.7545349597930908
  Val ROC-AUC: 0.7124999999999999
  Val Accuracy: 0.59375
Epoch 4/64:
  Train Loss: 0.7099224478006363
  Validation Loss: 0.7539175748825073
  Val ROC-AUC: 0.7124999999999999
  Val Accuracy: 0.59375
Epoch 5/64:
  Train Loss: 0.7093843519687653
  Validation Loss: 0.7533601522445679
  Val ROC-AUC: 0.7124999999999999
  Val Accuracy: 0.625
Epoch 6/64:
  Train Loss: 0.7088695019483566
  Validation Loss: 0.752885639667511
  Val ROC-AUC: 0.7208333333333333
  Val Accuracy: 0.625
Epoch 7/64:
  Train Loss: 0.7084507048130035
  Validation Loss: 0.7524322271347046
  Val ROC-AUC: 0.725
  Val Accuracy: 0.625
Epoch 8/64:
  Train Loss: 0.7080215364694595
  Validation Loss: 0.7520079612731934
  Val ROC-AUC: 0.7333333333333334
  Val Accuracy: 0.625
Epoch 9/64:
  Train Loss: 0.7075958251953125
  Validation Loss: 0.7516210079193115
  Val ROC-AUC: 0.7333333333333334
  Val Accuracy: 0.625
Epoch 10/64:
  Train Loss: 0.7071393579244614
  Validation Loss: 0.751221239566803
  Val ROC-AUC: 0.7333333333333334
  Val Accuracy: 0.625
Epoch 11/64:
  Train Loss: 0.7066867798566818
  Validation Loss: 0.7507548332214355
  Val ROC-AUC: 0.7374999999999999
  Val Accuracy: 0.625
Epoch 12/64:
  Train Loss: 0.7062235921621323
  Validation Loss: 0.750249981880188
  Val ROC-AUC: 0.7416666666666667
  Val Accuracy: 0.625
Epoch 13/64:
  Train Loss: 0.705648809671402
  Validation Loss: 0.749720573425293
  Val ROC-AUC: 0.7541666666666667
  Val Accuracy: 0.625
Epoch 14/64:
  Train Loss: 0.7050965875387192
  Validation Loss: 0.7493105530738831
  Val ROC-AUC: 0.7583333333333333
  Val Accuracy: 0.625
Epoch 15/64:
  Train Loss: 0.7046686112880707
  Validation Loss: 0.7489420771598816
  Val ROC-AUC: 0.7583333333333333
  Val Accuracy: 0.625
Epoch 16/64:
  Train Loss: 0.7043571919202805
  Validation Loss: 0.7486097812652588
  Val ROC-AUC: 0.7625
  Val Accuracy: 0.625
Epoch 17/64:
  Train Loss: 0.7039963603019714
  Validation Loss: 0.7483038902282715
  Val ROC-AUC: 0.7666666666666666
  Val Accuracy: 0.625
Epoch 18/64:
  Train Loss: 0.7037079036235809
  Validation Loss: 0.7479434013366699
  Val ROC-AUC: 0.7708333333333333
  Val Accuracy: 0.625
Epoch 19/64:
  Train Loss: 0.7033341228961945
  Validation Loss: 0.7474334239959717
  Val ROC-AUC: 0.7749999999999999
  Val Accuracy: 0.625
Epoch 20/64:
  Train Loss: 0.7027394473552704
  Validation Loss: 0.7469418048858643
  Val ROC-AUC: 0.7749999999999999
  Val Accuracy: 0.625
Epoch 21/64:
  Train Loss: 0.7022252082824707
  Validation Loss: 0.7465008497238159
  Val ROC-AUC: 0.7749999999999999
  Val Accuracy: 0.625
Epoch 22/64:
  Train Loss: 0.7017192840576172
  Validation Loss: 0.7460626363754272
  Val ROC-AUC: 0.7749999999999999
  Val Accuracy: 0.625
Epoch 23/64:
  Train Loss: 0.7012515068054199
  Validation Loss: 0.7457130551338196
  Val ROC-AUC: 0.7749999999999999
  Val Accuracy: 0.625
Epoch 24/64:
  Train Loss: 0.7008529007434845
  Validation Loss: 0.7452954053878784
  Val ROC-AUC: 0.7749999999999999
  Val Accuracy: 0.625
Epoch 25/64:
  Train Loss: 0.7003765404224396
  Validation Loss: 0.7449278831481934
  Val ROC-AUC: 0.7749999999999999
  Val Accuracy: 0.625
Epoch 26/64:
  Train Loss: 0.699944794178009
  Validation Loss: 0.744530439376831
  Val ROC-AUC: 0.7833333333333333
  Val Accuracy: 0.625
Epoch 27/64:
  Train Loss: 0.6994829028844833
  Validation Loss: 0.7441095113754272
  Val ROC-AUC: 0.7916666666666666
  Val Accuracy: 0.625
Epoch 28/64:
  Train Loss: 0.6989474296569824
  Validation Loss: 0.7436867952346802
  Val ROC-AUC: 0.7916666666666666
  Val Accuracy: 0.625
Epoch 29/64:
  Train Loss: 0.6985265016555786
  Validation Loss: 0.7432577013969421
  Val ROC-AUC: 0.7958333333333333
  Val Accuracy: 0.625
Epoch 30/64:
  Train Loss: 0.6980171650648117
  Validation Loss: 0.7427688837051392
  Val ROC-AUC: 0.7958333333333333
  Val Accuracy: 0.625
Epoch 31/64:
  Train Loss: 0.6975368857383728
  Validation Loss: 0.7423369288444519
  Val ROC-AUC: 0.7958333333333333
  Val Accuracy: 0.625
Epoch 32/64:
  Train Loss: 0.6970841586589813
  Validation Loss: 0.7419101595878601
  Val ROC-AUC: 0.7958333333333333
  Val Accuracy: 0.625
Epoch 33/64:
  Train Loss: 0.6966454833745956
  Validation Loss: 0.7414917945861816
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.625
Epoch 34/64:
  Train Loss: 0.6962158679962158
  Validation Loss: 0.7409310340881348
  Val ROC-AUC: 0.8125
  Val Accuracy: 0.625
Epoch 35/64:
  Train Loss: 0.6957478821277618
  Validation Loss: 0.740451455116272
  Val ROC-AUC: 0.8166666666666667
  Val Accuracy: 0.625
Epoch 36/64:
  Train Loss: 0.6954065561294556
  Validation Loss: 0.7402032017707825
  Val ROC-AUC: 0.8166666666666667
  Val Accuracy: 0.625
Epoch 37/64:
  Train Loss: 0.6952363699674606
  Validation Loss: 0.7400453090667725
  Val ROC-AUC: 0.8208333333333333
  Val Accuracy: 0.625
Epoch 38/64:
  Train Loss: 0.6950236558914185
  Validation Loss: 0.7397821545600891
  Val ROC-AUC: 0.8208333333333333
  Val Accuracy: 0.625
Epoch 39/64:
  Train Loss: 0.6947533488273621
  Validation Loss: 0.7394886016845703
  Val ROC-AUC: 0.8208333333333333
  Val Accuracy: 0.625
Epoch 40/64:
  Train Loss: 0.6944632828235626
  Validation Loss: 0.739203691482544
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.65625
Epoch 41/64:
  Train Loss: 0.6940996497869492
  Validation Loss: 0.7388770580291748
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.65625
Epoch 42/64:
  Train Loss: 0.6937578320503235
  Validation Loss: 0.7384816408157349
  Val ROC-AUC: 0.8250000000000001
  Val Accuracy: 0.65625
Epoch 43/64:
  Train Loss: 0.6934301108121872
  Validation Loss: 0.7380799651145935
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.65625
Epoch 44/64:
  Train Loss: 0.6930657029151917
  Validation Loss: 0.7376638054847717
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.65625
Epoch 45/64:
  Train Loss: 0.692632257938385
  Validation Loss: 0.7372442483901978
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.65625
Epoch 46/64:
  Train Loss: 0.6922677457332611
  Validation Loss: 0.736892580986023
  Val ROC-AUC: 0.8291666666666666
  Val Accuracy: 0.65625
Epoch 47/64:
  Train Loss: 0.6919205337762833/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:32:43:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:43:INFO:
[92mINFO [0m:      Received: evaluate message 0c973401-dc01-44dd-ace6-ec1c70de4165
02/07/2025 22:32:43:INFO:Received: evaluate message 0c973401-dc01-44dd-ace6-ec1c70de4165
[92mINFO [0m:      Sent reply
02/07/2025 22:32:45:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:45:INFO:
[92mINFO [0m:      Received: train message 64a4fac5-8968-4b4f-99b6-3362485da9fd
02/07/2025 22:32:45:INFO:Received: train message 64a4fac5-8968-4b4f-99b6-3362485da9fd
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)

  Validation Loss: 0.7364985346794128
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 48/64:
  Train Loss: 0.6915654987096786
  Validation Loss: 0.7359977960586548
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 49/64:
  Train Loss: 0.6912066489458084
  Validation Loss: 0.7355514168739319
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 50/64:
  Train Loss: 0.6907927691936493
  Validation Loss: 0.7350565195083618
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 51/64:
  Train Loss: 0.6903195679187775
  Validation Loss: 0.7345079779624939
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 52/64:
  Train Loss: 0.6898653954267502
  Validation Loss: 0.7339913845062256
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 53/64:
  Train Loss: 0.6894258707761765
  Validation Loss: 0.7335186004638672
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 54/64:
  Train Loss: 0.6890608817338943
  Validation Loss: 0.7331465482711792
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 55/64:
  Train Loss: 0.688714012503624
  Validation Loss: 0.7327775359153748
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 56/64:
  Train Loss: 0.6884016990661621
  Validation Loss: 0.7324259281158447
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 57/64:
  Train Loss: 0.6880482882261276
  Validation Loss: 0.7321078181266785
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 58/64:
  Train Loss: 0.6876736730337143
  Validation Loss: 0.7317672967910767
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 59/64:
  Train Loss: 0.6873240023851395
  Validation Loss: 0.7314754724502563
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 60/64:
  Train Loss: 0.6870138049125671
  Validation Loss: 0.7311604022979736
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 61/64:
  Train Loss: 0.6866828948259354
  Validation Loss: 0.7308030128479004
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 62/64:
  Train Loss: 0.68633833527565
  Validation Loss: 0.7304524183273315
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 63/64:
  Train Loss: 0.6860116124153137
  Validation Loss: 0.7302548885345459
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
Epoch 64/64:
  Train Loss: 0.6857857704162598
  Validation Loss: 0.7299779057502747
  Val ROC-AUC: 0.8333333333333333
  Val Accuracy: 0.65625
{'train_loss': 0.6857857704162598, 'val_roc_auc': 0.8333333333333333, 'val_accuracy': 0.65625, 'val_loss': 0.7299779057502747}
 ROC_AUC: 0.8333|| Accuracy 0.6562 || Train Loss: 0.6858
 Val Loss: 0.7300 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7195652803549399
Test ROC-AUC: 0.6923363095238095
Test Accuracy: 0.6346153846153846
test_loss: 0.7195652803549399
test_roc_auc: 0.6923363095238095
test_accuracy: 0.6346153846153846
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.7179976850748062
  Validation Loss: 0.711109459400177
  Val ROC-AUC: 0.62109375
  Val Accuracy: 0.5625
Epoch 2/64:
  Train Loss: 0.7173850387334824
  Validation Loss: 0.7107546329498291
  Val ROC-AUC: 0.6328125
  Val Accuracy: 0.5625
Epoch 3/64:
  Train Loss: 0.7167211621999741
  Validation Loss: 0.7102149724960327
  Val ROC-AUC: 0.6328125
  Val Accuracy: 0.5625
Epoch 4/64:
  Train Loss: 0.7160149216651917
  Validation Loss: 0.7096034288406372
  Val ROC-AUC: 0.63671875
  Val Accuracy: 0.5625
Epoch 5/64:
  Train Loss: 0.7153085470199585
  Validation Loss: 0.7090283632278442
  Val ROC-AUC: 0.63671875
  Val Accuracy: 0.5625
Epoch 6/64:
  Train Loss: 0.7146543115377426
  Validation Loss: 0.7085690498352051
  Val ROC-AUC: 0.640625
  Val Accuracy: 0.59375
Epoch 7/64:
  Train Loss: 0.7141054272651672
  Validation Loss: 0.7081388235092163
  Val ROC-AUC: 0.640625
  Val Accuracy: 0.59375
Epoch 8/64:
  Train Loss: 0.7136306166648865
  Validation Loss: 0.7077829241752625
  Val ROC-AUC: 0.64453125
  Val Accuracy: 0.59375
Epoch 9/64:
  Train Loss: 0.7132566273212433
  Validation Loss: 0.7074292898178101
  Val ROC-AUC: 0.64453125
  Val Accuracy: 0.59375
Epoch 10/64:
  Train Loss: 0.7129062116146088
  Validation Loss: 0.7070270776748657
  Val ROC-AUC: 0.65234375
  Val Accuracy: 0.59375
Epoch 11/64:
  Train Loss: 0.7125196605920792
  Validation Loss: 0.7066100239753723
  Val ROC-AUC: 0.6640625
  Val Accuracy: 0.59375
Epoch 12/64:
  Train Loss: 0.7120485156774521
  Validation Loss: 0.7062093019485474
  Val ROC-AUC: 0.66796875
  Val Accuracy: 0.625
Epoch 13/64:
  Train Loss: 0.7114801108837128
  Validation Loss: 0.7057644128799438
  Val ROC-AUC: 0.66796875
  Val Accuracy: 0.625
Epoch 14/64:
  Train Loss: 0.7108096480369568
  Validation Loss: 0.7053020596504211
  Val ROC-AUC: 0.66796875
  Val Accuracy: 0.625
Epoch 15/64:
  Train Loss: 0.7101587951183319
  Validation Loss: 0.7048078775405884
  Val ROC-AUC: 0.67578125
  Val Accuracy: 0.625
Epoch 16/64:
  Train Loss: 0.709494486451149
  Validation Loss: 0.704378604888916
  Val ROC-AUC: 0.6796875
  Val Accuracy: 0.625
Epoch 17/64:
  Train Loss: 0.7089418172836304
  Validation Loss: 0.7039551138877869
  Val ROC-AUC: 0.6796875
  Val Accuracy: 0.625
Epoch 18/64:
  Train Loss: 0.7084058970212936
  Validation Loss: 0.7034932374954224
  Val ROC-AUC: 0.6875
  Val Accuracy: 0.625
Epoch 19/64:
  Train Loss: 0.7078334242105484
  Validation Loss: 0.7031584978103638
  Val ROC-AUC: 0.6875
  Val Accuracy: 0.625
Epoch 20/64:
  Train Loss: 0.7073563784360886
  Validation Loss: 0.7027928829193115
  Val ROC-AUC: 0.69140625
  Val Accuracy: 0.65625
Epoch 21/64:
  Train Loss: 0.706912100315094
  Validation Loss: 0.7024322152137756
  Val ROC-AUC: 0.69140625
  Val Accuracy: 0.65625
Epoch 22/64:
  Train Loss: 0.7065202593803406
  Validation Loss: 0.702090859413147
  Val ROC-AUC: 0.6875
  Val Accuracy: 0.65625
Epoch 23/64:
  Train Loss: 0.7060623317956924
  Validation Loss: 0.701757550239563
  Val ROC-AUC: 0.6875
  Val Accuracy: 0.65625
Epoch 24/64:
  Train Loss: 0.7056013941764832
  Validation Loss: 0.7014706134796143
  Val ROC-AUC: 0.6875
  Val Accuracy: 0.65625
Epoch 25/64:
  Train Loss: 0.7051389962434769
  Validation Loss: 0.7012513875961304
  Val ROC-AUC: 0.6875
  Val Accuracy: 0.65625
Epoch 26/64:
  Train Loss: 0.7048578560352325
  Validation Loss: 0.7010810375213623
  Val ROC-AUC: 0.69140625
  Val Accuracy: 0.65625
Epoch 27/64:
  Train Loss: 0.7045989632606506
  Validation Loss: 0.700812578201294
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.65625
Epoch 28/64:
  Train Loss: 0.7041713148355484
  Validation Loss: 0.7004961967468262
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.65625
Epoch 29/64:
  Train Loss: 0.7037611156702042
  Validation Loss: 0.7002392411231995
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.65625
Epoch 30/64:
  Train Loss: 0.7033701241016388
  Validation Loss: 0.6999573707580566
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.65625
Epoch 31/64:
  Train Loss: 0.7029927670955658
  Validation Loss: 0.6995880603790283
  Val ROC-AUC: 0.69921875
  Val Accuracy: 0.65625
Epoch 32/64:
  Train Loss: 0.7025800943374634
  Validation Loss: 0.6991541385650635
  Val ROC-AUC: 0.69921875
  Val Accuracy: 0.65625
Epoch 33/64:
  Train Loss: 0.7020140290260315
  Validation Loss: 0.6987974643707275
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.65625
Epoch 34/64:
  Train Loss: 0.701570138335228
  Validation Loss: 0.6984326839447021
  Val ROC-AUC: 0.6953125
  Val Accuracy: 0.65625
Epoch 35/64:
  Train Loss: 0.7011448293924332
  Validation Loss: 0.6981515884399414
  Val ROC-AUC: 0.69921875
  Val Accuracy: 0.65625
Epoch 36/64:
  Train Loss: 0.7007788568735123
  Validation Loss: 0.6978847980499268
  Val ROC-AUC: 0.69921875
  Val Accuracy: 0.625
Epoch 37/64:
  Train Loss: 0.700317457318306
  Validation Loss: 0.6975240707397461
  Val ROC-AUC: 0.69921875
  Val Accuracy: 0.625
Epoch 38/64:
  Train Loss: 0.699786975979805
  Validation Loss: 0.6971775889396667
  Val ROC-AUC: 0.69921875
  Val Accuracy: 0.625
Epoch 39/64:
  Train Loss: 0.6992961466312408
  Validation Loss: 0.6968370676040649
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:32:55:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:55:INFO:
[92mINFO [0m:      Received: evaluate message b1cf1384-e90b-4225-abbc-0c528e4d18af
02/07/2025 22:32:55:INFO:Received: evaluate message b1cf1384-e90b-4225-abbc-0c528e4d18af
[92mINFO [0m:      Sent reply
02/07/2025 22:32:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:56:INFO:
[92mINFO [0m:      Received: train message a8c86f40-8e4c-47ed-9317-a34662bac438
02/07/2025 22:32:56:INFO:Received: train message a8c86f40-8e4c-47ed-9317-a34662bac438
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.70703125
  Val Accuracy: 0.625
Epoch 40/64:
  Train Loss: 0.6988834291696548
  Validation Loss: 0.6966005563735962
  Val ROC-AUC: 0.70703125
  Val Accuracy: 0.625
Epoch 41/64:
  Train Loss: 0.6985793709754944
  Validation Loss: 0.696490466594696
  Val ROC-AUC: 0.703125
  Val Accuracy: 0.625
Epoch 42/64:
  Train Loss: 0.6983572393655777
  Validation Loss: 0.6963262557983398
  Val ROC-AUC: 0.703125
  Val Accuracy: 0.625
Epoch 43/64:
  Train Loss: 0.6980467736721039
  Validation Loss: 0.6960843801498413
  Val ROC-AUC: 0.703125
  Val Accuracy: 0.625
Epoch 44/64:
  Train Loss: 0.6977323740720749
  Validation Loss: 0.6957525610923767
  Val ROC-AUC: 0.703125
  Val Accuracy: 0.625
Epoch 45/64:
  Train Loss: 0.6973095238208771
  Validation Loss: 0.6954010725021362
  Val ROC-AUC: 0.70703125
  Val Accuracy: 0.625
Epoch 46/64:
  Train Loss: 0.6967781037092209
  Validation Loss: 0.6950360536575317
  Val ROC-AUC: 0.70703125
  Val Accuracy: 0.625
Epoch 47/64:
  Train Loss: 0.6962836980819702
  Validation Loss: 0.6946860551834106
  Val ROC-AUC: 0.70703125
  Val Accuracy: 0.65625
Epoch 48/64:
  Train Loss: 0.695739820599556
  Validation Loss: 0.6943715810775757
  Val ROC-AUC: 0.70703125
  Val Accuracy: 0.65625
Epoch 49/64:
  Train Loss: 0.6952617913484573
  Validation Loss: 0.6940513849258423
  Val ROC-AUC: 0.70703125
  Val Accuracy: 0.625
Epoch 50/64:
  Train Loss: 0.6948316246271133
  Validation Loss: 0.6937509775161743
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 51/64:
  Train Loss: 0.6944443732500076
  Validation Loss: 0.6934936046600342
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 52/64:
  Train Loss: 0.6941086500883102
  Validation Loss: 0.6932399272918701
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 53/64:
  Train Loss: 0.6938218921422958
  Validation Loss: 0.69298255443573
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 54/64:
  Train Loss: 0.6935296654701233
  Validation Loss: 0.6926975846290588
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 55/64:
  Train Loss: 0.6931969374418259
  Validation Loss: 0.6924206018447876
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 56/64:
  Train Loss: 0.6928835958242416
  Validation Loss: 0.6921302080154419
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 57/64:
  Train Loss: 0.692535400390625
  Validation Loss: 0.6918293833732605
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 58/64:
  Train Loss: 0.6922110915184021
  Validation Loss: 0.6916391253471375
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 59/64:
  Train Loss: 0.6919947117567062
  Validation Loss: 0.6914107799530029
  Val ROC-AUC: 0.70703125
  Val Accuracy: 0.625
Epoch 60/64:
  Train Loss: 0.6917384117841721
  Validation Loss: 0.6911638975143433
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.625
Epoch 61/64:
  Train Loss: 0.6914701461791992
  Validation Loss: 0.6908813118934631
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.625
Epoch 62/64:
  Train Loss: 0.6912066489458084
  Validation Loss: 0.6906616687774658
  Val ROC-AUC: 0.7109375
  Val Accuracy: 0.625
Epoch 63/64:
  Train Loss: 0.6910447776317596
  Validation Loss: 0.6904082298278809
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.625
Epoch 64/64:
  Train Loss: 0.6907394379377365
  Validation Loss: 0.6901187896728516
  Val ROC-AUC: 0.71484375
  Val Accuracy: 0.625
{'train_loss': 0.6907394379377365, 'val_roc_auc': 0.71484375, 'val_accuracy': 0.625, 'val_loss': 0.6901187896728516}
 ROC_AUC: 0.7148|| Accuracy 0.6250 || Train Loss: 0.6907
 Val Loss: 0.6901 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7148902083818729
Test ROC-AUC: 0.7206101190476191
Test Accuracy: 0.6442307692307693
test_loss: 0.7148902083818729
test_roc_auc: 0.7206101190476191
test_accuracy: 0.6442307692307693
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.7170734703540802
  Validation Loss: 0.6938742399215698
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.71875
Epoch 2/64:
  Train Loss: 0.7162028551101685
  Validation Loss: 0.6933854818344116
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 3/64:
  Train Loss: 0.7154528796672821
  Validation Loss: 0.6929594874382019
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 4/64:
  Train Loss: 0.7148890346288681
  Validation Loss: 0.6927263736724854
  Val ROC-AUC: 0.8352941176470589
  Val Accuracy: 0.71875
Epoch 5/64:
  Train Loss: 0.7143872380256653
  Validation Loss: 0.6925068497657776
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 6/64:
  Train Loss: 0.7139376997947693
  Validation Loss: 0.6922471523284912
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 7/64:
  Train Loss: 0.7134807854890823
  Validation Loss: 0.6920580863952637
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.7130395472049713
  Validation Loss: 0.6919229626655579
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.7126737833023071
  Validation Loss: 0.6916869878768921
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.7122447639703751
  Validation Loss: 0.6913743019104004
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.7118826359510422
  Validation Loss: 0.6911532282829285
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.7115161865949631
  Validation Loss: 0.6909524202346802
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.7111195623874664
  Validation Loss: 0.6907949447631836
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.7106443792581558
  Validation Loss: 0.6905585527420044
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.7101400047540665
  Validation Loss: 0.6903573274612427
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.7097069621086121
  Validation Loss: 0.6902205944061279
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.7092427909374237
  Validation Loss: 0.690047562122345
  Val ROC-AUC: 0.8470588235294119
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.7087277621030807
  Validation Loss: 0.689880907535553
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.7082901298999786
  Validation Loss: 0.6897025108337402
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.7078327089548111
  Validation Loss: 0.6896063089370728
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.7075119465589523
  Validation Loss: 0.6895835399627686
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.7071391493082047
  Validation Loss: 0.6893657445907593
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.706767201423645
  Validation Loss: 0.6891376972198486
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.7064110636711121
  Validation Loss: 0.6889626383781433
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.7061481773853302
  Validation Loss: 0.688878059387207
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.7058099955320358
  Validation Loss: 0.6887580752372742
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.7054619193077087
  Validation Loss: 0.6885169744491577
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.7049819082021713
  Validation Loss: 0.6882696151733398
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.7045267820358276
  Validation Loss: 0.6879739761352539
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.7039554119110107
  Validation Loss: 0.6877111196517944
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 31/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:07:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:07:INFO:
[92mINFO [0m:      Received: evaluate message a9cefebf-b5de-4972-b395-c25d37d70121
02/07/2025 22:33:07:INFO:Received: evaluate message a9cefebf-b5de-4972-b395-c25d37d70121
[92mINFO [0m:      Sent reply
02/07/2025 22:33:10:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:10:INFO:
[92mINFO [0m:      Received: train message 3653efbe-cc66-467d-84aa-e5210cea0d40
02/07/2025 22:33:10:INFO:Received: train message 3653efbe-cc66-467d-84aa-e5210cea0d40
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.7035313993692398
  Validation Loss: 0.6874918937683105
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.7030729949474335
  Validation Loss: 0.6872533559799194
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.7026117146015167
  Validation Loss: 0.6870189309120178
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.7021515965461731
  Validation Loss: 0.6867741346359253
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.7017713785171509
  Validation Loss: 0.6865142583847046
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.7014189064502716
  Validation Loss: 0.6862689256668091
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.70101697742939
  Validation Loss: 0.6859560012817383
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.700506865978241
  Validation Loss: 0.6856642961502075
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.70014289021492
  Validation Loss: 0.6854207515716553
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6997465938329697
  Validation Loss: 0.6851812601089478
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.699304386973381
  Validation Loss: 0.6849725246429443
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6988858133554459
  Validation Loss: 0.6848000288009644
  Val ROC-AUC: 0.8392156862745098
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6984912157058716
  Validation Loss: 0.684675395488739
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6981818974018097
  Validation Loss: 0.684598982334137
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6978543251752853
  Validation Loss: 0.6844254732131958
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6975212097167969
  Validation Loss: 0.684260368347168
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6971305906772614
  Validation Loss: 0.6841533780097961
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6967696696519852
  Validation Loss: 0.6840724945068359
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6964027732610703
  Validation Loss: 0.6840346455574036
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6959936916828156
  Validation Loss: 0.6839172840118408
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6956034451723099
  Validation Loss: 0.6837959289550781
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.6953485012054443
  Validation Loss: 0.6837171316146851
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.6950962543487549
  Validation Loss: 0.683586597442627
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6948531419038773
  Validation Loss: 0.6833992004394531
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.6945506185293198
  Validation Loss: 0.6831927299499512
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6942450851202011
  Validation Loss: 0.6830772161483765
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6940181255340576
  Validation Loss: 0.6829761266708374
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6937836408615112
  Validation Loss: 0.6827560663223267
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6935003101825714
  Validation Loss: 0.6826187372207642
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6932981908321381
  Validation Loss: 0.6824636459350586
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6930825412273407
  Validation Loss: 0.6822780966758728
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6928910613059998
  Validation Loss: 0.6821190118789673
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6926411986351013
  Validation Loss: 0.6820221543312073
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6923891305923462
  Validation Loss: 0.6820278167724609
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.75
{'train_loss': 0.6923891305923462, 'val_roc_auc': 0.8509803921568628, 'val_accuracy': 0.75, 'val_loss': 0.6820278167724609}
 ROC_AUC: 0.8510|| Accuracy 0.7500 || Train Loss: 0.6924
 Val Loss: 0.6820 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7097873358199229
Test ROC-AUC: 0.7436755952380952
Test Accuracy: 0.6538461538461539
test_loss: 0.7097873358199229
test_roc_auc: 0.7436755952380952
test_accuracy: 0.6538461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.7121783345937729
  Validation Loss: 0.6922944784164429
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 2/64:
  Train Loss: 0.712178960442543
  Validation Loss: 0.6921296119689941
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 3/64:
  Train Loss: 0.7118962556123734
  Validation Loss: 0.6917736530303955
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.6875
Epoch 4/64:
  Train Loss: 0.7113971561193466
  Validation Loss: 0.6913933753967285
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.6875
Epoch 5/64:
  Train Loss: 0.7109601497650146
  Validation Loss: 0.6910796165466309
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.6875
Epoch 6/64:
  Train Loss: 0.7105429768562317
  Validation Loss: 0.6908954977989197
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.6875
Epoch 7/64:
  Train Loss: 0.7101080566644669
  Validation Loss: 0.6906790733337402
  Val ROC-AUC: 0.8196078431372549
  Val Accuracy: 0.6875
Epoch 8/64:
  Train Loss: 0.709731936454773
  Validation Loss: 0.6904152631759644
  Val ROC-AUC: 0.8196078431372549
  Val Accuracy: 0.6875
Epoch 9/64:
  Train Loss: 0.7093177139759064
  Validation Loss: 0.6901735067367554
  Val ROC-AUC: 0.8235294117647058
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.7090033441781998
  Validation Loss: 0.6899028420448303
  Val ROC-AUC: 0.8235294117647058
  Val Accuracy: 0.6875
Epoch 11/64:
  Train Loss: 0.7086305320262909
  Validation Loss: 0.6896076798439026
  Val ROC-AUC: 0.8235294117647058
  Val Accuracy: 0.6875
Epoch 12/64:
  Train Loss: 0.7082625180482864
  Validation Loss: 0.6894139051437378
  Val ROC-AUC: 0.8274509803921568
  Val Accuracy: 0.6875
Epoch 13/64:
  Train Loss: 0.7079974412918091
  Validation Loss: 0.6892120838165283
  Val ROC-AUC: 0.8274509803921568
  Val Accuracy: 0.6875
Epoch 14/64:
  Train Loss: 0.7076853364706039
  Validation Loss: 0.6889463663101196
  Val ROC-AUC: 0.8274509803921568
  Val Accuracy: 0.6875
Epoch 15/64:
  Train Loss: 0.707307979464531
  Validation Loss: 0.6886841058731079
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.6875
Epoch 16/64:
  Train Loss: 0.7069854587316513
  Validation Loss: 0.6884528398513794
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.6875
Epoch 17/64:
  Train Loss: 0.7067233473062515
  Validation Loss: 0.6882137060165405
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 18/64:
  Train Loss: 0.7064433097839355
  Validation Loss: 0.6879632472991943
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 19/64:
  Train Loss: 0.7061574012041092
  Validation Loss: 0.6877237558364868
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 20/64:
  Train Loss: 0.7057905793190002
  Validation Loss: 0.6875059604644775
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 21/64:
  Train Loss: 0.7054837048053741
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:22:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:22:INFO:
[92mINFO [0m:      Received: evaluate message 53d33c29-2247-4678-9483-60749dbae6b2
02/07/2025 22:33:22:INFO:Received: evaluate message 53d33c29-2247-4678-9483-60749dbae6b2
[92mINFO [0m:      Sent reply
02/07/2025 22:33:22:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:22:INFO:
[92mINFO [0m:      Received: train message d46aebf8-9808-4be9-849e-06ea2110ad94
02/07/2025 22:33:22:INFO:Received: train message d46aebf8-9808-4be9-849e-06ea2110ad94
  Validation Loss: 0.6872508525848389
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 22/64:
  Train Loss: 0.7051672786474228
  Validation Loss: 0.6869456768035889
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 23/64:
  Train Loss: 0.7047994136810303
  Validation Loss: 0.6865884065628052
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 24/64:
  Train Loss: 0.7043844163417816
  Validation Loss: 0.6862538456916809
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 25/64:
  Train Loss: 0.7040611058473587
  Validation Loss: 0.6859808564186096
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 26/64:
  Train Loss: 0.7037118375301361
  Validation Loss: 0.6856597661972046
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 27/64:
  Train Loss: 0.7033400684595108
  Validation Loss: 0.6854525804519653
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 28/64:
  Train Loss: 0.7030360400676727
  Validation Loss: 0.6851775646209717
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 29/64:
  Train Loss: 0.7026370316743851
  Validation Loss: 0.6849115490913391
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 30/64:
  Train Loss: 0.7022336274385452
  Validation Loss: 0.6847113966941833
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 31/64:
  Train Loss: 0.701949268579483
  Validation Loss: 0.6844815015792847
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 32/64:
  Train Loss: 0.7015523612499237
  Validation Loss: 0.6842832565307617
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.6875
Epoch 33/64:
  Train Loss: 0.7012970596551895
  Validation Loss: 0.6841634511947632
  Val ROC-AUC: 0.8313725490196078
  Val Accuracy: 0.6875
Epoch 34/64:
  Train Loss: 0.7010172605514526
  Validation Loss: 0.6840107440948486
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.6875
Epoch 35/64:
  Train Loss: 0.7007400691509247
  Validation Loss: 0.6837711334228516
  Val ROC-AUC: 0.8352941176470587
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.7003781795501709
  Validation Loss: 0.6835688352584839
  Val ROC-AUC: 0.8392156862745097
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.7000488191843033
  Validation Loss: 0.6834228038787842
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6997424066066742
  Validation Loss: 0.6832547187805176
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6994379758834839
  Validation Loss: 0.6830777525901794
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.699157252907753
  Validation Loss: 0.6829570531845093
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6989339739084244
  Validation Loss: 0.6827923059463501
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6986508220434189
  Validation Loss: 0.6825547814369202
  Val ROC-AUC: 0.8431372549019608
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6983237862586975
  Validation Loss: 0.6823026537895203
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6980366110801697
  Validation Loss: 0.6820802092552185
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6977269351482391
  Validation Loss: 0.6818513870239258
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6974183768033981
  Validation Loss: 0.681567907333374
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6971091032028198
  Validation Loss: 0.6813166737556458
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6968335807323456
  Validation Loss: 0.6811351776123047
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6966032236814499
  Validation Loss: 0.6809041500091553
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6963397115468979
  Validation Loss: 0.6806443929672241
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6960279792547226
  Validation Loss: 0.6803858280181885
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6957400590181351
  Validation Loss: 0.6801267266273499
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6954123824834824
  Validation Loss: 0.6798252463340759
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.695100724697113
  Validation Loss: 0.6795710325241089
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.6947223842144012
  Validation Loss: 0.6792588829994202
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.6943195760250092
  Validation Loss: 0.6789736151695251
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.6939767450094223
  Validation Loss: 0.6787306070327759
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.6936507076025009
  Validation Loss: 0.6784884929656982
  Val ROC-AUC: 0.8509803921568628
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.693353146314621
  Validation Loss: 0.678318977355957
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.6931139081716537
  Validation Loss: 0.6781537532806396
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.6928819119930267
  Validation Loss: 0.678040623664856
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6926765143871307
  Validation Loss: 0.6779341697692871
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6924943923950195
  Validation Loss: 0.6779025793075562
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6923850774765015
  Validation Loss: 0.6778706908226013
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
{'train_loss': 0.6923850774765015, 'val_roc_auc': 0.8549019607843138, 'val_accuracy': 0.71875, 'val_loss': 0.6778706908226013}
 ROC_AUC: 0.8549|| Accuracy 0.7188 || Train Loss: 0.6924
 Val Loss: 0.6779 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.7044996086221474
Test ROC-AUC: 0.7648809523809523
Test Accuracy: 0.6826923076923077
test_loss: 0.7044996086221474
test_roc_auc: 0.7648809523809523
test_accuracy: 0.6826923076923077
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6922856867313385
  Validation Loss: 0.7492131590843201
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.625
Epoch 2/64:
  Train Loss: 0.6920724809169769
  Validation Loss: 0.7487787008285522
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.625
Epoch 3/64:
  Train Loss: 0.6917729377746582
  Validation Loss: 0.7484098076820374
  Val ROC-AUC: 0.7449392712550608
  Val Accuracy: 0.625
Epoch 4/64:
  Train Loss: 0.6913788765668869
  Validation Loss: 0.7481081485748291
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.625
Epoch 5/64:
  Train Loss: 0.6909833252429962
  Validation Loss: 0.7478851079940796
  Val ROC-AUC: 0.7489878542510122
  Val Accuracy: 0.625
Epoch 6/64:
  Train Loss: 0.6905787438154221
  Validation Loss: 0.7477742433547974
  Val ROC-AUC: 0.7530364372469636
  Val Accuracy: 0.625
Epoch 7/64:
  Train Loss: 0.6902225911617279
  Validation Loss: 0.7475919723510742
  Val ROC-AUC: 0.7570850202429151
  Val Accuracy: 0.625
Epoch 8/64:
  Train Loss: 0.6897895485162735
  Validation Loss: 0.7473442554473877
  Val ROC-AUC: 0.7611336032388666
  Val Accuracy: 0.625
Epoch 9/64:
  Train Loss: 0.6894029378890991
  Validation Loss: 0.7471281290054321
  Val ROC-AUC: 0.7611336032388666
  Val Accuracy: 0.625
Epoch 10/64:
  Train Loss: 0.6890955120325089
  Validation Loss: 0.7469049096107483
  Val ROC-AUC: 0.7611336032388666
  Val Accuracy: 0.625
Epoch 11/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:33:INFO:
[92mINFO [0m:      Received: evaluate message 879efb26-88e1-436a-bc90-46019dc7efa7
02/07/2025 22:33:33:INFO:Received: evaluate message 879efb26-88e1-436a-bc90-46019dc7efa7
[92mINFO [0m:      Sent reply
02/07/2025 22:33:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:34:INFO:
[92mINFO [0m:      Received: train message 956ee4e8-eaef-4695-b578-1a25bf06e305
02/07/2025 22:33:34:INFO:Received: train message 956ee4e8-eaef-4695-b578-1a25bf06e305
  Train Loss: 0.6887793093919754
  Validation Loss: 0.746695876121521
  Val ROC-AUC: 0.7611336032388666
  Val Accuracy: 0.625
Epoch 12/64:
  Train Loss: 0.6884297877550125
  Validation Loss: 0.7465672492980957
  Val ROC-AUC: 0.7611336032388666
  Val Accuracy: 0.625
Epoch 13/64:
  Train Loss: 0.6881332844495773
  Validation Loss: 0.7463856935501099
  Val ROC-AUC: 0.7611336032388666
  Val Accuracy: 0.625
Epoch 14/64:
  Train Loss: 0.6877884715795517
  Validation Loss: 0.7461385130882263
  Val ROC-AUC: 0.7611336032388666
  Val Accuracy: 0.625
Epoch 15/64:
  Train Loss: 0.6874579042196274
  Validation Loss: 0.7458800077438354
  Val ROC-AUC: 0.7611336032388666
  Val Accuracy: 0.625
Epoch 16/64:
  Train Loss: 0.6871307343244553
  Validation Loss: 0.7456926107406616
  Val ROC-AUC: 0.7611336032388666
  Val Accuracy: 0.625
Epoch 17/64:
  Train Loss: 0.6867413520812988
  Validation Loss: 0.7454621195793152
  Val ROC-AUC: 0.7611336032388666
  Val Accuracy: 0.625
Epoch 18/64:
  Train Loss: 0.6862799525260925
  Validation Loss: 0.7452428340911865
  Val ROC-AUC: 0.7651821862348179
  Val Accuracy: 0.625
Epoch 19/64:
  Train Loss: 0.6858973801136017
  Validation Loss: 0.7449915409088135
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.625
Epoch 20/64:
  Train Loss: 0.6854666620492935
  Validation Loss: 0.7447219491004944
  Val ROC-AUC: 0.7692307692307693
  Val Accuracy: 0.625
Epoch 21/64:
  Train Loss: 0.6851090043783188
  Validation Loss: 0.7444714307785034
  Val ROC-AUC: 0.7732793522267206
  Val Accuracy: 0.625
Epoch 22/64:
  Train Loss: 0.6847447901964188
  Validation Loss: 0.7441343069076538
  Val ROC-AUC: 0.7773279352226721
  Val Accuracy: 0.625
Epoch 23/64:
  Train Loss: 0.6843628138303757
  Validation Loss: 0.7437978982925415
  Val ROC-AUC: 0.7773279352226721
  Val Accuracy: 0.625
Epoch 24/64:
  Train Loss: 0.6839963793754578
  Validation Loss: 0.7435071468353271
  Val ROC-AUC: 0.7813765182186235
  Val Accuracy: 0.625
Epoch 25/64:
  Train Loss: 0.6836234331130981
  Validation Loss: 0.7432326078414917
  Val ROC-AUC: 0.7813765182186235
  Val Accuracy: 0.625
Epoch 26/64:
  Train Loss: 0.6832384020090103
  Validation Loss: 0.7430448532104492
  Val ROC-AUC: 0.7813765182186235
  Val Accuracy: 0.625
Epoch 27/64:
  Train Loss: 0.6828337013721466
  Validation Loss: 0.7428415417671204
  Val ROC-AUC: 0.7854251012145749
  Val Accuracy: 0.625
Epoch 28/64:
  Train Loss: 0.6824652999639511
  Validation Loss: 0.7426644563674927
  Val ROC-AUC: 0.7854251012145749
  Val Accuracy: 0.625
Epoch 29/64:
  Train Loss: 0.682078942656517
  Validation Loss: 0.7424613237380981
  Val ROC-AUC: 0.7854251012145749
  Val Accuracy: 0.625
Epoch 30/64:
  Train Loss: 0.681779533624649
  Validation Loss: 0.7422201633453369
  Val ROC-AUC: 0.7813765182186235
  Val Accuracy: 0.625
Epoch 31/64:
  Train Loss: 0.6814151853322983
  Validation Loss: 0.7419435381889343
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.625
Epoch 32/64:
  Train Loss: 0.6811095029115677
  Validation Loss: 0.7416661977767944
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.625
Epoch 33/64:
  Train Loss: 0.6807666718959808
  Validation Loss: 0.7413957118988037
  Val ROC-AUC: 0.7935222672064778
  Val Accuracy: 0.625
Epoch 34/64:
  Train Loss: 0.6804518699645996
  Validation Loss: 0.7412433624267578
  Val ROC-AUC: 0.7935222672064778
  Val Accuracy: 0.625
Epoch 35/64:
  Train Loss: 0.6802891194820404
  Validation Loss: 0.7411249876022339
  Val ROC-AUC: 0.7935222672064778
  Val Accuracy: 0.625
Epoch 36/64:
  Train Loss: 0.6801135987043381
  Validation Loss: 0.7409329414367676
  Val ROC-AUC: 0.7975708502024291
  Val Accuracy: 0.625
Epoch 37/64:
  Train Loss: 0.6798638254404068
  Validation Loss: 0.7406967282295227
  Val ROC-AUC: 0.7975708502024291
  Val Accuracy: 0.625
Epoch 38/64:
  Train Loss: 0.679628998041153
  Validation Loss: 0.7404754161834717
  Val ROC-AUC: 0.7975708502024291
  Val Accuracy: 0.625
Epoch 39/64:
  Train Loss: 0.6794366538524628
  Validation Loss: 0.7403031587600708
  Val ROC-AUC: 0.8016194331983806
  Val Accuracy: 0.625
Epoch 40/64:
  Train Loss: 0.6792439520359039
  Validation Loss: 0.740175724029541
  Val ROC-AUC: 0.8016194331983806
  Val Accuracy: 0.625
Epoch 41/64:
  Train Loss: 0.6790804713964462
  Validation Loss: 0.7401098012924194
  Val ROC-AUC: 0.8016194331983806
  Val Accuracy: 0.625
Epoch 42/64:
  Train Loss: 0.6789640188217163
  Validation Loss: 0.7400264739990234
  Val ROC-AUC: 0.8016194331983806
  Val Accuracy: 0.625
Epoch 43/64:
  Train Loss: 0.6789143830537796
  Validation Loss: 0.7399201989173889
  Val ROC-AUC: 0.8016194331983806
  Val Accuracy: 0.625
Epoch 44/64:
  Train Loss: 0.6788051128387451
  Validation Loss: 0.739794135093689
  Val ROC-AUC: 0.8016194331983806
  Val Accuracy: 0.625
Epoch 45/64:
  Train Loss: 0.6786541640758514
  Validation Loss: 0.7396996021270752
  Val ROC-AUC: 0.8016194331983806
  Val Accuracy: 0.625
Epoch 46/64:
  Train Loss: 0.6785077601671219
  Validation Loss: 0.7396063208580017
  Val ROC-AUC: 0.7975708502024292
  Val Accuracy: 0.625
Epoch 47/64:
  Train Loss: 0.6782689541578293
  Validation Loss: 0.7395811080932617
  Val ROC-AUC: 0.8016194331983806
  Val Accuracy: 0.625
Epoch 48/64:
  Train Loss: 0.6780577898025513
  Validation Loss: 0.739539384841919
  Val ROC-AUC: 0.7975708502024291
  Val Accuracy: 0.625
Epoch 49/64:
  Train Loss: 0.677825540304184
  Validation Loss: 0.7394282221794128
  Val ROC-AUC: 0.7975708502024291
  Val Accuracy: 0.625
Epoch 50/64:
  Train Loss: 0.6775546371936798
  Validation Loss: 0.7393292188644409
  Val ROC-AUC: 0.7935222672064778
  Val Accuracy: 0.625
Epoch 51/64:
  Train Loss: 0.677356481552124
  Validation Loss: 0.7392603158950806
  Val ROC-AUC: 0.7935222672064778
  Val Accuracy: 0.625
Epoch 52/64:
  Train Loss: 0.6771643459796906
  Validation Loss: 0.7392324209213257
  Val ROC-AUC: 0.7935222672064778
  Val Accuracy: 0.625
Epoch 53/64:
  Train Loss: 0.6769078075885773
  Validation Loss: 0.7392227053642273
  Val ROC-AUC: 0.7935222672064778
  Val Accuracy: 0.65625
Epoch 54/64:
  Train Loss: 0.6766298562288284
  Validation Loss: 0.7391839027404785
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.65625
Epoch 55/64:
  Train Loss: 0.6764853447675705
  Validation Loss: 0.739179253578186
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.65625
Epoch 56/64:
  Train Loss: 0.6762979328632355
  Validation Loss: 0.739109456539154
  Val ROC-AUC: 0.785425101214575
  Val Accuracy: 0.65625
Epoch 57/64:
  Train Loss: 0.6760739386081696
  Validation Loss: 0.7389751076698303
  Val ROC-AUC: 0.785425101214575
  Val Accuracy: 0.65625
Epoch 58/64:
  Train Loss: 0.6759030222892761
  Validation Loss: 0.7388883829116821
  Val ROC-AUC: 0.785425101214575
  Val Accuracy: 0.65625
Epoch 59/64:
  Train Loss: 0.6757832020521164
  Validation Loss: 0.7387493252754211
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.65625
Epoch 60/64:
  Train Loss: 0.6755996942520142
  Validation Loss: 0.7386443614959717
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.65625
Epoch 61/64:
  Train Loss: 0.675465777516365
  Validation Loss: 0.7385045886039734
  Val ROC-AUC: 0.7935222672064778
  Val Accuracy: 0.65625
Epoch 62/64:
  Train Loss: 0.6752975732088089
  Validation Loss: 0.7382788062095642
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.65625
Epoch 63/64:
  Train Loss: 0.675103634595871
  Validation Loss: 0.7380986213684082
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.65625
Epoch 64/64:
  Train Loss: 0.6748722046613693
  Validation Loss: 0.7379677295684814
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.65625
{'train_loss': 0.6748722046613693, 'val_roc_auc': 0.7894736842105263, 'val_accuracy': 0.65625, 'val_loss': 0.7379677295684814}
 ROC_AUC: 0.7895|| Accuracy 0.6562 || Train Loss: 0.6749
 Val Loss: 0.7380 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6993210373016504
Test ROC-AUC: 0.7849702380952381
Test Accuracy: 0.7211538461538461
test_loss: 0.6993210373016504
test_roc_auc: 0.7849702380952381
test_accuracy: 0.7211538461538461
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.7007412165403366
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6938129663467407
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.71875
Epoch 2/64:
  Train Loss: 0.7006793916225433
  Validation Loss: 0.6937004327774048
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.6875
Epoch 3/64:
  Train Loss: 0.7005479484796524
  Validation Loss: 0.693583071231842
  Val ROC-AUC: 0.8549019607843138
  Val Accuracy: 0.6875
Epoch 4/64:
  Train Loss: 0.7003643661737442
  Validation Loss: 0.6933948993682861
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.6875
Epoch 5/64:
  Train Loss: 0.7001723051071167
  Validation Loss: 0.6932015419006348
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 6/64:
  Train Loss: 0.6999725699424744
  Validation Loss: 0.6931458711624146
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 7/64:
  Train Loss: 0.699843019247055
  Validation Loss: 0.6931315660476685
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.6996573060750961
  Validation Loss: 0.6930872201919556
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.6994280815124512
  Validation Loss: 0.693006157875061
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.6991337835788727
  Validation Loss: 0.6928495168685913
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.6987801939249039
  Validation Loss: 0.692694902420044
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.6984218508005142
  Validation Loss: 0.6925104856491089
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6980946958065033
  Validation Loss: 0.692292332649231
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6978780627250671
  Validation Loss: 0.6921377182006836
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6977237462997437
  Validation Loss: 0.691962718963623
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6975273340940475
  Validation Loss: 0.6918046474456787
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6973171383142471
  Validation Loss: 0.6915926337242126
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6970262974500656
  Validation Loss: 0.6913981437683105
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6966846287250519
  Validation Loss: 0.6912781596183777
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6964828073978424
  Validation Loss: 0.6912389993667603
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6963816434144974
  Validation Loss: 0.691209077835083
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6962331235408783
  Validation Loss: 0.6911176443099976
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6960223764181137
  Validation Loss: 0.691055953502655
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6957964450120926
  Validation Loss: 0.6909887194633484
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6955469101667404
  Validation Loss: 0.690865159034729
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.695348858833313
  Validation Loss: 0.6907838582992554
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6951002180576324
  Validation Loss: 0.690585196018219
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.69484943151474
  Validation Loss: 0.6903358101844788
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6945576667785645
  Validation Loss: 0.6901329755783081
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.694313108921051
  Validation Loss: 0.6899646520614624
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6941103935241699
  Validation Loss: 0.6897857189178467
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6939211040735245
  Validation Loss: 0.6896495819091797
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.693723127245903
  Validation Loss: 0.6895070672035217
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.693516418337822
  Validation Loss: 0.6893104314804077
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6933306306600571
  Validation Loss: 0.6890934109687805
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.693190410733223
  Validation Loss: 0.6889442205429077
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6930055767297745
  Validation Loss: 0.6887245774269104
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6927428394556046
  Validation Loss: 0.6884551048278809
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.6875
Epoch 39/64:
  Train Loss: 0.692464604973793
  Validation Loss: 0.6882255673408508
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.6875
Epoch 40/64:
  Train Loss: 0.6922557353973389
  Validation Loss: 0.6880824565887451
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.6875
Epoch 41/64:
  Train Loss: 0.6921101808547974
  Validation Loss: 0.6879359483718872
  Val ROC-AUC: 0.8627450980392156
  Val Accuracy: 0.6875
Epoch 42/64:
  Train Loss: 0.6919015944004059
  Validation Loss: 0.6878425478935242
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 43/64:
  Train Loss: 0.6917283236980438
  Validation Loss: 0.6877022981643677
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 44/64:
  Train Loss: 0.6915317624807358
  Validation Loss: 0.6874751448631287
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 45/64:
  Train Loss: 0.6913110464811325
  Validation Loss: 0.687265157699585
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 46/64:
  Train Loss: 0.691062405705452
  Validation Loss: 0.6870747208595276
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 47/64:
  Train Loss: 0.6907766759395599
  Validation Loss: 0.6868233680725098
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 48/64:
  Train Loss: 0.6904457062482834
  Validation Loss: 0.6865906119346619
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 49/64:
  Train Loss: 0.690179318189621
  Validation Loss: 0.6864190101623535
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 50/64:
  Train Loss: 0.6899700164794922
  Validation Loss: 0.6863129138946533
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 51/64:
  Train Loss: 0.6898097544908524
  Validation Loss: 0.6861693859100342
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 52/64:
  Train Loss: 0.6895916163921356
  Validation Loss: 0.6859927177429199
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 53/64:
  Train Loss: 0.6893807053565979
  Validation Loss: 0.6858844757080078
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 54/64:
  Train Loss: 0.6892146319150925
  Validation Loss: 0.6857266426086426
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 55/64:
  Train Loss: 0.6889760345220566
  Validation Loss: 0.6855964064598083
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 56/64:
  Train Loss: 0.6887924522161484
  Validation Loss: 0.685455322265625
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 57/64:
  Train Loss: 0.6886158585548401
  Validation Loss: 0.6852275133132935
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 58/64:
  Train Loss: 0.6884204298257828
  Validation Loss: 0.6850644946098328
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 59/64:
  Train Loss: 0.6882613152265549
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:44:INFO:
[92mINFO [0m:      Received: evaluate message 7801ccf4-f212-4b2d-b1b3-dfc873d7583f
02/07/2025 22:33:44:INFO:Received: evaluate message 7801ccf4-f212-4b2d-b1b3-dfc873d7583f
[92mINFO [0m:      Sent reply
02/07/2025 22:33:46:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:46:INFO:
[92mINFO [0m:      Received: train message 9ea7ca76-242b-418e-80f5-8addff81425f
02/07/2025 22:33:46:INFO:Received: train message 9ea7ca76-242b-418e-80f5-8addff81425f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6849316358566284
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 60/64:
  Train Loss: 0.6881322860717773
  Validation Loss: 0.6848498582839966
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 61/64:
  Train Loss: 0.6879964172840118
  Validation Loss: 0.6847581267356873
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 62/64:
  Train Loss: 0.6878404170274734
  Validation Loss: 0.6846284866333008
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 63/64:
  Train Loss: 0.6876159310340881
  Validation Loss: 0.6845216751098633
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
Epoch 64/64:
  Train Loss: 0.6874098032712936
  Validation Loss: 0.6844280958175659
  Val ROC-AUC: 0.8666666666666666
  Val Accuracy: 0.6875
{'train_loss': 0.6874098032712936, 'val_roc_auc': 0.8666666666666666, 'val_accuracy': 0.6875, 'val_loss': 0.6844280958175659}
 ROC_AUC: 0.8667|| Accuracy 0.6875 || Train Loss: 0.6874
 Val Loss: 0.6844 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6943300913732785
Test ROC-AUC: 0.8046875
Test Accuracy: 0.7403846153846154
test_loss: 0.6943300913732785
test_roc_auc: 0.8046875
test_accuracy: 0.7403846153846154
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.7012220919132233
  Validation Loss: 0.6707642078399658
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 2/64:
  Train Loss: 0.7008588463068008
  Validation Loss: 0.6705355048179626
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 3/64:
  Train Loss: 0.7003786265850067
  Validation Loss: 0.670369029045105
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 4/64:
  Train Loss: 0.7000111043453217
  Validation Loss: 0.6702648997306824
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.71875
Epoch 5/64:
  Train Loss: 0.6997248381376266
  Validation Loss: 0.670233964920044
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.6875
Epoch 6/64:
  Train Loss: 0.6994740515947342
  Validation Loss: 0.6701464653015137
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.6875
Epoch 7/64:
  Train Loss: 0.699144572019577
  Validation Loss: 0.669917106628418
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.6875
Epoch 8/64:
  Train Loss: 0.6987439543008804
  Validation Loss: 0.6698108315467834
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.6875
Epoch 9/64:
  Train Loss: 0.6985248923301697
  Validation Loss: 0.6696348190307617
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.6982647627592087
  Validation Loss: 0.6695113778114319
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.6980926543474197
  Validation Loss: 0.6694406867027283
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.6979372054338455
  Validation Loss: 0.6694127321243286
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6977590322494507
  Validation Loss: 0.6693667769432068
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6975793540477753
  Validation Loss: 0.6693878173828125
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6974851191043854
  Validation Loss: 0.6694144606590271
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6974010467529297
  Validation Loss: 0.6694213151931763
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6972666233778
  Validation Loss: 0.6693729162216187
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6971374303102493
  Validation Loss: 0.6692550182342529
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6969898343086243
  Validation Loss: 0.6692056655883789
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.696925014257431
  Validation Loss: 0.6692072749137878
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.69685959815979
  Validation Loss: 0.6692396402359009
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6967577338218689
  Validation Loss: 0.6692193746566772
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6965427994728088
  Validation Loss: 0.6690503358840942
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6962597221136093
  Validation Loss: 0.6687963008880615
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6959760636091232
  Validation Loss: 0.6685894727706909
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.6957265287637711
  Validation Loss: 0.6683727502822876
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6954252123832703
  Validation Loss: 0.6681942343711853
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.6951772421598434
  Validation Loss: 0.668033242225647
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6949506103992462
  Validation Loss: 0.6679650545120239
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6947784721851349
  Validation Loss: 0.6679279804229736
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6945692598819733
  Validation Loss: 0.6678376793861389
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.694372147321701
  Validation Loss: 0.6677365899085999
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6940851509571075
  Validation Loss: 0.6675366759300232
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6937452554702759
  Validation Loss: 0.6673460006713867
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.78125
Epoch 35/64:
  Train Loss: 0.6935298144817352
  Validation Loss: 0.6671109199523926
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.78125
Epoch 36/64:
  Train Loss: 0.6932402998209
  Validation Loss: 0.6668434143066406
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.78125
Epoch 37/64:
  Train Loss: 0.6930174380540848
  Validation Loss: 0.6666532754898071
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.6927992105484009
  Validation Loss: 0.6666092872619629
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6926709115505219
  Validation Loss: 0.6665314435958862
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6925520896911621
  Validation Loss: 0.6664478778839111
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6924203932285309
  Validation Loss: 0.6662930250167847
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6922808587551117
  Validation Loss: 0.6661560535430908
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6921862363815308
  Validation Loss: 0.6660761833190918
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6921116560697556
  Validation Loss: 0.665925145149231
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6919531524181366
  Validation Loss: 0.6656926870346069
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6916704475879669
  Validation Loss: 0.6653491258621216
  Val ROC-AUC: 0.828125
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6913864761590958
  Validation Loss: 0.6650170087814331
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.69107785820961
  Validation Loss: 0.664815366268158
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6908079832792282
  Validation Loss: 0.6646108627319336
  Val ROC-AUC: 0.83203125
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6905827522277832
  Validation Loss: 0.664402186870575
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6904099881649017
  Validation Loss: 0.6641926169395447
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6903647929430008
  Validation Loss: 0.6640459299087524
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:58:INFO:
[92mINFO [0m:      Received: evaluate message 6eaa12a7-174e-4a04-98a6-f3fffb1ec4a3
02/07/2025 22:33:58:INFO:Received: evaluate message 6eaa12a7-174e-4a04-98a6-f3fffb1ec4a3
[92mINFO [0m:      Sent reply
02/07/2025 22:34:02:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:02:INFO:
[92mINFO [0m:      Received: train message f5045604-0eed-499c-9e98-de52c602e59a
02/07/2025 22:34:02:INFO:Received: train message f5045604-0eed-499c-9e98-de52c602e59a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6903251856565475
  Validation Loss: 0.6639500856399536
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.6902334541082382
  Validation Loss: 0.6638268232345581
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.6901332885026932
  Validation Loss: 0.6636595726013184
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.6899630427360535
  Validation Loss: 0.6635451316833496
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.6898340433835983
  Validation Loss: 0.6634120941162109
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.6897093057632446
  Validation Loss: 0.663259744644165
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.6895983070135117
  Validation Loss: 0.6631443500518799
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.6894679665565491
  Validation Loss: 0.6629772782325745
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.6892648041248322
  Validation Loss: 0.6628991365432739
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6891104876995087
  Validation Loss: 0.6628590226173401
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6889352798461914
  Validation Loss: 0.6628727316856384
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6888003498315811
  Validation Loss: 0.6628868579864502
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
{'train_loss': 0.6888003498315811, 'val_roc_auc': 0.83984375, 'val_accuracy': 0.71875, 'val_loss': 0.6628868579864502}
 ROC_AUC: 0.8398|| Accuracy 0.7188 || Train Loss: 0.6888
 Val Loss: 0.6629 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6895404744606751
Test ROC-AUC: 0.8191964285714285
Test Accuracy: 0.7692307692307693
test_loss: 0.6895404744606751
test_roc_auc: 0.8191964285714285
test_accuracy: 0.7692307692307693
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6923086494207382
  Validation Loss: 0.6860822439193726
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 2/64:
  Train Loss: 0.6921336650848389
  Validation Loss: 0.6858193874359131
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.6918885856866837
  Validation Loss: 0.6855992078781128
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.691662535071373
  Validation Loss: 0.6854066252708435
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.6914240717887878
  Validation Loss: 0.6851190328598022
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.6911518424749374
  Validation Loss: 0.6847751140594482
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6908068507909775
  Validation Loss: 0.684394121170044
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6905325353145599
  Validation Loss: 0.6841954588890076
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6903302222490311
  Validation Loss: 0.6839418411254883
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.690073236823082
  Validation Loss: 0.6836299896240234
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6897988766431808
  Validation Loss: 0.6832388639450073
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6895082294940948
  Validation Loss: 0.6828083395957947
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6891762912273407
  Validation Loss: 0.6823651790618896
  Val ROC-AUC: 0.9166666666666667
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6889295130968094
  Validation Loss: 0.6820704936981201
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6887641102075577
  Validation Loss: 0.6818921566009521
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6885567456483841
  Validation Loss: 0.6816584467887878
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.688359722495079
  Validation Loss: 0.6814059019088745
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6881132423877716
  Validation Loss: 0.6811838150024414
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6878437548875809
  Validation Loss: 0.680995523929596
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6876071393489838
  Validation Loss: 0.6808279752731323
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6873869150876999
  Validation Loss: 0.6806105971336365
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.687201738357544
  Validation Loss: 0.6804338097572327
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6870148777961731
  Validation Loss: 0.6802864074707031
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6868563443422318
  Validation Loss: 0.680237889289856
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6867766082286835
  Validation Loss: 0.6802403926849365
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6867441833019257
  Validation Loss: 0.6803020238876343
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6868116408586502
  Validation Loss: 0.6804269552230835
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6868707537651062
  Validation Loss: 0.6805287599563599
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6868866086006165
  Validation Loss: 0.680646538734436
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6868171244859695
  Validation Loss: 0.6805773973464966
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6866734474897385
  Validation Loss: 0.680414617061615
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6864942908287048
  Validation Loss: 0.6801527142524719
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6863064020872116
  Validation Loss: 0.6799139380455017
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6861503273248672
  Validation Loss: 0.6797430515289307
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6860036849975586
  Validation Loss: 0.679561972618103
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6859425157308578
  Validation Loss: 0.6795052886009216
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.685885950922966
  Validation Loss: 0.6794575452804565
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6857605874538422
  Validation Loss: 0.6793165802955627
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6856062263250351
  Validation Loss: 0.6791117787361145
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.685443177819252
  Validation Loss: 0.67891526222229
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 41/64:
  Train Loss: 0.685311809182167
  Validation Loss: 0.6787195205688477
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 42/64:
  Train Loss: 0.6851623207330704
  Validation Loss: 0.6785035729408264
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 43/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:10:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:10:INFO:
[92mINFO [0m:      Received: evaluate message be6bb85f-c108-4c3c-bb53-f97aac6997d7
02/07/2025 22:34:10:INFO:Received: evaluate message be6bb85f-c108-4c3c-bb53-f97aac6997d7
[92mINFO [0m:      Sent reply
02/07/2025 22:34:10:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:11:INFO:
[92mINFO [0m:      Received: train message dbded07d-99de-4c9d-8a2d-96d6576cb728
02/07/2025 22:34:11:INFO:Received: train message dbded07d-99de-4c9d-8a2d-96d6576cb728
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6849516779184341
  Validation Loss: 0.6782985925674438
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 44/64:
  Train Loss: 0.684728354215622
  Validation Loss: 0.6780690550804138
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 45/64:
  Train Loss: 0.6844631731510162
  Validation Loss: 0.6778348684310913
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 46/64:
  Train Loss: 0.684263065457344
  Validation Loss: 0.6776635646820068
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 47/64:
  Train Loss: 0.6840764731168747
  Validation Loss: 0.6775020956993103
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 48/64:
  Train Loss: 0.6839139461517334
  Validation Loss: 0.6773974895477295
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 49/64:
  Train Loss: 0.6837696880102158
  Validation Loss: 0.6771496534347534
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 50/64:
  Train Loss: 0.6835970431566238
  Validation Loss: 0.6767756342887878
  Val ROC-AUC: 0.9206349206349207
  Val Accuracy: 0.875
Epoch 51/64:
  Train Loss: 0.6834043711423874
  Validation Loss: 0.6764931678771973
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
Epoch 52/64:
  Train Loss: 0.6832131296396255
  Validation Loss: 0.6761961579322815
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 53/64:
  Train Loss: 0.6829677522182465
  Validation Loss: 0.6759319305419922
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 54/64:
  Train Loss: 0.6827639192342758
  Validation Loss: 0.6757447123527527
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 55/64:
  Train Loss: 0.6825639009475708
  Validation Loss: 0.6755210161209106
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 56/64:
  Train Loss: 0.6823037713766098
  Validation Loss: 0.6752365827560425
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 57/64:
  Train Loss: 0.6820959001779556
  Validation Loss: 0.6749812364578247
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 58/64:
  Train Loss: 0.6818787157535553
  Validation Loss: 0.6747037768363953
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 59/64:
  Train Loss: 0.681629866361618
  Validation Loss: 0.6744253635406494
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 60/64:
  Train Loss: 0.6814161688089371
  Validation Loss: 0.6742216348648071
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 61/64:
  Train Loss: 0.6812018603086472
  Validation Loss: 0.674004077911377
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 62/64:
  Train Loss: 0.681005209684372
  Validation Loss: 0.6738790273666382
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 63/64:
  Train Loss: 0.6807804554700851
  Validation Loss: 0.6735622882843018
  Val ROC-AUC: 0.9246031746031746
  Val Accuracy: 0.875
Epoch 64/64:
  Train Loss: 0.6805469244718552
  Validation Loss: 0.6733226776123047
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.875
{'train_loss': 0.6805469244718552, 'val_roc_auc': 0.9285714285714286, 'val_accuracy': 0.875, 'val_loss': 0.6733226776123047}
 ROC_AUC: 0.9286|| Accuracy 0.8750 || Train Loss: 0.6805
 Val Loss: 0.6733 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6850663280257812
Test ROC-AUC: 0.8348214285714286
Test Accuracy: 0.7788461538461539
test_loss: 0.6850663280257812
test_roc_auc: 0.8348214285714286
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6956039667129517
  Validation Loss: 0.6537270545959473
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 2/64:
  Train Loss: 0.6952397227287292
  Validation Loss: 0.6532691121101379
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.6948940604925156
  Validation Loss: 0.6530309319496155
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6946993917226791
  Validation Loss: 0.6527688503265381
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.6944735944271088
  Validation Loss: 0.6524863839149475
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6942233294248581
  Validation Loss: 0.6522841453552246
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.6940097659826279
  Validation Loss: 0.6521611213684082
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.6938206255435944
  Validation Loss: 0.6520814895629883
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6936861425638199
  Validation Loss: 0.6520190238952637
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6935822516679764
  Validation Loss: 0.6519032716751099
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.693430483341217
  Validation Loss: 0.651880145072937
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6933686286211014
  Validation Loss: 0.6518638134002686
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6933128982782364
  Validation Loss: 0.6517848968505859
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6931967586278915
  Validation Loss: 0.6516125202178955
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6929900497198105
  Validation Loss: 0.6513152718544006
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.692637026309967
  Validation Loss: 0.6510270237922668
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6923234462738037
  Validation Loss: 0.6507785320281982
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6920391321182251
  Validation Loss: 0.6505887508392334
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.691820502281189
  Validation Loss: 0.6503952741622925
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6915029436349869
  Validation Loss: 0.650151789188385
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6911509782075882
  Validation Loss: 0.6499043703079224
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6907993853092194
  Validation Loss: 0.6497000455856323
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6905725449323654
  Validation Loss: 0.6496009826660156
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6903412193059921
  Validation Loss: 0.6494821906089783
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6901423782110214
  Validation Loss: 0.6494663953781128
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6900244355201721
  Validation Loss: 0.6493927240371704
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6898510456085205
  Validation Loss: 0.6493037939071655
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6896688044071198
  Validation Loss: 0.6491022706031799
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6893839240074158
  Validation Loss: 0.6488454341888428
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6891156584024429
  Validation Loss: 0.6486101150512695
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6888645142316818
  Validation Loss: 0.6483525633811951
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6885911077260971
  Validation Loss: 0.6480876803398132
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 33/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:18:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:18:INFO:
[92mINFO [0m:      Received: evaluate message 0c1aba52-b31b-4341-bfef-201a735762a3
02/07/2025 22:34:18:INFO:Received: evaluate message 0c1aba52-b31b-4341-bfef-201a735762a3
[92mINFO [0m:      Sent reply
02/07/2025 22:34:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:19:INFO:
[92mINFO [0m:      Received: train message 73d550aa-151e-46dd-9860-86a4f6a8232b
02/07/2025 22:34:19:INFO:Received: train message 73d550aa-151e-46dd-9860-86a4f6a8232b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6883197277784348
  Validation Loss: 0.6478542685508728
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.688070610165596
  Validation Loss: 0.6475965976715088
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.687832847237587
  Validation Loss: 0.6473597288131714
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6876187771558762
  Validation Loss: 0.6472471952438354
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.687443271279335
  Validation Loss: 0.6471928358078003
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6872530877590179
  Validation Loss: 0.6471059322357178
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6869858205318451
  Validation Loss: 0.6470162272453308
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6868158429861069
  Validation Loss: 0.6468994617462158
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6866306811571121
  Validation Loss: 0.6468274593353271
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6864634454250336
  Validation Loss: 0.6467634439468384
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.686320349574089
  Validation Loss: 0.6466752886772156
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6861738115549088
  Validation Loss: 0.6466259360313416
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.6860683113336563
  Validation Loss: 0.646592378616333
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6859553158283234
  Validation Loss: 0.6465439796447754
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.6857690364122391
  Validation Loss: 0.6464105248451233
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6855456233024597
  Validation Loss: 0.6463319063186646
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6853527128696442
  Validation Loss: 0.6461819410324097
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.6851812154054642
  Validation Loss: 0.6460932493209839
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.6850653290748596
  Validation Loss: 0.6459858417510986
  Val ROC-AUC: 0.9450980392156862
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.6849130690097809
  Validation Loss: 0.6458630561828613
  Val ROC-AUC: 0.9490196078431372
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6847636103630066
  Validation Loss: 0.6456878781318665
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.6846122443675995
  Validation Loss: 0.6455587148666382
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.6844563335180283
  Validation Loss: 0.6454089879989624
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.6843345761299133
  Validation Loss: 0.6453521251678467
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.6842255741357803
  Validation Loss: 0.6452584266662598
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.6841438412666321
  Validation Loss: 0.6451683044433594
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6840828955173492
  Validation Loss: 0.6450836658477783
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.84375
Epoch 60/64:
  Train Loss: 0.6839789003133774
  Validation Loss: 0.6450278162956238
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6839267909526825
  Validation Loss: 0.6449507474899292
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.6837874948978424
  Validation Loss: 0.644842267036438
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.6836173683404922
  Validation Loss: 0.6448166370391846
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6835165023803711
  Validation Loss: 0.6447317004203796
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8125
{'train_loss': 0.6835165023803711, 'val_roc_auc': 0.9529411764705882, 'val_accuracy': 0.8125, 'val_loss': 0.6447317004203796}
 ROC_AUC: 0.9529|| Accuracy 0.8125 || Train Loss: 0.6835
 Val Loss: 0.6447 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6807962610171392
Test ROC-AUC: 0.8381696428571429
Test Accuracy: 0.8076923076923077
test_loss: 0.6807962610171392
test_roc_auc: 0.8381696428571429
test_accuracy: 0.8076923076923077
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6957809329032898
  Validation Loss: 0.635701596736908
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6954619437456131
  Validation Loss: 0.6354053616523743
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6951469779014587
  Validation Loss: 0.6350854635238647
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.6948205977678299
  Validation Loss: 0.6347271203994751
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.694482147693634
  Validation Loss: 0.6344550848007202
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.6941637098789215
  Validation Loss: 0.6342175006866455
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.78125
Epoch 7/64:
  Train Loss: 0.6939241886138916
  Validation Loss: 0.6340276002883911
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.78125
Epoch 8/64:
  Train Loss: 0.6936847120523453
  Validation Loss: 0.6338574290275574
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.693492591381073
  Validation Loss: 0.6337240934371948
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6933219134807587
  Validation Loss: 0.6336274147033691
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 11/64:
  Train Loss: 0.6931073665618896
  Validation Loss: 0.63349449634552
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.6927780359983444
  Validation Loss: 0.6332796812057495
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.6924524009227753
  Validation Loss: 0.6330685019493103
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 14/64:
  Train Loss: 0.6922087371349335
  Validation Loss: 0.6329109072685242
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 15/64:
  Train Loss: 0.6920101791620255
  Validation Loss: 0.6328302025794983
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 16/64:
  Train Loss: 0.6918652504682541
  Validation Loss: 0.6327760815620422
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.6917480379343033
  Validation Loss: 0.6326826810836792
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.6916036754846573
  Validation Loss: 0.6325799226760864
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6915233731269836
  Validation Loss: 0.6325005292892456
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6914092749357224
  Validation Loss: 0.6324871778488159
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 21/64:
  Train Loss: 0.6913946568965912
  Validation Loss: 0.6324591636657715
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 22/64:
  Train Loss: 0.6913457363843918
  Validation Loss: 0.6323713064193726
  Val ROC-AUC: 0.9058823529411766
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:26:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:26:INFO:
[92mINFO [0m:      Received: evaluate message d62b3208-a81a-42bc-bb5d-80981396c33f
02/07/2025 22:34:26:INFO:Received: evaluate message d62b3208-a81a-42bc-bb5d-80981396c33f
[92mINFO [0m:      Sent reply
02/07/2025 22:34:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:28:INFO:
[92mINFO [0m:      Received: train message e296d20c-202b-4ead-8f31-db0bbde3337e
02/07/2025 22:34:28:INFO:Received: train message e296d20c-202b-4ead-8f31-db0bbde3337e
  Val Accuracy: 0.8125
Epoch 23/64:
  Train Loss: 0.691337987780571
  Validation Loss: 0.6323837041854858
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 24/64:
  Train Loss: 0.691349446773529
  Validation Loss: 0.6324504613876343
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 25/64:
  Train Loss: 0.6914191246032715
  Validation Loss: 0.6324983835220337
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 26/64:
  Train Loss: 0.6914602220058441
  Validation Loss: 0.6324840784072876
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 27/64:
  Train Loss: 0.6914112865924835
  Validation Loss: 0.6324431896209717
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 28/64:
  Train Loss: 0.6913240551948547
  Validation Loss: 0.6324450969696045
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.8125
Epoch 29/64:
  Train Loss: 0.6912561655044556
  Validation Loss: 0.63236403465271
  Val ROC-AUC: 0.9137254901960785
  Val Accuracy: 0.8125
Epoch 30/64:
  Train Loss: 0.6910608261823654
  Validation Loss: 0.6322271823883057
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 31/64:
  Train Loss: 0.6908637434244156
  Validation Loss: 0.6320798397064209
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 32/64:
  Train Loss: 0.6906789094209671
  Validation Loss: 0.6319576501846313
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 33/64:
  Train Loss: 0.6905706375837326
  Validation Loss: 0.6318820714950562
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 34/64:
  Train Loss: 0.6904239654541016
  Validation Loss: 0.6317992210388184
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6902755051851273
  Validation Loss: 0.631740927696228
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.6901222616434097
  Validation Loss: 0.6316626071929932
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6899389028549194
  Validation Loss: 0.6316045522689819
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6897955536842346
  Validation Loss: 0.6315672397613525
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6896965652704239
  Validation Loss: 0.6315442323684692
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.6896268725395203
  Validation Loss: 0.6315215826034546
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6895388066768646
  Validation Loss: 0.6314685344696045
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6894468367099762
  Validation Loss: 0.6314523220062256
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6894003450870514
  Validation Loss: 0.6313859820365906
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.6893748342990875
  Validation Loss: 0.6313195824623108
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6893109083175659
  Validation Loss: 0.6312277317047119
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.689201295375824
  Validation Loss: 0.6311919689178467
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6890770941972733
  Validation Loss: 0.6311272978782654
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6889539062976837
  Validation Loss: 0.6310504674911499
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6888399571180344
  Validation Loss: 0.631000280380249
  Val ROC-AUC: 0.9098039215686275
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.6887247860431671
  Validation Loss: 0.6309971809387207
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.6886279433965683
  Validation Loss: 0.6309638619422913
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.6885019093751907
  Validation Loss: 0.6309184432029724
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.6883325725793839
  Validation Loss: 0.6308541297912598
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6881570369005203
  Validation Loss: 0.6308292746543884
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6880456656217575
  Validation Loss: 0.630845308303833
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6879296600818634
  Validation Loss: 0.6308556795120239
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.6877613365650177
  Validation Loss: 0.6308506727218628
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.6875845491886139
  Validation Loss: 0.6307933926582336
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6874391585588455
  Validation Loss: 0.6307770013809204
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.687252089381218
  Validation Loss: 0.6307030320167542
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6870894432067871
  Validation Loss: 0.6305785179138184
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6868925988674164
  Validation Loss: 0.6304660439491272
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6867409497499466
  Validation Loss: 0.6302834153175354
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6866113394498825
  Validation Loss: 0.6301956176757812
  Val ROC-AUC: 0.9058823529411766
  Val Accuracy: 0.78125
{'train_loss': 0.6866113394498825, 'val_roc_auc': 0.9058823529411766, 'val_accuracy': 0.78125, 'val_loss': 0.6301956176757812}
 ROC_AUC: 0.9059|| Accuracy 0.7812 || Train Loss: 0.6866
 Val Loss: 0.6302 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6766937280503603
Test ROC-AUC: 0.8478422619047619
Test Accuracy: 0.7980769230769231
test_loss: 0.6766937280503603
test_roc_auc: 0.8478422619047619
test_accuracy: 0.7980769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6877327263355255
  Validation Loss: 0.6517940759658813
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6873297989368439
  Validation Loss: 0.6515388488769531
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6870049387216568
  Validation Loss: 0.651249885559082
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.6867097020149231
  Validation Loss: 0.6510083079338074
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.6865061670541763
  Validation Loss: 0.6508234739303589
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.6862564831972122
  Validation Loss: 0.6505900621414185
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 7/64:
  Train Loss: 0.6860059797763824
  Validation Loss: 0.650364875793457
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 8/64:
  Train Loss: 0.6857466995716095
  Validation Loss: 0.6501889228820801
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 9/64:
  Train Loss: 0.6855156719684601
  Validation Loss: 0.6500232815742493
  Val ROC-AUC: 0.9098039215686273
  Val Accuracy: 0.78125
Epoch 10/64:
  Train Loss: 0.6852881759405136
  Validation Loss: 0.6498664617538452
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.78125
Epoch 11/64:
  Train Loss: 0.6849994212388992
  Validation Loss: 0.6497262716293335
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.78125
Epoch 12/64:
  Train Loss: 0.6847173720598221
  Validation Loss: 0.6496386528015137
  Val ROC-AUC: 0.9058823529411764/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:33:INFO:
[92mINFO [0m:      Received: evaluate message 15c6b6e7-a9a7-4a08-9626-277e5c9ffd1c
02/07/2025 22:34:33:INFO:Received: evaluate message 15c6b6e7-a9a7-4a08-9626-277e5c9ffd1c
[92mINFO [0m:      Sent reply
02/07/2025 22:34:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:33:INFO:
[92mINFO [0m:      Received: train message 0f72cbad-fe05-47a4-ab6f-428c0019c7ae
02/07/2025 22:34:33:INFO:Received: train message 0f72cbad-fe05-47a4-ab6f-428c0019c7ae

  Val Accuracy: 0.78125
Epoch 13/64:
  Train Loss: 0.6845412850379944
  Validation Loss: 0.6495029330253601
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.78125
Epoch 14/64:
  Train Loss: 0.684304416179657
  Validation Loss: 0.6492930054664612
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.78125
Epoch 15/64:
  Train Loss: 0.6840128302574158
  Validation Loss: 0.649066686630249
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.78125
Epoch 16/64:
  Train Loss: 0.683732807636261
  Validation Loss: 0.6489526033401489
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.6835006028413773
  Validation Loss: 0.6488572359085083
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.6832581162452698
  Validation Loss: 0.6487548351287842
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6830279231071472
  Validation Loss: 0.6486680507659912
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6828015446662903
  Validation Loss: 0.6486450433731079
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
Epoch 21/64:
  Train Loss: 0.6825953871011734
  Validation Loss: 0.6486070156097412
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 22/64:
  Train Loss: 0.6824329197406769
  Validation Loss: 0.6485404968261719
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 23/64:
  Train Loss: 0.6822803914546967
  Validation Loss: 0.6484326124191284
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 24/64:
  Train Loss: 0.6821096837520599
  Validation Loss: 0.6483328342437744
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 25/64:
  Train Loss: 0.6819611638784409
  Validation Loss: 0.6482626795768738
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 26/64:
  Train Loss: 0.6818107962608337
  Validation Loss: 0.6481854915618896
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 27/64:
  Train Loss: 0.6816991567611694
  Validation Loss: 0.648146390914917
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 28/64:
  Train Loss: 0.6816839128732681
  Validation Loss: 0.6481388807296753
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 29/64:
  Train Loss: 0.6816418766975403
  Validation Loss: 0.6480753421783447
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 30/64:
  Train Loss: 0.6815602332353592
  Validation Loss: 0.6479750871658325
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 31/64:
  Train Loss: 0.6814077645540237
  Validation Loss: 0.6479002237319946
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 32/64:
  Train Loss: 0.6812760233879089
  Validation Loss: 0.6477930545806885
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 33/64:
  Train Loss: 0.6811007857322693
  Validation Loss: 0.6476478576660156
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 34/64:
  Train Loss: 0.6808974891901016
  Validation Loss: 0.6474732160568237
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6806938201189041
  Validation Loss: 0.6473153829574585
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.6805239319801331
  Validation Loss: 0.6472194790840149
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6804013848304749
  Validation Loss: 0.6471250057220459
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6802456974983215
  Validation Loss: 0.6470467448234558
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6801175177097321
  Validation Loss: 0.6469430923461914
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.679913654923439
  Validation Loss: 0.646820068359375
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6797256916761398
  Validation Loss: 0.6467002630233765
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6795289814472198
  Validation Loss: 0.6465332508087158
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6792878657579422
  Validation Loss: 0.6463459730148315
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.6791295558214188
  Validation Loss: 0.6462209224700928
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6789313703775406
  Validation Loss: 0.6461463570594788
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6787268668413162
  Validation Loss: 0.6460179090499878
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6785015016794205
  Validation Loss: 0.6458633542060852
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6782714575529099
  Validation Loss: 0.6457762122154236
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6781273931264877
  Validation Loss: 0.6456970572471619
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.677953764796257
  Validation Loss: 0.6456024646759033
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.6777264475822449
  Validation Loss: 0.6455450057983398
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.6775667369365692
  Validation Loss: 0.6454766988754272
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.6773731410503387
  Validation Loss: 0.645361602306366
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6771311014890671
  Validation Loss: 0.6452068090438843
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6768814921379089
  Validation Loss: 0.6450752019882202
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6767011284828186
  Validation Loss: 0.6449683904647827
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.6765106022357941
  Validation Loss: 0.6448867917060852
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.676370695233345
  Validation Loss: 0.644784688949585
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.67624831199646
  Validation Loss: 0.6446918845176697
  Val ROC-AUC: 0.8980392156862744
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6762411445379257
  Validation Loss: 0.6446042060852051
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 61/64:
  Train Loss: 0.6762252002954483
  Validation Loss: 0.6444990038871765
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 62/64:
  Train Loss: 0.6761254519224167
  Validation Loss: 0.6443561911582947
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 63/64:
  Train Loss: 0.675977498292923
  Validation Loss: 0.6442054510116577
  Val ROC-AUC: 0.9019607843137254
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6758638769388199
  Validation Loss: 0.6440715193748474
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8125
{'train_loss': 0.6758638769388199, 'val_roc_auc': 0.9058823529411764, 'val_accuracy': 0.8125, 'val_loss': 0.6440715193748474}
 ROC_AUC: 0.9059|| Accuracy 0.8125 || Train Loss: 0.6759
 Val Loss: 0.6441 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6727262465999677
Test ROC-AUC: 0.8575148809523809
Test Accuracy: 0.7884615384615384
test_loss: 0.6727262465999677
test_roc_auc: 0.8575148809523809
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6631419807672501
  Validation Loss: 0.7361839413642883
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6628212332725525
  Validation Loss: 0.7359859943389893
  Val ROC-AUC: 0.8614718614718615
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.662463366985321
  Validation Loss: 0.7358392477035522
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6622367799282074
  Validation Loss: 0.7356854677200317
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.662013828754425
  Validation Loss: 0.735703706741333
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6618971526622772
  Validation Loss: 0.7356943488121033
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.6618115156888962
  Validation Loss: 0.7356037497520447
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.6616870164871216
  Validation Loss: 0.7355639338493347
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6615896821022034
  Validation Loss: 0.7354875802993774
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6614560931921005
  Validation Loss: 0.7353618144989014
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 11/64:
  Train Loss: 0.6613434106111526
  Validation Loss: 0.7353079319000244
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.661299079656601
  Validation Loss: 0.7352697849273682
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.6612486988306046
  Validation Loss: 0.7352821826934814
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 14/64:
  Train Loss: 0.6612153053283691
  Validation Loss: 0.7352176904678345
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 15/64:
  Train Loss: 0.6611471921205521
  Validation Loss: 0.7350926399230957
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 16/64:
  Train Loss: 0.6610741019248962
  Validation Loss: 0.7349292039871216
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.661004364490509
  Validation Loss: 0.7347227931022644
  Val ROC-AUC: 0.8658008658008659
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.660904049873352
  Validation Loss: 0.7345399856567383
  Val ROC-AUC: 0.8701298701298702
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6607995480298996
  Validation Loss: 0.7343353033065796
  Val ROC-AUC: 0.8701298701298702
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6606728732585907
  Validation Loss: 0.734251856803894
  Val ROC-AUC: 0.8701298701298702
  Val Accuracy: 0.8125
Epoch 21/64:
  Train Loss: 0.6606291085481644
  Validation Loss: 0.7342549562454224
  Val ROC-AUC: 0.8701298701298702
  Val Accuracy: 0.8125
Epoch 22/64:
  Train Loss: 0.6606091856956482
  Validation Loss: 0.7343237400054932
  Val ROC-AUC: 0.8701298701298702
  Val Accuracy: 0.8125
Epoch 23/64:
  Train Loss: 0.6605782061815262
  Validation Loss: 0.73441481590271
  Val ROC-AUC: 0.8701298701298702
  Val Accuracy: 0.8125
Epoch 24/64:
  Train Loss: 0.6605490297079086
  Validation Loss: 0.7345017194747925
  Val ROC-AUC: 0.8701298701298702
  Val Accuracy: 0.8125
Epoch 25/64:
  Train Loss: 0.6604818403720856
  Validation Loss: 0.7344897389411926
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.8125
Epoch 26/64:
  Train Loss: 0.6604118943214417
  Validation Loss: 0.7345303297042847
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.8125
Epoch 27/64:
  Train Loss: 0.6603737324476242
  Validation Loss: 0.7345818877220154
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.8125
Epoch 28/64:
  Train Loss: 0.6603084951639175
  Validation Loss: 0.734539270401001
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.8125
Epoch 29/64:
  Train Loss: 0.6602015942335129
  Validation Loss: 0.7344210147857666
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 30/64:
  Train Loss: 0.6600582748651505
  Validation Loss: 0.7342891693115234
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 31/64:
  Train Loss: 0.6599423438310623
  Validation Loss: 0.7341550588607788
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 32/64:
  Train Loss: 0.6598488688468933
  Validation Loss: 0.7340457439422607
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 33/64:
  Train Loss: 0.6597971320152283
  Validation Loss: 0.7339960336685181
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 34/64:
  Train Loss: 0.6597343236207962
  Validation Loss: 0.7338919043540955
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6596499085426331
  Validation Loss: 0.7337807416915894
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.6595754325389862
  Validation Loss: 0.7336763739585876
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6594775319099426
  Validation Loss: 0.733647346496582
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.659385621547699
  Validation Loss: 0.7336503863334656
  Val ROC-AUC: 0.8658008658008658
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.659349262714386
  Validation Loss: 0.7337230443954468
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.6592999249696732
  Validation Loss: 0.7338205575942993
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.659256786108017
  Validation Loss: 0.7339560985565186
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6591894924640656
  Validation Loss: 0.7339940071105957
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6591188609600067
  Validation Loss: 0.7339928150177002
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.6590979099273682
  Validation Loss: 0.7339999675750732
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.659116268157959
  Validation Loss: 0.7339637279510498
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6590896397829056
  Validation Loss: 0.73394775390625
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6590999960899353
  Validation Loss: 0.7340022325515747
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6591795980930328
  Validation Loss: 0.7341001629829407
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6592230200767517
  Validation Loss: 0.734136700630188
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.6591498404741287
  Validation Loss: 0.7341223955154419
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.65911865234375
  Validation Loss: 0.7341259717941284
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.6591222435235977
  Validation Loss: 0.734143853187561
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.6591836363077164
  Validation Loss: 0.7341495156288147
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6592910885810852
  Validation Loss: 0.7341315150260925
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6593724638223648
  Validation Loss: 0.7341389656066895
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6594308167695999
  Validation Loss: 0.7341576814651489
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.659416064620018
  Validation Loss: 0.7341634035110474
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.6593496054410934
  Validation Loss: 0.7341955304145813
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6592796146869659
  Validation Loss: 0.7342323064804077
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6592535674571991
  Validation Loss: 0.7343152761459351
  Val ROC-AUC: 0.8614718614718615
  Val Accuracy: 0.8125
Epoch 61/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:38:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:38:INFO:
[92mINFO [0m:      Received: evaluate message c3896b97-d1f2-45a5-b074-58b3bd0b070c
02/07/2025 22:34:38:INFO:Received: evaluate message c3896b97-d1f2-45a5-b074-58b3bd0b070c
[92mINFO [0m:      Sent reply
02/07/2025 22:34:39:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:39:INFO:
[92mINFO [0m:      Received: train message 8da7e027-2b7a-4083-a96a-e4538ce3807a
02/07/2025 22:34:39:INFO:Received: train message 8da7e027-2b7a-4083-a96a-e4538ce3807a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.659194141626358
  Validation Loss: 0.7342208027839661
  Val ROC-AUC: 0.8571428571428571
  Val Accuracy: 0.8125
Epoch 62/64:
  Train Loss: 0.6591342687606812
  Validation Loss: 0.7341746091842651
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.8125
Epoch 63/64:
  Train Loss: 0.6590868681669235
  Validation Loss: 0.7340907454490662
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6590136289596558
  Validation Loss: 0.7340046763420105
  Val ROC-AUC: 0.8528138528138528
  Val Accuracy: 0.8125
{'train_loss': 0.6590136289596558, 'val_roc_auc': 0.8528138528138528, 'val_accuracy': 0.8125, 'val_loss': 0.7340046763420105}
 ROC_AUC: 0.8528|| Accuracy 0.8125 || Train Loss: 0.6590
 Val Loss: 0.7340 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6692004610712712
Test ROC-AUC: 0.8608630952380952
Test Accuracy: 0.7884615384615384
test_loss: 0.6692004610712712
test_roc_auc: 0.8608630952380952
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6786114722490311
  Validation Loss: 0.6618379354476929
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6785158812999725
  Validation Loss: 0.6616387367248535
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6784539073705673
  Validation Loss: 0.6614031791687012
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.6783483177423477
  Validation Loss: 0.6612657308578491
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.6782348603010178
  Validation Loss: 0.6611508727073669
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.67813441157341
  Validation Loss: 0.6609644889831543
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.6780504882335663
  Validation Loss: 0.6608504056930542
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.6780399084091187
  Validation Loss: 0.6608244180679321
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 9/64:
  Train Loss: 0.6780420690774918
  Validation Loss: 0.6608352065086365
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 10/64:
  Train Loss: 0.6780584752559662
  Validation Loss: 0.6608130931854248
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 11/64:
  Train Loss: 0.6780225783586502
  Validation Loss: 0.6607335805892944
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.6779550015926361
  Validation Loss: 0.6606518626213074
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.6778522431850433
  Validation Loss: 0.6605826616287231
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 14/64:
  Train Loss: 0.6777955591678619
  Validation Loss: 0.6605014801025391
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 15/64:
  Train Loss: 0.6777517199516296
  Validation Loss: 0.6604632139205933
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 16/64:
  Train Loss: 0.6776941865682602
  Validation Loss: 0.6604375839233398
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 17/64:
  Train Loss: 0.6776133924722672
  Validation Loss: 0.6604340672492981
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 18/64:
  Train Loss: 0.6775398701429367
  Validation Loss: 0.6604433059692383
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 19/64:
  Train Loss: 0.6774616241455078
  Validation Loss: 0.6604502201080322
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 20/64:
  Train Loss: 0.6773626953363419
  Validation Loss: 0.6604530811309814
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 21/64:
  Train Loss: 0.6772850453853607
  Validation Loss: 0.6604232788085938
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 22/64:
  Train Loss: 0.67722088098526
  Validation Loss: 0.6603959798812866
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.78125
Epoch 23/64:
  Train Loss: 0.6771489977836609
  Validation Loss: 0.660308837890625
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.75
Epoch 24/64:
  Train Loss: 0.6770420521497726
  Validation Loss: 0.6601730585098267
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.75
Epoch 25/64:
  Train Loss: 0.6768416911363602
  Validation Loss: 0.6600064039230347
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.75
Epoch 26/64:
  Train Loss: 0.6766573637723923
  Validation Loss: 0.6599358320236206
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.75
Epoch 27/64:
  Train Loss: 0.67646524310112
  Validation Loss: 0.6598982810974121
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.6762860119342804
  Validation Loss: 0.6598401069641113
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.6760774552822113
  Validation Loss: 0.6597434878349304
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6758896559476852
  Validation Loss: 0.6596220135688782
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6757253259420395
  Validation Loss: 0.6596047282218933
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.6756397783756256
  Validation Loss: 0.6596065759658813
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6755640208721161
  Validation Loss: 0.659565806388855
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6754722595214844
  Validation Loss: 0.6594574451446533
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 35/64:
  Train Loss: 0.6753553748130798
  Validation Loss: 0.6592931747436523
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 36/64:
  Train Loss: 0.6752105057239532
  Validation Loss: 0.6591364145278931
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.6750781089067459
  Validation Loss: 0.6590040922164917
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.6749361008405685
  Validation Loss: 0.6588958501815796
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6748018264770508
  Validation Loss: 0.6587808728218079
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6746578961610794
  Validation Loss: 0.6586583256721497
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.674466073513031
  Validation Loss: 0.6585671305656433
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.6743508130311966
  Validation Loss: 0.6585347652435303
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.75
Epoch 43/64:
  Train Loss: 0.6742698848247528
  Validation Loss: 0.6584553122520447
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.75
Epoch 44/64:
  Train Loss: 0.6741327196359634
  Validation Loss: 0.6582985520362854
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.75
Epoch 45/64:
  Train Loss: 0.6739548891782761
  Validation Loss: 0.6581522226333618
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 46/64:
  Train Loss: 0.6737524569034576
  Validation Loss: 0.6580135822296143
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 47/64:
  Train Loss: 0.6735302209854126
  Validation Loss: 0.657913863658905
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 48/64:
  Train Loss: 0.6733747869729996
  Validation Loss: 0.6577916145324707
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 49/64:
  Train Loss: 0.6732320785522461
  Validation Loss: 0.657585620880127
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 50/64:
  Train Loss: 0.6730629503726959
  Validation Loss: 0.6574258208274841
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 51/64:
  Train Loss: 0.6729155033826828
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:44:INFO:
[92mINFO [0m:      Received: evaluate message 4eded181-fbbe-4b5e-80cb-148f8cc09ff2
02/07/2025 22:34:44:INFO:Received: evaluate message 4eded181-fbbe-4b5e-80cb-148f8cc09ff2
[92mINFO [0m:      Sent reply
02/07/2025 22:34:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:44:INFO:
[92mINFO [0m:      Received: train message 6bcad79e-6a2f-4adf-86fe-d30dd2f1428c
02/07/2025 22:34:44:INFO:Received: train message 6bcad79e-6a2f-4adf-86fe-d30dd2f1428c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6572552919387817
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 52/64:
  Train Loss: 0.672733724117279
  Validation Loss: 0.6571227312088013
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 53/64:
  Train Loss: 0.672603040933609
  Validation Loss: 0.6570360660552979
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 54/64:
  Train Loss: 0.6724633425474167
  Validation Loss: 0.6568929553031921
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 55/64:
  Train Loss: 0.672285869717598
  Validation Loss: 0.656711757183075
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 56/64:
  Train Loss: 0.6721298396587372
  Validation Loss: 0.6566009521484375
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 57/64:
  Train Loss: 0.6719909757375717
  Validation Loss: 0.6565067172050476
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 58/64:
  Train Loss: 0.6719141155481339
  Validation Loss: 0.6565011739730835
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 59/64:
  Train Loss: 0.6718915104866028
  Validation Loss: 0.6564689874649048
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 60/64:
  Train Loss: 0.6718621701002121
  Validation Loss: 0.6563994884490967
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 61/64:
  Train Loss: 0.6717600971460342
  Validation Loss: 0.6562861800193787
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 62/64:
  Train Loss: 0.6716344654560089
  Validation Loss: 0.6561204195022583
  Val ROC-AUC: 0.8862745098039215
  Val Accuracy: 0.75
Epoch 63/64:
  Train Loss: 0.6715440452098846
  Validation Loss: 0.6560420989990234
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.75
Epoch 64/64:
  Train Loss: 0.6714984625577927
  Validation Loss: 0.6559340953826904
  Val ROC-AUC: 0.8901960784313725
  Val Accuracy: 0.75
{'train_loss': 0.6714984625577927, 'val_roc_auc': 0.8901960784313725, 'val_accuracy': 0.75, 'val_loss': 0.6559340953826904}
 ROC_AUC: 0.8902|| Accuracy 0.7500 || Train Loss: 0.6715
 Val Loss: 0.6559 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6660322655852025
Test ROC-AUC: 0.8664434523809523
Test Accuracy: 0.7884615384615384
test_loss: 0.6660322655852025
test_roc_auc: 0.8664434523809523
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6771927922964096
  Validation Loss: 0.6556786298751831
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 2/64:
  Train Loss: 0.6769093722105026
  Validation Loss: 0.6557357311248779
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 3/64:
  Train Loss: 0.676847904920578
  Validation Loss: 0.6557161211967468
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 4/64:
  Train Loss: 0.6767828315496445
  Validation Loss: 0.6557279825210571
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 5/64:
  Train Loss: 0.6767049878835678
  Validation Loss: 0.6556351184844971
  Val ROC-AUC: 0.7960784313725491
  Val Accuracy: 0.65625
Epoch 6/64:
  Train Loss: 0.676625207066536
  Validation Loss: 0.6555358171463013
  Val ROC-AUC: 0.8
  Val Accuracy: 0.65625
Epoch 7/64:
  Train Loss: 0.6765073537826538
  Validation Loss: 0.6553841233253479
  Val ROC-AUC: 0.8
  Val Accuracy: 0.65625
Epoch 8/64:
  Train Loss: 0.6763582974672318
  Validation Loss: 0.655252993106842
  Val ROC-AUC: 0.8
  Val Accuracy: 0.65625
Epoch 9/64:
  Train Loss: 0.6761849820613861
  Validation Loss: 0.6551035642623901
  Val ROC-AUC: 0.8
  Val Accuracy: 0.65625
Epoch 10/64:
  Train Loss: 0.6759133785963058
  Validation Loss: 0.6548929810523987
  Val ROC-AUC: 0.8
  Val Accuracy: 0.65625
Epoch 11/64:
  Train Loss: 0.6756927669048309
  Validation Loss: 0.654775857925415
  Val ROC-AUC: 0.8
  Val Accuracy: 0.65625
Epoch 12/64:
  Train Loss: 0.6755573749542236
  Validation Loss: 0.6547421216964722
  Val ROC-AUC: 0.8
  Val Accuracy: 0.65625
Epoch 13/64:
  Train Loss: 0.6754820942878723
  Validation Loss: 0.6547156572341919
  Val ROC-AUC: 0.8
  Val Accuracy: 0.65625
Epoch 14/64:
  Train Loss: 0.6753975003957748
  Validation Loss: 0.6547164916992188
  Val ROC-AUC: 0.8
  Val Accuracy: 0.65625
Epoch 15/64:
  Train Loss: 0.6753417253494263
  Validation Loss: 0.6546752452850342
  Val ROC-AUC: 0.8
  Val Accuracy: 0.65625
Epoch 16/64:
  Train Loss: 0.6752259135246277
  Validation Loss: 0.6545524597167969
  Val ROC-AUC: 0.803921568627451
  Val Accuracy: 0.65625
Epoch 17/64:
  Train Loss: 0.6750482320785522
  Validation Loss: 0.6544049978256226
  Val ROC-AUC: 0.803921568627451
  Val Accuracy: 0.65625
Epoch 18/64:
  Train Loss: 0.6749362051486969
  Validation Loss: 0.6542826294898987
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 19/64:
  Train Loss: 0.6748501807451248
  Validation Loss: 0.6541070938110352
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 20/64:
  Train Loss: 0.6747837215662003
  Validation Loss: 0.6539402008056641
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 21/64:
  Train Loss: 0.6746211796998978
  Validation Loss: 0.6537747979164124
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 22/64:
  Train Loss: 0.6744743585586548
  Validation Loss: 0.6536306142807007
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 23/64:
  Train Loss: 0.6743344962596893
  Validation Loss: 0.6535093188285828
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 24/64:
  Train Loss: 0.674180880188942
  Validation Loss: 0.6534138321876526
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 25/64:
  Train Loss: 0.6740427315235138
  Validation Loss: 0.6533139944076538
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 26/64:
  Train Loss: 0.6739291548728943
  Validation Loss: 0.653189480304718
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 27/64:
  Train Loss: 0.6738494783639908
  Validation Loss: 0.6530405282974243
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 28/64:
  Train Loss: 0.673757404088974
  Validation Loss: 0.652885377407074
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 29/64:
  Train Loss: 0.6736321598291397
  Validation Loss: 0.6527019739151001
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 30/64:
  Train Loss: 0.6734054833650589
  Validation Loss: 0.6525636315345764
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 31/64:
  Train Loss: 0.673214390873909
  Validation Loss: 0.6524944305419922
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 32/64:
  Train Loss: 0.6730707883834839
  Validation Loss: 0.6524631977081299
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 33/64:
  Train Loss: 0.6729220151901245
  Validation Loss: 0.6523868441581726
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 34/64:
  Train Loss: 0.6727567911148071
  Validation Loss: 0.6522312164306641
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 35/64:
  Train Loss: 0.672539621591568
  Validation Loss: 0.652068555355072
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 36/64:
  Train Loss: 0.6723381727933884
  Validation Loss: 0.6519367098808289
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 37/64:
  Train Loss: 0.6721637099981308
  Validation Loss: 0.651711642742157
  Val ROC-AUC: 0.8117647058823529
  Val Accuracy: 0.65625
Epoch 38/64:
  Train Loss: 0.6719606816768646
  Validation Loss: 0.6515250205993652
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 39/64:
  Train Loss: 0.6718273460865021
  Validation Loss: 0.6513718366622925
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 40/64:
  Train Loss: 0.6716860234737396
  Validation Loss: 0.6512820720672607
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 41/64:
  Train Loss: 0.6715700924396515
  Validation Loss: 0.6512316465377808
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 42/64:
  Train Loss: 0.6714460104703903
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:48:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:48:INFO:
[92mINFO [0m:      Received: evaluate message ec493d9e-4a72-4eb1-b808-e5e067b604ca
02/07/2025 22:34:48:INFO:Received: evaluate message ec493d9e-4a72-4eb1-b808-e5e067b604ca
[92mINFO [0m:      Sent reply
02/07/2025 22:34:49:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:49:INFO:
[92mINFO [0m:      Received: train message 421a674b-99e0-4b47-a1d1-2cf2e4844a7f
02/07/2025 22:34:49:INFO:Received: train message 421a674b-99e0-4b47-a1d1-2cf2e4844a7f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6511298418045044
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 43/64:
  Train Loss: 0.6713907867670059
  Validation Loss: 0.6510078310966492
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 44/64:
  Train Loss: 0.6712862849235535
  Validation Loss: 0.6508843302726746
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 45/64:
  Train Loss: 0.6711794137954712
  Validation Loss: 0.6507670879364014
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 46/64:
  Train Loss: 0.6710826903581619
  Validation Loss: 0.6506586670875549
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 47/64:
  Train Loss: 0.6710244417190552
  Validation Loss: 0.6505900621414185
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 48/64:
  Train Loss: 0.6709805279970169
  Validation Loss: 0.650610089302063
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 49/64:
  Train Loss: 0.6709657311439514
  Validation Loss: 0.6506804823875427
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 50/64:
  Train Loss: 0.6709355264902115
  Validation Loss: 0.6507667899131775
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 51/64:
  Train Loss: 0.6709664016962051
  Validation Loss: 0.6508783102035522
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 52/64:
  Train Loss: 0.6709809750318527
  Validation Loss: 0.6509628295898438
  Val ROC-AUC: 0.807843137254902
  Val Accuracy: 0.65625
Epoch 53/64:
  Train Loss: 0.6709990948438644
  Validation Loss: 0.6510272026062012
  Val ROC-AUC: 0.803921568627451
  Val Accuracy: 0.65625
Epoch 54/64:
  Train Loss: 0.670979306101799
  Validation Loss: 0.6510774493217468
  Val ROC-AUC: 0.803921568627451
  Val Accuracy: 0.65625
Epoch 55/64:
  Train Loss: 0.6709685772657394
  Validation Loss: 0.6511249542236328
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.65625
Epoch 56/64:
  Train Loss: 0.6709000915288925
  Validation Loss: 0.651107668876648
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.65625
Epoch 57/64:
  Train Loss: 0.6708162277936935
  Validation Loss: 0.6510598659515381
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.65625
Epoch 58/64:
  Train Loss: 0.6707791239023209
  Validation Loss: 0.6509627103805542
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.65625
Epoch 59/64:
  Train Loss: 0.6707116067409515
  Validation Loss: 0.6509100198745728
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.65625
Epoch 60/64:
  Train Loss: 0.6706104576587677
  Validation Loss: 0.650830090045929
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.65625
Epoch 61/64:
  Train Loss: 0.6704908907413483
  Validation Loss: 0.6507477164268494
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.65625
Epoch 62/64:
  Train Loss: 0.6703381091356277
  Validation Loss: 0.6508009433746338
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.65625
Epoch 63/64:
  Train Loss: 0.6702465116977692
  Validation Loss: 0.6508498191833496
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.65625
Epoch 64/64:
  Train Loss: 0.6701462417840958
  Validation Loss: 0.6508842706680298
  Val ROC-AUC: 0.7999999999999999
  Val Accuracy: 0.65625
{'train_loss': 0.6701462417840958, 'val_roc_auc': 0.7999999999999999, 'val_accuracy': 0.65625, 'val_loss': 0.6508842706680298}
 ROC_AUC: 0.8000|| Accuracy 0.6562 || Train Loss: 0.6701
 Val Loss: 0.6509 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6631916635311567
Test ROC-AUC: 0.8701636904761905
Test Accuracy: 0.7884615384615384
test_loss: 0.6631916635311567
test_roc_auc: 0.8701636904761905
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.683888167142868
  Validation Loss: 0.6190933585166931
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 2/64:
  Train Loss: 0.6839112639427185
  Validation Loss: 0.6192389726638794
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.6838779449462891
  Validation Loss: 0.6193587779998779
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.683793231844902
  Validation Loss: 0.6194047331809998
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.6836903542280197
  Validation Loss: 0.6194243431091309
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.6836130321025848
  Validation Loss: 0.619418740272522
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6834940910339355
  Validation Loss: 0.6193372011184692
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6834372729063034
  Validation Loss: 0.6193564534187317
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6833710670471191
  Validation Loss: 0.6193506121635437
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6832373142242432
  Validation Loss: 0.6193159818649292
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6831511855125427
  Validation Loss: 0.6192612648010254
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6831006407737732
  Validation Loss: 0.619224488735199
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6830534785985947
  Validation Loss: 0.6192261576652527
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6830395460128784
  Validation Loss: 0.6192221641540527
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6830258965492249
  Validation Loss: 0.6192399263381958
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6829816401004791
  Validation Loss: 0.6192478537559509
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6830044388771057
  Validation Loss: 0.6192680597305298
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6830154210329056
  Validation Loss: 0.6192299127578735
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6829542368650436
  Validation Loss: 0.6191315650939941
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6827979236841202
  Validation Loss: 0.6189801692962646
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6825935244560242
  Validation Loss: 0.6188294291496277
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6823741495609283
  Validation Loss: 0.6187065839767456
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6821860820055008
  Validation Loss: 0.6185763478279114
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6820092350244522
  Validation Loss: 0.6184775233268738
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6818183362483978
  Validation Loss: 0.618341326713562
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6816187649965286
  Validation Loss: 0.6181933283805847
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6814840883016586
  Validation Loss: 0.6180370450019836
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.681310772895813
  Validation Loss: 0.6178880929946899
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6811208724975586
  Validation Loss: 0.6177682876586914
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6809560805559158
  Validation Loss: 0.6177082061767578
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.68081034719944
  Validation Loss: 0.6176514625549316
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 32/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:53:INFO:
[92mINFO [0m:      Received: evaluate message 0cef38eb-cb68-49db-af38-37529232dbf5
02/07/2025 22:34:53:INFO:Received: evaluate message 0cef38eb-cb68-49db-af38-37529232dbf5
[92mINFO [0m:      Sent reply
02/07/2025 22:34:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:53:INFO:
[92mINFO [0m:      Received: train message 9ddb7c2b-33c1-4aac-afb3-8363f1f15be4
02/07/2025 22:34:53:INFO:Received: train message 9ddb7c2b-33c1-4aac-afb3-8363f1f15be4
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6806049793958664
  Validation Loss: 0.6175724267959595
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6803885698318481
  Validation Loss: 0.6175079345703125
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6802139431238174
  Validation Loss: 0.6174448132514954
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6801250874996185
  Validation Loss: 0.6173417568206787
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6799757033586502
  Validation Loss: 0.6172014474868774
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6798332631587982
  Validation Loss: 0.6170353293418884
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6796661615371704
  Validation Loss: 0.6168327331542969
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6795014590024948
  Validation Loss: 0.6166636347770691
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6793632358312607
  Validation Loss: 0.6165260672569275
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6792539209127426
  Validation Loss: 0.6164747476577759
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.679200753569603
  Validation Loss: 0.6164484024047852
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.6791286915540695
  Validation Loss: 0.6163691878318787
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6790694743394852
  Validation Loss: 0.6163063049316406
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.6789884716272354
  Validation Loss: 0.6163210868835449
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6788446307182312
  Validation Loss: 0.6162554621696472
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.6787429749965668
  Validation Loss: 0.6161519885063171
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6786156594753265
  Validation Loss: 0.6160460114479065
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6785326451063156
  Validation Loss: 0.6159725189208984
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.6784754395484924
  Validation Loss: 0.6158592700958252
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.6784585118293762
  Validation Loss: 0.6157734990119934
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.6784325540065765
  Validation Loss: 0.6156215667724609
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6783366054296494
  Validation Loss: 0.6154940128326416
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.6783240884542465
  Validation Loss: 0.6154558062553406
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.6783021539449692
  Validation Loss: 0.6153666973114014
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.6781654953956604
  Validation Loss: 0.6152565479278564
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.6780087947845459
  Validation Loss: 0.6151482462882996
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.6779338717460632
  Validation Loss: 0.6151631474494934
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6780011802911758
  Validation Loss: 0.615241289138794
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 60/64:
  Train Loss: 0.6781038641929626
  Validation Loss: 0.6153451800346375
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6781679093837738
  Validation Loss: 0.6154404878616333
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.6782125979661942
  Validation Loss: 0.6154593825340271
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.6782445013523102
  Validation Loss: 0.6155093908309937
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.6782670468091965
  Validation Loss: 0.6155900359153748
  Val ROC-AUC: 0.9019607843137256
  Val Accuracy: 0.84375
{'train_loss': 0.6782670468091965, 'val_roc_auc': 0.9019607843137256, 'val_accuracy': 0.84375, 'val_loss': 0.6155900359153748}
 ROC_AUC: 0.9020|| Accuracy 0.8438 || Train Loss: 0.6783
 Val Loss: 0.6156 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6606766644578713
Test ROC-AUC: 0.8720238095238094
Test Accuracy: 0.7884615384615384
test_loss: 0.6606766644578713
test_roc_auc: 0.8720238095238094
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6855558753013611
  Validation Loss: 0.6027689576148987
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.875
Epoch 2/64:
  Train Loss: 0.6854695826768875
  Validation Loss: 0.6027430295944214
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.875
Epoch 3/64:
  Train Loss: 0.6853749305009842
  Validation Loss: 0.6027498245239258
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.875
Epoch 4/64:
  Train Loss: 0.6853783577680588
  Validation Loss: 0.6028361916542053
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.875
Epoch 5/64:
  Train Loss: 0.6853422224521637
  Validation Loss: 0.6029838919639587
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.875
Epoch 6/64:
  Train Loss: 0.6852984130382538
  Validation Loss: 0.603088915348053
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.875
Epoch 7/64:
  Train Loss: 0.6852702349424362
  Validation Loss: 0.6031955480575562
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.875
Epoch 8/64:
  Train Loss: 0.6851902604103088
  Validation Loss: 0.6032477617263794
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.875
Epoch 9/64:
  Train Loss: 0.685090109705925
  Validation Loss: 0.6032570600509644
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.875
Epoch 10/64:
  Train Loss: 0.6849644780158997
  Validation Loss: 0.60326087474823
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.875
Epoch 11/64:
  Train Loss: 0.6848353743553162
  Validation Loss: 0.6033143401145935
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.875
Epoch 12/64:
  Train Loss: 0.6847652196884155
  Validation Loss: 0.6034048795700073
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.875
Epoch 13/64:
  Train Loss: 0.6847134381532669
  Validation Loss: 0.603482723236084
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.875
Epoch 14/64:
  Train Loss: 0.6846114099025726
  Validation Loss: 0.6034693717956543
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.875
Epoch 15/64:
  Train Loss: 0.6844696998596191
  Validation Loss: 0.6034621000289917
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.684313103556633
  Validation Loss: 0.6034896969795227
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6841798424720764
  Validation Loss: 0.6035369634628296
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6840601116418839
  Validation Loss: 0.6035706400871277
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6839177012443542
  Validation Loss: 0.6035584807395935
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6838101744651794
  Validation Loss: 0.6035854816436768
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6837433576583862
  Validation Loss: 0.6036197543144226
  Val ROC-AUC: 0.9686274509803923
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:57:INFO:
[92mINFO [0m:      Received: evaluate message c0f6273b-ca28-4e83-9774-203439e5e34d
02/07/2025 22:34:57:INFO:Received: evaluate message c0f6273b-ca28-4e83-9774-203439e5e34d
[92mINFO [0m:      Sent reply
02/07/2025 22:34:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:58:INFO:
[92mINFO [0m:      Received: train message 205e2512-1eca-409e-a173-fa091dc35bfa
02/07/2025 22:34:58:INFO:Received: train message 205e2512-1eca-409e-a173-fa091dc35bfa
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6836811006069183
  Validation Loss: 0.6036171317100525
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6835998892784119
  Validation Loss: 0.6035177707672119
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.683426558971405
  Validation Loss: 0.6034114956855774
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6832974404096603
  Validation Loss: 0.6033938527107239
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6831881552934647
  Validation Loss: 0.6033877730369568
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6830320507287979
  Validation Loss: 0.6033933162689209
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6828688532114029
  Validation Loss: 0.6033944487571716
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6827524453401566
  Validation Loss: 0.6034892797470093
  Val ROC-AUC: 0.9686274509803923
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6826757937669754
  Validation Loss: 0.6035442352294922
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6825659275054932
  Validation Loss: 0.6035593152046204
  Val ROC-AUC: 0.9647058823529413
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6824577301740646
  Validation Loss: 0.603560209274292
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6822926700115204
  Validation Loss: 0.6035029888153076
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6820917725563049
  Validation Loss: 0.6035231351852417
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.681918278336525
  Validation Loss: 0.6035264134407043
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6817017942667007
  Validation Loss: 0.6034864187240601
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6815664917230606
  Validation Loss: 0.6034537553787231
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.681465357542038
  Validation Loss: 0.6033281087875366
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6813395917415619
  Validation Loss: 0.6032981872558594
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6812733262777328
  Validation Loss: 0.6032851934432983
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6811829060316086
  Validation Loss: 0.6032390594482422
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6810855567455292
  Validation Loss: 0.6032683253288269
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.681005209684372
  Validation Loss: 0.6032416820526123
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6809265613555908
  Validation Loss: 0.603156566619873
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.68080273270607
  Validation Loss: 0.6030720472335815
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.680668443441391
  Validation Loss: 0.6029537916183472
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.6804849058389664
  Validation Loss: 0.6028450727462769
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6803344488143921
  Validation Loss: 0.6027917861938477
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6802163869142532
  Validation Loss: 0.6027785539627075
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.6801716387271881
  Validation Loss: 0.6028003692626953
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.6800907850265503
  Validation Loss: 0.6027815937995911
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.6800333559513092
  Validation Loss: 0.6027705669403076
  Val ROC-AUC: 0.9607843137254902
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6799775063991547
  Validation Loss: 0.6027305126190186
  Val ROC-AUC: 0.9568627450980393
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.6798602193593979
  Validation Loss: 0.6027007102966309
  Val ROC-AUC: 0.9568627450980393
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.6796711981296539
  Validation Loss: 0.6026289463043213
  Val ROC-AUC: 0.9568627450980393
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.6794528216123581
  Validation Loss: 0.6025285124778748
  Val ROC-AUC: 0.9568627450980393
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.6793123483657837
  Validation Loss: 0.602458119392395
  Val ROC-AUC: 0.9529411764705883
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.6791420876979828
  Validation Loss: 0.6023703813552856
  Val ROC-AUC: 0.9529411764705883
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6789649575948715
  Validation Loss: 0.6023120284080505
  Val ROC-AUC: 0.9529411764705883
  Val Accuracy: 0.84375
Epoch 60/64:
  Train Loss: 0.678854763507843
  Validation Loss: 0.6022284030914307
  Val ROC-AUC: 0.9529411764705883
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6786987781524658
  Validation Loss: 0.6021465063095093
  Val ROC-AUC: 0.9529411764705883
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.6785505712032318
  Validation Loss: 0.6020834445953369
  Val ROC-AUC: 0.9529411764705883
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.6784579753875732
  Validation Loss: 0.6020651459693909
  Val ROC-AUC: 0.9529411764705883
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.6783667057752609
  Validation Loss: 0.6021349430084229
  Val ROC-AUC: 0.9529411764705883
  Val Accuracy: 0.84375
{'train_loss': 0.6783667057752609, 'val_roc_auc': 0.9529411764705883, 'val_accuracy': 0.84375, 'val_loss': 0.6021349430084229}
 ROC_AUC: 0.9529|| Accuracy 0.8438 || Train Loss: 0.6784
 Val Loss: 0.6021 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6583622745596446
Test ROC-AUC: 0.8723958333333334
Test Accuracy: 0.7980769230769231
test_loss: 0.6583622745596446
test_roc_auc: 0.8723958333333334
test_accuracy: 0.7980769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.67240309715271
  Validation Loss: 0.6462527513504028
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6721481680870056
  Validation Loss: 0.6460338830947876
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.6720370650291443
  Validation Loss: 0.6458987593650818
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.671972468495369
  Validation Loss: 0.6457823514938354
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.6719185262918472
  Validation Loss: 0.6456794738769531
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.6718360036611557
  Validation Loss: 0.6454970836639404
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6717487871646881
  Validation Loss: 0.6454137563705444
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6717132329940796
  Validation Loss: 0.6453624963760376
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6716660410165787
  Validation Loss: 0.6452558040618896
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6716628074645996
  Validation Loss: 0.6451031565666199
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6715965270996094
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:02:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:02:INFO:
[92mINFO [0m:      Received: evaluate message dfe1fb69-b2ce-4272-8041-28bf71591bd1
02/07/2025 22:35:02:INFO:Received: evaluate message dfe1fb69-b2ce-4272-8041-28bf71591bd1
[92mINFO [0m:      Sent reply
02/07/2025 22:35:03:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:03:INFO:
[92mINFO [0m:      Received: train message 557b14db-c530-4e1d-a255-b2a8b2354fac
02/07/2025 22:35:03:INFO:Received: train message 557b14db-c530-4e1d-a255-b2a8b2354fac
  Validation Loss: 0.6449567079544067
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6715271323919296
  Validation Loss: 0.6448739767074585
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6714747697114944
  Validation Loss: 0.644816517829895
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6714852601289749
  Validation Loss: 0.6447958946228027
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6714665740728378
  Validation Loss: 0.644763708114624
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.67146235704422
  Validation Loss: 0.6447767019271851
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.6714672446250916
  Validation Loss: 0.6448653936386108
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.6714732497930527
  Validation Loss: 0.645000696182251
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6715184450149536
  Validation Loss: 0.645060122013092
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6715088039636612
  Validation Loss: 0.6450058817863464
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 21/64:
  Train Loss: 0.6714764982461929
  Validation Loss: 0.6449722051620483
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 22/64:
  Train Loss: 0.6713833659887314
  Validation Loss: 0.6448578834533691
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 23/64:
  Train Loss: 0.6713181287050247
  Validation Loss: 0.6448155641555786
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 24/64:
  Train Loss: 0.671265572309494
  Validation Loss: 0.6447068452835083
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 25/64:
  Train Loss: 0.671208068728447
  Validation Loss: 0.6446409821510315
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 26/64:
  Train Loss: 0.6711606681346893
  Validation Loss: 0.6446473002433777
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 27/64:
  Train Loss: 0.6711083352565765
  Validation Loss: 0.6446605324745178
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 28/64:
  Train Loss: 0.6710742264986038
  Validation Loss: 0.6447080969810486
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 29/64:
  Train Loss: 0.6710770577192307
  Validation Loss: 0.6447936296463013
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 30/64:
  Train Loss: 0.6710861623287201
  Validation Loss: 0.6448268294334412
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 31/64:
  Train Loss: 0.671112522482872
  Validation Loss: 0.6448492407798767
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 32/64:
  Train Loss: 0.6711484044790268
  Validation Loss: 0.6448107957839966
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 33/64:
  Train Loss: 0.6711582839488983
  Validation Loss: 0.644764244556427
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 34/64:
  Train Loss: 0.6711481511592865
  Validation Loss: 0.6447043418884277
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6711025536060333
  Validation Loss: 0.6446064710617065
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.6710425913333893
  Validation Loss: 0.6445017457008362
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.671011671423912
  Validation Loss: 0.6444575786590576
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6709854751825333
  Validation Loss: 0.6443480253219604
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6709176152944565
  Validation Loss: 0.6442012786865234
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.6708368211984634
  Validation Loss: 0.6440601348876953
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6707272976636887
  Validation Loss: 0.6439622640609741
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6706570237874985
  Validation Loss: 0.6438807249069214
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.670617938041687
  Validation Loss: 0.643791675567627
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.6706198304891586
  Validation Loss: 0.6437966823577881
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6706652939319611
  Validation Loss: 0.643752932548523
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6706621050834656
  Validation Loss: 0.6436225175857544
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6705907583236694
  Validation Loss: 0.6435176134109497
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6705259680747986
  Validation Loss: 0.6434938907623291
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6704642325639725
  Validation Loss: 0.6434139013290405
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.6703631579875946
  Validation Loss: 0.6432523131370544
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.670209988951683
  Validation Loss: 0.6430548429489136
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.670041561126709
  Validation Loss: 0.6428905725479126
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.6699385195970535
  Validation Loss: 0.6428437829017639
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6698966920375824
  Validation Loss: 0.6428122520446777
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6698318123817444
  Validation Loss: 0.6427841186523438
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6697346568107605
  Validation Loss: 0.6426486968994141
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.6695955395698547
  Validation Loss: 0.642464280128479
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.6694258451461792
  Validation Loss: 0.642239511013031
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6693103909492493
  Validation Loss: 0.6420471668243408
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.84375
Epoch 60/64:
  Train Loss: 0.6691727042198181
  Validation Loss: 0.6419034600257874
  Val ROC-AUC: 0.9087301587301587
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6690684854984283
  Validation Loss: 0.6417295932769775
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.6689887195825577
  Validation Loss: 0.6416296362876892
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.66892009973526
  Validation Loss: 0.6415543556213379
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.6688463240861893
  Validation Loss: 0.641437292098999
  Val ROC-AUC: 0.9126984126984127
  Val Accuracy: 0.84375
{'train_loss': 0.6688463240861893, 'val_roc_auc': 0.9126984126984127, 'val_accuracy': 0.84375, 'val_loss': 0.641437292098999}
 ROC_AUC: 0.9127|| Accuracy 0.8438 || Train Loss: 0.6688
 Val Loss: 0.6414 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6562117266540344
Test ROC-AUC: 0.8738839285714286
Test Accuracy: 0.7980769230769231
test_loss: 0.6562117266540344
test_roc_auc: 0.8738839285714286
test_accuracy: 0.7980769230769231
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6791612356901169
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6111775636672974
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6789005249738693
  Validation Loss: 0.6109946966171265
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.6787693053483963
  Validation Loss: 0.6109445095062256
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6786408126354218
  Validation Loss: 0.6108496785163879
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.6785417646169662
  Validation Loss: 0.6108358502388
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6784806996583939
  Validation Loss: 0.6108845472335815
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.6784711480140686
  Validation Loss: 0.6109070777893066
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.6785188168287277
  Validation Loss: 0.6108858585357666
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6785488575696945
  Validation Loss: 0.6107184886932373
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6785340160131454
  Validation Loss: 0.610538899898529
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 11/64:
  Train Loss: 0.6785004734992981
  Validation Loss: 0.6103507280349731
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.6784596592187881
  Validation Loss: 0.6102010011672974
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.6783625185489655
  Validation Loss: 0.610047459602356
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 14/64:
  Train Loss: 0.678277850151062
  Validation Loss: 0.6100083589553833
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 15/64:
  Train Loss: 0.6782136857509613
  Validation Loss: 0.610011100769043
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 16/64:
  Train Loss: 0.6781620532274246
  Validation Loss: 0.6099783182144165
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.6781564205884933
  Validation Loss: 0.6100255250930786
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.6781470030546188
  Validation Loss: 0.6100321412086487
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6781459152698517
  Validation Loss: 0.6099437475204468
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6780378222465515
  Validation Loss: 0.6098455190658569
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 21/64:
  Train Loss: 0.6778693944215775
  Validation Loss: 0.6097689867019653
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 22/64:
  Train Loss: 0.6777193397283554
  Validation Loss: 0.609723687171936
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 23/64:
  Train Loss: 0.6776217669248581
  Validation Loss: 0.6096897125244141
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 24/64:
  Train Loss: 0.6775155663490295
  Validation Loss: 0.6097041368484497
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 25/64:
  Train Loss: 0.6773857176303864
  Validation Loss: 0.6097897887229919
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 26/64:
  Train Loss: 0.6773057579994202
  Validation Loss: 0.6098842620849609
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 27/64:
  Train Loss: 0.6772569864988327
  Validation Loss: 0.609896719455719
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 28/64:
  Train Loss: 0.677160382270813
  Validation Loss: 0.6099036931991577
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 29/64:
  Train Loss: 0.6771350651979446
  Validation Loss: 0.609912097454071
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 30/64:
  Train Loss: 0.6770793348550797
  Validation Loss: 0.6098603010177612
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 31/64:
  Train Loss: 0.6769969612360001
  Validation Loss: 0.6097216606140137
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 32/64:
  Train Loss: 0.6769299656152725
  Validation Loss: 0.6095479130744934
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 33/64:
  Train Loss: 0.6767921298742294
  Validation Loss: 0.6093990206718445
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 34/64:
  Train Loss: 0.6766567230224609
  Validation Loss: 0.6092480421066284
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6764851361513138
  Validation Loss: 0.6090686917304993
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.676344245672226
  Validation Loss: 0.6089969873428345
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6762565523386002
  Validation Loss: 0.6089776754379272
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6762276589870453
  Validation Loss: 0.6089390516281128
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6762243509292603
  Validation Loss: 0.608887255191803
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.676223561167717
  Validation Loss: 0.6089017391204834
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6761523634195328
  Validation Loss: 0.6090006828308105
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.676074281334877
  Validation Loss: 0.6090644598007202
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 43/64:
  Train Loss: 0.6760023087263107
  Validation Loss: 0.6090583801269531
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 44/64:
  Train Loss: 0.6758905798196793
  Validation Loss: 0.6089522838592529
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 45/64:
  Train Loss: 0.6757651716470718
  Validation Loss: 0.6088786125183105
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 46/64:
  Train Loss: 0.6756785660982132
  Validation Loss: 0.6088570356369019
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 47/64:
  Train Loss: 0.675620511174202
  Validation Loss: 0.6089621186256409
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.6755860447883606
  Validation Loss: 0.6090638637542725
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.6755459159612656
  Validation Loss: 0.6091001629829407
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6755041778087616
  Validation Loss: 0.6090642213821411
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.6754368394613266
  Validation Loss: 0.6090176701545715
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.6754209101200104
  Validation Loss: 0.6090255975723267
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6753954589366913
  Validation Loss: 0.6089214086532593
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.6753199696540833
  Validation Loss: 0.6087710857391357
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6752760112285614
  Validation Loss: 0.6086139678955078
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.6752320826053619
  Validation Loss: 0.608457088470459
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.6751776188611984
  Validation Loss: 0.608277440071106
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.6751397401094437
  Validation Loss: 0.6081754565238953
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6751264780759811
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:08:INFO:
[92mINFO [0m:      Received: evaluate message 22cf1c17-4069-4ff9-98a2-b3790cf3be46
02/07/2025 22:35:08:INFO:Received: evaluate message 22cf1c17-4069-4ff9-98a2-b3790cf3be46
[92mINFO [0m:      Sent reply
02/07/2025 22:35:09:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:09:INFO:
[92mINFO [0m:      Received: train message 0cc09a84-e629-46bd-8f83-4ce317ee1729
02/07/2025 22:35:09:INFO:Received: train message 0cc09a84-e629-46bd-8f83-4ce317ee1729
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6080961227416992
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6750957518815994
  Validation Loss: 0.6080079078674316
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6750920414924622
  Validation Loss: 0.6079829931259155
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6750864535570145
  Validation Loss: 0.6079817414283752
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6750354170799255
  Validation Loss: 0.6079564094543457
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6749309599399567
  Validation Loss: 0.6079031229019165
  Val ROC-AUC: 0.9047619047619048
  Val Accuracy: 0.8125
{'train_loss': 0.6749309599399567, 'val_roc_auc': 0.9047619047619048, 'val_accuracy': 0.8125, 'val_loss': 0.6079031229019165}
 ROC_AUC: 0.9048|| Accuracy 0.8125 || Train Loss: 0.6749
 Val Loss: 0.6079 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6544166843478496
Test ROC-AUC: 0.8757440476190476
Test Accuracy: 0.8173076923076923
test_loss: 0.6544166843478496
test_roc_auc: 0.8757440476190476
test_accuracy: 0.8173076923076923
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6641134172677994
  Validation Loss: 0.6644798517227173
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 2/64:
  Train Loss: 0.6639417260885239
  Validation Loss: 0.6641974449157715
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.6637795120477676
  Validation Loss: 0.6640498638153076
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.663713127374649
  Validation Loss: 0.6640282869338989
  Val ROC-AUC: 0.9433198380566802
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.6636464893817902
  Validation Loss: 0.6638934016227722
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.6635526567697525
  Validation Loss: 0.6637382507324219
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6634704917669296
  Validation Loss: 0.6636722683906555
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6634025573730469
  Validation Loss: 0.6636414527893066
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6633177697658539
  Validation Loss: 0.6636258363723755
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6633121967315674
  Validation Loss: 0.6635640859603882
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6632874310016632
  Validation Loss: 0.6635411381721497
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6632774025201797
  Validation Loss: 0.663552463054657
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6632478088140488
  Validation Loss: 0.6635416746139526
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6632055044174194
  Validation Loss: 0.6634426116943359
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.663119450211525
  Validation Loss: 0.6633341312408447
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6630113869905472
  Validation Loss: 0.663226842880249
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6629398316144943
  Validation Loss: 0.6632065773010254
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.6629163473844528
  Validation Loss: 0.6631783246994019
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6628749668598175
  Validation Loss: 0.6631078720092773
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6628113687038422
  Validation Loss: 0.6630027294158936
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6627328544855118
  Validation Loss: 0.6627840995788574
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6626090258359909
  Validation Loss: 0.6626009941101074
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.662540391087532
  Validation Loss: 0.6625417470932007
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6625392735004425
  Validation Loss: 0.6625162959098816
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.662530243396759
  Validation Loss: 0.6624669432640076
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.6625369042158127
  Validation Loss: 0.6624541282653809
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6625460833311081
  Validation Loss: 0.6624524593353271
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6625483632087708
  Validation Loss: 0.6624458432197571
  Val ROC-AUC: 0.9433198380566802
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.662565678358078
  Validation Loss: 0.6624768972396851
  Val ROC-AUC: 0.9433198380566802
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.662585586309433
  Validation Loss: 0.6624833345413208
  Val ROC-AUC: 0.9433198380566802
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6625339388847351
  Validation Loss: 0.6624886989593506
  Val ROC-AUC: 0.9433198380566802
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6625248789787292
  Validation Loss: 0.6625056266784668
  Val ROC-AUC: 0.9433198380566802
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6624959260225296
  Validation Loss: 0.662525475025177
  Val ROC-AUC: 0.9433198380566802
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6625153124332428
  Validation Loss: 0.6625863313674927
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6624920070171356
  Validation Loss: 0.6626214981079102
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6624515503644943
  Validation Loss: 0.6625818014144897
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6623799055814743
  Validation Loss: 0.6625032424926758
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6623230576515198
  Validation Loss: 0.6623825430870056
  Val ROC-AUC: 0.9392712550607287
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6622671782970428
  Validation Loss: 0.6622779369354248
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.66224005818367
  Validation Loss: 0.6621699333190918
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6621503233909607
  Validation Loss: 0.6620913147926331
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6620717495679855
  Validation Loss: 0.6619788408279419
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 43/64:
  Train Loss: 0.6619702130556107
  Validation Loss: 0.6618798971176147
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 44/64:
  Train Loss: 0.6619452238082886
  Validation Loss: 0.6618615388870239
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 45/64:
  Train Loss: 0.6618913263082504
  Validation Loss: 0.6618351936340332
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 46/64:
  Train Loss: 0.661850318312645
  Validation Loss: 0.6618005633354187
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 47/64:
  Train Loss: 0.6617680341005325
  Validation Loss: 0.6617854833602905
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 48/64:
  Train Loss: 0.6617141962051392
  Validation Loss: 0.661740779876709
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 49/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:15:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:15:INFO:
[92mINFO [0m:      Received: evaluate message 0afc3beb-2e59-40bf-ac36-d3360af20857
02/07/2025 22:35:15:INFO:Received: evaluate message 0afc3beb-2e59-40bf-ac36-d3360af20857
[92mINFO [0m:      Sent reply
02/07/2025 22:35:16:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:16:INFO:
[92mINFO [0m:      Received: train message 96492081-b1a1-490b-8109-247a95b00ddf
02/07/2025 22:35:16:INFO:Received: train message 96492081-b1a1-490b-8109-247a95b00ddf
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6616571992635727
  Validation Loss: 0.661697506904602
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 50/64:
  Train Loss: 0.6615906655788422
  Validation Loss: 0.661591649055481
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 51/64:
  Train Loss: 0.6614815294742584
  Validation Loss: 0.6615358591079712
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 52/64:
  Train Loss: 0.6614348590373993
  Validation Loss: 0.6615591645240784
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 53/64:
  Train Loss: 0.6613824218511581
  Validation Loss: 0.6615843772888184
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 54/64:
  Train Loss: 0.6613274365663528
  Validation Loss: 0.661565363407135
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 55/64:
  Train Loss: 0.6613068878650665
  Validation Loss: 0.6616005897521973
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 56/64:
  Train Loss: 0.6613006889820099
  Validation Loss: 0.6615625619888306
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 57/64:
  Train Loss: 0.6612644046545029
  Validation Loss: 0.661548376083374
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 58/64:
  Train Loss: 0.6612527817487717
  Validation Loss: 0.6615414619445801
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 59/64:
  Train Loss: 0.6612101048231125
  Validation Loss: 0.6614466905593872
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 60/64:
  Train Loss: 0.6611506342887878
  Validation Loss: 0.6613368988037109
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 61/64:
  Train Loss: 0.6611040681600571
  Validation Loss: 0.6612548232078552
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 62/64:
  Train Loss: 0.661059096455574
  Validation Loss: 0.6612039804458618
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 63/64:
  Train Loss: 0.6610355526208878
  Validation Loss: 0.6611477732658386
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
Epoch 64/64:
  Train Loss: 0.6610079854726791
  Validation Loss: 0.661119818687439
  Val ROC-AUC: 0.9433198380566801
  Val Accuracy: 0.875
{'train_loss': 0.6610079854726791, 'val_roc_auc': 0.9433198380566801, 'val_accuracy': 0.875, 'val_loss': 0.661119818687439}
 ROC_AUC: 0.9433|| Accuracy 0.8750 || Train Loss: 0.6610
 Val Loss: 0.6611 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6529406824937234
Test ROC-AUC: 0.875
Test Accuracy: 0.8173076923076923
test_loss: 0.6529406824937234
test_roc_auc: 0.875
test_accuracy: 0.8173076923076923
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6636533141136169
  Validation Loss: 0.6593480110168457
  Val ROC-AUC: 0.9635627530364372
  Val Accuracy: 0.875
Epoch 2/64:
  Train Loss: 0.663487896323204
  Validation Loss: 0.6592892408370972
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 3/64:
  Train Loss: 0.6634436398744583
  Validation Loss: 0.6592636108398438
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 4/64:
  Train Loss: 0.6633463054895401
  Validation Loss: 0.6591780185699463
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 5/64:
  Train Loss: 0.663239374756813
  Validation Loss: 0.659134566783905
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 6/64:
  Train Loss: 0.6631304770708084
  Validation Loss: 0.6591103076934814
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 7/64:
  Train Loss: 0.6630218327045441
  Validation Loss: 0.6591511964797974
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 8/64:
  Train Loss: 0.6629525125026703
  Validation Loss: 0.6591790914535522
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 9/64:
  Train Loss: 0.6628689020872116
  Validation Loss: 0.6591339111328125
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 10/64:
  Train Loss: 0.6627570688724518
  Validation Loss: 0.659098207950592
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 11/64:
  Train Loss: 0.6626710146665573
  Validation Loss: 0.6590985059738159
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 12/64:
  Train Loss: 0.6625920236110687
  Validation Loss: 0.6591314077377319
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 13/64:
  Train Loss: 0.6625885516405106
  Validation Loss: 0.6591737270355225
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 14/64:
  Train Loss: 0.6625935137271881
  Validation Loss: 0.6592479944229126
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 15/64:
  Train Loss: 0.6625654548406601
  Validation Loss: 0.6592768430709839
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 16/64:
  Train Loss: 0.6625337898731232
  Validation Loss: 0.6592684984207153
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 17/64:
  Train Loss: 0.6624908745288849
  Validation Loss: 0.6592922210693359
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 18/64:
  Train Loss: 0.662465363740921
  Validation Loss: 0.6592645645141602
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6623745858669281
  Validation Loss: 0.6591812968254089
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.6623033136129379
  Validation Loss: 0.659132719039917
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 21/64:
  Train Loss: 0.6622493863105774
  Validation Loss: 0.6591670513153076
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 22/64:
  Train Loss: 0.6622328609228134
  Validation Loss: 0.6592500805854797
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 23/64:
  Train Loss: 0.6622123867273331
  Validation Loss: 0.6593153476715088
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 24/64:
  Train Loss: 0.6621776223182678
  Validation Loss: 0.6593671441078186
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 25/64:
  Train Loss: 0.6621153056621552
  Validation Loss: 0.659307599067688
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 26/64:
  Train Loss: 0.6620473265647888
  Validation Loss: 0.6592842936515808
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 27/64:
  Train Loss: 0.6619763225317001
  Validation Loss: 0.6593184471130371
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.875
Epoch 28/64:
  Train Loss: 0.6619536876678467
  Validation Loss: 0.6593303084373474
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6619109213352203
  Validation Loss: 0.6593905687332153
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6619444787502289
  Validation Loss: 0.6594693660736084
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6619319021701813
  Validation Loss: 0.6595601439476013
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6619452387094498
  Validation Loss: 0.6596212387084961
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6619437336921692
  Validation Loss: 0.6595994234085083
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6618523746728897
  Validation Loss: 0.6596097946166992
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.6618267595767975
  Validation Loss: 0.6595960259437561
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6617491245269775
  Validation Loss: 0.6595383882522583
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6617037653923035
  Validation Loss: 0.659521758556366
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6616479307413101
  Validation Loss: 0.6595149040222168
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6615868210792542
  Validation Loss: 0.6595093011856079
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:24:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:24:INFO:
[92mINFO [0m:      Received: evaluate message d6e17e0b-84df-4e88-84f8-5dd55ccf7dbd
02/07/2025 22:35:24:INFO:Received: evaluate message d6e17e0b-84df-4e88-84f8-5dd55ccf7dbd
[92mINFO [0m:      Sent reply
02/07/2025 22:35:24:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:24:INFO:
[92mINFO [0m:      Received: train message deed6ef1-edd9-43e9-80e7-0cb7b4bc1e36
02/07/2025 22:35:24:INFO:Received: train message deed6ef1-edd9-43e9-80e7-0cb7b4bc1e36
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6614767014980316
  Validation Loss: 0.6595124006271362
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6613851487636566
  Validation Loss: 0.6595256328582764
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6612662822008133
  Validation Loss: 0.6594550609588623
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.6611227840185165
  Validation Loss: 0.6594836711883545
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.661039412021637
  Validation Loss: 0.6595886945724487
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.660990446805954
  Validation Loss: 0.6596707105636597
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6609592139720917
  Validation Loss: 0.6597402691841125
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.6609065532684326
  Validation Loss: 0.6598570346832275
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6609611511230469
  Validation Loss: 0.6600024700164795
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6609348058700562
  Validation Loss: 0.660076379776001
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.660907119512558
  Validation Loss: 0.66020268201828
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.6608400642871857
  Validation Loss: 0.660305380821228
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.660783052444458
  Validation Loss: 0.6603909730911255
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6607293635606766
  Validation Loss: 0.6604373455047607
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.660666212439537
  Validation Loss: 0.660470724105835
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.6605956107378006
  Validation Loss: 0.6604537963867188
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.6605397462844849
  Validation Loss: 0.6604071259498596
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.6604967266321182
  Validation Loss: 0.6603782773017883
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.6604506969451904
  Validation Loss: 0.6603958606719971
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6603956520557404
  Validation Loss: 0.660422682762146
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 60/64:
  Train Loss: 0.660321906208992
  Validation Loss: 0.6604570150375366
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6602703183889389
  Validation Loss: 0.6604536771774292
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.6602280139923096
  Validation Loss: 0.6605299711227417
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.6602018922567368
  Validation Loss: 0.6605324745178223
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.660191223025322
  Validation Loss: 0.6605038642883301
  Val ROC-AUC: 0.9595141700404859
  Val Accuracy: 0.84375
{'train_loss': 0.660191223025322, 'val_roc_auc': 0.9595141700404859, 'val_accuracy': 0.84375, 'val_loss': 0.6605038642883301}
 ROC_AUC: 0.9595|| Accuracy 0.8438 || Train Loss: 0.6602
 Val Loss: 0.6605 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6516708995287235
Test ROC-AUC: 0.8735119047619048
Test Accuracy: 0.8076923076923077
test_loss: 0.6516708995287235
test_roc_auc: 0.8735119047619048
test_accuracy: 0.8076923076923077
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6650880426168442
  Validation Loss: 0.649418830871582
  Val ROC-AUC: 0.8359375
  Val Accuracy: 0.75
Epoch 2/64:
  Train Loss: 0.6650086343288422
  Validation Loss: 0.6494026184082031
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.75
Epoch 3/64:
  Train Loss: 0.6649805009365082
  Validation Loss: 0.6493213176727295
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.75
Epoch 4/64:
  Train Loss: 0.6649449914693832
  Validation Loss: 0.6492505669593811
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 5/64:
  Train Loss: 0.6649187058210373
  Validation Loss: 0.6492546796798706
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 6/64:
  Train Loss: 0.6650145500898361
  Validation Loss: 0.6492971777915955
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 7/64:
  Train Loss: 0.6650873124599457
  Validation Loss: 0.6492655277252197
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 8/64:
  Train Loss: 0.6650690585374832
  Validation Loss: 0.649251401424408
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 9/64:
  Train Loss: 0.6650941967964172
  Validation Loss: 0.6492784023284912
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 10/64:
  Train Loss: 0.6650947332382202
  Validation Loss: 0.6492815017700195
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 11/64:
  Train Loss: 0.6650736927986145
  Validation Loss: 0.6492946147918701
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.75
Epoch 12/64:
  Train Loss: 0.6650648564100266
  Validation Loss: 0.6493252515792847
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6650661826133728
  Validation Loss: 0.6493467092514038
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.665084719657898
  Validation Loss: 0.6493076086044312
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6651040315628052
  Validation Loss: 0.649249792098999
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6651164293289185
  Validation Loss: 0.6492336392402649
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6651406735181808
  Validation Loss: 0.6491864919662476
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6651143729686737
  Validation Loss: 0.6491419076919556
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6650745272636414
  Validation Loss: 0.6491309404373169
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6649932861328125
  Validation Loss: 0.6490377187728882
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6649174839258194
  Validation Loss: 0.6489379405975342
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6648252606391907
  Validation Loss: 0.6488622426986694
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6647390574216843
  Validation Loss: 0.6487446427345276
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6646150052547455
  Validation Loss: 0.6486145853996277
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.664462223649025
  Validation Loss: 0.648496150970459
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.6643768846988678
  Validation Loss: 0.6483802795410156
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6642612814903259
  Validation Loss: 0.6483101844787598
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.6641710847616196
  Validation Loss: 0.6482405662536621
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6641367822885513
  Validation Loss: 0.6481590867042542
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.6641169786453247
  Validation Loss: 0.6481174826622009
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6640789955854416
  Validation Loss: 0.6480500102043152
  Val ROC-AUC: 0.84375
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:36:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:36:INFO:
[92mINFO [0m:      Received: evaluate message ced30ac5-22c3-462a-84ff-2fc5d7911bde
02/07/2025 22:35:36:INFO:Received: evaluate message ced30ac5-22c3-462a-84ff-2fc5d7911bde
[92mINFO [0m:      Sent reply
02/07/2025 22:35:36:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:36:INFO:
[92mINFO [0m:      Received: train message 37af014a-77ac-4fa1-aed4-16deb920ceb4
02/07/2025 22:35:36:INFO:Received: train message 37af014a-77ac-4fa1-aed4-16deb920ceb4
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6640278249979019
  Validation Loss: 0.6480060815811157
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6640027910470963
  Validation Loss: 0.647983193397522
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6639885157346725
  Validation Loss: 0.6479460597038269
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6639285236597061
  Validation Loss: 0.6478713750839233
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6638529896736145
  Validation Loss: 0.6478607058525085
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6638610512018204
  Validation Loss: 0.6478934288024902
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6638624966144562
  Validation Loss: 0.6479247808456421
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6638402789831161
  Validation Loss: 0.6479551792144775
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6638000756502151
  Validation Loss: 0.6479473114013672
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6637684106826782
  Validation Loss: 0.647929310798645
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6637260615825653
  Validation Loss: 0.6479102373123169
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6637275516986847
  Validation Loss: 0.6478927731513977
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6637057662010193
  Validation Loss: 0.6479102373123169
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6637016385793686
  Validation Loss: 0.6478772759437561
  Val ROC-AUC: 0.83984375
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6636179089546204
  Validation Loss: 0.6478801965713501
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6635746657848358
  Validation Loss: 0.6478615999221802
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6635471880435944
  Validation Loss: 0.6478584408760071
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6635294258594513
  Validation Loss: 0.6477903127670288
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
Epoch 50/64:
  Train Loss: 0.663490355014801
  Validation Loss: 0.6477170586585999
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
Epoch 51/64:
  Train Loss: 0.6634775996208191
  Validation Loss: 0.6476171016693115
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
Epoch 52/64:
  Train Loss: 0.6634022444486618
  Validation Loss: 0.6475247740745544
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
Epoch 53/64:
  Train Loss: 0.6633494645357132
  Validation Loss: 0.6474127769470215
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.6875
Epoch 54/64:
  Train Loss: 0.6633144617080688
  Validation Loss: 0.6472964882850647
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.6875
Epoch 55/64:
  Train Loss: 0.6632413119077682
  Validation Loss: 0.6471390724182129
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.6875
Epoch 56/64:
  Train Loss: 0.6631685644388199
  Validation Loss: 0.6470664739608765
  Val ROC-AUC: 0.84765625
  Val Accuracy: 0.6875
Epoch 57/64:
  Train Loss: 0.6631703227758408
  Validation Loss: 0.6470205187797546
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
Epoch 58/64:
  Train Loss: 0.6631811708211899
  Validation Loss: 0.6469917893409729
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
Epoch 59/64:
  Train Loss: 0.6632007509469986
  Validation Loss: 0.6469074487686157
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
Epoch 60/64:
  Train Loss: 0.6631617695093155
  Validation Loss: 0.6469018459320068
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
Epoch 61/64:
  Train Loss: 0.6631491780281067
  Validation Loss: 0.646887481212616
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
Epoch 62/64:
  Train Loss: 0.663144052028656
  Validation Loss: 0.6468499898910522
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
Epoch 63/64:
  Train Loss: 0.66312175989151
  Validation Loss: 0.6468508243560791
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
Epoch 64/64:
  Train Loss: 0.6630843728780746
  Validation Loss: 0.6468343734741211
  Val ROC-AUC: 0.84375
  Val Accuracy: 0.6875
{'train_loss': 0.6630843728780746, 'val_roc_auc': 0.84375, 'val_accuracy': 0.6875, 'val_loss': 0.6468343734741211}
 ROC_AUC: 0.8438|| Accuracy 0.6875 || Train Loss: 0.6631
 Val Loss: 0.6468 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6505485798877019
Test ROC-AUC: 0.874627976190476
Test Accuracy: 0.8076923076923077
test_loss: 0.6505485798877019
test_roc_auc: 0.874627976190476
test_accuracy: 0.8076923076923077
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6635807752609253
  Validation Loss: 0.6504155397415161
  Val ROC-AUC: 0.9126984126984128
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6634335368871689
  Validation Loss: 0.6503269672393799
  Val ROC-AUC: 0.9087301587301588
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6633333116769791
  Validation Loss: 0.6502934694290161
  Val ROC-AUC: 0.9087301587301588
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.6632900983095169
  Validation Loss: 0.6502753496170044
  Val ROC-AUC: 0.9087301587301588
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.663233146071434
  Validation Loss: 0.6502929925918579
  Val ROC-AUC: 0.9087301587301588
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.663144513964653
  Validation Loss: 0.6502959728240967
  Val ROC-AUC: 0.9087301587301588
  Val Accuracy: 0.78125
Epoch 7/64:
  Train Loss: 0.6630524098873138
  Validation Loss: 0.6502972841262817
  Val ROC-AUC: 0.9087301587301588
  Val Accuracy: 0.78125
Epoch 8/64:
  Train Loss: 0.6628953516483307
  Validation Loss: 0.6502685546875
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.75
Epoch 9/64:
  Train Loss: 0.6627857536077499
  Validation Loss: 0.650263786315918
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.75
Epoch 10/64:
  Train Loss: 0.6626782417297363
  Validation Loss: 0.6502026319503784
  Val ROC-AUC: 0.9047619047619049
  Val Accuracy: 0.75
Epoch 11/64:
  Train Loss: 0.6625151038169861
  Validation Loss: 0.6501379609107971
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 12/64:
  Train Loss: 0.6623278856277466
  Validation Loss: 0.6500999331474304
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 13/64:
  Train Loss: 0.6621931493282318
  Validation Loss: 0.6501344442367554
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 14/64:
  Train Loss: 0.662148118019104
  Validation Loss: 0.6501849889755249
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 15/64:
  Train Loss: 0.6620095372200012
  Validation Loss: 0.6501964330673218
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 16/64:
  Train Loss: 0.6618974059820175
  Validation Loss: 0.650222897529602
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 17/64:
  Train Loss: 0.6618023812770844
  Validation Loss: 0.6502900123596191
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 18/64:
  Train Loss: 0.6617466360330582
  Validation Loss: 0.6503503322601318
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 19/64:
  Train Loss: 0.6617011278867722
  Validation Loss: 0.6504327058792114
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 20/64:
  Train Loss: 0.6616806387901306
  Validation Loss: 0.6505608558654785
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 21/64:
  Train Loss: 0.6617000102996826
  Validation Loss: 0.6506754159927368
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 22/64:
  Train Loss: 0.6617055535316467
  Validation Loss: 0.6507663726806641
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 23/64:
  Train Loss: 0.6616465300321579
  Validation Loss: 0.6507859230041504
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 24/64:
  Train Loss: 0.6615637689828873
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:48:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:48:INFO:
[92mINFO [0m:      Received: evaluate message 47588e5d-06ca-467d-a39c-e2d8cbb35138
02/07/2025 22:35:48:INFO:Received: evaluate message 47588e5d-06ca-467d-a39c-e2d8cbb35138
[92mINFO [0m:      Sent reply
02/07/2025 22:35:48:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:48:INFO:
[92mINFO [0m:      Received: train message ef1b7962-9f8e-4dee-b9f7-0f3b9670362b
02/07/2025 22:35:48:INFO:Received: train message ef1b7962-9f8e-4dee-b9f7-0f3b9670362b
  Validation Loss: 0.6507903337478638
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 25/64:
  Train Loss: 0.6614650636911392
  Validation Loss: 0.6508474349975586
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 26/64:
  Train Loss: 0.6613697409629822
  Validation Loss: 0.6508229970932007
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 27/64:
  Train Loss: 0.6612695604562759
  Validation Loss: 0.6508036255836487
  Val ROC-AUC: 0.9007936507936508
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.6611732393503189
  Validation Loss: 0.6508147716522217
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.6610993891954422
  Validation Loss: 0.650795042514801
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6610053777694702
  Validation Loss: 0.6508005857467651
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6609104424715042
  Validation Loss: 0.6507786512374878
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6607981622219086
  Validation Loss: 0.6507110595703125
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6606767922639847
  Validation Loss: 0.6506847143173218
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6605936884880066
  Validation Loss: 0.650644063949585
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6605284214019775
  Validation Loss: 0.6505697965621948
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6604178696870804
  Validation Loss: 0.6506140232086182
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6603739857673645
  Validation Loss: 0.6506417989730835
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6603178232908249
  Validation Loss: 0.6506635546684265
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6602428555488586
  Validation Loss: 0.6506775617599487
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6601516306400299
  Validation Loss: 0.6506842374801636
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6600543856620789
  Validation Loss: 0.6506997346878052
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6599303781986237
  Validation Loss: 0.6506978273391724
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6598650962114334
  Validation Loss: 0.6507619619369507
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6598121225833893
  Validation Loss: 0.650812029838562
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.659781813621521
  Validation Loss: 0.6508530974388123
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6597639471292496
  Validation Loss: 0.6508707404136658
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6597576588392258
  Validation Loss: 0.6508677005767822
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6596857905387878
  Validation Loss: 0.650869607925415
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6596194505691528
  Validation Loss: 0.6508634090423584
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6595278084278107
  Validation Loss: 0.6508601903915405
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6594482958316803
  Validation Loss: 0.650911808013916
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6593588590621948
  Validation Loss: 0.6508952975273132
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6592121869325638
  Validation Loss: 0.6508784294128418
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.6590911746025085
  Validation Loss: 0.650879442691803
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.6589738875627518
  Validation Loss: 0.6508752703666687
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.6589144468307495
  Validation Loss: 0.650830864906311
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.6588392853736877
  Validation Loss: 0.6508113741874695
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.6587973386049271
  Validation Loss: 0.650765061378479
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.65873122215271
  Validation Loss: 0.6506462097167969
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.6586089432239532
  Validation Loss: 0.6505914926528931
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.6585687100887299
  Validation Loss: 0.6506167650222778
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6585709005594254
  Validation Loss: 0.6506508588790894
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6585738807916641
  Validation Loss: 0.6506562232971191
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6585679352283478
  Validation Loss: 0.6505827307701111
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.71875
{'train_loss': 0.6585679352283478, 'val_roc_auc': 0.8928571428571429, 'val_accuracy': 0.71875, 'val_loss': 0.6505827307701111}
 ROC_AUC: 0.8929|| Accuracy 0.7188 || Train Loss: 0.6586
 Val Loss: 0.6506 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.649578662445912
Test ROC-AUC: 0.8735119047619047
Test Accuracy: 0.7884615384615384
test_loss: 0.649578662445912
test_roc_auc: 0.8735119047619047
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6621721088886261
  Validation Loss: 0.6528177261352539
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 2/64:
  Train Loss: 0.6621212512254715
  Validation Loss: 0.6527634859085083
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 3/64:
  Train Loss: 0.662124365568161
  Validation Loss: 0.6527326107025146
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 4/64:
  Train Loss: 0.6621092855930328
  Validation Loss: 0.6526833176612854
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 5/64:
  Train Loss: 0.6620232313871384
  Validation Loss: 0.65257728099823
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 6/64:
  Train Loss: 0.6618756353855133
  Validation Loss: 0.6525132060050964
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 7/64:
  Train Loss: 0.6617714613676071
  Validation Loss: 0.6524717807769775
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 8/64:
  Train Loss: 0.661700427532196
  Validation Loss: 0.6524317264556885
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 9/64:
  Train Loss: 0.6616506278514862
  Validation Loss: 0.6524045467376709
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 10/64:
  Train Loss: 0.6616135388612747
  Validation Loss: 0.6523706912994385
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 11/64:
  Train Loss: 0.6615957319736481
  Validation Loss: 0.6523792743682861
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 12/64:
  Train Loss: 0.6615455001592636
  Validation Loss: 0.6523907780647278
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 13/64:
  Train Loss: 0.6614871621131897
  Validation Loss: 0.652396559715271
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 14/64:
  Train Loss: 0.6614343971014023
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:00:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:00:INFO:
[92mINFO [0m:      Received: evaluate message 1b5b4157-6535-4e50-aadd-d6e354152d4c
02/07/2025 22:36:00:INFO:Received: evaluate message 1b5b4157-6535-4e50-aadd-d6e354152d4c
[92mINFO [0m:      Sent reply
02/07/2025 22:36:03:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:03:INFO:
[92mINFO [0m:      Received: train message ce6c5fcc-1bdb-4f04-95a6-583f7e3aedda
02/07/2025 22:36:03:INFO:Received: train message ce6c5fcc-1bdb-4f04-95a6-583f7e3aedda
  Validation Loss: 0.6524317264556885
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 15/64:
  Train Loss: 0.6613992750644684
  Validation Loss: 0.6524562239646912
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.8125
Epoch 16/64:
  Train Loss: 0.6613565981388092
  Validation Loss: 0.6524854898452759
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 17/64:
  Train Loss: 0.6613186001777649
  Validation Loss: 0.652542233467102
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 18/64:
  Train Loss: 0.6612879484891891
  Validation Loss: 0.6525830030441284
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 19/64:
  Train Loss: 0.661213755607605
  Validation Loss: 0.6526095867156982
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 20/64:
  Train Loss: 0.6611592769622803
  Validation Loss: 0.6525866985321045
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 21/64:
  Train Loss: 0.6611242592334747
  Validation Loss: 0.6525879502296448
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 22/64:
  Train Loss: 0.6611205190420151
  Validation Loss: 0.6525677442550659
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 23/64:
  Train Loss: 0.6610802859067917
  Validation Loss: 0.652504563331604
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 24/64:
  Train Loss: 0.6609770506620407
  Validation Loss: 0.6524213552474976
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 25/64:
  Train Loss: 0.6608610302209854
  Validation Loss: 0.6523594856262207
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 26/64:
  Train Loss: 0.6607968658208847
  Validation Loss: 0.6523445844650269
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 27/64:
  Train Loss: 0.6607795506715775
  Validation Loss: 0.6523351073265076
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 28/64:
  Train Loss: 0.6607381999492645
  Validation Loss: 0.6523290872573853
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 29/64:
  Train Loss: 0.660700112581253
  Validation Loss: 0.6522765159606934
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 30/64:
  Train Loss: 0.6606292128562927
  Validation Loss: 0.65220707654953
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 31/64:
  Train Loss: 0.660529375076294
  Validation Loss: 0.6521742343902588
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 32/64:
  Train Loss: 0.6604693830013275
  Validation Loss: 0.6521927118301392
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.78125
Epoch 33/64:
  Train Loss: 0.660447359085083
  Validation Loss: 0.6521668434143066
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.78125
Epoch 34/64:
  Train Loss: 0.6604048013687134
  Validation Loss: 0.6521539092063904
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.78125
Epoch 35/64:
  Train Loss: 0.6603980213403702
  Validation Loss: 0.6521046161651611
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.78125
Epoch 36/64:
  Train Loss: 0.6603644639253616
  Validation Loss: 0.6521485447883606
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.78125
Epoch 37/64:
  Train Loss: 0.6603227108716965
  Validation Loss: 0.652097761631012
  Val ROC-AUC: 0.888888888888889
  Val Accuracy: 0.78125
Epoch 38/64:
  Train Loss: 0.6602219343185425
  Validation Loss: 0.6519808173179626
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 39/64:
  Train Loss: 0.6601506024599075
  Validation Loss: 0.651921808719635
  Val ROC-AUC: 0.8928571428571429
  Val Accuracy: 0.78125
Epoch 40/64:
  Train Loss: 0.6601067930459976
  Validation Loss: 0.651923418045044
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 41/64:
  Train Loss: 0.6600894927978516
  Validation Loss: 0.651917576789856
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 42/64:
  Train Loss: 0.660047858953476
  Validation Loss: 0.65189528465271
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 43/64:
  Train Loss: 0.6599927395582199
  Validation Loss: 0.6518853902816772
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 44/64:
  Train Loss: 0.6599782109260559
  Validation Loss: 0.651898980140686
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 45/64:
  Train Loss: 0.6599733233451843
  Validation Loss: 0.6519210338592529
  Val ROC-AUC: 0.8968253968253969
  Val Accuracy: 0.78125
Epoch 46/64:
  Train Loss: 0.659918025135994
  Validation Loss: 0.6519320011138916
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 47/64:
  Train Loss: 0.6598487943410873
  Validation Loss: 0.6519286632537842
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.6598115563392639
  Validation Loss: 0.6519196033477783
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.659792497754097
  Validation Loss: 0.6519129276275635
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6597662568092346
  Validation Loss: 0.6518704891204834
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.6596876531839371
  Validation Loss: 0.6518250107765198
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.6596536785364151
  Validation Loss: 0.6518088579177856
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6596185564994812
  Validation Loss: 0.6517930030822754
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.659623771905899
  Validation Loss: 0.6517753601074219
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.6596515327692032
  Validation Loss: 0.6517471075057983
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.6596421748399734
  Validation Loss: 0.6516751646995544
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.6596001386642456
  Validation Loss: 0.6516008377075195
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6594818830490112
  Validation Loss: 0.6515831351280212
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.6593934148550034
  Validation Loss: 0.6515781283378601
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6593159735202789
  Validation Loss: 0.6515330672264099
  Val ROC-AUC: 0.8928571428571428
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6591925621032715
  Validation Loss: 0.6514974236488342
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6590804904699326
  Validation Loss: 0.6514034271240234
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6589727401733398
  Validation Loss: 0.6513491868972778
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6588924676179886
  Validation Loss: 0.6512047052383423
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.78125
{'train_loss': 0.6588924676179886, 'val_roc_auc': 0.8888888888888888, 'val_accuracy': 0.78125, 'val_loss': 0.6512047052383423}
 ROC_AUC: 0.8889|| Accuracy 0.7812 || Train Loss: 0.6589
 Val Loss: 0.6512 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6486979800348098
Test ROC-AUC: 0.8716517857142858
Test Accuracy: 0.7884615384615384
test_loss: 0.6486979800348098
test_roc_auc: 0.8716517857142858
test_accuracy: 0.7884615384615384
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6579221785068512
  Validation Loss: 0.6670740842819214
  Val ROC-AUC: 0.78515625
  Val Accuracy: 0.71875
Epoch 2/64:
  Train Loss: 0.6581389605998993
  Validation Loss: 0.6670195460319519
  Val ROC-AUC: 0.78515625
  Val Accuracy: 0.71875
Epoch 3/64:
  Train Loss: 0.6581693738698959
  Validation Loss: 0.6669812202453613
  Val ROC-AUC: 0.78515625
  Val Accuracy: 0.71875
Epoch 4/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6581577211618423
  Validation Loss: 0.6669061183929443
  Val ROC-AUC: 0.78515625
  Val Accuracy: 0.71875
Epoch 5/64:
  Train Loss: 0.6581241190433502
  Validation Loss: 0.6668565273284912
  Val ROC-AUC: 0.78515625
  Val Accuracy: 0.71875
Epoch 6/64:
  Train Loss: 0.6580445021390915
  Validation Loss: 0.6667641401290894
  Val ROC-AUC: 0.78515625
  Val Accuracy: 0.71875
Epoch 7/64:
  Train Loss: 0.657859593629837
  Validation Loss: 0.6665836572647095
  Val ROC-AUC: 0.78515625
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.6576397567987442
  Validation Loss: 0.6663769483566284
  Val ROC-AUC: 0.7890625
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.6574564576148987
  Validation Loss: 0.6662559509277344
  Val ROC-AUC: 0.7890625
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.6573073267936707
  Validation Loss: 0.6661026477813721
  Val ROC-AUC: 0.7890625
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.6571678668260574
  Validation Loss: 0.6659536957740784
  Val ROC-AUC: 0.7890625
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.6570566743612289
  Validation Loss: 0.6658070087432861
  Val ROC-AUC: 0.7890625
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6569782197475433
  Validation Loss: 0.6656413078308105
  Val ROC-AUC: 0.79296875
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6568724364042282
  Validation Loss: 0.6655147075653076
  Val ROC-AUC: 0.79296875
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.65682353079319
  Validation Loss: 0.6654568910598755
  Val ROC-AUC: 0.79296875
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6567667424678802
  Validation Loss: 0.6654203534126282
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6566877216100693
  Validation Loss: 0.6653563976287842
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.6565756648778915
  Validation Loss: 0.6653157472610474
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6564533859491348
  Validation Loss: 0.6652662754058838
  Val ROC-AUC: 0.79296875
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6563463360071182
  Validation Loss: 0.6651365756988525
  Val ROC-AUC: 0.79296875
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6562719792127609
  Validation Loss: 0.6650071144104004
  Val ROC-AUC: 0.79296875
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6561659723520279
  Validation Loss: 0.664849042892456
  Val ROC-AUC: 0.79296875
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.6560302078723907
  Validation Loss: 0.6646808981895447
  Val ROC-AUC: 0.79296875
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6558560281991959
  Validation Loss: 0.6645479798316956
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6557189226150513
  Validation Loss: 0.6644890904426575
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.6556526571512222
  Validation Loss: 0.6643974781036377
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6555369049310684
  Validation Loss: 0.6642385125160217
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.6554393172264099
  Validation Loss: 0.6641532778739929
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.6553843021392822
  Validation Loss: 0.6640916466712952
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.6553049236536026
  Validation Loss: 0.6640217304229736
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6552562415599823
  Validation Loss: 0.6639735698699951
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6552267074584961
  Validation Loss: 0.6639361381530762
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.6551554799079895
  Validation Loss: 0.6639350056648254
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6551168859004974
  Validation Loss: 0.6639714241027832
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6551255285739899
  Validation Loss: 0.664013147354126
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6551320254802704
  Validation Loss: 0.6640411615371704
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6551694273948669
  Validation Loss: 0.664018452167511
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6551097482442856
  Validation Loss: 0.6639847755432129
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6550953686237335
  Validation Loss: 0.6639285683631897
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.65501269698143
  Validation Loss: 0.6638655662536621
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6549414247274399
  Validation Loss: 0.6637800931930542
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6548267304897308
  Validation Loss: 0.6636780500411987
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6547134518623352
  Validation Loss: 0.6635570526123047
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6545526683330536
  Validation Loss: 0.6634407043457031
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6543613374233246
  Validation Loss: 0.6633520126342773
  Val ROC-AUC: 0.796875
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6543014794588089
  Validation Loss: 0.6633414626121521
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6542310416698456
  Validation Loss: 0.6632875204086304
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6541259735822678
  Validation Loss: 0.6632483601570129
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.654040053486824
  Validation Loss: 0.663245439529419
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6539752334356308
  Validation Loss: 0.6631962060928345
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6539227068424225
  Validation Loss: 0.6631258726119995
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6538447737693787
  Validation Loss: 0.6630295515060425
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6537640392780304
  Validation Loss: 0.6629246473312378
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.6537014544010162
  Validation Loss: 0.6627953052520752
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.653647854924202
  Validation Loss: 0.6626454591751099
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.6536533087491989
  Validation Loss: 0.6625609397888184
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.6536104679107666
  Validation Loss: 0.6625193357467651
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.6535560339689255
  Validation Loss: 0.6623978614807129
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.653443768620491
  Validation Loss: 0.6623193621635437
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.6533967554569244
  Validation Loss: 0.662287175655365
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.6533184796571732
  Validation Loss: 0.6622934937477112
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.653312936425209
  Validation Loss: 0.6623343825340271
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6533006131649017
  Validation Loss: 0.6623693704605103
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6532746106386185
  Validation Loss: 0.6623687744140625
  Val ROC-AUC: 0.80078125
  Val Accuracy: 0.71875
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:13:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:13:INFO:
[92mINFO [0m:      Received: evaluate message 1841889d-a142-47b8-894e-0ed7387f8875
02/07/2025 22:36:13:INFO:Received: evaluate message 1841889d-a142-47b8-894e-0ed7387f8875
[92mINFO [0m:      Sent reply
02/07/2025 22:36:18:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:18:INFO:
[92mINFO [0m:      Received: train message eb3c2342-e03e-4ab8-842f-8bd2b3439834
02/07/2025 22:36:18:INFO:Received: train message eb3c2342-e03e-4ab8-842f-8bd2b3439834
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
{'train_loss': 0.6532746106386185, 'val_roc_auc': 0.80078125, 'val_accuracy': 0.71875, 'val_loss': 0.6623687744140625}
 ROC_AUC: 0.8008|| Accuracy 0.7188 || Train Loss: 0.6533
 Val Loss: 0.6624 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6479411609470844
Test ROC-AUC: 0.8716517857142856
Test Accuracy: 0.7788461538461539
test_loss: 0.6479411609470844
test_roc_auc: 0.8716517857142856
test_accuracy: 0.7788461538461539
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6639952063560486
  Validation Loss: 0.6396292448043823
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6638170629739761
  Validation Loss: 0.6397292017936707
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6636813133955002
  Validation Loss: 0.6398425102233887
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.6634897291660309
  Validation Loss: 0.6398615837097168
  Val ROC-AUC: 0.9372549019607843
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.6633145958185196
  Validation Loss: 0.6399233341217041
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.6631553769111633
  Validation Loss: 0.6400441527366638
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 7/64:
  Train Loss: 0.6630228459835052
  Validation Loss: 0.6401429772377014
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 8/64:
  Train Loss: 0.6629053056240082
  Validation Loss: 0.6402967572212219
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 9/64:
  Train Loss: 0.6627608239650726
  Validation Loss: 0.6404932141304016
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 10/64:
  Train Loss: 0.6626798808574677
  Validation Loss: 0.6406575441360474
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 11/64:
  Train Loss: 0.6625632643699646
  Validation Loss: 0.6407650709152222
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 12/64:
  Train Loss: 0.6624529361724854
  Validation Loss: 0.6409425735473633
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 13/64:
  Train Loss: 0.6623443216085434
  Validation Loss: 0.641087532043457
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.78125
Epoch 14/64:
  Train Loss: 0.6622237116098404
  Validation Loss: 0.6412662267684937
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.78125
Epoch 15/64:
  Train Loss: 0.6621307581663132
  Validation Loss: 0.6414016485214233
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.78125
Epoch 16/64:
  Train Loss: 0.6620279550552368
  Validation Loss: 0.6414569616317749
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.78125
Epoch 17/64:
  Train Loss: 0.6618680506944656
  Validation Loss: 0.6415243744850159
  Val ROC-AUC: 0.9294117647058823
  Val Accuracy: 0.78125
Epoch 18/64:
  Train Loss: 0.6617400795221329
  Validation Loss: 0.641604483127594
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 19/64:
  Train Loss: 0.6616448909044266
  Validation Loss: 0.6416175365447998
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 20/64:
  Train Loss: 0.661536917090416
  Validation Loss: 0.6416066288948059
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 21/64:
  Train Loss: 0.6614327728748322
  Validation Loss: 0.6416574716567993
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 22/64:
  Train Loss: 0.6613044291734695
  Validation Loss: 0.6417190432548523
  Val ROC-AUC: 0.9254901960784313
  Val Accuracy: 0.78125
Epoch 23/64:
  Train Loss: 0.6611513793468475
  Validation Loss: 0.6417183876037598
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 24/64:
  Train Loss: 0.660992294549942
  Validation Loss: 0.6417429447174072
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 25/64:
  Train Loss: 0.6608937978744507
  Validation Loss: 0.6417837142944336
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 26/64:
  Train Loss: 0.6607781648635864
  Validation Loss: 0.6418139934539795
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 27/64:
  Train Loss: 0.6606575697660446
  Validation Loss: 0.641823410987854
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 28/64:
  Train Loss: 0.6605647653341293
  Validation Loss: 0.6418502926826477
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 29/64:
  Train Loss: 0.6604578197002411
  Validation Loss: 0.6418895721435547
  Val ROC-AUC: 0.9215686274509803
  Val Accuracy: 0.78125
Epoch 30/64:
  Train Loss: 0.6602983921766281
  Validation Loss: 0.6419662237167358
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.78125
Epoch 31/64:
  Train Loss: 0.6601252406835556
  Validation Loss: 0.6419764757156372
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.78125
Epoch 32/64:
  Train Loss: 0.6600043922662735
  Validation Loss: 0.6420086622238159
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.78125
Epoch 33/64:
  Train Loss: 0.659915566444397
  Validation Loss: 0.6420220136642456
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.78125
Epoch 34/64:
  Train Loss: 0.6598054617643356
  Validation Loss: 0.6420741081237793
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.78125
Epoch 35/64:
  Train Loss: 0.6597002595663071
  Validation Loss: 0.6422095894813538
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.78125
Epoch 36/64:
  Train Loss: 0.659615620970726
  Validation Loss: 0.6423990726470947
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.78125
Epoch 37/64:
  Train Loss: 0.6595965176820755
  Validation Loss: 0.6425774693489075
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 38/64:
  Train Loss: 0.6595488786697388
  Validation Loss: 0.6427233219146729
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 39/64:
  Train Loss: 0.6594953835010529
  Validation Loss: 0.6428256034851074
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 40/64:
  Train Loss: 0.6594230979681015
  Validation Loss: 0.642913818359375
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 41/64:
  Train Loss: 0.6593167334794998
  Validation Loss: 0.6430163383483887
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 42/64:
  Train Loss: 0.6592935770750046
  Validation Loss: 0.6431506872177124
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 43/64:
  Train Loss: 0.6592534333467484
  Validation Loss: 0.6432140469551086
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 44/64:
  Train Loss: 0.659221887588501
  Validation Loss: 0.6432839632034302
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 45/64:
  Train Loss: 0.6591988205909729
  Validation Loss: 0.6433839201927185
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 46/64:
  Train Loss: 0.6591572910547256
  Validation Loss: 0.643505334854126
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 47/64:
  Train Loss: 0.6590839922428131
  Validation Loss: 0.6436241269111633
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 48/64:
  Train Loss: 0.658945232629776
  Validation Loss: 0.6436760425567627
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 49/64:
  Train Loss: 0.6588186621665955
  Validation Loss: 0.6437646150588989
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 50/64:
  Train Loss: 0.6587662547826767
  Validation Loss: 0.6439007520675659
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 51/64:
  Train Loss: 0.658751368522644
  Validation Loss: 0.6440223455429077
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 52/64:
  Train Loss: 0.6586723476648331
  Validation Loss: 0.6441280245780945
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 53/64:
  Train Loss: 0.6585896015167236
  Validation Loss: 0.6441926956176758
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 54/64:
  Train Loss: 0.6584760248661041
  Validation Loss: 0.6442737579345703
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:29:INFO:
[92mINFO [0m:      Received: evaluate message a582a02b-e3c9-4c6e-93a4-efae1192a8c1
02/07/2025 22:36:29:INFO:Received: evaluate message a582a02b-e3c9-4c6e-93a4-efae1192a8c1
[92mINFO [0m:      Sent reply
02/07/2025 22:36:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:30:INFO:
[92mINFO [0m:      Received: train message bff88f60-1283-464b-9997-aa0459177061
02/07/2025 22:36:30:INFO:Received: train message bff88f60-1283-464b-9997-aa0459177061
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 55/64:
  Train Loss: 0.658422514796257
  Validation Loss: 0.6443511247634888
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 56/64:
  Train Loss: 0.6584386378526688
  Validation Loss: 0.6444545388221741
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 57/64:
  Train Loss: 0.6584159582853317
  Validation Loss: 0.6445927023887634
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 58/64:
  Train Loss: 0.6584114283323288
  Validation Loss: 0.644730806350708
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 59/64:
  Train Loss: 0.658317819237709
  Validation Loss: 0.6448866128921509
  Val ROC-AUC: 0.9098039215686274
  Val Accuracy: 0.78125
Epoch 60/64:
  Train Loss: 0.6582399159669876
  Validation Loss: 0.6450599431991577
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.78125
Epoch 61/64:
  Train Loss: 0.6581469923257828
  Validation Loss: 0.6452016830444336
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.78125
Epoch 62/64:
  Train Loss: 0.6580538302659988
  Validation Loss: 0.6451944708824158
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.78125
Epoch 63/64:
  Train Loss: 0.6579757928848267
  Validation Loss: 0.6452299952507019
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.78125
Epoch 64/64:
  Train Loss: 0.6579203903675079
  Validation Loss: 0.6453531384468079
  Val ROC-AUC: 0.9019607843137255
  Val Accuracy: 0.78125
{'train_loss': 0.6579203903675079, 'val_roc_auc': 0.9019607843137255, 'val_accuracy': 0.78125, 'val_loss': 0.6453531384468079}
 ROC_AUC: 0.9020|| Accuracy 0.7812 || Train Loss: 0.6579
 Val Loss: 0.6454 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6473757558717177
Test ROC-AUC: 0.8701636904761905
Test Accuracy: 0.7692307692307693
test_loss: 0.6473757558717177
test_roc_auc: 0.8701636904761905
test_accuracy: 0.7692307692307693
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6704812049865723
  Validation Loss: 0.6107763051986694
  Val ROC-AUC: 0.8690476190476191
  Val Accuracy: 0.84375
Epoch 2/64:
  Train Loss: 0.6702424585819244
  Validation Loss: 0.6106845140457153
  Val ROC-AUC: 0.8650793650793651
  Val Accuracy: 0.84375
Epoch 3/64:
  Train Loss: 0.6700844317674637
  Validation Loss: 0.6105152368545532
  Val ROC-AUC: 0.8650793650793651
  Val Accuracy: 0.84375
Epoch 4/64:
  Train Loss: 0.6699042767286301
  Validation Loss: 0.6103963851928711
  Val ROC-AUC: 0.8690476190476192
  Val Accuracy: 0.84375
Epoch 5/64:
  Train Loss: 0.6697628498077393
  Validation Loss: 0.6103044748306274
  Val ROC-AUC: 0.8690476190476192
  Val Accuracy: 0.84375
Epoch 6/64:
  Train Loss: 0.6696432828903198
  Validation Loss: 0.6102148294448853
  Val ROC-AUC: 0.8690476190476192
  Val Accuracy: 0.84375
Epoch 7/64:
  Train Loss: 0.6695923656225204
  Validation Loss: 0.6101670861244202
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 8/64:
  Train Loss: 0.6695566922426224
  Validation Loss: 0.6102216839790344
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 9/64:
  Train Loss: 0.6695331633090973
  Validation Loss: 0.6102864742279053
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 10/64:
  Train Loss: 0.6695302575826645
  Validation Loss: 0.6103125810623169
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 11/64:
  Train Loss: 0.6695369631052017
  Validation Loss: 0.6103227138519287
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 12/64:
  Train Loss: 0.6695496886968613
  Validation Loss: 0.6102865934371948
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 13/64:
  Train Loss: 0.6695468872785568
  Validation Loss: 0.6102544069290161
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 14/64:
  Train Loss: 0.6695160269737244
  Validation Loss: 0.6102300882339478
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 15/64:
  Train Loss: 0.6694648563861847
  Validation Loss: 0.6101831793785095
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 16/64:
  Train Loss: 0.6694227606058121
  Validation Loss: 0.6101440191268921
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 17/64:
  Train Loss: 0.6693871766328812
  Validation Loss: 0.6101217269897461
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 18/64:
  Train Loss: 0.669319212436676
  Validation Loss: 0.6100931763648987
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 19/64:
  Train Loss: 0.6692629456520081
  Validation Loss: 0.6100852489471436
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.84375
Epoch 20/64:
  Train Loss: 0.669229581952095
  Validation Loss: 0.6100431084632874
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.6691426634788513
  Validation Loss: 0.6100344657897949
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6690852791070938
  Validation Loss: 0.6100469827651978
  Val ROC-AUC: 0.865079365079365
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6690102815628052
  Validation Loss: 0.6100178360939026
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6689220517873764
  Validation Loss: 0.6099839806556702
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6688433587551117
  Validation Loss: 0.6099713444709778
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.66880302131176
  Validation Loss: 0.6099579334259033
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6687681078910828
  Validation Loss: 0.6099533438682556
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.6687387377023697
  Validation Loss: 0.6098946332931519
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6686856299638748
  Validation Loss: 0.6097638010978699
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6686090677976608
  Validation Loss: 0.6096477508544922
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6685654371976852
  Validation Loss: 0.6095747947692871
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6685194224119186
  Validation Loss: 0.6095024347305298
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 33/64:
  Train Loss: 0.6684374511241913
  Validation Loss: 0.6094274520874023
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 34/64:
  Train Loss: 0.6683633327484131
  Validation Loss: 0.6093370914459229
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 35/64:
  Train Loss: 0.668238639831543
  Validation Loss: 0.6093457937240601
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 36/64:
  Train Loss: 0.6681700348854065
  Validation Loss: 0.609343945980072
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 37/64:
  Train Loss: 0.6681212186813354
  Validation Loss: 0.6093717813491821
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 38/64:
  Train Loss: 0.6681001782417297
  Validation Loss: 0.6093696355819702
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 39/64:
  Train Loss: 0.6681007891893387
  Validation Loss: 0.609390914440155
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 40/64:
  Train Loss: 0.6681197285652161
  Validation Loss: 0.6094825267791748
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 41/64:
  Train Loss: 0.6680963337421417
  Validation Loss: 0.6095284223556519
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 42/64:
  Train Loss: 0.6680337488651276
  Validation Loss: 0.6095255017280579
  Val ROC-AUC: 0.869047619047619
  Val Accuracy: 0.84375
Epoch 43/64:
  Train Loss: 0.6679879575967789
  Validation Loss: 0.609522819519043
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.84375
Epoch 44/64:
  Train Loss: 0.6679134219884872
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:42:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:42:INFO:
[92mINFO [0m:      Received: evaluate message 6fd01a23-51a0-4f57-8e41-291c719ba77a
02/07/2025 22:36:42:INFO:Received: evaluate message 6fd01a23-51a0-4f57-8e41-291c719ba77a
[92mINFO [0m:      Sent reply
02/07/2025 22:36:46:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:46:INFO:
[92mINFO [0m:      Received: train message b1d68d76-c3b1-401c-b13e-581488a037c9
02/07/2025 22:36:46:INFO:Received: train message b1d68d76-c3b1-401c-b13e-581488a037c9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6095057725906372
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.84375
Epoch 45/64:
  Train Loss: 0.6678499430418015
  Validation Loss: 0.6095147132873535
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.84375
Epoch 46/64:
  Train Loss: 0.6677865236997604
  Validation Loss: 0.6095227003097534
  Val ROC-AUC: 0.873015873015873
  Val Accuracy: 0.84375
Epoch 47/64:
  Train Loss: 0.6677330434322357
  Validation Loss: 0.6095513105392456
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 48/64:
  Train Loss: 0.6677025854587555
  Validation Loss: 0.6095401644706726
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 49/64:
  Train Loss: 0.6676637083292007
  Validation Loss: 0.609508216381073
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 50/64:
  Train Loss: 0.6676529943943024
  Validation Loss: 0.6094661355018616
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 51/64:
  Train Loss: 0.667612761259079
  Validation Loss: 0.6094725728034973
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 52/64:
  Train Loss: 0.6675799936056137
  Validation Loss: 0.6094104647636414
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 53/64:
  Train Loss: 0.6675607115030289
  Validation Loss: 0.6093989014625549
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 54/64:
  Train Loss: 0.6675173044204712
  Validation Loss: 0.6093511581420898
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 55/64:
  Train Loss: 0.6674544364213943
  Validation Loss: 0.609295129776001
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 56/64:
  Train Loss: 0.6673942804336548
  Validation Loss: 0.609113335609436
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 57/64:
  Train Loss: 0.6672819405794144
  Validation Loss: 0.6090370416641235
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 58/64:
  Train Loss: 0.6672588586807251
  Validation Loss: 0.6090526580810547
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 59/64:
  Train Loss: 0.6672551482915878
  Validation Loss: 0.6091163158416748
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 60/64:
  Train Loss: 0.6672229021787643
  Validation Loss: 0.6091068983078003
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 61/64:
  Train Loss: 0.6671553254127502
  Validation Loss: 0.6090828776359558
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 62/64:
  Train Loss: 0.6670802533626556
  Validation Loss: 0.6090896129608154
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 63/64:
  Train Loss: 0.667003720998764
  Validation Loss: 0.6091252565383911
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
Epoch 64/64:
  Train Loss: 0.6669935882091522
  Validation Loss: 0.6091799139976501
  Val ROC-AUC: 0.876984126984127
  Val Accuracy: 0.84375
{'train_loss': 0.6669935882091522, 'val_roc_auc': 0.876984126984127, 'val_accuracy': 0.84375, 'val_loss': 0.6091799139976501}
 ROC_AUC: 0.8770|| Accuracy 0.8438 || Train Loss: 0.6670
 Val Loss: 0.6092 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6470159186193576
Test ROC-AUC: 0.8679315476190477
Test Accuracy: 0.7692307692307693
test_loss: 0.6470159186193576
test_roc_auc: 0.8679315476190477
test_accuracy: 0.7692307692307693
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6513271033763885
  Validation Loss: 0.6851928234100342
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 2/64:
  Train Loss: 0.6510813981294632
  Validation Loss: 0.6851357221603394
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 3/64:
  Train Loss: 0.650911420583725
  Validation Loss: 0.6850591897964478
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 4/64:
  Train Loss: 0.6507682800292969
  Validation Loss: 0.6849982142448425
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 5/64:
  Train Loss: 0.6506650894880295
  Validation Loss: 0.6849537491798401
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 6/64:
  Train Loss: 0.6505209654569626
  Validation Loss: 0.6848695278167725
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 7/64:
  Train Loss: 0.6503765434026718
  Validation Loss: 0.6847795248031616
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 8/64:
  Train Loss: 0.6501958668231964
  Validation Loss: 0.6847050189971924
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 9/64:
  Train Loss: 0.6500021070241928
  Validation Loss: 0.6846531629562378
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 10/64:
  Train Loss: 0.6498669385910034
  Validation Loss: 0.6846381425857544
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 11/64:
  Train Loss: 0.6496898978948593
  Validation Loss: 0.6846526265144348
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 12/64:
  Train Loss: 0.6495827734470367
  Validation Loss: 0.684677004814148
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 13/64:
  Train Loss: 0.6495162099599838
  Validation Loss: 0.6847125291824341
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 14/64:
  Train Loss: 0.6494638174772263
  Validation Loss: 0.6848336458206177
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.75
Epoch 15/64:
  Train Loss: 0.6494440734386444
  Validation Loss: 0.6849792003631592
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 16/64:
  Train Loss: 0.6493981629610062
  Validation Loss: 0.685085117816925
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 17/64:
  Train Loss: 0.6493956595659256
  Validation Loss: 0.6851693391799927
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 18/64:
  Train Loss: 0.6493655443191528
  Validation Loss: 0.6851488351821899
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 19/64:
  Train Loss: 0.6493452042341232
  Validation Loss: 0.685082197189331
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.75
Epoch 20/64:
  Train Loss: 0.6492883414030075
  Validation Loss: 0.6850539445877075
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 21/64:
  Train Loss: 0.6492156535387039
  Validation Loss: 0.6849701404571533
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 22/64:
  Train Loss: 0.6491276174783707
  Validation Loss: 0.6849117279052734
  Val ROC-AUC: 0.8791666666666668
  Val Accuracy: 0.75
Epoch 23/64:
  Train Loss: 0.649012953042984
  Validation Loss: 0.6848764419555664
  Val ROC-AUC: 0.8833333333333334
  Val Accuracy: 0.75
Epoch 24/64:
  Train Loss: 0.6489056199789047
  Validation Loss: 0.684850811958313
  Val ROC-AUC: 0.8833333333333334
  Val Accuracy: 0.75
Epoch 25/64:
  Train Loss: 0.648817628622055
  Validation Loss: 0.684867262840271
  Val ROC-AUC: 0.8791666666666668
  Val Accuracy: 0.75
Epoch 26/64:
  Train Loss: 0.6487389504909515
  Validation Loss: 0.6848903894424438
  Val ROC-AUC: 0.8791666666666668
  Val Accuracy: 0.75
Epoch 27/64:
  Train Loss: 0.6486848145723343
  Validation Loss: 0.6848807334899902
  Val ROC-AUC: 0.8791666666666668
  Val Accuracy: 0.75
Epoch 28/64:
  Train Loss: 0.6486487686634064
  Validation Loss: 0.6848338842391968
  Val ROC-AUC: 0.8791666666666668
  Val Accuracy: 0.75
Epoch 29/64:
  Train Loss: 0.6486098915338516
  Validation Loss: 0.684770941734314
  Val ROC-AUC: 0.8791666666666668
  Val Accuracy: 0.75
Epoch 30/64:
  Train Loss: 0.6485627740621567
  Validation Loss: 0.6847077012062073
  Val ROC-AUC: 0.8791666666666668
  Val Accuracy: 0.75
Epoch 31/64:
  Train Loss: 0.6485214531421661
  Validation Loss: 0.6846740245819092
  Val ROC-AUC: 0.8791666666666668
  Val Accuracy: 0.75
Epoch 32/64:
  Train Loss: 0.6484972834587097
  Validation Loss: 0.6847560405731201
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 33/64:
  Train Loss: 0.6484958231449127
  Validation Loss: 0.6847753524780273
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 34/64:
  Train Loss: 0.6484898924827576
  Validation Loss: 0.6848340034484863
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 35/64:
  Train Loss: 0.648441806435585
  Validation Loss: 0.6848559975624084
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 36/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:59:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:59:INFO:
[92mINFO [0m:      Received: evaluate message 35c0638e-f794-4a84-844d-c3fe5afd1b09
02/07/2025 22:36:59:INFO:Received: evaluate message 35c0638e-f794-4a84-844d-c3fe5afd1b09
[92mINFO [0m:      Sent reply
02/07/2025 22:37:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:01:INFO:
[92mINFO [0m:      Received: train message f27bf5d3-d2ea-45f5-a304-0b496cef4a87
02/07/2025 22:37:01:INFO:Received: train message f27bf5d3-d2ea-45f5-a304-0b496cef4a87
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6483493596315384
  Validation Loss: 0.6848426461219788
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 37/64:
  Train Loss: 0.6482503265142441
  Validation Loss: 0.6848177909851074
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 38/64:
  Train Loss: 0.6481465399265289
  Validation Loss: 0.6847617626190186
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 39/64:
  Train Loss: 0.6480642259120941
  Validation Loss: 0.6846660375595093
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 40/64:
  Train Loss: 0.6479514986276627
  Validation Loss: 0.6845998764038086
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 41/64:
  Train Loss: 0.6478461027145386
  Validation Loss: 0.6845857501029968
  Val ROC-AUC: 0.875
  Val Accuracy: 0.75
Epoch 42/64:
  Train Loss: 0.647771567106247
  Validation Loss: 0.6845886707305908
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6476713418960571
  Validation Loss: 0.6846518516540527
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6476282477378845
  Validation Loss: 0.684752345085144
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6475995928049088
  Validation Loss: 0.6848490834236145
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6475785225629807
  Validation Loss: 0.6849397420883179
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6475324630737305
  Validation Loss: 0.6849932670593262
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6474987417459488
  Validation Loss: 0.6850082278251648
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6474301218986511
  Validation Loss: 0.685021162033081
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6473855823278427
  Validation Loss: 0.6850367784500122
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6473980247974396
  Validation Loss: 0.6851128935813904
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.6474134474992752
  Validation Loss: 0.6851335763931274
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6474467664957047
  Validation Loss: 0.685073733329773
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.6474707722663879
  Validation Loss: 0.6850274801254272
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.6474390625953674
  Validation Loss: 0.684938907623291
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.6474046409130096
  Validation Loss: 0.6849294900894165
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.6473959386348724
  Validation Loss: 0.6849283576011658
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.6473707854747772
  Validation Loss: 0.6848853230476379
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.6473312377929688
  Validation Loss: 0.6848418116569519
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.6473260372877121
  Validation Loss: 0.684805691242218
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.6473255753517151
  Validation Loss: 0.6847275495529175
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6472993344068527
  Validation Loss: 0.6847031116485596
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6472872197628021
  Validation Loss: 0.684754490852356
  Val ROC-AUC: 0.875
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6472982466220856
  Validation Loss: 0.6847882270812988
  Val ROC-AUC: 0.8708333333333333
  Val Accuracy: 0.71875
{'train_loss': 0.6472982466220856, 'val_roc_auc': 0.8708333333333333, 'val_accuracy': 0.71875, 'val_loss': 0.6847882270812988}
 ROC_AUC: 0.8708|| Accuracy 0.7188 || Train Loss: 0.6473
 Val Loss: 0.6848 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6468281192848315
Test ROC-AUC: 0.8694196428571429
Test Accuracy: 0.7692307692307693
test_loss: 0.6468281192848315
test_roc_auc: 0.8694196428571429
test_accuracy: 0.7692307692307693
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.6404460072517395
  Validation Loss: 0.7283005118370056
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.75
Epoch 2/64:
  Train Loss: 0.6402388513088226
  Validation Loss: 0.7281914949417114
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.75
Epoch 3/64:
  Train Loss: 0.6400281190872192
  Validation Loss: 0.7281163930892944
  Val ROC-AUC: 0.7792207792207793
  Val Accuracy: 0.75
Epoch 4/64:
  Train Loss: 0.6398392170667648
  Validation Loss: 0.7280706167221069
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.75
Epoch 5/64:
  Train Loss: 0.6396376490592957
  Validation Loss: 0.7280343770980835
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.75
Epoch 6/64:
  Train Loss: 0.6394387185573578
  Validation Loss: 0.7279480695724487
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.75
Epoch 7/64:
  Train Loss: 0.6392097175121307
  Validation Loss: 0.7278878688812256
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.71875
Epoch 8/64:
  Train Loss: 0.6390359848737717
  Validation Loss: 0.7278555631637573
  Val ROC-AUC: 0.7792207792207793
  Val Accuracy: 0.71875
Epoch 9/64:
  Train Loss: 0.6388289779424667
  Validation Loss: 0.7278082966804504
  Val ROC-AUC: 0.7792207792207793
  Val Accuracy: 0.71875
Epoch 10/64:
  Train Loss: 0.6386590301990509
  Validation Loss: 0.7277336120605469
  Val ROC-AUC: 0.7792207792207793
  Val Accuracy: 0.71875
Epoch 11/64:
  Train Loss: 0.6384949088096619
  Validation Loss: 0.7276832461357117
  Val ROC-AUC: 0.7792207792207793
  Val Accuracy: 0.71875
Epoch 12/64:
  Train Loss: 0.6383965611457825
  Validation Loss: 0.727643609046936
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.71875
Epoch 13/64:
  Train Loss: 0.6382429152727127
  Validation Loss: 0.7276002764701843
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.71875
Epoch 14/64:
  Train Loss: 0.6380855888128281
  Validation Loss: 0.7275497913360596
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.71875
Epoch 15/64:
  Train Loss: 0.6379953920841217
  Validation Loss: 0.7275098562240601
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.71875
Epoch 16/64:
  Train Loss: 0.6378735303878784
  Validation Loss: 0.7274584770202637
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.71875
Epoch 17/64:
  Train Loss: 0.6377756297588348
  Validation Loss: 0.727431058883667
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.71875
Epoch 18/64:
  Train Loss: 0.637698233127594
  Validation Loss: 0.7274703979492188
  Val ROC-AUC: 0.7878787878787878
  Val Accuracy: 0.71875
Epoch 19/64:
  Train Loss: 0.6375866532325745
  Validation Loss: 0.7274904847145081
  Val ROC-AUC: 0.7878787878787878
  Val Accuracy: 0.71875
Epoch 20/64:
  Train Loss: 0.6374780535697937
  Validation Loss: 0.7274985909461975
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.71875
Epoch 21/64:
  Train Loss: 0.6373326182365417
  Validation Loss: 0.7274777889251709
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.71875
Epoch 22/64:
  Train Loss: 0.6371995955705643
  Validation Loss: 0.727426290512085
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.71875
Epoch 23/64:
  Train Loss: 0.637041911482811
  Validation Loss: 0.7273996472358704
  Val ROC-AUC: 0.7835497835497836
  Val Accuracy: 0.71875
Epoch 24/64:
  Train Loss: 0.6369250267744064
  Validation Loss: 0.727358341217041
  Val ROC-AUC: 0.7792207792207793
  Val Accuracy: 0.71875
Epoch 25/64:
  Train Loss: 0.6368310749530792
  Validation Loss: 0.7273330092430115
  Val ROC-AUC: 0.774891774891775
  Val Accuracy: 0.71875
Epoch 26/64:
  Train Loss: 0.63674595952034
  Validation Loss: 0.7273162603378296
  Val ROC-AUC: 0.774891774891775
  Val Accuracy: 0.71875
Epoch 27/64:
  Train Loss: 0.6366509199142456
  Validation Loss: 0.7273019552230835
  Val ROC-AUC: 0.774891774891775
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:37:14:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:14:INFO:
[92mINFO [0m:      Received: evaluate message ad68c59a-71c3-4aff-a9cd-8f866bca7a8a
02/07/2025 22:37:14:INFO:Received: evaluate message ad68c59a-71c3-4aff-a9cd-8f866bca7a8a
[92mINFO [0m:      Sent reply
02/07/2025 22:37:14:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:14:INFO:
[92mINFO [0m:      Received: train message 675fac3e-7967-4ed0-ac81-42058de7fc8e
02/07/2025 22:37:14:INFO:Received: train message 675fac3e-7967-4ed0-ac81-42058de7fc8e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.71875
Epoch 28/64:
  Train Loss: 0.6365419626235962
  Validation Loss: 0.7273074388504028
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 29/64:
  Train Loss: 0.636449784040451
  Validation Loss: 0.7273238897323608
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 30/64:
  Train Loss: 0.6363202780485153
  Validation Loss: 0.7273486256599426
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 31/64:
  Train Loss: 0.6362058371305466
  Validation Loss: 0.7274002432823181
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 32/64:
  Train Loss: 0.6361401975154877
  Validation Loss: 0.727481484413147
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 33/64:
  Train Loss: 0.63606758415699
  Validation Loss: 0.7274621725082397
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 34/64:
  Train Loss: 0.6359652280807495
  Validation Loss: 0.7274681329727173
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 35/64:
  Train Loss: 0.6358834356069565
  Validation Loss: 0.7274802327156067
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 36/64:
  Train Loss: 0.6357906311750412
  Validation Loss: 0.7274959087371826
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 37/64:
  Train Loss: 0.6357299089431763
  Validation Loss: 0.7275576591491699
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 38/64:
  Train Loss: 0.6356895864009857
  Validation Loss: 0.7275279760360718
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 39/64:
  Train Loss: 0.6356302052736282
  Validation Loss: 0.7275300621986389
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 40/64:
  Train Loss: 0.6356284469366074
  Validation Loss: 0.7275476455688477
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 41/64:
  Train Loss: 0.6356126815080643
  Validation Loss: 0.7275640964508057
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 42/64:
  Train Loss: 0.6355816423892975
  Validation Loss: 0.7275292873382568
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 43/64:
  Train Loss: 0.6355249732732773
  Validation Loss: 0.727476954460144
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 44/64:
  Train Loss: 0.6354558914899826
  Validation Loss: 0.7274700403213501
  Val ROC-AUC: 0.7705627705627706
  Val Accuracy: 0.71875
Epoch 45/64:
  Train Loss: 0.6354269981384277
  Validation Loss: 0.7274861335754395
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 46/64:
  Train Loss: 0.6353892385959625
  Validation Loss: 0.7275100946426392
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 47/64:
  Train Loss: 0.6353341490030289
  Validation Loss: 0.7275317907333374
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 48/64:
  Train Loss: 0.6352783590555191
  Validation Loss: 0.7275214791297913
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 49/64:
  Train Loss: 0.6351988166570663
  Validation Loss: 0.7275394201278687
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 50/64:
  Train Loss: 0.6351363509893417
  Validation Loss: 0.7276209592819214
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 51/64:
  Train Loss: 0.6350743770599365
  Validation Loss: 0.7276746034622192
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 52/64:
  Train Loss: 0.635006919503212
  Validation Loss: 0.7277213931083679
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 53/64:
  Train Loss: 0.6349549293518066
  Validation Loss: 0.7277414798736572
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 54/64:
  Train Loss: 0.6349325776100159
  Validation Loss: 0.7277380228042603
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 55/64:
  Train Loss: 0.6349077671766281
  Validation Loss: 0.727741003036499
  Val ROC-AUC: 0.7662337662337662
  Val Accuracy: 0.71875
Epoch 56/64:
  Train Loss: 0.634863942861557
  Validation Loss: 0.7277709245681763
  Val ROC-AUC: 0.7619047619047619
  Val Accuracy: 0.71875
Epoch 57/64:
  Train Loss: 0.634809210896492
  Validation Loss: 0.7278121709823608
  Val ROC-AUC: 0.7575757575757576
  Val Accuracy: 0.71875
Epoch 58/64:
  Train Loss: 0.6347241103649139
  Validation Loss: 0.727813720703125
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 59/64:
  Train Loss: 0.6346389055252075
  Validation Loss: 0.7277981042861938
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 60/64:
  Train Loss: 0.6345780193805695
  Validation Loss: 0.7277747392654419
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 61/64:
  Train Loss: 0.6345211714506149
  Validation Loss: 0.727739691734314
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 62/64:
  Train Loss: 0.6344733089208603
  Validation Loss: 0.727712869644165
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 63/64:
  Train Loss: 0.6344105899333954
  Validation Loss: 0.7277058362960815
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
Epoch 64/64:
  Train Loss: 0.6343501061201096
  Validation Loss: 0.7277058362960815
  Val ROC-AUC: 0.7532467532467533
  Val Accuracy: 0.71875
{'train_loss': 0.6343501061201096, 'val_roc_auc': 0.7532467532467533, 'val_accuracy': 0.71875, 'val_loss': 0.7277058362960815}
 ROC_AUC: 0.7532|| Accuracy 0.7188 || Train Loss: 0.6344
 Val Loss: 0.7277 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6466510444879532
Test ROC-AUC: 0.8697916666666667
Test Accuracy: 0.7692307692307693
test_loss: 0.6466510444879532
test_roc_auc: 0.8697916666666667
test_accuracy: 0.7692307692307693
eval_cid: 0
[Client 0] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.4296875
Epoch 1/64:
  Train Loss: 0.662714958190918
  Validation Loss: 0.6385565996170044
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 2/64:
  Train Loss: 0.6624021381139755
  Validation Loss: 0.6385307908058167
  Val ROC-AUC: 0.875
  Val Accuracy: 0.78125
Epoch 3/64:
  Train Loss: 0.6621719747781754
  Validation Loss: 0.638479471206665
  Val ROC-AUC: 0.8671875
  Val Accuracy: 0.78125
Epoch 4/64:
  Train Loss: 0.6618959456682205
  Validation Loss: 0.6384578943252563
  Val ROC-AUC: 0.8671875
  Val Accuracy: 0.78125
Epoch 5/64:
  Train Loss: 0.6616727113723755
  Validation Loss: 0.638412594795227
  Val ROC-AUC: 0.8671875
  Val Accuracy: 0.78125
Epoch 6/64:
  Train Loss: 0.6614192724227905
  Validation Loss: 0.6383812427520752
  Val ROC-AUC: 0.8671875
  Val Accuracy: 0.78125
Epoch 7/64:
  Train Loss: 0.6611960381269455
  Validation Loss: 0.6383748054504395
  Val ROC-AUC: 0.8671875
  Val Accuracy: 0.78125
Epoch 8/64:
  Train Loss: 0.6609433591365814
  Validation Loss: 0.6383867859840393
  Val ROC-AUC: 0.8671875
  Val Accuracy: 0.78125
Epoch 9/64:
  Train Loss: 0.6607412546873093
  Validation Loss: 0.6383686065673828
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.78125
Epoch 10/64:
  Train Loss: 0.6605463325977325
  Validation Loss: 0.6383678913116455
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.78125
Epoch 11/64:
  Train Loss: 0.6603346765041351
  Validation Loss: 0.6383702754974365
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.78125
Epoch 12/64:
  Train Loss: 0.6601452827453613
  Validation Loss: 0.6383544206619263
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.78125
Epoch 13/64:
  Train Loss: 0.6599470674991608
  Validation Loss: 0.6383646726608276
  Val ROC-AUC: 0.86328125
  Val Accuracy: 0.78125
Epoch 14/64:
  Train Loss: 0.6597664058208466
  Validation Loss: 0.6383765339851379
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 15/64:
  Train Loss: 0.6596041768789291
  Validation Loss: 0.638418436050415
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 16/64:
  Train Loss: 0.6594300121068954
  Validation Loss: 0.6384534239768982
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 17/64:
  Train Loss: 0.6592680066823959
  Validation Loss: 0.6384556889533997
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 18/64:
  Train Loss: 0.6591152995824814
  Validation Loss: 0.6384978294372559
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:37:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:28:INFO:
[92mINFO [0m:      Received: evaluate message 4484f002-507b-4ec0-b7a4-39556f58c7df
02/07/2025 22:37:28:INFO:Received: evaluate message 4484f002-507b-4ec0-b7a4-39556f58c7df
[92mINFO [0m:      Sent reply
02/07/2025 22:37:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:30:INFO:
[92mINFO [0m:      Received: reconnect message 12289c3d-a37a-41f0-bad4-08fdea068057
02/07/2025 22:37:30:INFO:Received: reconnect message 12289c3d-a37a-41f0-bad4-08fdea068057
02/07/2025 22:37:30:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/07/2025 22:37:30:INFO:Disconnect and shut down
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 19/64:
  Train Loss: 0.6589704304933548
  Validation Loss: 0.6385403275489807
  Val ROC-AUC: 0.859375
  Val Accuracy: 0.8125
Epoch 20/64:
  Train Loss: 0.6588414758443832
  Validation Loss: 0.6385762095451355
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 21/64:
  Train Loss: 0.65868279337883
  Validation Loss: 0.6386288404464722
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 22/64:
  Train Loss: 0.6585643887519836
  Validation Loss: 0.6386677026748657
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 23/64:
  Train Loss: 0.6584465354681015
  Validation Loss: 0.6386978626251221
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 24/64:
  Train Loss: 0.6583316028118134
  Validation Loss: 0.6387474536895752
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 25/64:
  Train Loss: 0.6581904888153076
  Validation Loss: 0.638775646686554
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 26/64:
  Train Loss: 0.658105731010437
  Validation Loss: 0.6388338804244995
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 27/64:
  Train Loss: 0.6579691618680954
  Validation Loss: 0.6388648748397827
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 28/64:
  Train Loss: 0.65785713493824
  Validation Loss: 0.6389135122299194
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 29/64:
  Train Loss: 0.6577405631542206
  Validation Loss: 0.63896644115448
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 30/64:
  Train Loss: 0.6576534509658813
  Validation Loss: 0.6390213966369629
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 31/64:
  Train Loss: 0.6575573980808258
  Validation Loss: 0.6390926837921143
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.84375
Epoch 32/64:
  Train Loss: 0.6575027853250504
  Validation Loss: 0.639163613319397
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 33/64:
  Train Loss: 0.6574009656906128
  Validation Loss: 0.6392219066619873
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 34/64:
  Train Loss: 0.6573036015033722
  Validation Loss: 0.6392784118652344
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 35/64:
  Train Loss: 0.6572239995002747
  Validation Loss: 0.6393401622772217
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 36/64:
  Train Loss: 0.6571640968322754
  Validation Loss: 0.6393842101097107
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 37/64:
  Train Loss: 0.6570912003517151
  Validation Loss: 0.639452338218689
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 38/64:
  Train Loss: 0.6569936275482178
  Validation Loss: 0.6395113468170166
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 39/64:
  Train Loss: 0.6569282561540604
  Validation Loss: 0.6395643949508667
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 40/64:
  Train Loss: 0.6568650752305984
  Validation Loss: 0.6396092772483826
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 41/64:
  Train Loss: 0.6568073779344559
  Validation Loss: 0.6396871209144592
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 42/64:
  Train Loss: 0.6567419618368149
  Validation Loss: 0.639738917350769
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 43/64:
  Train Loss: 0.6566722095012665
  Validation Loss: 0.6397832036018372
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 44/64:
  Train Loss: 0.656633198261261
  Validation Loss: 0.639846920967102
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 45/64:
  Train Loss: 0.6565618962049484
  Validation Loss: 0.6399003267288208
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 46/64:
  Train Loss: 0.6565229743719101
  Validation Loss: 0.6399838328361511
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 47/64:
  Train Loss: 0.6564783453941345
  Validation Loss: 0.6400285959243774
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 48/64:
  Train Loss: 0.6564221680164337
  Validation Loss: 0.6401079297065735
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 49/64:
  Train Loss: 0.6563880294561386
  Validation Loss: 0.6401591300964355
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 50/64:
  Train Loss: 0.6563493460416794
  Validation Loss: 0.6402356624603271
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 51/64:
  Train Loss: 0.6563210040330887
  Validation Loss: 0.6403123140335083
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 52/64:
  Train Loss: 0.656293511390686
  Validation Loss: 0.6403629779815674
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 53/64:
  Train Loss: 0.6562412977218628
  Validation Loss: 0.640420138835907
  Val ROC-AUC: 0.85546875
  Val Accuracy: 0.8125
Epoch 54/64:
  Train Loss: 0.6561892926692963
  Validation Loss: 0.6404563188552856
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 55/64:
  Train Loss: 0.6561542302370071
  Validation Loss: 0.6405118703842163
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 56/64:
  Train Loss: 0.6561276763677597
  Validation Loss: 0.640587329864502
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 57/64:
  Train Loss: 0.656086653470993
  Validation Loss: 0.6406362056732178
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 58/64:
  Train Loss: 0.6560646593570709
  Validation Loss: 0.6407173871994019
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 59/64:
  Train Loss: 0.6560374945402145
  Validation Loss: 0.6407836675643921
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 60/64:
  Train Loss: 0.6560136377811432
  Validation Loss: 0.6408435106277466
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 61/64:
  Train Loss: 0.6559962183237076
  Validation Loss: 0.6409018039703369
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 62/64:
  Train Loss: 0.6559753865003586
  Validation Loss: 0.6409522891044617
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 63/64:
  Train Loss: 0.6559535712003708
  Validation Loss: 0.6410095691680908
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
Epoch 64/64:
  Train Loss: 0.6559308916330338
  Validation Loss: 0.6410659551620483
  Val ROC-AUC: 0.8515625
  Val Accuracy: 0.8125
{'train_loss': 0.6559308916330338, 'val_roc_auc': 0.8515625, 'val_accuracy': 0.8125, 'val_loss': 0.6410659551620483}
 ROC_AUC: 0.8516|| Accuracy 0.8125 || Train Loss: 0.6559
 Val Loss: 0.6411 
[Client 0] evaluate, config: {'batch_size': 1}
Test Loss: 0.6465500343877536
Test ROC-AUC: 0.8683035714285714
Test Accuracy: 0.7692307692307693
test_loss: 0.6465500343877536
test_roc_auc: 0.8683035714285714
test_accuracy: 0.7692307692307693
eval_cid: 0
CPU Time: 198.447876 seconds
Elapsed Time: 317.2675986289978 seconds
RAM Usage: 0.3733482360839844 megabytes
Logs saved in current directory
