nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:32:16:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:32:16:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 22:32:16:DEBUG:ChannelConnectivity.IDLE
02/07/2025 22:32:16:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738996336.533410 1759975 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/07/2025 22:32:17:INFO:
[92mINFO [0m:      Received: train message d3060c70-dcd4-4d55-8822-9c4d5dfc53c6
02/07/2025 22:32:17:INFO:Received: train message d3060c70-dcd4-4d55-8822-9c4d5dfc53c6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours/1.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours']
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5509706437587738
  Validation Loss: 0.6017811894416809
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 2/64:
  Train Loss: 0.5599904656410217
  Validation Loss: 0.6017228364944458
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 3/64:
  Train Loss: 0.5562376379966736
  Validation Loss: 0.6017314791679382
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 4/64:
  Train Loss: 0.5517419576644897
  Validation Loss: 0.6017599701881409
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 5/64:
  Train Loss: 0.5588986575603485
  Validation Loss: 0.6018285751342773
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 6/64:
  Train Loss: 0.557028591632843
  Validation Loss: 0.6018757224082947
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 7/64:
  Train Loss: 0.5523338615894318
  Validation Loss: 0.6018672585487366
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 8/64:
  Train Loss: 0.5538218915462494
  Validation Loss: 0.6018584370613098
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 9/64:
  Train Loss: 0.551697164773941
  Validation Loss: 0.6018087863922119
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 10/64:
  Train Loss: 0.5507595539093018
  Validation Loss: 0.6017659902572632
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 11/64:
  Train Loss: 0.5569232106208801
  Validation Loss: 0.6017346978187561
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 12/64:
  Train Loss: 0.5531815588474274
  Validation Loss: 0.6017114520072937
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 13/64:
  Train Loss: 0.5558716058731079
  Validation Loss: 0.6016945242881775
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 14/64:
  Train Loss: 0.559653639793396
  Validation Loss: 0.6016708016395569
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 15/64:
  Train Loss: 0.5543457269668579
  Validation Loss: 0.6016615629196167
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 16/64:
  Train Loss: 0.554450273513794
  Validation Loss: 0.6016038060188293
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 17/64:
  Train Loss: 0.5546780526638031
  Validation Loss: 0.6015563607215881
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 18/64:
  Train Loss: 0.561202198266983
  Validation Loss: 0.6015452146530151
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 19/64:
  Train Loss: 0.5672068297863007
  Validation Loss: 0.6015142798423767
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 20/64:
  Train Loss: 0.5489107072353363
  Validation Loss: 0.6015018820762634
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 21/64:
  Train Loss: 0.5574161410331726
  Validation Loss: 0.6015322208404541
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 22/64:
  Train Loss: 0.564842939376831
  Validation Loss: 0.6015482544898987
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 23/64:
  Train Loss: 0.5545384287834167
  Validation Loss: 0.6015645265579224
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 24/64:
  Train Loss: 0.5538657307624817
  Validation Loss: 0.6015989184379578
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 25/64:
  Train Loss: 0.5487677156925201
  Validation Loss: 0.6016038060188293
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 26/64:
  Train Loss: 0.5556744039058685
  Validation Loss: 0.6016167402267456
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 27/64:
  Train Loss: 0.5601425170898438
  Validation Loss: 0.6016796231269836
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 28/64:
  Train Loss: 0.556809663772583
  Validation Loss: 0.6017557978630066
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 29/64:
  Train Loss: 0.5616821944713593
  Validation Loss: 0.6018446087837219
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 30/64:
  Train Loss: 0.553379088640213
  Validation Loss: 0.6018735766410828
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 31/64:
  Train Loss: 0.5505943894386292
  Validation Loss: 0.6019044518470764
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 32/64:
  Train Loss: 0.5584166049957275
  Validation Loss: 0.6018876433372498
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 33/64:
  Train Loss: 0.5471790432929993
  Validation Loss: 0.6018285155296326
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 34/64:
  Train Loss: 0.5473782122135162
  Validation Loss: 0.6017829775810242
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7692307829856873
Epoch 35/64:
  Train Loss: 0.5623899102210999
  Validation Loss: 0.601714015007019
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 36/64:
  Train Loss: 0.5472607016563416
  Validation Loss: 0.6016940474510193
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 37/64:
  Train Loss: 0.5477672815322876
  Validation Loss: 0.6016255617141724
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 38/64:
  Train Loss: 0.5610294044017792
  Validation Loss: 0.601588249206543
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 39/64:
  Train Loss: 0.5519266426563263
  Validation Loss: 0.6015138626098633
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 40/64:
  Train Loss: 0.5484700202941895
  Validation Loss: 0.6014614105224609
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 41/64:
  Train Loss: 0.5537988543510437
  Validation Loss: 0.6014401316642761
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 42/64:
  Train Loss: 0.5552193224430084
  Validation Loss: 0.6014545559883118
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 43/64:
  Train Loss: 0.5547796785831451
  Validation Loss: 0.6014890670776367
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 44/64:
  Train Loss: 0.5478930175304413
  Validation Loss: 0.6015690565109253
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 45/64:
  Train Loss: 0.5569333732128143
  Validation Loss: 0.6016476154327393
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 46/64:
  Train Loss: 0.5513655543327332
  Validation Loss: 0.6016952991485596
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 47/64:
  Train Loss: 0.5570423305034637
  Validation Loss: 0.6017491817474365
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 48/64:
  Train Loss: 0.5503791272640228
  Validation Loss: 0.6018186807632446
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 49/64:
  Train Loss: 0.5511239171028137
  Validation Loss: 0.6018937230110168
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 50/64:
  Train Loss: 0.5500134527683258
  Validation Loss: 0.6019864082336426
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:32:24:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:29:INFO:
[92mINFO [0m:      Received: evaluate message 0395075e-bd52-489c-a8c0-188dbff5e52b
02/07/2025 22:32:29:INFO:Received: evaluate message 0395075e-bd52-489c-a8c0-188dbff5e52b
[92mINFO [0m:      Sent reply
02/07/2025 22:32:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:33:INFO:
[92mINFO [0m:      Received: train message d83244d6-1bee-4f38-aabc-7f7a61807c66
02/07/2025 22:32:33:INFO:Received: train message d83244d6-1bee-4f38-aabc-7f7a61807c66
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 51/64:
  Train Loss: 0.5562916398048401
  Validation Loss: 0.6020935773849487
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 52/64:
  Train Loss: 0.5517072677612305
  Validation Loss: 0.6021838188171387
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 53/64:
  Train Loss: 0.5473246872425079
  Validation Loss: 0.6022141575813293
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 54/64:
  Train Loss: 0.5506986379623413
  Validation Loss: 0.6022265553474426
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 55/64:
  Train Loss: 0.5503641366958618
  Validation Loss: 0.6022467613220215
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 56/64:
  Train Loss: 0.5556329786777496
  Validation Loss: 0.6022667288780212
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 57/64:
  Train Loss: 0.5566451847553253
  Validation Loss: 0.6022476553916931
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 58/64:
  Train Loss: 0.5513373613357544
  Validation Loss: 0.6022652983665466
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 59/64:
  Train Loss: 0.550490528345108
  Validation Loss: 0.6023268103599548
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 60/64:
  Train Loss: 0.5499642491340637
  Validation Loss: 0.6024071574211121
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 61/64:
  Train Loss: 0.5511540472507477
  Validation Loss: 0.6025009751319885
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 62/64:
  Train Loss: 0.5526275634765625
  Validation Loss: 0.602568507194519
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 63/64:
  Train Loss: 0.5510505139827728
  Validation Loss: 0.6026673913002014
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
Epoch 64/64:
  Train Loss: 0.5488118231296539
  Validation Loss: 0.6027715802192688
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.8461538553237915
{'train_loss': 0.5488118231296539, 'val_roc_auc': 0.7777777777777778, 'val_accuracy': 0.8461538553237915, 'val_loss': 0.6027715802192688}
 ROC_AUC: 0.7778|| Accuracy 0.8462 || Train Loss: 0.5488
 Val Loss: 0.6028 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5802012622356415
Test ROC-AUC: 0.5914285714285714
Test Accuracy: 0.6
test_loss: 0.5802012622356415
test_roc_auc: 0.5914285714285714
test_accuracy: 0.6
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5848462581634521
  Validation Loss: 0.4950617849826813
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.567441388964653
  Validation Loss: 0.49503248929977417
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5846201181411743
  Validation Loss: 0.49491626024246216
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5850517153739929
  Validation Loss: 0.4948274493217468
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5797692835330963
  Validation Loss: 0.4947924017906189
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5816065073013306
  Validation Loss: 0.49477526545524597
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5834009051322937
  Validation Loss: 0.494764119386673
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5725291669368744
  Validation Loss: 0.49479448795318604
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5750342607498169
  Validation Loss: 0.4948403537273407
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5791228115558624
  Validation Loss: 0.49491268396377563
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5795902907848358
  Validation Loss: 0.4949107766151428
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5789729654788971
  Validation Loss: 0.49487054347991943
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.587325245141983
  Validation Loss: 0.4948599934577942
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5832378268241882
  Validation Loss: 0.494871586561203
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5692802667617798
  Validation Loss: 0.4948246479034424
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5859613716602325
  Validation Loss: 0.4948176145553589
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5799500346183777
  Validation Loss: 0.4948205351829529
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5803887248039246
  Validation Loss: 0.49481451511383057
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5861404538154602
  Validation Loss: 0.4947468042373657
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5803874135017395
  Validation Loss: 0.49466472864151
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5814031362533569
  Validation Loss: 0.49463993310928345
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5840467810630798
  Validation Loss: 0.49463027715682983
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5790089964866638
  Validation Loss: 0.49460771679878235
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5751971304416656
  Validation Loss: 0.4945894479751587
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5906046628952026
  Validation Loss: 0.4946017861366272
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5786924958229065
  Validation Loss: 0.49458247423171997
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5777190029621124
  Validation Loss: 0.49453312158584595
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5821202099323273
  Validation Loss: 0.494417279958725
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5778741538524628
  Validation Loss: 0.49426019191741943
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5714618265628815
  Validation Loss: 0.49417468905448914
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5781140923500061
  Validation Loss: 0.4941233992576599
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5792643427848816
  Validation Loss: 0.49402472376823425
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5735720694065094
  Validation Loss: 0.4939284026622772
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5721631348133087
  Validation Loss: 0.49380114674568176
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5671893358230591
  Validation Loss: 0.49367988109588623
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5796516835689545
  Validation Loss: 0.49353834986686707
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5898537337779999
  Validation Loss: 0.4934140145778656
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5781588852405548
  Validation Loss: 0.49328672885894775
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5735734403133392
  Validation Loss: 0.49318164587020874
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5802772343158722
  Validation Loss: 0.4931012988090515
  Val ROC-AUC: nan
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 22:32:40:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:43:INFO:
[92mINFO [0m:      Received: evaluate message b2b593f7-0629-4bbf-bf3a-f4661239d44a
02/07/2025 22:32:43:INFO:Received: evaluate message b2b593f7-0629-4bbf-bf3a-f4661239d44a
[92mINFO [0m:      Sent reply
02/07/2025 22:32:45:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:45:INFO:
[92mINFO [0m:      Received: train message fcf35ba0-1b77-4267-a678-3e7d5cb631c9
02/07/2025 22:32:45:INFO:Received: train message fcf35ba0-1b77-4267-a678-3e7d5cb631c9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5647643804550171
  Validation Loss: 0.49304863810539246
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.5786102116107941
  Validation Loss: 0.4929784834384918
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.5747142136096954
  Validation Loss: 0.49289315938949585
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5806275308132172
  Validation Loss: 0.49277791380882263
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5767622590065002
  Validation Loss: 0.49268123507499695
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5712524950504303
  Validation Loss: 0.49258458614349365
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5756140053272247
  Validation Loss: 0.49248307943344116
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5726117193698883
  Validation Loss: 0.49241751432418823
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.5744059681892395
  Validation Loss: 0.4923708438873291
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5862691700458527
  Validation Loss: 0.4922903776168823
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5744222402572632
  Validation Loss: 0.492237389087677
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5816936194896698
  Validation Loss: 0.492219477891922
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5766085684299469
  Validation Loss: 0.4922214150428772
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5791843235492706
  Validation Loss: 0.4922446012496948
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5757948458194733
  Validation Loss: 0.4923166334629059
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5861678421497345
  Validation Loss: 0.4923740029335022
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5684485733509064
  Validation Loss: 0.4924120008945465
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5820963084697723
  Validation Loss: 0.4923999607563019
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.5720727741718292
  Validation Loss: 0.49238017201423645
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5814400017261505
  Validation Loss: 0.4923858046531677
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5818406641483307
  Validation Loss: 0.49239739775657654
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5780615210533142
  Validation Loss: 0.4924160838127136
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5747126340866089
  Validation Loss: 0.49243900179862976
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5758648216724396
  Validation Loss: 0.49242594838142395
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5758648216724396, 'val_roc_auc': nan, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.49242594838142395}
 ROC_AUC: nan|| Accuracy 0.6154 || Train Loss: 0.5759
 Val Loss: 0.4924 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5796777917279138
Test ROC-AUC: 0.6028571428571429
Test Accuracy: 0.6
test_loss: 0.5796777917279138
test_roc_auc: 0.6028571428571429
test_accuracy: 0.6
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5498733520507812
  Validation Loss: 0.6050075888633728
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 2/64:
  Train Loss: 0.5512882769107819
  Validation Loss: 0.6049171686172485
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 3/64:
  Train Loss: 0.5527588129043579
  Validation Loss: 0.6048107743263245
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 4/64:
  Train Loss: 0.5571779310703278
  Validation Loss: 0.604712188243866
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 5/64:
  Train Loss: 0.5524243116378784
  Validation Loss: 0.6046425700187683
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 6/64:
  Train Loss: 0.55177041888237
  Validation Loss: 0.6046370267868042
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 7/64:
  Train Loss: 0.5484420657157898
  Validation Loss: 0.6046136021614075
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 8/64:
  Train Loss: 0.5571356117725372
  Validation Loss: 0.6045984625816345
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 9/64:
  Train Loss: 0.5547276735305786
  Validation Loss: 0.6045933961868286
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 10/64:
  Train Loss: 0.5525661110877991
  Validation Loss: 0.6045994758605957
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 11/64:
  Train Loss: 0.5439119189977646
  Validation Loss: 0.6046053767204285
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 12/64:
  Train Loss: 0.5487202703952789
  Validation Loss: 0.6046050190925598
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 13/64:
  Train Loss: 0.5565219521522522
  Validation Loss: 0.6045937538146973
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 14/64:
  Train Loss: 0.5545091331005096
  Validation Loss: 0.6045695543289185
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 15/64:
  Train Loss: 0.5497438013553619
  Validation Loss: 0.6045611500740051
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 16/64:
  Train Loss: 0.55839604139328
  Validation Loss: 0.6045666933059692
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 17/64:
  Train Loss: 0.5550545752048492
  Validation Loss: 0.6045839190483093
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 18/64:
  Train Loss: 0.551126092672348
  Validation Loss: 0.6045883297920227
  Val ROC-AUC: 0.5
  Val Accuracy: 0.46153849363327026
Epoch 19/64:
  Train Loss: 0.5544001460075378
  Validation Loss: 0.6045711636543274
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 20/64:
  Train Loss: 0.5578201115131378
  Validation Loss: 0.6045676469802856
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 21/64:
  Train Loss: 0.5561017394065857
  Validation Loss: 0.6045733690261841
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 22/64:
  Train Loss: 0.5418593436479568
  Validation Loss: 0.6045808792114258
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 23/64:
  Train Loss: 0.5476646423339844
  Validation Loss: 0.6045978665351868
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 24/64:
  Train Loss: 0.5556400418281555
  Validation Loss: 0.6046228408813477
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 25/64:
  Train Loss: 0.5496685802936554
  Validation Loss: 0.604642927646637
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 26/64:
  Train Loss: 0.5498770773410797
  Validation Loss: 0.6046539545059204
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 27/64:
  Train Loss: 0.5542329251766205
  Validation Loss: 0.6046440005302429
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 28/64:
  Train Loss: 0.5492835342884064
  Validation Loss: 0.604655385017395
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 29/64:
  Train Loss: 0.5487005412578583
  Validation Loss: 0.6046429872512817
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 30/64:
  Train Loss: 0.5576124787330627
  Validation Loss: 0.6046092510223389
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:32:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:55:INFO:
[92mINFO [0m:      Received: evaluate message 9a20748f-c28a-4e34-bb61-5471ad5c887c
02/07/2025 22:32:55:INFO:Received: evaluate message 9a20748f-c28a-4e34-bb61-5471ad5c887c
[92mINFO [0m:      Sent reply
02/07/2025 22:32:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:56:INFO:
[92mINFO [0m:      Received: train message 6c0c4136-df34-466a-b694-28e20e67338d
02/07/2025 22:32:56:INFO:Received: train message 6c0c4136-df34-466a-b694-28e20e67338d
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 31/64:
  Train Loss: 0.5362756997346878
  Validation Loss: 0.6045740842819214
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 32/64:
  Train Loss: 0.5459607839584351
  Validation Loss: 0.6045383810997009
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 33/64:
  Train Loss: 0.5467671751976013
  Validation Loss: 0.6045088768005371
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 34/64:
  Train Loss: 0.5467588305473328
  Validation Loss: 0.6044878959655762
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 35/64:
  Train Loss: 0.5540898740291595
  Validation Loss: 0.6044653058052063
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 36/64:
  Train Loss: 0.5423895120620728
  Validation Loss: 0.6044435501098633
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 37/64:
  Train Loss: 0.5488206148147583
  Validation Loss: 0.6044130325317383
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 38/64:
  Train Loss: 0.5429753959178925
  Validation Loss: 0.6044251322746277
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 39/64:
  Train Loss: 0.5465885102748871
  Validation Loss: 0.604466438293457
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 40/64:
  Train Loss: 0.54555344581604
  Validation Loss: 0.6044948101043701
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 41/64:
  Train Loss: 0.5516289472579956
  Validation Loss: 0.6045488715171814
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 42/64:
  Train Loss: 0.5409832298755646
  Validation Loss: 0.6045982241630554
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 43/64:
  Train Loss: 0.5492637157440186
  Validation Loss: 0.604657769203186
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 44/64:
  Train Loss: 0.544982522726059
  Validation Loss: 0.6047059893608093
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 45/64:
  Train Loss: 0.5490083694458008
  Validation Loss: 0.6047806739807129
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 46/64:
  Train Loss: 0.5517745912075043
  Validation Loss: 0.6048411130905151
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 47/64:
  Train Loss: 0.5459451377391815
  Validation Loss: 0.6048914790153503
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 48/64:
  Train Loss: 0.5418298542499542
  Validation Loss: 0.60489422082901
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 49/64:
  Train Loss: 0.5527803897857666
  Validation Loss: 0.6048949956893921
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 50/64:
  Train Loss: 0.5460194051265717
  Validation Loss: 0.6049095392227173
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 51/64:
  Train Loss: 0.5426552891731262
  Validation Loss: 0.604897677898407
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 52/64:
  Train Loss: 0.5436506569385529
  Validation Loss: 0.6049074530601501
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 53/64:
  Train Loss: 0.5440475046634674
  Validation Loss: 0.6049057245254517
  Val ROC-AUC: 0.43333333333333335
  Val Accuracy: 0.46153849363327026
Epoch 54/64:
  Train Loss: 0.5514703989028931
  Validation Loss: 0.6049163341522217
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 55/64:
  Train Loss: 0.5493453443050385
  Validation Loss: 0.6049196720123291
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 56/64:
  Train Loss: 0.5475963950157166
  Validation Loss: 0.6048833727836609
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 57/64:
  Train Loss: 0.5381378531455994
  Validation Loss: 0.604822039604187
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 58/64:
  Train Loss: 0.5510253608226776
  Validation Loss: 0.6047744154930115
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 59/64:
  Train Loss: 0.5411430597305298
  Validation Loss: 0.6047534942626953
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 60/64:
  Train Loss: 0.5450792908668518
  Validation Loss: 0.6047172546386719
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 61/64:
  Train Loss: 0.540437787771225
  Validation Loss: 0.6046695709228516
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 62/64:
  Train Loss: 0.5426720678806305
  Validation Loss: 0.6046259999275208
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 63/64:
  Train Loss: 0.5462498962879181
  Validation Loss: 0.6045961380004883
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
Epoch 64/64:
  Train Loss: 0.5496023595333099
  Validation Loss: 0.6045761108398438
  Val ROC-AUC: 0.4
  Val Accuracy: 0.46153849363327026
{'train_loss': 0.5496023595333099, 'val_roc_auc': 0.4, 'val_accuracy': 0.46153849363327026, 'val_loss': 0.6045761108398438}
 ROC_AUC: 0.4000|| Accuracy 0.4615 || Train Loss: 0.5496
 Val Loss: 0.6046 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5791647083229489
Test ROC-AUC: 0.6057142857142858
Test Accuracy: 0.6222222222222222
test_loss: 0.5791647083229489
test_roc_auc: 0.6057142857142858
test_accuracy: 0.6222222222222222
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5610548257827759
  Validation Loss: 0.5546218752861023
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5737941563129425
  Validation Loss: 0.5544576048851013
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5639932453632355
  Validation Loss: 0.5543022155761719
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.568530261516571
  Validation Loss: 0.554242730140686
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.5556142330169678
  Validation Loss: 0.554169237613678
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.5675408244132996
  Validation Loss: 0.5540907382965088
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5601403713226318
  Validation Loss: 0.5539922118186951
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5673363208770752
  Validation Loss: 0.5539250373840332
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.5699689388275146
  Validation Loss: 0.5538598895072937
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.5701369643211365
  Validation Loss: 0.5538380742073059
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.558811604976654
  Validation Loss: 0.5538039207458496
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5621211230754852
  Validation Loss: 0.5537672638893127
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5654807686805725
  Validation Loss: 0.5537388324737549
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5662716925144196
  Validation Loss: 0.5537232160568237
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 15/64:
  Train Loss: 0.5584960579872131
  Validation Loss: 0.5536860227584839
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 16/64:
  Train Loss: 0.5708446502685547
  Validation Loss: 0.5536358952522278
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 17/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:04:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:07:INFO:
[92mINFO [0m:      Received: evaluate message 4a9d978e-df1f-4fe9-ba93-d4bf7f4e982d
02/07/2025 22:33:07:INFO:Received: evaluate message 4a9d978e-df1f-4fe9-ba93-d4bf7f4e982d
[92mINFO [0m:      Sent reply
02/07/2025 22:33:10:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:10:INFO:
[92mINFO [0m:      Received: train message f83ee1cf-f522-4af4-90da-7fd7230814ca
02/07/2025 22:33:10:INFO:Received: train message f83ee1cf-f522-4af4-90da-7fd7230814ca
  Train Loss: 0.5635291934013367
  Validation Loss: 0.5535765290260315
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 18/64:
  Train Loss: 0.5697952806949615
  Validation Loss: 0.5535592436790466
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 19/64:
  Train Loss: 0.5555093586444855
  Validation Loss: 0.5535228848457336
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 20/64:
  Train Loss: 0.5688677430152893
  Validation Loss: 0.5534840822219849
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 21/64:
  Train Loss: 0.5608297288417816
  Validation Loss: 0.5534407496452332
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 22/64:
  Train Loss: 0.5650880038738251
  Validation Loss: 0.5533595085144043
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 23/64:
  Train Loss: 0.5633966624736786
  Validation Loss: 0.5532554388046265
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 24/64:
  Train Loss: 0.5632994472980499
  Validation Loss: 0.5530999302864075
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 25/64:
  Train Loss: 0.5604861080646515
  Validation Loss: 0.5529522895812988
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 26/64:
  Train Loss: 0.5630280077457428
  Validation Loss: 0.5528290271759033
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 27/64:
  Train Loss: 0.5583503246307373
  Validation Loss: 0.5527116060256958
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 28/64:
  Train Loss: 0.5633819699287415
  Validation Loss: 0.5525790452957153
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 29/64:
  Train Loss: 0.5647141337394714
  Validation Loss: 0.5524568557739258
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 30/64:
  Train Loss: 0.5614595711231232
  Validation Loss: 0.5523467063903809
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 31/64:
  Train Loss: 0.5673249363899231
  Validation Loss: 0.5522192716598511
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 32/64:
  Train Loss: 0.5656627118587494
  Validation Loss: 0.55210942029953
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 33/64:
  Train Loss: 0.5616955757141113
  Validation Loss: 0.5520273447036743
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 34/64:
  Train Loss: 0.5679581463336945
  Validation Loss: 0.5519193410873413
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 35/64:
  Train Loss: 0.560880720615387
  Validation Loss: 0.5518244504928589
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 36/64:
  Train Loss: 0.5602491199970245
  Validation Loss: 0.5517667531967163
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 37/64:
  Train Loss: 0.5655319392681122
  Validation Loss: 0.5516955256462097
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 38/64:
  Train Loss: 0.5615927278995514
  Validation Loss: 0.5515934824943542
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 39/64:
  Train Loss: 0.5651916861534119
  Validation Loss: 0.5515168905258179
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 40/64:
  Train Loss: 0.560887485742569
  Validation Loss: 0.5514378547668457
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5679427981376648
  Validation Loss: 0.5513365268707275
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.562141627073288
  Validation Loss: 0.5512650609016418
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.5637266039848328
  Validation Loss: 0.5511921644210815
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5562929511070251
  Validation Loss: 0.5511217713356018
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5623211860656738
  Validation Loss: 0.5510281920433044
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5654658675193787
  Validation Loss: 0.550912082195282
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5530018508434296
  Validation Loss: 0.5508236885070801
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5551950335502625
  Validation Loss: 0.5507469177246094
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.5552709698677063
  Validation Loss: 0.5507002472877502
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5599230527877808
  Validation Loss: 0.5506308078765869
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5526130646467209
  Validation Loss: 0.550564706325531
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5577656328678131
  Validation Loss: 0.5505267977714539
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5661982297897339
  Validation Loss: 0.5504961609840393
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5559475123882294
  Validation Loss: 0.5504899024963379
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.55233234167099
  Validation Loss: 0.550506055355072
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5609560310840607
  Validation Loss: 0.5505157113075256
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5600777268409729
  Validation Loss: 0.5505191683769226
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5698254704475403
  Validation Loss: 0.550512433052063
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.5579907596111298
  Validation Loss: 0.5504820942878723
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5634112060070038
  Validation Loss: 0.550433874130249
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5528816431760788
  Validation Loss: 0.5503983497619629
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5597991943359375
  Validation Loss: 0.5503825545310974
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5581016838550568
  Validation Loss: 0.550365149974823
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5612075626850128
  Validation Loss: 0.5503278970718384
  Val ROC-AUC: 0.4090909090909091
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5612075626850128, 'val_roc_auc': 0.4090909090909091, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.5503278970718384}
 ROC_AUC: 0.4091|| Accuracy 0.6154 || Train Loss: 0.5612
 Val Loss: 0.5503 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5785362554921044
Test ROC-AUC: 0.6285714285714286
Test Accuracy: 0.6
test_loss: 0.5785362554921044
test_roc_auc: 0.6285714285714286
test_accuracy: 0.6
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5737398862838745
  Validation Loss: 0.5251923203468323
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5703187882900238
  Validation Loss: 0.5251739621162415
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Epoch 3/64:
  Train Loss: 0.5821481347084045
  Validation Loss: 0.5251503586769104
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5709077715873718
  Validation Loss: 0.5251784920692444
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.575181245803833
  Validation Loss: 0.5251247882843018
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5670806467533112
  Validation Loss: 0.5251018404960632
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5686782896518707
  Validation Loss: 0.5250719785690308
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5774731636047363
  Validation Loss: 0.5250182151794434
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5650111138820648
  Validation Loss: 0.5249711871147156
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5754321217536926
  Validation Loss: 0.5249325633049011
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5704417526721954
  Validation Loss: 0.5249154567718506
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5720841884613037
  Validation Loss: 0.5249072909355164
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5683991611003876
  Validation Loss: 0.5248886942863464
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.575629860162735
  Validation Loss: 0.5248613357543945
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5723137557506561
  Validation Loss: 0.5248000025749207
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5673997104167938
  Validation Loss: 0.5247462391853333
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5722402334213257
  Validation Loss: 0.5247329473495483
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5661720037460327
  Validation Loss: 0.5246891975402832
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5649259984493256
  Validation Loss: 0.5246495604515076
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5618029832839966
  Validation Loss: 0.5245881080627441
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5731357336044312
  Validation Loss: 0.5245414972305298
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5705631971359253
  Validation Loss: 0.524501621723175
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5741658210754395
  Validation Loss: 0.5244916081428528
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5659803748130798
  Validation Loss: 0.5245004892349243
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5698533952236176
  Validation Loss: 0.5245003700256348
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5836104154586792
  Validation Loss: 0.524545431137085
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5725522935390472
  Validation Loss: 0.5245929956436157
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5774507522583008
  Validation Loss: 0.5246423482894897
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5654678344726562
  Validation Loss: 0.5246899127960205
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5722714960575104
  Validation Loss: 0.5247483849525452
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5714260935783386
  Validation Loss: 0.5248173475265503
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5756914615631104
  Validation Loss: 0.5248776078224182
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5674609541893005
  Validation Loss: 0.5249229073524475
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5793258845806122
  Validation Loss: 0.5249314308166504
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5621609687805176
  Validation Loss: 0.5249338746070862
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5635073781013489
  Validation Loss: 0.5249273180961609
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5664044618606567
  Validation Loss: 0.5248842835426331
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5667339563369751
  Validation Loss: 0.5248923301696777
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5665543675422668
  Validation Loss: 0.5249013900756836
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.571883350610733
  Validation Loss: 0.5248798131942749
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.560176819562912
  Validation Loss: 0.5248289704322815
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5661686658859253
  Validation Loss: 0.5247454643249512
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5691452026367188
  Validation Loss: 0.524655282497406
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5639140009880066
  Validation Loss: 0.52459317445755
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.57740718126297
  Validation Loss: 0.5245634913444519
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5680865049362183
  Validation Loss: 0.5245058536529541
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5721376538276672
  Validation Loss: 0.5244652032852173
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5634543895721436
  Validation Loss: 0.5244337916374207
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5658937096595764
  Validation Loss: 0.5244265794754028
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5664416253566742
  Validation Loss: 0.5243884325027466
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5710749924182892
  Validation Loss: 0.5243440866470337
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5656967759132385
  Validation Loss: 0.5243113040924072
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5614930987358093
  Validation Loss: 0.5242961645126343
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5659652054309845
  Validation Loss: 0.5242499113082886
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5696154534816742
  Validation Loss: 0.5242325663566589
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5668387115001678
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:17:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:22:INFO:
[92mINFO [0m:      Received: evaluate message 472e548a-b4f1-4ac3-9538-8edb02c90558
02/07/2025 22:33:22:INFO:Received: evaluate message 472e548a-b4f1-4ac3-9538-8edb02c90558
[92mINFO [0m:      Sent reply
02/07/2025 22:33:22:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:22:INFO:
[92mINFO [0m:      Received: train message edd4c03b-21ca-4605-a30d-2329db6f1f5e
02/07/2025 22:33:22:INFO:Received: train message edd4c03b-21ca-4605-a30d-2329db6f1f5e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5242052674293518
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5702541172504425
  Validation Loss: 0.5241857171058655
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5585021674633026
  Validation Loss: 0.5241838097572327
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5634962916374207
  Validation Loss: 0.5241740345954895
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.568536102771759
  Validation Loss: 0.5241755247116089
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5637728273868561
  Validation Loss: 0.5241782069206238
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.563296914100647
  Validation Loss: 0.524148166179657
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5712607204914093
  Validation Loss: 0.5241315364837646
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5612086057662964
  Validation Loss: 0.5241175889968872
  Val ROC-AUC: 0.08333333333333333
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5612086057662964, 'val_roc_auc': 0.08333333333333333, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5241175889968872}
 ROC_AUC: 0.0833|| Accuracy 0.5385 || Train Loss: 0.5612
 Val Loss: 0.5241 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5779035217232175
Test ROC-AUC: 0.6542857142857142
Test Accuracy: 0.5777777777777777
test_loss: 0.5779035217232175
test_roc_auc: 0.6542857142857142
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5650089979171753
  Validation Loss: 0.5403908491134644
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5645146667957306
  Validation Loss: 0.5404887199401855
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5730074644088745
  Validation Loss: 0.5404852032661438
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5621680617332458
  Validation Loss: 0.5403780937194824
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5756853818893433
  Validation Loss: 0.5403114557266235
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5667949318885803
  Validation Loss: 0.5402958989143372
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.565181165933609
  Validation Loss: 0.5402563214302063
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5646438002586365
  Validation Loss: 0.5402309894561768
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.566484808921814
  Validation Loss: 0.5401565432548523
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5770650804042816
  Validation Loss: 0.5400883555412292
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5692721605300903
  Validation Loss: 0.539984405040741
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5696658492088318
  Validation Loss: 0.5398667454719543
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5698799192905426
  Validation Loss: 0.539811909198761
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5661351680755615
  Validation Loss: 0.5397282242774963
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.566475123167038
  Validation Loss: 0.5396072268486023
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5677959322929382
  Validation Loss: 0.5394537448883057
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5691619515419006
  Validation Loss: 0.5393030047416687
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.56967693567276
  Validation Loss: 0.5391392707824707
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5644918382167816
  Validation Loss: 0.5389944911003113
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5634862184524536
  Validation Loss: 0.5388513803482056
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5651672780513763
  Validation Loss: 0.538732647895813
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5674068033695221
  Validation Loss: 0.5386388897895813
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5587941706180573
  Validation Loss: 0.5385370850563049
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5628165602684021
  Validation Loss: 0.5384501814842224
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5652833580970764
  Validation Loss: 0.5383517146110535
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.563976377248764
  Validation Loss: 0.5382565259933472
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.565685510635376
  Validation Loss: 0.5381420850753784
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5601291358470917
  Validation Loss: 0.5380508899688721
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5618617236614227
  Validation Loss: 0.5379549264907837
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.569242000579834
  Validation Loss: 0.5378812551498413
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5662646293640137
  Validation Loss: 0.5378166437149048
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5616313219070435
  Validation Loss: 0.5377415418624878
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5722052156925201
  Validation Loss: 0.5376631617546082
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5658018290996552
  Validation Loss: 0.5375866293907166
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5690068602561951
  Validation Loss: 0.5375305414199829
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5567349791526794
  Validation Loss: 0.5374749898910522
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5546073317527771
  Validation Loss: 0.5374113321304321
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5705795288085938
  Validation Loss: 0.5373227000236511
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5557360053062439
  Validation Loss: 0.537208080291748
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5598581433296204
  Validation Loss: 0.5371204018592834
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5690868496894836
  Validation Loss: 0.5370515584945679
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.565909206867218
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:33:INFO:
[92mINFO [0m:      Received: evaluate message 2e040449-57ae-4b31-8620-8ad7e74d1275
02/07/2025 22:33:33:INFO:Received: evaluate message 2e040449-57ae-4b31-8620-8ad7e74d1275
[92mINFO [0m:      Sent reply
02/07/2025 22:33:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:34:INFO:
[92mINFO [0m:      Received: train message 121d4e67-bd33-4b41-9119-4f21e6b6062c
02/07/2025 22:33:34:INFO:Received: train message 121d4e67-bd33-4b41-9119-4f21e6b6062c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5370122790336609
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5657525956630707
  Validation Loss: 0.5370180606842041
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5684162974357605
  Validation Loss: 0.5370129346847534
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5620608627796173
  Validation Loss: 0.5370107293128967
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5574793815612793
  Validation Loss: 0.5370373725891113
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5639488101005554
  Validation Loss: 0.537041962146759
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5662116408348083
  Validation Loss: 0.5370278358459473
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5649167001247406
  Validation Loss: 0.5370373129844666
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5668638348579407
  Validation Loss: 0.53704434633255
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5614772439002991
  Validation Loss: 0.537060022354126
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5601401925086975
  Validation Loss: 0.537045419216156
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5628593266010284
  Validation Loss: 0.5370259881019592
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5653530061244965
  Validation Loss: 0.5369609594345093
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.571270763874054
  Validation Loss: 0.5368943810462952
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5648272931575775
  Validation Loss: 0.5368167757987976
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5635795295238495
  Validation Loss: 0.5367704629898071
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5599115490913391
  Validation Loss: 0.5367621779441833
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5603346526622772
  Validation Loss: 0.5367443561553955
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5638749897480011
  Validation Loss: 0.5366992950439453
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5639720261096954
  Validation Loss: 0.5366398692131042
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5679807066917419
  Validation Loss: 0.5365660786628723
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5642693340778351
  Validation Loss: 0.5364941358566284
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5674242675304413
  Validation Loss: 0.5364007949829102
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5674242675304413, 'val_roc_auc': 0.7272727272727273, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5364007949829102}
 ROC_AUC: 0.7273|| Accuracy 0.6923 || Train Loss: 0.5674
 Val Loss: 0.5364 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5773725728193919
Test ROC-AUC: 0.6628571428571428
Test Accuracy: 0.5777777777777777
test_loss: 0.5773725728193919
test_roc_auc: 0.6628571428571428
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5498562753200531
  Validation Loss: 0.6119596362113953
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.551356852054596
  Validation Loss: 0.6121853590011597
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5444779694080353
  Validation Loss: 0.6123729944229126
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5446600914001465
  Validation Loss: 0.612472653388977
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5399444252252579
  Validation Loss: 0.6125527620315552
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5460856556892395
  Validation Loss: 0.6126225590705872
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5461134314537048
  Validation Loss: 0.6126317381858826
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.545442134141922
  Validation Loss: 0.6126581430435181
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.54682657122612
  Validation Loss: 0.6126585006713867
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5527781844139099
  Validation Loss: 0.6127128601074219
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5431524217128754
  Validation Loss: 0.6128070950508118
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 12/64:
  Train Loss: 0.5407680869102478
  Validation Loss: 0.6128675937652588
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 13/64:
  Train Loss: 0.5535925626754761
  Validation Loss: 0.6128806471824646
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 14/64:
  Train Loss: 0.5524850487709045
  Validation Loss: 0.612898051738739
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 15/64:
  Train Loss: 0.5522556304931641
  Validation Loss: 0.6129144430160522
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 16/64:
  Train Loss: 0.5465099513530731
  Validation Loss: 0.6129654049873352
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 17/64:
  Train Loss: 0.5437768399715424
  Validation Loss: 0.6130207777023315
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 18/64:
  Train Loss: 0.5462765395641327
  Validation Loss: 0.613074004650116
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 19/64:
  Train Loss: 0.5514548122882843
  Validation Loss: 0.6131893992424011
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 20/64:
  Train Loss: 0.5502200722694397
  Validation Loss: 0.6132619976997375
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 21/64:
  Train Loss: 0.540697455406189
  Validation Loss: 0.6132926344871521
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 22/64:
  Train Loss: 0.5378676205873489
  Validation Loss: 0.6133531928062439
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 23/64:
  Train Loss: 0.5482595562934875
  Validation Loss: 0.6134508848190308
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 24/64:
  Train Loss: 0.5516324639320374
  Validation Loss: 0.6135638952255249
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 25/64:
  Train Loss: 0.5528469085693359
  Validation Loss: 0.6136710047721863
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 26/64:
  Train Loss: 0.550558477640152
  Validation Loss: 0.6137781143188477
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 27/64:
  Train Loss: 0.5480712652206421
  Validation Loss: 0.6138572692871094
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 28/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:40:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:44:INFO:
[92mINFO [0m:      Received: evaluate message 9c0e8af7-53e9-4e0e-aeb7-0a570f43be59
02/07/2025 22:33:44:INFO:Received: evaluate message 9c0e8af7-53e9-4e0e-aeb7-0a570f43be59
[92mINFO [0m:      Sent reply
02/07/2025 22:33:45:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:46:INFO:
[92mINFO [0m:      Received: train message bed7efbd-cac1-4b4d-9bee-7997a06985bb
02/07/2025 22:33:46:INFO:Received: train message bed7efbd-cac1-4b4d-9bee-7997a06985bb
  Train Loss: 0.5450770854949951
  Validation Loss: 0.6139200329780579
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 29/64:
  Train Loss: 0.5473698973655701
  Validation Loss: 0.6139684915542603
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 30/64:
  Train Loss: 0.5422123372554779
  Validation Loss: 0.6140186190605164
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 31/64:
  Train Loss: 0.553744912147522
  Validation Loss: 0.6140301823616028
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 32/64:
  Train Loss: 0.5382736921310425
  Validation Loss: 0.6140438318252563
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 33/64:
  Train Loss: 0.537681981921196
  Validation Loss: 0.614076554775238
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 34/64:
  Train Loss: 0.5454249083995819
  Validation Loss: 0.6141089797019958
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 35/64:
  Train Loss: 0.5380042195320129
  Validation Loss: 0.6141573786735535
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 36/64:
  Train Loss: 0.5449256896972656
  Validation Loss: 0.6142037510871887
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 37/64:
  Train Loss: 0.5349044501781464
  Validation Loss: 0.6142364144325256
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 38/64:
  Train Loss: 0.5435352921485901
  Validation Loss: 0.6142289042472839
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 39/64:
  Train Loss: 0.5464781522750854
  Validation Loss: 0.6142169833183289
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 40/64:
  Train Loss: 0.5395248830318451
  Validation Loss: 0.614170491695404
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 41/64:
  Train Loss: 0.54918372631073
  Validation Loss: 0.6141418814659119
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 42/64:
  Train Loss: 0.550358384847641
  Validation Loss: 0.6141154170036316
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 43/64:
  Train Loss: 0.5459855496883392
  Validation Loss: 0.614111602306366
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 44/64:
  Train Loss: 0.5459074079990387
  Validation Loss: 0.6141465306282043
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 45/64:
  Train Loss: 0.543084442615509
  Validation Loss: 0.6141982674598694
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 46/64:
  Train Loss: 0.5413439571857452
  Validation Loss: 0.6142224669456482
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 47/64:
  Train Loss: 0.5416679382324219
  Validation Loss: 0.614195704460144
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 48/64:
  Train Loss: 0.5419025719165802
  Validation Loss: 0.6141534447669983
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 49/64:
  Train Loss: 0.5503016114234924
  Validation Loss: 0.6140927672386169
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 50/64:
  Train Loss: 0.5456869900226593
  Validation Loss: 0.6140217185020447
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 51/64:
  Train Loss: 0.5453425943851471
  Validation Loss: 0.613948404788971
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 52/64:
  Train Loss: 0.550509512424469
  Validation Loss: 0.6138588786125183
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 53/64:
  Train Loss: 0.5371981412172318
  Validation Loss: 0.6138404011726379
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 54/64:
  Train Loss: 0.5433469712734222
  Validation Loss: 0.6138601899147034
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 55/64:
  Train Loss: 0.5379526317119598
  Validation Loss: 0.6138647198677063
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 56/64:
  Train Loss: 0.5373408049345016
  Validation Loss: 0.6138903498649597
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 57/64:
  Train Loss: 0.5422472059726715
  Validation Loss: 0.6138781309127808
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 58/64:
  Train Loss: 0.5411957800388336
  Validation Loss: 0.6138159036636353
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 59/64:
  Train Loss: 0.5432552993297577
  Validation Loss: 0.6137292981147766
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 60/64:
  Train Loss: 0.5417923629283905
  Validation Loss: 0.613653302192688
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 61/64:
  Train Loss: 0.5384877324104309
  Validation Loss: 0.6135883331298828
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 62/64:
  Train Loss: 0.5493135154247284
  Validation Loss: 0.6135193705558777
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 63/64:
  Train Loss: 0.539490669965744
  Validation Loss: 0.6135179400444031
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
Epoch 64/64:
  Train Loss: 0.5422497093677521
  Validation Loss: 0.6134960651397705
  Val ROC-AUC: 0.4666666666666667
  Val Accuracy: 0.46153849363327026
{'train_loss': 0.5422497093677521, 'val_roc_auc': 0.4666666666666667, 'val_accuracy': 0.46153849363327026, 'val_loss': 0.6134960651397705}
 ROC_AUC: 0.4667|| Accuracy 0.4615 || Train Loss: 0.5422
 Val Loss: 0.6135 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5769105129771762
Test ROC-AUC: 0.6799999999999999
Test Accuracy: 0.5777777777777777
test_loss: 0.5769105129771762
test_roc_auc: 0.6799999999999999
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5680762827396393
  Validation Loss: 0.5333033800125122
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5691460072994232
  Validation Loss: 0.5334500074386597
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5644053220748901
  Validation Loss: 0.533501923084259
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5597605407238007
  Validation Loss: 0.533494770526886
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5648837089538574
  Validation Loss: 0.5335058569908142
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5583246946334839
  Validation Loss: 0.5334978699684143
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5555222630500793
  Validation Loss: 0.5335007905960083
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5604326128959656
  Validation Loss: 0.5335504412651062
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.561351090669632
  Validation Loss: 0.5336220860481262
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5604662597179413
  Validation Loss: 0.5336564183235168
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5694812536239624
  Validation Loss: 0.5336869955062866
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5708441734313965
  Validation Loss: 0.5336576700210571
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5597520470619202
  Validation Loss: 0.5335856676101685
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5662956535816193
  Validation Loss: 0.5334730744361877
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:54:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:58:INFO:
[92mINFO [0m:      Received: evaluate message e10d5bbe-afc6-468d-b6df-229e1545cd82
02/07/2025 22:33:58:INFO:Received: evaluate message e10d5bbe-afc6-468d-b6df-229e1545cd82
[92mINFO [0m:      Sent reply
02/07/2025 22:34:00:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:02:INFO:
[92mINFO [0m:      Received: train message f53ecfd1-70cb-42a7-bf29-fe34f37f72f3
02/07/2025 22:34:02:INFO:Received: train message f53ecfd1-70cb-42a7-bf29-fe34f37f72f3
Epoch 15/64:
  Train Loss: 0.5714290738105774
  Validation Loss: 0.5334018468856812
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5692138373851776
  Validation Loss: 0.5334044694900513
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5646971762180328
  Validation Loss: 0.5333935022354126
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5637563765048981
  Validation Loss: 0.5333684086799622
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5627410709857941
  Validation Loss: 0.5333091616630554
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5637570917606354
  Validation Loss: 0.5332847833633423
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5693714022636414
  Validation Loss: 0.533315896987915
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5573497414588928
  Validation Loss: 0.5333565473556519
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5673071146011353
  Validation Loss: 0.5333499908447266
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.561104953289032
  Validation Loss: 0.5333439707756042
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5637397170066833
  Validation Loss: 0.5333486199378967
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5614829063415527
  Validation Loss: 0.5333797931671143
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5613095164299011
  Validation Loss: 0.5333734750747681
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5729615688323975
  Validation Loss: 0.5333654284477234
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.563822329044342
  Validation Loss: 0.5333436727523804
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5639110207557678
  Validation Loss: 0.5333672761917114
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5739530920982361
  Validation Loss: 0.5333749055862427
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.561460554599762
  Validation Loss: 0.5333396196365356
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5583118200302124
  Validation Loss: 0.5333461761474609
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5616277456283569
  Validation Loss: 0.5333328247070312
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5694972574710846
  Validation Loss: 0.533316433429718
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5708608627319336
  Validation Loss: 0.5333449840545654
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5683181881904602
  Validation Loss: 0.5333817601203918
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5667152404785156
  Validation Loss: 0.5334200859069824
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5642974376678467
  Validation Loss: 0.5333918333053589
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5549900233745575
  Validation Loss: 0.5333544015884399
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5610608756542206
  Validation Loss: 0.5333069562911987
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5621669590473175
  Validation Loss: 0.5332300662994385
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5652613937854767
  Validation Loss: 0.5331501960754395
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5728361010551453
  Validation Loss: 0.5330791473388672
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5632928609848022
  Validation Loss: 0.5330267548561096
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5695061683654785
  Validation Loss: 0.5330013036727905
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5648818910121918
  Validation Loss: 0.5329822301864624
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.566010594367981
  Validation Loss: 0.5329602956771851
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5569741129875183
  Validation Loss: 0.5329381823539734
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5642310678958893
  Validation Loss: 0.5329264402389526
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5556423366069794
  Validation Loss: 0.5329101085662842
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5586029589176178
  Validation Loss: 0.5328459739685059
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.565679669380188
  Validation Loss: 0.5327801704406738
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5607964098453522
  Validation Loss: 0.532700777053833
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5648227334022522
  Validation Loss: 0.5325992107391357
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5616738796234131
  Validation Loss: 0.532468855381012
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5597904920578003
  Validation Loss: 0.5323733687400818
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5642369985580444
  Validation Loss: 0.5322871804237366
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5573657155036926
  Validation Loss: 0.5322127938270569
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5618644654750824
  Validation Loss: 0.5321352481842041
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5614648163318634
  Validation Loss: 0.5320948362350464
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5618475377559662
  Validation Loss: 0.532030463218689
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.563359409570694
  Validation Loss: 0.5319432020187378
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5651519596576691
  Validation Loss: 0.5318482518196106
  Val ROC-AUC: 0.5
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5651519596576691, 'val_roc_auc': 0.5, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5318482518196106}
 ROC_AUC: 0.5000|| Accuracy 0.5385 || Train Loss: 0.5652
 Val Loss: 0.5318 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5766676240497165
Test ROC-AUC: 0.6828571428571428
Test Accuracy: 0.5777777777777777
test_loss: 0.5766676240497165
test_roc_auc: 0.6828571428571428
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5784346163272858
  Validation Loss: 0.49805670976638794
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5658677220344543
  Validation Loss: 0.4979909062385559
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5799218416213989
  Validation Loss: 0.49787208437919617
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5682857036590576
  Validation Loss: 0.49780407547950745
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5775114595890045
  Validation Loss: 0.4977293908596039
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 6/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.5698840916156769
  Validation Loss: 0.4977115988731384
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5786117911338806
  Validation Loss: 0.4977257549762726
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.572554737329483
  Validation Loss: 0.49771368503570557
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5805879831314087
  Validation Loss: 0.49772322177886963
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5669761002063751
  Validation Loss: 0.49772050976753235
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5785099864006042
  Validation Loss: 0.4977371394634247
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5755032002925873
  Validation Loss: 0.49772927165031433
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5766479074954987
  Validation Loss: 0.4977321922779083
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5772093236446381
  Validation Loss: 0.4977177679538727
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5759762227535248
  Validation Loss: 0.497702032327652
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5858454704284668
  Validation Loss: 0.49770018458366394
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5719934105873108
  Validation Loss: 0.4976866841316223
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5619176924228668
  Validation Loss: 0.4976489841938019
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5714203417301178
  Validation Loss: 0.4975939095020294
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5764518678188324
  Validation Loss: 0.4975287914276123
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5657819211483002
  Validation Loss: 0.49746638536453247
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5749812126159668
  Validation Loss: 0.49738794565200806
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5724233090877533
  Validation Loss: 0.4973062574863434
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5715755522251129
  Validation Loss: 0.497218519449234
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5768595337867737
  Validation Loss: 0.4971192181110382
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5704540312290192
  Validation Loss: 0.4970121681690216
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5775748789310455
  Validation Loss: 0.4968763589859009
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5758353471755981
  Validation Loss: 0.4967288374900818
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5723391175270081
  Validation Loss: 0.4966201186180115
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5740634799003601
  Validation Loss: 0.49650537967681885
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5746512413024902
  Validation Loss: 0.49642154574394226
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5692503452301025
  Validation Loss: 0.4963654577732086
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5741883218288422
  Validation Loss: 0.49631941318511963
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5770896375179291
  Validation Loss: 0.496256560087204
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.571680098772049
  Validation Loss: 0.49621817469596863
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5799817144870758
  Validation Loss: 0.4961647093296051
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5730673670768738
  Validation Loss: 0.4961031973361969
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5786299109458923
  Validation Loss: 0.4960290789604187
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5781961381435394
  Validation Loss: 0.4959399402141571
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5742693245410919
  Validation Loss: 0.4958353340625763
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5677534639835358
  Validation Loss: 0.49572160840034485
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5774241387844086
  Validation Loss: 0.49560606479644775
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5711531043052673
  Validation Loss: 0.49553629755973816
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5641745328903198
  Validation Loss: 0.4954764246940613
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5747597813606262
  Validation Loss: 0.4953998327255249
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5715748369693756
  Validation Loss: 0.4953629672527313
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5747541189193726
  Validation Loss: 0.4953431785106659
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5802577435970306
  Validation Loss: 0.49531394243240356
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5735658705234528
  Validation Loss: 0.495306134223938
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5783779621124268
  Validation Loss: 0.4952830374240875
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5679218173027039
  Validation Loss: 0.4952421486377716
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5632282495498657
  Validation Loss: 0.49520406126976013
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5757633745670319
  Validation Loss: 0.49515923857688904
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5671424567699432
  Validation Loss: 0.4951508045196533
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5728153884410858
  Validation Loss: 0.4951883554458618
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5749453008174896
  Validation Loss: 0.49519234895706177
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.572773665189743
  Validation Loss: 0.4952203929424286
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5762135088443756
  Validation Loss: 0.4952443838119507
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5703794956207275
  Validation Loss: 0.4952402710914612
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5707103908061981
  Validation Loss: 0.49525192379951477
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5660251080989838
  Validation Loss: 0.49521902203559875
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.57111856341362
  Validation Loss: 0.4951886832714081
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5742356777191162
  Validation Loss: 0.495172917842865
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5728192031383514
  Validation Loss: 0.49514344334602356
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:10:INFO:
[92mINFO [0m:      Received: evaluate message f280d67a-317e-4398-913c-ecdea6269636
02/07/2025 22:34:10:INFO:Received: evaluate message f280d67a-317e-4398-913c-ecdea6269636
[92mINFO [0m:      Sent reply
02/07/2025 22:34:10:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:11:INFO:
[92mINFO [0m:      Received: train message b82193d5-95e6-48e8-9f7f-108b015dfcc1
02/07/2025 22:34:11:INFO:Received: train message b82193d5-95e6-48e8-9f7f-108b015dfcc1
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
{'train_loss': 0.5728192031383514, 'val_roc_auc': 0.75, 'val_accuracy': 0.692307710647583, 'val_loss': 0.49514344334602356}
 ROC_AUC: 0.7500|| Accuracy 0.6923 || Train Loss: 0.5728
 Val Loss: 0.4951 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5765440404415131
Test ROC-AUC: 0.68
Test Accuracy: 0.5777777777777777
test_loss: 0.5765440404415131
test_roc_auc: 0.68
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5427039265632629
  Validation Loss: 0.6187768578529358
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5357404351234436
  Validation Loss: 0.6189153790473938
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5429390370845795
  Validation Loss: 0.6189810037612915
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5475291609764099
  Validation Loss: 0.6189952492713928
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5433077812194824
  Validation Loss: 0.6189666390419006
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.537395641207695
  Validation Loss: 0.618920624256134
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5413995385169983
  Validation Loss: 0.6188828349113464
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5423107743263245
  Validation Loss: 0.6188363432884216
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5421585142612457
  Validation Loss: 0.6188105940818787
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5501545071601868
  Validation Loss: 0.6187778115272522
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5409573912620544
  Validation Loss: 0.6187300086021423
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5428113639354706
  Validation Loss: 0.618693470954895
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5394960641860962
  Validation Loss: 0.6186597943305969
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5399665236473083
  Validation Loss: 0.6186166405677795
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5487206280231476
  Validation Loss: 0.6186172962188721
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5403929650783539
  Validation Loss: 0.6186119318008423
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.546476811170578
  Validation Loss: 0.6185845136642456
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.543369710445404
  Validation Loss: 0.61855149269104
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5399946570396423
  Validation Loss: 0.6185317039489746
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5468662083148956
  Validation Loss: 0.6185259819030762
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5381535887718201
  Validation Loss: 0.6184906959533691
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5406683087348938
  Validation Loss: 0.6184436082839966
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.543690413236618
  Validation Loss: 0.6184179186820984
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5452326536178589
  Validation Loss: 0.6183681488037109
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5445539355278015
  Validation Loss: 0.6182954907417297
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.540588766336441
  Validation Loss: 0.6182318925857544
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5350049734115601
  Validation Loss: 0.6181783080101013
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5468924045562744
  Validation Loss: 0.6181580424308777
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5465665757656097
  Validation Loss: 0.6181525588035583
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5392999649047852
  Validation Loss: 0.6181341409683228
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5466569662094116
  Validation Loss: 0.6181452870368958
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5402282178401947
  Validation Loss: 0.6181865930557251
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5474028885364532
  Validation Loss: 0.6182217001914978
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5453460216522217
  Validation Loss: 0.6182176470756531
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5504074096679688
  Validation Loss: 0.6181929707527161
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5407511293888092
  Validation Loss: 0.6181583404541016
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5452371537685394
  Validation Loss: 0.6181709170341492
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5385962426662445
  Validation Loss: 0.6181630492210388
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5451169610023499
  Validation Loss: 0.6181589365005493
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5438579320907593
  Validation Loss: 0.6181610226631165
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5452114641666412
  Validation Loss: 0.6181837916374207
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.537916749715805
  Validation Loss: 0.618187427520752
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5496979355812073
  Validation Loss: 0.6181702613830566
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5329751819372177
  Validation Loss: 0.6181284785270691
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5386750400066376
  Validation Loss: 0.6180483102798462
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5473744869232178
  Validation Loss: 0.6180157661437988
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5359546840190887
  Validation Loss: 0.6179734468460083
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5372988283634186
  Validation Loss: 0.6179587244987488
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5381908714771271
  Validation Loss: 0.6179588437080383
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5412621796131134
  Validation Loss: 0.6179577708244324
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5456542074680328
  Validation Loss: 0.6179542541503906
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:15:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:18:INFO:
[92mINFO [0m:      Received: evaluate message b8ed3cc1-f4e6-43ea-8b88-865e4de231e6
02/07/2025 22:34:18:INFO:Received: evaluate message b8ed3cc1-f4e6-43ea-8b88-865e4de231e6
[92mINFO [0m:      Sent reply
02/07/2025 22:34:18:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:19:INFO:
[92mINFO [0m:      Received: train message 262c7e9b-6039-4571-b428-eca3cfcf6596
02/07/2025 22:34:19:INFO:Received: train message 262c7e9b-6039-4571-b428-eca3cfcf6596
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5388466119766235
  Validation Loss: 0.6179485321044922
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5408346056938171
  Validation Loss: 0.6180078387260437
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5366897284984589
  Validation Loss: 0.6180561780929565
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5403488278388977
  Validation Loss: 0.6180988550186157
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5453793108463287
  Validation Loss: 0.61813884973526
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5340534895658493
  Validation Loss: 0.6182186603546143
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5309611856937408
  Validation Loss: 0.6183069944381714
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5411122143268585
  Validation Loss: 0.618384599685669
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5438072383403778
  Validation Loss: 0.618439793586731
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.539850115776062
  Validation Loss: 0.6184796094894409
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5389695167541504
  Validation Loss: 0.6185306906700134
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5420337915420532
  Validation Loss: 0.6185691952705383
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5425447225570679
  Validation Loss: 0.6186038255691528
  Val ROC-AUC: 0.638888888888889
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5425447225570679, 'val_roc_auc': 0.638888888888889, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.6186038255691528}
 ROC_AUC: 0.6389|| Accuracy 0.6154 || Train Loss: 0.5425
 Val Loss: 0.6186 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.576487586233351
Test ROC-AUC: 0.68
Test Accuracy: 0.5777777777777777
test_loss: 0.576487586233351
test_roc_auc: 0.68
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5656310021877289
  Validation Loss: 0.520804762840271
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5681605935096741
  Validation Loss: 0.5208106637001038
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5618980228900909
  Validation Loss: 0.5208722949028015
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.570542573928833
  Validation Loss: 0.5209357738494873
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.5600310862064362
  Validation Loss: 0.5209869742393494
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.5688705146312714
  Validation Loss: 0.5210310816764832
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5718307495117188
  Validation Loss: 0.5210646986961365
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5612302124500275
  Validation Loss: 0.5211088061332703
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.574523001909256
  Validation Loss: 0.5211043953895569
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.569960206747055
  Validation Loss: 0.5210810899734497
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.5670817792415619
  Validation Loss: 0.5210335850715637
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5664900541305542
  Validation Loss: 0.5210139155387878
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5635800361633301
  Validation Loss: 0.5209789276123047
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5630350112915039
  Validation Loss: 0.5209738612174988
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 15/64:
  Train Loss: 0.5704193413257599
  Validation Loss: 0.5209618210792542
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 16/64:
  Train Loss: 0.5651436746120453
  Validation Loss: 0.5209625363349915
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 17/64:
  Train Loss: 0.5694898962974548
  Validation Loss: 0.5209557414054871
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 18/64:
  Train Loss: 0.5642693936824799
  Validation Loss: 0.5209642052650452
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 19/64:
  Train Loss: 0.5722962319850922
  Validation Loss: 0.5209582448005676
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 20/64:
  Train Loss: 0.5646557211875916
  Validation Loss: 0.5209550857543945
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 21/64:
  Train Loss: 0.5707007944583893
  Validation Loss: 0.5209650993347168
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 22/64:
  Train Loss: 0.5642507374286652
  Validation Loss: 0.5209680795669556
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 23/64:
  Train Loss: 0.5644203424453735
  Validation Loss: 0.520950973033905
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 24/64:
  Train Loss: 0.5591045022010803
  Validation Loss: 0.520948052406311
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 25/64:
  Train Loss: 0.5639362633228302
  Validation Loss: 0.5209771990776062
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 26/64:
  Train Loss: 0.5700233280658722
  Validation Loss: 0.5210118889808655
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 27/64:
  Train Loss: 0.5629239976406097
  Validation Loss: 0.5209957361221313
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 28/64:
  Train Loss: 0.5654405653476715
  Validation Loss: 0.5209506154060364
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 29/64:
  Train Loss: 0.5701724886894226
  Validation Loss: 0.5209137201309204
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 30/64:
  Train Loss: 0.5687662959098816
  Validation Loss: 0.5208643674850464
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 31/64:
  Train Loss: 0.5677862465381622
  Validation Loss: 0.5208160281181335
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 32/64:
  Train Loss: 0.5611112713813782
  Validation Loss: 0.5207776427268982
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 33/64:
  Train Loss: 0.5626542568206787
  Validation Loss: 0.5207388401031494
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 34/64:
  Train Loss: 0.5681871473789215
  Validation Loss: 0.520724892616272
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 35/64:
  Train Loss: 0.5594903528690338
  Validation Loss: 0.5207145810127258
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 36/64:
  Train Loss: 0.5611354112625122
  Validation Loss: 0.5207054615020752
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 37/64:
  Train Loss: 0.5715955495834351
  Validation Loss: 0.5207012891769409
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:26:INFO:
[92mINFO [0m:      Received: evaluate message f8f1979a-2b99-421d-a890-ab94db43df59
02/07/2025 22:34:26:INFO:Received: evaluate message f8f1979a-2b99-421d-a890-ab94db43df59
[92mINFO [0m:      Sent reply
02/07/2025 22:34:27:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:28:INFO:
[92mINFO [0m:      Received: train message 9b687865-13e8-4e78-9574-e4417c830ed6
02/07/2025 22:34:28:INFO:Received: train message 9b687865-13e8-4e78-9574-e4417c830ed6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 38/64:
  Train Loss: 0.5696113705635071
  Validation Loss: 0.5206834077835083
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 39/64:
  Train Loss: 0.5650906562805176
  Validation Loss: 0.5206901431083679
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 40/64:
  Train Loss: 0.5625343322753906
  Validation Loss: 0.5207204818725586
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5592797994613647
  Validation Loss: 0.5207222104072571
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.5730179846286774
  Validation Loss: 0.5207282304763794
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.5603903532028198
  Validation Loss: 0.5207687020301819
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5698481500148773
  Validation Loss: 0.5208028554916382
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5678165555000305
  Validation Loss: 0.5208120346069336
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5616022646427155
  Validation Loss: 0.5208208560943604
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5624231100082397
  Validation Loss: 0.5208264589309692
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5621906816959381
  Validation Loss: 0.5208333134651184
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.5679499208927155
  Validation Loss: 0.5208216905593872
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.558271050453186
  Validation Loss: 0.5208138823509216
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5651422739028931
  Validation Loss: 0.5207845568656921
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5693331658840179
  Validation Loss: 0.520745575428009
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5551003068685532
  Validation Loss: 0.5207164883613586
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5659182667732239
  Validation Loss: 0.5206708312034607
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5594747364521027
  Validation Loss: 0.520627498626709
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5673412680625916
  Validation Loss: 0.5205855965614319
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5580576062202454
  Validation Loss: 0.5205402374267578
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5682967603206635
  Validation Loss: 0.5204916000366211
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.5614706873893738
  Validation Loss: 0.5204392075538635
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5544563382863998
  Validation Loss: 0.5203967690467834
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5651163160800934
  Validation Loss: 0.5203632116317749
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5632153451442719
  Validation Loss: 0.5203381180763245
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5620134174823761
  Validation Loss: 0.5203037261962891
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5630243420600891
  Validation Loss: 0.5202785730361938
  Val ROC-AUC: 0.3333333333333333
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5630243420600891, 'val_roc_auc': 0.3333333333333333, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.5202785730361938}
 ROC_AUC: 0.3333|| Accuracy 0.6154 || Train Loss: 0.5630
 Val Loss: 0.5203 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5764074981212616
Test ROC-AUC: 0.6828571428571428
Test Accuracy: 0.5777777777777777
test_loss: 0.5764074981212616
test_roc_auc: 0.6828571428571428
test_accuracy: 0.5777777777777777
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5541073381900787
  Validation Loss: 0.5858916640281677
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.38461539149284363
Epoch 2/64:
  Train Loss: 0.5511075556278229
  Validation Loss: 0.585927426815033
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 3/64:
  Train Loss: 0.5589611530303955
  Validation Loss: 0.5859091877937317
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 4/64:
  Train Loss: 0.5536090731620789
  Validation Loss: 0.5858749747276306
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 5/64:
  Train Loss: 0.5559431612491608
  Validation Loss: 0.5858464241027832
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 6/64:
  Train Loss: 0.5524259507656097
  Validation Loss: 0.5857940316200256
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 7/64:
  Train Loss: 0.5477970242500305
  Validation Loss: 0.5857539176940918
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 8/64:
  Train Loss: 0.5507167279720306
  Validation Loss: 0.5857171416282654
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 9/64:
  Train Loss: 0.5501733720302582
  Validation Loss: 0.5856900215148926
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 10/64:
  Train Loss: 0.5403369665145874
  Validation Loss: 0.5856286287307739
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 11/64:
  Train Loss: 0.5421628504991531
  Validation Loss: 0.5855591297149658
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.38461539149284363
Epoch 12/64:
  Train Loss: 0.5548970401287079
  Validation Loss: 0.585516095161438
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.38461539149284363
Epoch 13/64:
  Train Loss: 0.552913248538971
  Validation Loss: 0.5854907035827637
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.38461539149284363
Epoch 14/64:
  Train Loss: 0.5430445224046707
  Validation Loss: 0.5854408740997314
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 15/64:
  Train Loss: 0.5621339976787567
  Validation Loss: 0.5854318737983704
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 16/64:
  Train Loss: 0.5468704998493195
  Validation Loss: 0.5854114890098572
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 17/64:
  Train Loss: 0.5474022030830383
  Validation Loss: 0.5853686928749084
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 18/64:
  Train Loss: 0.5473455488681793
  Validation Loss: 0.5853168368339539
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 19/64:
  Train Loss: 0.5652533769607544
  Validation Loss: 0.5852482318878174
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 20/64:
  Train Loss: 0.5549652576446533
  Validation Loss: 0.5851494669914246
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 21/64:
  Train Loss: 0.5525988340377808
  Validation Loss: 0.5850823521614075
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 22/64:
  Train Loss: 0.5520474910736084
  Validation Loss: 0.5850498080253601
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 23/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:31:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:33:INFO:
[92mINFO [0m:      Received: evaluate message c063d271-737c-4501-9d0b-961c914935af
02/07/2025 22:34:33:INFO:Received: evaluate message c063d271-737c-4501-9d0b-961c914935af
[92mINFO [0m:      Sent reply
02/07/2025 22:34:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:33:INFO:
[92mINFO [0m:      Received: train message 497d4a76-20a8-4217-a5dc-709298552669
02/07/2025 22:34:33:INFO:Received: train message 497d4a76-20a8-4217-a5dc-709298552669
  Train Loss: 0.5548180639743805
  Validation Loss: 0.5850642323493958
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 24/64:
  Train Loss: 0.5433819591999054
  Validation Loss: 0.5850831270217896
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 25/64:
  Train Loss: 0.5553285777568817
  Validation Loss: 0.5850673913955688
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 26/64:
  Train Loss: 0.5560852885246277
  Validation Loss: 0.5850481986999512
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 27/64:
  Train Loss: 0.5586569905281067
  Validation Loss: 0.5850321054458618
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 28/64:
  Train Loss: 0.5512605607509613
  Validation Loss: 0.5850531458854675
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 29/64:
  Train Loss: 0.5435690581798553
  Validation Loss: 0.5850602984428406
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 30/64:
  Train Loss: 0.5544721484184265
  Validation Loss: 0.5850633978843689
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 31/64:
  Train Loss: 0.5401589423418045
  Validation Loss: 0.5850644707679749
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 32/64:
  Train Loss: 0.5515588223934174
  Validation Loss: 0.5850578546524048
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 33/64:
  Train Loss: 0.5473066866397858
  Validation Loss: 0.5850821733474731
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 34/64:
  Train Loss: 0.5537801682949066
  Validation Loss: 0.5851166248321533
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 35/64:
  Train Loss: 0.5572899878025055
  Validation Loss: 0.5851171612739563
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 36/64:
  Train Loss: 0.5427369773387909
  Validation Loss: 0.585090160369873
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 37/64:
  Train Loss: 0.546659380197525
  Validation Loss: 0.585066020488739
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 38/64:
  Train Loss: 0.5499962568283081
  Validation Loss: 0.5850576758384705
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 39/64:
  Train Loss: 0.5464689433574677
  Validation Loss: 0.5850529670715332
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 40/64:
  Train Loss: 0.5520603060722351
  Validation Loss: 0.5850571393966675
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 41/64:
  Train Loss: 0.550212174654007
  Validation Loss: 0.5850607752799988
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 42/64:
  Train Loss: 0.5557726621627808
  Validation Loss: 0.5850459337234497
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 43/64:
  Train Loss: 0.5482670366764069
  Validation Loss: 0.5850299596786499
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 44/64:
  Train Loss: 0.5504276156425476
  Validation Loss: 0.585016131401062
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 45/64:
  Train Loss: 0.5503859519958496
  Validation Loss: 0.5850271582603455
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 46/64:
  Train Loss: 0.5463964343070984
  Validation Loss: 0.5850488543510437
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 47/64:
  Train Loss: 0.5513018071651459
  Validation Loss: 0.5850985050201416
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 48/64:
  Train Loss: 0.5393450558185577
  Validation Loss: 0.585165798664093
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 49/64:
  Train Loss: 0.553341269493103
  Validation Loss: 0.5852108001708984
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 50/64:
  Train Loss: 0.5503657162189484
  Validation Loss: 0.5852495431900024
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 51/64:
  Train Loss: 0.5493574738502502
  Validation Loss: 0.5852668285369873
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 52/64:
  Train Loss: 0.5462633371353149
  Validation Loss: 0.5852451324462891
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 53/64:
  Train Loss: 0.544857382774353
  Validation Loss: 0.5852344632148743
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 54/64:
  Train Loss: 0.5515085160732269
  Validation Loss: 0.585254430770874
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 55/64:
  Train Loss: 0.5467133522033691
  Validation Loss: 0.5852802395820618
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 56/64:
  Train Loss: 0.5475482046604156
  Validation Loss: 0.5853232741355896
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 57/64:
  Train Loss: 0.5539222955703735
  Validation Loss: 0.5853525996208191
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 58/64:
  Train Loss: 0.5492753982543945
  Validation Loss: 0.5853654146194458
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 59/64:
  Train Loss: 0.5416341125965118
  Validation Loss: 0.5853815078735352
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 60/64:
  Train Loss: 0.5515679121017456
  Validation Loss: 0.5854037404060364
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 61/64:
  Train Loss: 0.5467365682125092
  Validation Loss: 0.5854129791259766
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 62/64:
  Train Loss: 0.5510404706001282
  Validation Loss: 0.5854223966598511
  Val ROC-AUC: 0.45454545454545453
  Val Accuracy: 0.3076923191547394
Epoch 63/64:
  Train Loss: 0.5493300259113312
  Validation Loss: 0.5854336023330688
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
Epoch 64/64:
  Train Loss: 0.5450974404811859
  Validation Loss: 0.5854476094245911
  Val ROC-AUC: 0.40909090909090906
  Val Accuracy: 0.3076923191547394
{'train_loss': 0.5450974404811859, 'val_roc_auc': 0.40909090909090906, 'val_accuracy': 0.3076923191547394, 'val_loss': 0.5854476094245911}
 ROC_AUC: 0.4091|| Accuracy 0.3077 || Train Loss: 0.5451
 Val Loss: 0.5854 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5762367539935642
Test ROC-AUC: 0.6885714285714285
Test Accuracy: 0.5555555555555556
test_loss: 0.5762367539935642
test_roc_auc: 0.6885714285714285
test_accuracy: 0.5555555555555556
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5479490756988525
  Validation Loss: 0.5865554213523865
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 2/64:
  Train Loss: 0.5587353706359863
  Validation Loss: 0.5865554809570312
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 3/64:
  Train Loss: 0.5420330613851547
  Validation Loss: 0.5866572260856628
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 4/64:
  Train Loss: 0.5590150654315948
  Validation Loss: 0.5867398381233215
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 5/64:
  Train Loss: 0.5486155152320862
  Validation Loss: 0.5867949724197388
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 6/64:
  Train Loss: 0.548504114151001
  Validation Loss: 0.5868674516677856
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 7/64:
  Train Loss: 0.5475234389305115
  Validation Loss: 0.5869418978691101
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 8/64:
  Train Loss: 0.5517959892749786
  Validation Loss: 0.5870163440704346
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 9/64:
  Train Loss: 0.5449247658252716
  Validation Loss: 0.5870746970176697
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 10/64:
  Train Loss: 0.5538822412490845
  Validation Loss: 0.587173581123352
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 11/64:
  Train Loss: 0.5564591586589813
  Validation Loss: 0.5872883200645447
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 12/64:
  Train Loss: 0.5520428419113159
  Validation Loss: 0.5874109268188477
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 13/64:
  Train Loss: 0.55281662940979
  Validation Loss: 0.5875097513198853
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 14/64:
  Train Loss: 0.5389324575662613
  Validation Loss: 0.5876051187515259
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 15/64:
  Train Loss: 0.5482997596263885
  Validation Loss: 0.587668240070343
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 16/64:
  Train Loss: 0.5456203520298004
  Validation Loss: 0.5877445936203003
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 17/64:
  Train Loss: 0.5488423109054565
  Validation Loss: 0.5878556370735168
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 18/64:
  Train Loss: 0.5475571751594543
  Validation Loss: 0.5879524350166321
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 19/64:
  Train Loss: 0.5462895631790161
  Validation Loss: 0.5880326628684998
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 20/64:
  Train Loss: 0.5464477241039276
  Validation Loss: 0.588080883026123
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 21/64:
  Train Loss: 0.5476233065128326
  Validation Loss: 0.5881302356719971
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 22/64:
  Train Loss: 0.5525618493556976
  Validation Loss: 0.5881308317184448
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 23/64:
  Train Loss: 0.5554836988449097
  Validation Loss: 0.5881397128105164
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 24/64:
  Train Loss: 0.5480412542819977
  Validation Loss: 0.5881250500679016
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 25/64:
  Train Loss: 0.5451493263244629
  Validation Loss: 0.5881230235099792
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 26/64:
  Train Loss: 0.5436029434204102
  Validation Loss: 0.5882096886634827
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 27/64:
  Train Loss: 0.5450499653816223
  Validation Loss: 0.5883021354675293
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 28/64:
  Train Loss: 0.5517869889736176
  Validation Loss: 0.5883998274803162
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 29/64:
  Train Loss: 0.5454188883304596
  Validation Loss: 0.588485836982727
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 30/64:
  Train Loss: 0.5511777400970459
  Validation Loss: 0.5885496139526367
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 31/64:
  Train Loss: 0.5554455518722534
  Validation Loss: 0.5885927677154541
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 32/64:
  Train Loss: 0.5494081676006317
  Validation Loss: 0.5886700749397278
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 33/64:
  Train Loss: 0.5505940318107605
  Validation Loss: 0.588743269443512
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 34/64:
  Train Loss: 0.5519827008247375
  Validation Loss: 0.588840901851654
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 35/64:
  Train Loss: 0.546519011259079
  Validation Loss: 0.5889296531677246
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 36/64:
  Train Loss: 0.546898752450943
  Validation Loss: 0.5889662504196167
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 37/64:
  Train Loss: 0.553524374961853
  Validation Loss: 0.5890251994132996
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 38/64:
  Train Loss: 0.5523481667041779
  Validation Loss: 0.5891146659851074
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 39/64:
  Train Loss: 0.5440496802330017
  Validation Loss: 0.5892254114151001
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 40/64:
  Train Loss: 0.5504701137542725
  Validation Loss: 0.589314877986908
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 41/64:
  Train Loss: 0.556680828332901
  Validation Loss: 0.5893800854682922
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 42/64:
  Train Loss: 0.5489736199378967
  Validation Loss: 0.5894452929496765
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 43/64:
  Train Loss: 0.5395248532295227
  Validation Loss: 0.5894675850868225
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 44/64:
  Train Loss: 0.5425974130630493
  Validation Loss: 0.5894679427146912
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 45/64:
  Train Loss: 0.5399816632270813
  Validation Loss: 0.5894652605056763
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 46/64:
  Train Loss: 0.5429569184780121
  Validation Loss: 0.5894689559936523
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 47/64:
  Train Loss: 0.546251654624939
  Validation Loss: 0.5894587635993958
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 48/64:
  Train Loss: 0.5467154085636139
  Validation Loss: 0.5894491076469421
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 49/64:
  Train Loss: 0.5486258864402771
  Validation Loss: 0.5894434452056885
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 50/64:
  Train Loss: 0.5490359663963318
  Validation Loss: 0.589469313621521
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 51/64:
  Train Loss: 0.5551688373088837
  Validation Loss: 0.5894880890846252
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 52/64:
  Train Loss: 0.5502013564109802
  Validation Loss: 0.589506983757019
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 53/64:
  Train Loss: 0.5507853031158447
  Validation Loss: 0.5895123481750488
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 54/64:
  Train Loss: 0.546026349067688
  Validation Loss: 0.5895295739173889
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 55/64:
  Train Loss: 0.5515845715999603
  Validation Loss: 0.5895472764968872
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 56/64:
  Train Loss: 0.5545443892478943
  Validation Loss: 0.5895911455154419
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 57/64:
  Train Loss: 0.5488819777965546
  Validation Loss: 0.5896342396736145
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 58/64:
  Train Loss: 0.545293539762497
  Validation Loss: 0.5896806120872498
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 59/64:
  Train Loss: 0.5503525137901306
  Validation Loss: 0.5897731781005859
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 60/64:
  Train Loss: 0.5431517958641052
  Validation Loss: 0.5898825526237488
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 61/64:
  Train Loss: 0.5412798821926117
  Validation Loss: 0.5899834632873535
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 62/64:
  Train Loss: 0.5424346327781677
  Validation Loss: 0.5900977253913879
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:36:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:38:INFO:
[92mINFO [0m:      Received: evaluate message 5e60fb5b-2316-45e8-9c11-673792a8096e
02/07/2025 22:34:38:INFO:Received: evaluate message 5e60fb5b-2316-45e8-9c11-673792a8096e
[92mINFO [0m:      Sent reply
02/07/2025 22:34:39:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:39:INFO:
[92mINFO [0m:      Received: train message cc30d8d3-ae5b-42a5-a2b4-776b08b15219
02/07/2025 22:34:39:INFO:Received: train message cc30d8d3-ae5b-42a5-a2b4-776b08b15219
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 63/64:
  Train Loss: 0.5496566295623779
  Validation Loss: 0.5901975035667419
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
Epoch 64/64:
  Train Loss: 0.5498451590538025
  Validation Loss: 0.5903011560440063
  Val ROC-AUC: 0.861111111111111
  Val Accuracy: 0.8461538553237915
{'train_loss': 0.5498451590538025, 'val_roc_auc': 0.861111111111111, 'val_accuracy': 0.8461538553237915, 'val_loss': 0.5903011560440063}
 ROC_AUC: 0.8611|| Accuracy 0.8462 || Train Loss: 0.5498
 Val Loss: 0.5903 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5760817223125034
Test ROC-AUC: 0.6942857142857143
Test Accuracy: 0.5333333333333333
test_loss: 0.5760817223125034
test_roc_auc: 0.6942857142857143
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5564159154891968
  Validation Loss: 0.5658817291259766
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5520766079425812
  Validation Loss: 0.5659364461898804
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5538933873176575
  Validation Loss: 0.5659651160240173
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5550747215747833
  Validation Loss: 0.5659840703010559
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.5541254281997681
  Validation Loss: 0.5660069584846497
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5463634431362152
  Validation Loss: 0.5660256743431091
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5610751509666443
  Validation Loss: 0.5660381317138672
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5566394925117493
  Validation Loss: 0.5660532116889954
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5584484934806824
  Validation Loss: 0.5660721063613892
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5536532998085022
  Validation Loss: 0.5660735964775085
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5503634512424469
  Validation Loss: 0.5660829544067383
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5506256520748138
  Validation Loss: 0.5661114454269409
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5608564913272858
  Validation Loss: 0.5661401152610779
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5521440505981445
  Validation Loss: 0.566162109375
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5579352378845215
  Validation Loss: 0.5661702752113342
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5515857040882111
  Validation Loss: 0.566152036190033
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5486360490322113
  Validation Loss: 0.5661280751228333
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5476055443286896
  Validation Loss: 0.56609708070755
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5495500862598419
  Validation Loss: 0.56605464220047
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5572105944156647
  Validation Loss: 0.5660039186477661
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.551811546087265
  Validation Loss: 0.5659750699996948
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.555052638053894
  Validation Loss: 0.5659768581390381
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5549283027648926
  Validation Loss: 0.5659884214401245
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5564985275268555
  Validation Loss: 0.5659902691841125
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5584561228752136
  Validation Loss: 0.5659779906272888
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.550277590751648
  Validation Loss: 0.5659609436988831
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5494241416454315
  Validation Loss: 0.5659311413764954
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5504584908485413
  Validation Loss: 0.565890908241272
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5604645013809204
  Validation Loss: 0.5658655166625977
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5563730895519257
  Validation Loss: 0.5658379793167114
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5529672205448151
  Validation Loss: 0.5658192038536072
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5580752491950989
  Validation Loss: 0.5657831430435181
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5555687248706818
  Validation Loss: 0.56574547290802
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5539030730724335
  Validation Loss: 0.5657153129577637
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.559103399515152
  Validation Loss: 0.5656672716140747
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5595450699329376
  Validation Loss: 0.5656222701072693
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5497937202453613
  Validation Loss: 0.565579354763031
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5499727129936218
  Validation Loss: 0.5655408501625061
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5497009754180908
  Validation Loss: 0.5655167698860168
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5499726235866547
  Validation Loss: 0.5654768943786621
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5500185191631317
  Validation Loss: 0.5654525756835938
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5575230717658997
  Validation Loss: 0.5654257535934448
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5547354221343994
  Validation Loss: 0.5653838515281677
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5551398694515228
  Validation Loss: 0.5653596520423889
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5548305213451385
  Validation Loss: 0.5653387308120728
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5556136965751648
  Validation Loss: 0.5653049349784851
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5541790127754211
  Validation Loss: 0.5652823448181152
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5446094870567322
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:42:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:44:INFO:
[92mINFO [0m:      Received: evaluate message ba5f310e-8c16-47f5-a6c6-e225cd6f058a
02/07/2025 22:34:44:INFO:Received: evaluate message ba5f310e-8c16-47f5-a6c6-e225cd6f058a
[92mINFO [0m:      Sent reply
02/07/2025 22:34:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:44:INFO:
[92mINFO [0m:      Received: train message dd0394f6-bfc1-4e95-8b97-9b22bca7d34f
02/07/2025 22:34:44:INFO:Received: train message dd0394f6-bfc1-4e95-8b97-9b22bca7d34f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5652711987495422
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5495993793010712
  Validation Loss: 0.5652728080749512
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5531134307384491
  Validation Loss: 0.5652709007263184
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5480925738811493
  Validation Loss: 0.5652756094932556
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5514480471611023
  Validation Loss: 0.565279483795166
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5499786138534546
  Validation Loss: 0.565294086933136
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5544470846652985
  Validation Loss: 0.5653166174888611
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5517631769180298
  Validation Loss: 0.5653302073478699
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5526216328144073
  Validation Loss: 0.5653496384620667
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.558252215385437
  Validation Loss: 0.565373420715332
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5523114502429962
  Validation Loss: 0.5653783082962036
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5519030690193176
  Validation Loss: 0.5653980374336243
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.552096426486969
  Validation Loss: 0.5654201507568359
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5571525394916534
  Validation Loss: 0.565463125705719
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5499351620674133
  Validation Loss: 0.5655079483985901
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5550925731658936
  Validation Loss: 0.5655457377433777
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5593234002590179
  Validation Loss: 0.565584659576416
  Val ROC-AUC: 0.5454545454545454
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5593234002590179, 'val_roc_auc': 0.5454545454545454, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.565584659576416}
 ROC_AUC: 0.5455|| Accuracy 0.5385 || Train Loss: 0.5593
 Val Loss: 0.5656 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5760447409417894
Test ROC-AUC: 0.6971428571428571
Test Accuracy: 0.5555555555555556
test_loss: 0.5760447409417894
test_roc_auc: 0.6971428571428571
test_accuracy: 0.5555555555555556
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5495874881744385
  Validation Loss: 0.6189265251159668
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5391561388969421
  Validation Loss: 0.6189736127853394
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5410974621772766
  Validation Loss: 0.6190671324729919
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5417628586292267
  Validation Loss: 0.6191579699516296
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5424663126468658
  Validation Loss: 0.61919766664505
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5452681481838226
  Validation Loss: 0.6192470788955688
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5374977290630341
  Validation Loss: 0.6192669868469238
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5392556488513947
  Validation Loss: 0.6192896962165833
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5469918549060822
  Validation Loss: 0.6192650198936462
  Val ROC-AUC: 0.825
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5386335253715515
  Validation Loss: 0.6192333102226257
  Val ROC-AUC: 0.825
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5417772531509399
  Validation Loss: 0.6192137598991394
  Val ROC-AUC: 0.825
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.543813556432724
  Validation Loss: 0.6191937327384949
  Val ROC-AUC: 0.825
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5446376204490662
  Validation Loss: 0.6191736459732056
  Val ROC-AUC: 0.825
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5430758595466614
  Validation Loss: 0.6191818118095398
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5342288464307785
  Validation Loss: 0.6192294955253601
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.545922040939331
  Validation Loss: 0.6192733645439148
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5444822013378143
  Validation Loss: 0.6193245053291321
  Val ROC-AUC: 0.85
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.542486160993576
  Validation Loss: 0.6193824410438538
  Val ROC-AUC: 0.825
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5394852757453918
  Validation Loss: 0.6194491982460022
  Val ROC-AUC: 0.825
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5433003008365631
  Validation Loss: 0.6195213794708252
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5535958260297775
  Validation Loss: 0.6195967793464661
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5363746285438538
  Validation Loss: 0.6196490526199341
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5450575053691864
  Validation Loss: 0.6196960806846619
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5434380769729614
  Validation Loss: 0.6197433471679688
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.543324202299118
  Validation Loss: 0.619805634021759
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5424448251724243
  Validation Loss: 0.619873046875
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5431842505931854
  Validation Loss: 0.6199460625648499
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5429980158805847
  Validation Loss: 0.6199867725372314
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.543217122554779
  Validation Loss: 0.6199689507484436
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5403944551944733
  Validation Loss: 0.6199286580085754
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5405394434928894
  Validation Loss: 0.6198948621749878
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5403357446193695
  Validation Loss: 0.6198871731758118
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5401960611343384
  Validation Loss: 0.6198855638504028
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5395467281341553
  Validation Loss: 0.6198837161064148
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5390350222587585
  Validation Loss: 0.6198803782463074
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5487716197967529
  Validation Loss: 0.6198777556419373
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.541120171546936
  Validation Loss: 0.6198886036872864
  Val ROC-AUC: 0.8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:47:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:48:INFO:
[92mINFO [0m:      Received: evaluate message 165c5984-a79a-4eb8-adc2-055c63befdda
02/07/2025 22:34:48:INFO:Received: evaluate message 165c5984-a79a-4eb8-adc2-055c63befdda
[92mINFO [0m:      Sent reply
02/07/2025 22:34:48:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:49:INFO:
[92mINFO [0m:      Received: train message 8afd7ba6-6c19-48db-bf6d-762c46152da9
02/07/2025 22:34:49:INFO:Received: train message 8afd7ba6-6c19-48db-bf6d-762c46152da9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5456914007663727
  Validation Loss: 0.6198922991752625
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5440096259117126
  Validation Loss: 0.6199144721031189
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5363531708717346
  Validation Loss: 0.6199471354484558
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5349422991275787
  Validation Loss: 0.6199696063995361
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5367636978626251
  Validation Loss: 0.6200101971626282
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5424776673316956
  Validation Loss: 0.6200491189956665
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5389730036258698
  Validation Loss: 0.6200816035270691
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5371598601341248
  Validation Loss: 0.6200661659240723
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5357691049575806
  Validation Loss: 0.6200553178787231
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5296192914247513
  Validation Loss: 0.6200626492500305
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5395670533180237
  Validation Loss: 0.6200665831565857
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5346640050411224
  Validation Loss: 0.6200880408287048
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5394052565097809
  Validation Loss: 0.6201236844062805
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5405060350894928
  Validation Loss: 0.6201633810997009
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.540011078119278
  Validation Loss: 0.6202051043510437
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5362361967563629
  Validation Loss: 0.6202375292778015
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.535940408706665
  Validation Loss: 0.6202649474143982
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5316459834575653
  Validation Loss: 0.6203024387359619
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5356737971305847
  Validation Loss: 0.6203494668006897
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5453985929489136
  Validation Loss: 0.6203933358192444
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5330247730016708
  Validation Loss: 0.6204386949539185
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5384564697742462
  Validation Loss: 0.6204606890678406
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.543898195028305
  Validation Loss: 0.6204279065132141
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5365487635135651
  Validation Loss: 0.6203885674476624
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5425559878349304
  Validation Loss: 0.6203761100769043
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5423998534679413
  Validation Loss: 0.620408296585083
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5404901802539825
  Validation Loss: 0.6204357147216797
  Val ROC-AUC: 0.8
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5404901802539825, 'val_roc_auc': 0.8, 'val_accuracy': 0.692307710647583, 'val_loss': 0.6204357147216797}
 ROC_AUC: 0.8000|| Accuracy 0.6923 || Train Loss: 0.5405
 Val Loss: 0.6204 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5760906040668488
Test ROC-AUC: 0.7028571428571428
Test Accuracy: 0.5333333333333333
test_loss: 0.5760906040668488
test_roc_auc: 0.7028571428571428
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5677749216556549
  Validation Loss: 0.5144871473312378
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5667979419231415
  Validation Loss: 0.5143955945968628
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5657410025596619
  Validation Loss: 0.5143237113952637
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5711714625358582
  Validation Loss: 0.5143195986747742
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5631318092346191
  Validation Loss: 0.5143287777900696
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5697828233242035
  Validation Loss: 0.5143454670906067
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5699727833271027
  Validation Loss: 0.5143114328384399
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5715737044811249
  Validation Loss: 0.5142769813537598
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.562881201505661
  Validation Loss: 0.5142694115638733
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5690405368804932
  Validation Loss: 0.5142518877983093
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5655571222305298
  Validation Loss: 0.5142497420310974
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.567855954170227
  Validation Loss: 0.5142337083816528
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5652310848236084
  Validation Loss: 0.5142150521278381
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5717931985855103
  Validation Loss: 0.5141719579696655
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5667189657688141
  Validation Loss: 0.5140940546989441
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5697922110557556
  Validation Loss: 0.5140054225921631
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5686288774013519
  Validation Loss: 0.5139482617378235
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5625282526016235
  Validation Loss: 0.5139012336730957
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5610434412956238
  Validation Loss: 0.5138367414474487
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5703807771205902
  Validation Loss: 0.5137839317321777
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5677266120910645
  Validation Loss: 0.5137508511543274
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5710738301277161
  Validation Loss: 0.5137342214584351
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5702669024467468
  Validation Loss: 0.5136890411376953
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5720419883728027
  Validation Loss: 0.5136455297470093
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5633693933486938
  Validation Loss: 0.5136063098907471
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5653709173202515
  Validation Loss: 0.5135489106178284
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:51:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:53:INFO:
[92mINFO [0m:      Received: evaluate message 6dae005e-ed0a-4044-802f-fc240fab97bd
02/07/2025 22:34:53:INFO:Received: evaluate message 6dae005e-ed0a-4044-802f-fc240fab97bd
[92mINFO [0m:      Sent reply
02/07/2025 22:34:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:53:INFO:
[92mINFO [0m:      Received: train message 5e4f04f3-7bdf-43a1-a795-626f77418a26
02/07/2025 22:34:53:INFO:Received: train message 5e4f04f3-7bdf-43a1-a795-626f77418a26
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5678866803646088
  Validation Loss: 0.5134857296943665
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5559396892786026
  Validation Loss: 0.5134018063545227
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5736104846000671
  Validation Loss: 0.513312041759491
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5720680952072144
  Validation Loss: 0.5132213234901428
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5649576485157013
  Validation Loss: 0.5131423473358154
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5755110383033752
  Validation Loss: 0.5130575299263
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5679184198379517
  Validation Loss: 0.5129790902137756
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5684487819671631
  Validation Loss: 0.5128970742225647
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5686925649642944
  Validation Loss: 0.5128347277641296
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5620231330394745
  Validation Loss: 0.5127881169319153
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5674710273742676
  Validation Loss: 0.5127303004264832
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5642894208431244
  Validation Loss: 0.5126816630363464
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5659935772418976
  Validation Loss: 0.5126731991767883
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5633270144462585
  Validation Loss: 0.512656033039093
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5619296133518219
  Validation Loss: 0.5126579403877258
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5642097890377045
  Validation Loss: 0.512649416923523
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5641058385372162
  Validation Loss: 0.5126298069953918
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5624967217445374
  Validation Loss: 0.5126342177391052
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5697885155677795
  Validation Loss: 0.5126609802246094
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5642989873886108
  Validation Loss: 0.5126937627792358
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5677186548709869
  Validation Loss: 0.5127428770065308
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5680662095546722
  Validation Loss: 0.5127701163291931
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5695742666721344
  Validation Loss: 0.5127936601638794
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.568893700838089
  Validation Loss: 0.5128287076950073
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5752519369125366
  Validation Loss: 0.5128695368766785
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5710799694061279
  Validation Loss: 0.51289963722229
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5618838369846344
  Validation Loss: 0.5129099488258362
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5758036971092224
  Validation Loss: 0.5129146575927734
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5607070028781891
  Validation Loss: 0.5129296183586121
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.564772367477417
  Validation Loss: 0.5129300951957703
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5592855215072632
  Validation Loss: 0.512936532497406
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5694696009159088
  Validation Loss: 0.5129410028457642
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5644346475601196
  Validation Loss: 0.5129303336143494
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5678802132606506
  Validation Loss: 0.5129310488700867
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5667013227939606
  Validation Loss: 0.5129671096801758
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5653471052646637
  Validation Loss: 0.5129772424697876
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5630177557468414
  Validation Loss: 0.5129810571670532
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.564692884683609
  Validation Loss: 0.5129637718200684
  Val ROC-AUC: 0.9090909090909092
  Val Accuracy: 0.692307710647583
{'train_loss': 0.564692884683609, 'val_roc_auc': 0.9090909090909092, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5129637718200684}
 ROC_AUC: 0.9091|| Accuracy 0.6923 || Train Loss: 0.5647
 Val Loss: 0.5130 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5762214276525709
Test ROC-AUC: 0.7057142857142856
Test Accuracy: 0.5111111111111111
test_loss: 0.5762214276525709
test_roc_auc: 0.7057142857142856
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5835675895214081
  Validation Loss: 0.4542611241340637
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5841816067695618
  Validation Loss: 0.454074501991272
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5787106156349182
  Validation Loss: 0.4540465176105499
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5788591802120209
  Validation Loss: 0.45399966835975647
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5818494260311127
  Validation Loss: 0.4539784789085388
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5820439159870148
  Validation Loss: 0.45394113659858704
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5796144902706146
  Validation Loss: 0.45389696955680847
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5831865966320038
  Validation Loss: 0.45387449860572815
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5819066762924194
  Validation Loss: 0.45391517877578735
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.583008885383606
  Validation Loss: 0.4539271891117096
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5792209506034851
  Validation Loss: 0.45393645763397217
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5740997791290283
  Validation Loss: 0.45391127467155457
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5754043459892273
  Validation Loss: 0.45391517877578735
  Val ROC-AUC: nan
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 22:34:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:57:INFO:
[92mINFO [0m:      Received: evaluate message 7e4b9cf8-73d3-448f-85cb-0c3d85f183fb
02/07/2025 22:34:57:INFO:Received: evaluate message 7e4b9cf8-73d3-448f-85cb-0c3d85f183fb
[92mINFO [0m:      Sent reply
02/07/2025 22:34:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:58:INFO:
[92mINFO [0m:      Received: train message 75b1f1ff-f85d-4e69-84ba-e7d7faa9caf8
02/07/2025 22:34:58:INFO:Received: train message 75b1f1ff-f85d-4e69-84ba-e7d7faa9caf8
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5869668424129486
  Validation Loss: 0.4539232552051544
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5774701237678528
  Validation Loss: 0.4539249539375305
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5753699243068695
  Validation Loss: 0.45394521951675415
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5826252102851868
  Validation Loss: 0.4539852440357208
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5816892385482788
  Validation Loss: 0.45402947068214417
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5864528715610504
  Validation Loss: 0.4540935158729553
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5923208594322205
  Validation Loss: 0.45411646366119385
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5811999142169952
  Validation Loss: 0.4541102945804596
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5729803740978241
  Validation Loss: 0.4540671706199646
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5756683051586151
  Validation Loss: 0.454048752784729
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5824975669384003
  Validation Loss: 0.45402100682258606
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5819739401340485
  Validation Loss: 0.4539743661880493
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5847202837467194
  Validation Loss: 0.4539511501789093
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5753779709339142
  Validation Loss: 0.453951895236969
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5798103213310242
  Validation Loss: 0.4539949595928192
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5850339829921722
  Validation Loss: 0.45400893688201904
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5800119042396545
  Validation Loss: 0.4539850950241089
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5807016789913177
  Validation Loss: 0.4539355933666229
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5828477442264557
  Validation Loss: 0.45387542247772217
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5787462890148163
  Validation Loss: 0.4538193643093109
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5841097831726074
  Validation Loss: 0.45374614000320435
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5807589292526245
  Validation Loss: 0.45368653535842896
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5777566134929657
  Validation Loss: 0.45366767048835754
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5775309801101685
  Validation Loss: 0.4536723494529724
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5872231721878052
  Validation Loss: 0.4537072777748108
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5837627947330475
  Validation Loss: 0.45370662212371826
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.590752512216568
  Validation Loss: 0.4536854922771454
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.58649942278862
  Validation Loss: 0.4536827802658081
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5701712667942047
  Validation Loss: 0.4536653161048889
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5898596942424774
  Validation Loss: 0.4536152780056
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5798300206661224
  Validation Loss: 0.45357823371887207
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5868058502674103
  Validation Loss: 0.4534952640533447
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.581219881772995
  Validation Loss: 0.4533994793891907
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5788579285144806
  Validation Loss: 0.4533124268054962
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5837571322917938
  Validation Loss: 0.453233540058136
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.586197555065155
  Validation Loss: 0.4531576633453369
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5784977376461029
  Validation Loss: 0.45310303568840027
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5878559052944183
  Validation Loss: 0.45304834842681885
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5785419344902039
  Validation Loss: 0.4530266523361206
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5846618115901947
  Validation Loss: 0.4530113935470581
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5790181457996368
  Validation Loss: 0.4530065059661865
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5804957747459412
  Validation Loss: 0.45296186208724976
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5822902321815491
  Validation Loss: 0.45291534066200256
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5850822925567627
  Validation Loss: 0.4528563618659973
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5809555053710938
  Validation Loss: 0.45277491211891174
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.57330521941185
  Validation Loss: 0.45267242193222046
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5796722769737244
  Validation Loss: 0.4525839388370514
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5767417550086975
  Validation Loss: 0.4524378180503845
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5772416591644287
  Validation Loss: 0.45231467485427856
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5758691430091858
  Validation Loss: 0.4521980583667755
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5810762643814087
  Validation Loss: 0.4520935118198395
  Val ROC-AUC: nan
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5810762643814087, 'val_roc_auc': nan, 'val_accuracy': 0.692307710647583, 'val_loss': 0.4520935118198395}
 ROC_AUC: nan|| Accuracy 0.6923 || Train Loss: 0.5811
 Val Loss: 0.4521 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5762155983183119
Test ROC-AUC: 0.7085714285714285
Test Accuracy: 0.5111111111111111
test_loss: 0.5762155983183119
test_roc_auc: 0.7085714285714285
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5555371046066284
  Validation Loss: 0.5875797271728516
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5566064119338989
  Validation Loss: 0.5875592231750488
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5554927885532379
  Validation Loss: 0.5875712633132935
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5531555414199829
  Validation Loss: 0.5875949859619141
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5474798679351807/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)

  Validation Loss: 0.5876297950744629
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5529449880123138
  Validation Loss: 0.5876854658126831
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5563696622848511
  Validation Loss: 0.5877332091331482
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5424486696720123
  Validation Loss: 0.5877667665481567
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5507887899875641
  Validation Loss: 0.5877732634544373
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.552838921546936
  Validation Loss: 0.5878017544746399
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5468991100788116
  Validation Loss: 0.5878108143806458
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5517990589141846
  Validation Loss: 0.5878310799598694
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5546649098396301
  Validation Loss: 0.5878018736839294
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5474159419536591
  Validation Loss: 0.587781548500061
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5544109344482422
  Validation Loss: 0.5877577066421509
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5445549190044403
  Validation Loss: 0.5877442359924316
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5515776574611664
  Validation Loss: 0.5877355933189392
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5452529191970825
  Validation Loss: 0.5877363085746765
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5454042553901672
  Validation Loss: 0.5877346992492676
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5517131686210632
  Validation Loss: 0.5877290964126587
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5503019690513611
  Validation Loss: 0.5877277255058289
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5439106822013855
  Validation Loss: 0.5877152681350708
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5480928122997284
  Validation Loss: 0.5876908898353577
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.548522025346756
  Validation Loss: 0.587647020816803
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5539294481277466
  Validation Loss: 0.587605357170105
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5485570430755615
  Validation Loss: 0.587580680847168
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5460502207279205
  Validation Loss: 0.5875951647758484
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5446441769599915
  Validation Loss: 0.5876273512840271
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5476636290550232
  Validation Loss: 0.5876625776290894
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5388611108064651
  Validation Loss: 0.5877168774604797
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5541841983795166
  Validation Loss: 0.5877543091773987
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.550673633813858
  Validation Loss: 0.5877723693847656
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5529696643352509
  Validation Loss: 0.587780773639679
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.5554498434066772
  Validation Loss: 0.5877631306648254
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5528759062290192
  Validation Loss: 0.5877401232719421
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5500068068504333
  Validation Loss: 0.5877177119255066
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5518203973770142
  Validation Loss: 0.5876968502998352
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5469028353691101
  Validation Loss: 0.5876790881156921
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5477091372013092
  Validation Loss: 0.5876500010490417
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5470137000083923
  Validation Loss: 0.5876173377037048
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5499359965324402
  Validation Loss: 0.5876058340072632
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5469805300235748
  Validation Loss: 0.5876105427742004
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5511585175991058
  Validation Loss: 0.5876229405403137
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5416743159294128
  Validation Loss: 0.5876278281211853
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.54499751329422
  Validation Loss: 0.5876274704933167
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5481070280075073
  Validation Loss: 0.5876302719116211
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5557729005813599
  Validation Loss: 0.5876282453536987
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5532399117946625
  Validation Loss: 0.5876374840736389
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5506522357463837
  Validation Loss: 0.5876423120498657
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.540020763874054
  Validation Loss: 0.5876451134681702
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5558024644851685
  Validation Loss: 0.5876362919807434
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5461476147174835
  Validation Loss: 0.5876339077949524
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5437515079975128
  Validation Loss: 0.5876394510269165
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5430451333522797
  Validation Loss: 0.5876178741455078
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5497580766677856
  Validation Loss: 0.5875925421714783
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5477564930915833
  Validation Loss: 0.5875623822212219
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5526038706302643
  Validation Loss: 0.5875388383865356
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5519880652427673
  Validation Loss: 0.587530255317688
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.553889125585556
  Validation Loss: 0.5875465273857117
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5482670962810516
  Validation Loss: 0.5875579118728638
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5466329753398895
  Validation Loss: 0.5875576138496399
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5496692359447479
  Validation Loss: 0.587543785572052
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5452307462692261
  Validation Loss: 0.5875424146652222
  Val ROC-AUC: 0.75
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5492558181285858
  Validation Loss: 0.587530255317688
  Val ROC-AUC: 0.75
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:01:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:02:INFO:
[92mINFO [0m:      Received: evaluate message a8872bc1-35db-448d-85a0-c3ef4e6cf446
02/07/2025 22:35:02:INFO:Received: evaluate message a8872bc1-35db-448d-85a0-c3ef4e6cf446
[92mINFO [0m:      Sent reply
02/07/2025 22:35:03:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:03:INFO:
[92mINFO [0m:      Received: train message 250180aa-1419-40f4-aef9-5e3f999d1398
02/07/2025 22:35:03:INFO:Received: train message 250180aa-1419-40f4-aef9-5e3f999d1398
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5492558181285858, 'val_roc_auc': 0.75, 'val_accuracy': 0.692307710647583, 'val_loss': 0.587530255317688}
 ROC_AUC: 0.7500|| Accuracy 0.6923 || Train Loss: 0.5493
 Val Loss: 0.5875 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5762022356192271
Test ROC-AUC: 0.7142857142857143
Test Accuracy: 0.5111111111111111
test_loss: 0.5762022356192271
test_roc_auc: 0.7142857142857143
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5678472518920898
  Validation Loss: 0.5376023054122925
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 2/64:
  Train Loss: 0.5661697387695312
  Validation Loss: 0.5377145409584045
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 3/64:
  Train Loss: 0.5638357400894165
  Validation Loss: 0.5376655459403992
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 4/64:
  Train Loss: 0.5593552887439728
  Validation Loss: 0.5375983119010925
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 5/64:
  Train Loss: 0.572792649269104
  Validation Loss: 0.537541925907135
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 6/64:
  Train Loss: 0.5609015226364136
  Validation Loss: 0.5374633073806763
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 7/64:
  Train Loss: 0.5670256018638611
  Validation Loss: 0.5373802185058594
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 8/64:
  Train Loss: 0.5559037625789642
  Validation Loss: 0.5372880697250366
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 9/64:
  Train Loss: 0.5636175870895386
  Validation Loss: 0.537177562713623
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 10/64:
  Train Loss: 0.5626291036605835
  Validation Loss: 0.5370737314224243
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 11/64:
  Train Loss: 0.5656419396400452
  Validation Loss: 0.5369983315467834
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 12/64:
  Train Loss: 0.5581326484680176
  Validation Loss: 0.5369542837142944
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 13/64:
  Train Loss: 0.5590135455131531
  Validation Loss: 0.5369314551353455
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 14/64:
  Train Loss: 0.560201495885849
  Validation Loss: 0.536955714225769
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 15/64:
  Train Loss: 0.5684597790241241
  Validation Loss: 0.5369597673416138
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 16/64:
  Train Loss: 0.5612072348594666
  Validation Loss: 0.5369627475738525
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 17/64:
  Train Loss: 0.5548062026500702
  Validation Loss: 0.5369611382484436
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 18/64:
  Train Loss: 0.5662983655929565
  Validation Loss: 0.5369702577590942
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 19/64:
  Train Loss: 0.5691295862197876
  Validation Loss: 0.5369856357574463
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 20/64:
  Train Loss: 0.5597134232521057
  Validation Loss: 0.5370101928710938
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 21/64:
  Train Loss: 0.5600275099277496
  Validation Loss: 0.5370613932609558
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 22/64:
  Train Loss: 0.5603355765342712
  Validation Loss: 0.5371052622795105
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 23/64:
  Train Loss: 0.5645716488361359
  Validation Loss: 0.5371273159980774
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 24/64:
  Train Loss: 0.5594706237316132
  Validation Loss: 0.5370988249778748
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 25/64:
  Train Loss: 0.5629332065582275
  Validation Loss: 0.5370567440986633
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 26/64:
  Train Loss: 0.5540223717689514
  Validation Loss: 0.5370020866394043
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 27/64:
  Train Loss: 0.5643578171730042
  Validation Loss: 0.5369330644607544
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 28/64:
  Train Loss: 0.5590469837188721
  Validation Loss: 0.5368576645851135
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 29/64:
  Train Loss: 0.5624452829360962
  Validation Loss: 0.5367927551269531
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 30/64:
  Train Loss: 0.5559468865394592
  Validation Loss: 0.5367130041122437
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 31/64:
  Train Loss: 0.5663171112537384
  Validation Loss: 0.5366337895393372
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 32/64:
  Train Loss: 0.5602452158927917
  Validation Loss: 0.536577045917511
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 33/64:
  Train Loss: 0.5565531551837921
  Validation Loss: 0.5365152359008789
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 34/64:
  Train Loss: 0.5629118382930756
  Validation Loss: 0.536490261554718
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 35/64:
  Train Loss: 0.5598767995834351
  Validation Loss: 0.5364828109741211
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 36/64:
  Train Loss: 0.5674915015697479
  Validation Loss: 0.5364975929260254
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 37/64:
  Train Loss: 0.5597943961620331
  Validation Loss: 0.5365009903907776
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 38/64:
  Train Loss: 0.5631319284439087
  Validation Loss: 0.5364931225776672
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 39/64:
  Train Loss: 0.5738125443458557
  Validation Loss: 0.5364648103713989
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 40/64:
  Train Loss: 0.5637789070606232
  Validation Loss: 0.5364436507225037
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 41/64:
  Train Loss: 0.5694749057292938
  Validation Loss: 0.5364199280738831
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 42/64:
  Train Loss: 0.5673063099384308
  Validation Loss: 0.5363606214523315
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 43/64:
  Train Loss: 0.5625819861888885
  Validation Loss: 0.5363126993179321
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 44/64:
  Train Loss: 0.5547467768192291
  Validation Loss: 0.5362865328788757
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 45/64:
  Train Loss: 0.5659930109977722
  Validation Loss: 0.5362848043441772
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 46/64:
  Train Loss: 0.5609661936759949
  Validation Loss: 0.5362847447395325
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 47/64:
  Train Loss: 0.5627199113368988
  Validation Loss: 0.5362906455993652
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 48/64:
  Train Loss: 0.5576084852218628
  Validation Loss: 0.5362884402275085
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 49/64:
  Train Loss: 0.5680936276912689
  Validation Loss: 0.5363444089889526
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 50/64:
  Train Loss: 0.5629473924636841
  Validation Loss: 0.5363962054252625
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:06:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:08:INFO:
[92mINFO [0m:      Received: evaluate message 78111783-4187-46cf-a951-109bc7a2aa5e
02/07/2025 22:35:08:INFO:Received: evaluate message 78111783-4187-46cf-a951-109bc7a2aa5e
[92mINFO [0m:      Sent reply
02/07/2025 22:35:08:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:09:INFO:
[92mINFO [0m:      Received: train message 7969da98-4c7f-4b1e-9a21-93f1a1e0ea97
02/07/2025 22:35:09:INFO:Received: train message 7969da98-4c7f-4b1e-9a21-93f1a1e0ea97
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 51/64:
  Train Loss: 0.5621820390224457
  Validation Loss: 0.5363948941230774
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 52/64:
  Train Loss: 0.559458464384079
  Validation Loss: 0.5364184379577637
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 53/64:
  Train Loss: 0.5704529583454132
  Validation Loss: 0.5364384651184082
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 54/64:
  Train Loss: 0.5596698820590973
  Validation Loss: 0.5364600419998169
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 55/64:
  Train Loss: 0.5675674676895142
  Validation Loss: 0.5364556908607483
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 56/64:
  Train Loss: 0.5649944841861725
  Validation Loss: 0.5364370346069336
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 57/64:
  Train Loss: 0.5625938773155212
  Validation Loss: 0.5364265441894531
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 58/64:
  Train Loss: 0.5576657056808472
  Validation Loss: 0.5364180207252502
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 59/64:
  Train Loss: 0.5642160773277283
  Validation Loss: 0.5364067554473877
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 60/64:
  Train Loss: 0.5561447441577911
  Validation Loss: 0.5363621711730957
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 61/64:
  Train Loss: 0.5608783066272736
  Validation Loss: 0.5363378524780273
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 62/64:
  Train Loss: 0.5627919137477875
  Validation Loss: 0.5363106727600098
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 63/64:
  Train Loss: 0.5599375069141388
  Validation Loss: 0.536307692527771
  Val ROC-AUC: 0.9333333333333333
  Val Accuracy: 0.7692307829856873
Epoch 64/64:
  Train Loss: 0.5547416508197784
  Validation Loss: 0.5363212823867798
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7692307829856873
{'train_loss': 0.5547416508197784, 'val_roc_auc': 0.9, 'val_accuracy': 0.7692307829856873, 'val_loss': 0.5363212823867798}
 ROC_AUC: 0.9000|| Accuracy 0.7692 || Train Loss: 0.5547
 Val Loss: 0.5363 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5762486649884118
Test ROC-AUC: 0.72
Test Accuracy: 0.5111111111111111
test_loss: 0.5762486649884118
test_roc_auc: 0.72
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5712987780570984
  Validation Loss: 0.5232909321784973
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5714273154735565
  Validation Loss: 0.5231754183769226
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5656274557113647
  Validation Loss: 0.5231038928031921
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5683758854866028
  Validation Loss: 0.5231115221977234
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5653203427791595
  Validation Loss: 0.523047685623169
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5674117505550385
  Validation Loss: 0.5230318903923035
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.565474271774292
  Validation Loss: 0.5229881405830383
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5597904920578003
  Validation Loss: 0.5229837894439697
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5703913569450378
  Validation Loss: 0.5230044722557068
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5597918033599854
  Validation Loss: 0.5230324864387512
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5666883885860443
  Validation Loss: 0.5230931043624878
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5647462606430054
  Validation Loss: 0.5231457948684692
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5668926537036896
  Validation Loss: 0.5231462121009827
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.574254184961319
  Validation Loss: 0.5231760144233704
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5642754435539246
  Validation Loss: 0.5232490301132202
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.561695784330368
  Validation Loss: 0.523306667804718
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5695263147354126
  Validation Loss: 0.523316502571106
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5724620223045349
  Validation Loss: 0.5232694745063782
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5601588189601898
  Validation Loss: 0.5232117772102356
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.558343917131424
  Validation Loss: 0.5231369137763977
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5627541840076447
  Validation Loss: 0.5230833292007446
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5607404410839081
  Validation Loss: 0.5230401754379272
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5686376690864563
  Validation Loss: 0.5229927897453308
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5637122392654419
  Validation Loss: 0.5229982733726501
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5709205865859985
  Validation Loss: 0.5230259895324707
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5649212002754211
  Validation Loss: 0.5230602025985718
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5731611251831055
  Validation Loss: 0.5230861902236938
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.5643648505210876
  Validation Loss: 0.5230761170387268
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5659756064414978
  Validation Loss: 0.5230729579925537
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5740606784820557
  Validation Loss: 0.5230779051780701
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5586283504962921
  Validation Loss: 0.5230754613876343
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5566727519035339
  Validation Loss: 0.5231083631515503
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5645377933979034
  Validation Loss: 0.5231369137763977
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 34/64:
  Train Loss: 0.557200163602829
  Validation Loss: 0.5231436491012573
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5634434223175049
  Validation Loss: 0.5230958461761475
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5679164230823517
  Validation Loss: 0.5230427980422974
  Val ROC-AUC: 0.8636363636363636
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:13:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:15:INFO:
[92mINFO [0m:      Received: evaluate message d932d2dd-ba9e-4d1b-8b0a-6c08dbdc83f3
02/07/2025 22:35:15:INFO:Received: evaluate message d932d2dd-ba9e-4d1b-8b0a-6c08dbdc83f3
[92mINFO [0m:      Sent reply
02/07/2025 22:35:16:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:16:INFO:
[92mINFO [0m:      Received: train message 3211b5e9-26da-4ed1-bc2b-2ca3d961784c
02/07/2025 22:35:16:INFO:Received: train message 3211b5e9-26da-4ed1-bc2b-2ca3d961784c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.567764550447464
  Validation Loss: 0.5230305194854736
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5627249777317047
  Validation Loss: 0.5230374336242676
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5641551911830902
  Validation Loss: 0.523043155670166
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.5652188360691071
  Validation Loss: 0.5230619311332703
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.563023716211319
  Validation Loss: 0.5230759382247925
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5636131763458252
  Validation Loss: 0.5230790972709656
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5632807910442352
  Validation Loss: 0.5230735540390015
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5639460384845734
  Validation Loss: 0.5230892896652222
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5584729015827179
  Validation Loss: 0.5231282114982605
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5673136711120605
  Validation Loss: 0.5231426954269409
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5657702386379242
  Validation Loss: 0.523169994354248
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5580577254295349
  Validation Loss: 0.5232391357421875
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5628227293491364
  Validation Loss: 0.5232993960380554
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5576332211494446
  Validation Loss: 0.5233620405197144
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5658125579357147
  Validation Loss: 0.5233974456787109
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5654465854167938
  Validation Loss: 0.523373007774353
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5623047351837158
  Validation Loss: 0.5233389139175415
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5605848431587219
  Validation Loss: 0.5233157873153687
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.559719055891037
  Validation Loss: 0.5232766270637512
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5590837001800537
  Validation Loss: 0.5232575535774231
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5692218542098999
  Validation Loss: 0.5232287645339966
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5621086955070496
  Validation Loss: 0.5232195854187012
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5654856860637665
  Validation Loss: 0.5232092142105103
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5578457415103912
  Validation Loss: 0.5232118368148804
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5603145956993103
  Validation Loss: 0.5231794714927673
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5686086118221283
  Validation Loss: 0.5231519341468811
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5606202185153961
  Validation Loss: 0.5231428146362305
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.5625914335250854
  Validation Loss: 0.5231278538703918
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.692307710647583
{'train_loss': 0.5625914335250854, 'val_roc_auc': 0.8636363636363636, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5231278538703918}
 ROC_AUC: 0.8636|| Accuracy 0.6923 || Train Loss: 0.5626
 Val Loss: 0.5231 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5762564473681979
Test ROC-AUC: 0.72
Test Accuracy: 0.5111111111111111
test_loss: 0.5762564473681979
test_roc_auc: 0.72
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5601021647453308
  Validation Loss: 0.5756596922874451
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5451536625623703
  Validation Loss: 0.5757455229759216
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5502052307128906
  Validation Loss: 0.5757718086242676
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.5553536415100098
  Validation Loss: 0.5758315324783325
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.553858608007431
  Validation Loss: 0.5758687853813171
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.5594629347324371
  Validation Loss: 0.5758885145187378
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5621747672557831
  Validation Loss: 0.5758542418479919
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5508032739162445
  Validation Loss: 0.575822651386261
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.5530920922756195
  Validation Loss: 0.575812578201294
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.5615513920783997
  Validation Loss: 0.5758198499679565
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.5546965003013611
  Validation Loss: 0.5758183598518372
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5476727187633514
  Validation Loss: 0.5758070945739746
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5517067611217499
  Validation Loss: 0.5757892727851868
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5550250709056854
  Validation Loss: 0.5757418870925903
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 15/64:
  Train Loss: 0.5517330467700958
  Validation Loss: 0.5757080912590027
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 16/64:
  Train Loss: 0.5592767894268036
  Validation Loss: 0.575674295425415
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 17/64:
  Train Loss: 0.5657874196767807
  Validation Loss: 0.5756374597549438
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 18/64:
  Train Loss: 0.5556726157665253
  Validation Loss: 0.5755912065505981
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 19/64:
  Train Loss: 0.5549953579902649
  Validation Loss: 0.5755577087402344
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 20/64:
  Train Loss: 0.5493151247501373
  Validation Loss: 0.57554030418396
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 21/64:
  Train Loss: 0.5508585274219513
  Validation Loss: 0.5755653381347656
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 22/64:
  Train Loss: 0.5599362850189209
  Validation Loss: 0.5755836367607117
  Val ROC-AUC: 0.6333333333333333
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:21:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:24:INFO:
[92mINFO [0m:      Received: evaluate message 790d9255-7523-4b22-8e94-ced71fed5fe4
02/07/2025 22:35:24:INFO:Received: evaluate message 790d9255-7523-4b22-8e94-ced71fed5fe4
[92mINFO [0m:      Sent reply
02/07/2025 22:35:24:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:24:INFO:
[92mINFO [0m:      Received: train message e7d3e2fb-9564-4084-9ca7-e63a35d7b321
02/07/2025 22:35:24:INFO:Received: train message e7d3e2fb-9564-4084-9ca7-e63a35d7b321
  Val Accuracy: 0.6153846383094788
Epoch 23/64:
  Train Loss: 0.5501783490180969
  Validation Loss: 0.5755786299705505
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 24/64:
  Train Loss: 0.5529349148273468
  Validation Loss: 0.5755705237388611
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 25/64:
  Train Loss: 0.5462164878845215
  Validation Loss: 0.5755538940429688
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 26/64:
  Train Loss: 0.5485624969005585
  Validation Loss: 0.5755468010902405
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 27/64:
  Train Loss: 0.5493654310703278
  Validation Loss: 0.5755409598350525
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 28/64:
  Train Loss: 0.5540187060832977
  Validation Loss: 0.5755196809768677
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 29/64:
  Train Loss: 0.547292560338974
  Validation Loss: 0.575501024723053
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 30/64:
  Train Loss: 0.5460898280143738
  Validation Loss: 0.5754989981651306
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 31/64:
  Train Loss: 0.5592718720436096
  Validation Loss: 0.5754762291908264
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 32/64:
  Train Loss: 0.5533324182033539
  Validation Loss: 0.5754342079162598
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 33/64:
  Train Loss: 0.5563252866268158
  Validation Loss: 0.575410008430481
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 34/64:
  Train Loss: 0.5464742481708527
  Validation Loss: 0.5753868818283081
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 35/64:
  Train Loss: 0.5483354032039642
  Validation Loss: 0.57534259557724
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 36/64:
  Train Loss: 0.5523069798946381
  Validation Loss: 0.5753049850463867
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 37/64:
  Train Loss: 0.5451537370681763
  Validation Loss: 0.5752924084663391
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 38/64:
  Train Loss: 0.5540467202663422
  Validation Loss: 0.5752813816070557
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 39/64:
  Train Loss: 0.5459087491035461
  Validation Loss: 0.5752781629562378
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 40/64:
  Train Loss: 0.5476936399936676
  Validation Loss: 0.5752711892127991
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5529637932777405
  Validation Loss: 0.5752772688865662
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.5591441690921783
  Validation Loss: 0.5752794146537781
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.5545309484004974
  Validation Loss: 0.5752589106559753
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5457615256309509
  Validation Loss: 0.5752625465393066
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5559230446815491
  Validation Loss: 0.5752753615379333
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5589503347873688
  Validation Loss: 0.5753085017204285
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5509673357009888
  Validation Loss: 0.5753359198570251
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5475459396839142
  Validation Loss: 0.5753206014633179
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.5457764267921448
  Validation Loss: 0.5753328204154968
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5465116202831268
  Validation Loss: 0.5753510594367981
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5535820424556732
  Validation Loss: 0.5753337740898132
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5547402799129486
  Validation Loss: 0.5752876996994019
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5419777035713196
  Validation Loss: 0.5752575397491455
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5499356985092163
  Validation Loss: 0.5752321481704712
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5540663003921509
  Validation Loss: 0.575249195098877
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5488843321800232
  Validation Loss: 0.5752187967300415
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5459522902965546
  Validation Loss: 0.5751919150352478
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.552707314491272
  Validation Loss: 0.5752013325691223
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5442392230033875
  Validation Loss: 0.5752241015434265
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5451592803001404
  Validation Loss: 0.5752369165420532
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5508226752281189
  Validation Loss: 0.5752888917922974
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.541133776307106
  Validation Loss: 0.575359582901001
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5446235239505768
  Validation Loss: 0.5754181146621704
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5502101480960846
  Validation Loss: 0.5754554271697998
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5502101480960846, 'val_roc_auc': 0.6333333333333333, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5754554271697998}
 ROC_AUC: 0.6333|| Accuracy 0.5385 || Train Loss: 0.5502
 Val Loss: 0.5755 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5763092007901933
Test ROC-AUC: 0.7257142857142856
Test Accuracy: 0.5111111111111111
test_loss: 0.5763092007901933
test_roc_auc: 0.7257142857142856
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5577391088008881
  Validation Loss: 0.5690269470214844
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5659393072128296
  Validation Loss: 0.5688532590866089
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5598150193691254
  Validation Loss: 0.5687329173088074
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5533643960952759
  Validation Loss: 0.5686055421829224
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5611674785614014
  Validation Loss: 0.5685824751853943
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5566440224647522
  Validation Loss: 0.5685586929321289
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5584482252597809
  Validation Loss: 0.568493664264679
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5560521185398102
  Validation Loss: 0.568463921546936
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5636802017688751
  Validation Loss: 0.5684677362442017
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5478654503822327
  Validation Loss: 0.5685074925422668
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5571517944335938
  Validation Loss: 0.568527102470398
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5552550554275513
  Validation Loss: 0.5685767531394958
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5518493354320526
  Validation Loss: 0.568623960018158
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.555267721414566
  Validation Loss: 0.568696916103363
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5614103376865387
  Validation Loss: 0.5687544941902161
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5576336979866028
  Validation Loss: 0.5687747001647949
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.557208925485611
  Validation Loss: 0.5687745213508606
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.554884672164917
  Validation Loss: 0.5688065886497498
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5563485324382782
  Validation Loss: 0.5688830614089966
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 20/64:
  Train Loss: 0.5506141483783722
  Validation Loss: 0.5689661502838135
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 21/64:
  Train Loss: 0.5586098432540894
  Validation Loss: 0.5690408945083618
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 22/64:
  Train Loss: 0.5568943917751312
  Validation Loss: 0.5690656900405884
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 23/64:
  Train Loss: 0.5598882138729095
  Validation Loss: 0.5690891146659851
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5578970611095428
  Validation Loss: 0.5691114664077759
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 25/64:
  Train Loss: 0.5557886958122253
  Validation Loss: 0.569108247756958
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 26/64:
  Train Loss: 0.5627109408378601
  Validation Loss: 0.5691287517547607
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 27/64:
  Train Loss: 0.5514553189277649
  Validation Loss: 0.5691576600074768
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 28/64:
  Train Loss: 0.5571205317974091
  Validation Loss: 0.569175660610199
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 29/64:
  Train Loss: 0.5560265779495239
  Validation Loss: 0.5692002773284912
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 30/64:
  Train Loss: 0.5568622648715973
  Validation Loss: 0.569187343120575
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 31/64:
  Train Loss: 0.5511470437049866
  Validation Loss: 0.5691592693328857
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 32/64:
  Train Loss: 0.5508099496364594
  Validation Loss: 0.5691213607788086
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 33/64:
  Train Loss: 0.559860497713089
  Validation Loss: 0.5690979957580566
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 34/64:
  Train Loss: 0.5520797073841095
  Validation Loss: 0.5690680742263794
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 35/64:
  Train Loss: 0.5550823509693146
  Validation Loss: 0.5690457820892334
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 36/64:
  Train Loss: 0.557977706193924
  Validation Loss: 0.5689949989318848
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 37/64:
  Train Loss: 0.5511551201343536
  Validation Loss: 0.5689783096313477
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 38/64:
  Train Loss: 0.5469401776790619
  Validation Loss: 0.5689841508865356
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 39/64:
  Train Loss: 0.5521697103977203
  Validation Loss: 0.569001317024231
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 40/64:
  Train Loss: 0.5556095540523529
  Validation Loss: 0.5690075159072876
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 41/64:
  Train Loss: 0.558620274066925
  Validation Loss: 0.5689788460731506
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 42/64:
  Train Loss: 0.5570137798786163
  Validation Loss: 0.5689564943313599
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 43/64:
  Train Loss: 0.5528907775878906
  Validation Loss: 0.5689451098442078
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 44/64:
  Train Loss: 0.551214337348938
  Validation Loss: 0.5689789056777954
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 45/64:
  Train Loss: 0.5554398894309998
  Validation Loss: 0.5690298080444336
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 46/64:
  Train Loss: 0.551843523979187
  Validation Loss: 0.5690625309944153
  Val ROC-AUC: 0.6000000000000001
  Val Accuracy: 0.7692307829856873
Epoch 47/64:
  Train Loss: 0.5502005517482758
  Validation Loss: 0.5690925121307373
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 48/64:
  Train Loss: 0.5529728829860687
  Validation Loss: 0.569117546081543
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 49/64:
  Train Loss: 0.5584920644760132
  Validation Loss: 0.56916344165802
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 50/64:
  Train Loss: 0.5508595108985901
  Validation Loss: 0.5692278742790222
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 51/64:
  Train Loss: 0.5582862198352814
  Validation Loss: 0.5692719221115112
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 52/64:
  Train Loss: 0.5504632294178009
  Validation Loss: 0.5693418383598328
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 53/64:
  Train Loss: 0.5552626550197601
  Validation Loss: 0.5693998336791992
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 54/64:
  Train Loss: 0.544796034693718
  Validation Loss: 0.5694553852081299
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 55/64:
  Train Loss: 0.5581471920013428
  Validation Loss: 0.5695067048072815
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 56/64:
  Train Loss: 0.5511972904205322
  Validation Loss: 0.5695561170578003
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 57/64:
  Train Loss: 0.5588690042495728
  Validation Loss: 0.569606363773346
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 58/64:
  Train Loss: 0.5514538586139679
  Validation Loss: 0.569649875164032
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 59/64:
  Train Loss: 0.5507642030715942
  Validation Loss: 0.5697274804115295
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 60/64:
  Train Loss: 0.553126871585846
  Validation Loss: 0.5698056221008301
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 61/64:
  Train Loss: 0.5561212599277496
  Validation Loss: 0.569870114326477
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 62/64:
  Train Loss: 0.5517159700393677
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:36:INFO:
[92mINFO [0m:      Received: evaluate message c53fe6b9-fdee-4bb6-ba5b-03a23f959792
02/07/2025 22:35:36:INFO:Received: evaluate message c53fe6b9-fdee-4bb6-ba5b-03a23f959792
[92mINFO [0m:      Sent reply
02/07/2025 22:35:36:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:36:INFO:
[92mINFO [0m:      Received: train message 274a0b94-b0ae-4ae0-8d70-8e061c2ec2f2
02/07/2025 22:35:36:INFO:Received: train message 274a0b94-b0ae-4ae0-8d70-8e061c2ec2f2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.5699458718299866
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 63/64:
  Train Loss: 0.5522468686103821
  Validation Loss: 0.5700125098228455
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
Epoch 64/64:
  Train Loss: 0.5527135133743286
  Validation Loss: 0.5701029300689697
  Val ROC-AUC: 0.5666666666666668
  Val Accuracy: 0.7692307829856873
{'train_loss': 0.5527135133743286, 'val_roc_auc': 0.5666666666666668, 'val_accuracy': 0.7692307829856873, 'val_loss': 0.5701029300689697}
 ROC_AUC: 0.5667|| Accuracy 0.7692 || Train Loss: 0.5527
 Val Loss: 0.5701 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5764112068547143
Test ROC-AUC: 0.7257142857142858
Test Accuracy: 0.5333333333333333
test_loss: 0.5764112068547143
test_roc_auc: 0.7257142857142858
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5619173645973206
  Validation Loss: 0.5507529973983765
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5670203268527985
  Validation Loss: 0.550855815410614
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5639166831970215
  Validation Loss: 0.5509553551673889
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5587925612926483
  Validation Loss: 0.5510396957397461
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.565923422574997
  Validation Loss: 0.5510997176170349
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5646547973155975
  Validation Loss: 0.5511968731880188
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5645649135112762
  Validation Loss: 0.5512732267379761
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5560195446014404
  Validation Loss: 0.5512831807136536
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5582480132579803
  Validation Loss: 0.5512416958808899
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5589071214199066
  Validation Loss: 0.551191508769989
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.568933755159378
  Validation Loss: 0.5511393547058105
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5655728876590729
  Validation Loss: 0.5511099100112915
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5658714473247528
  Validation Loss: 0.5511054992675781
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5638835430145264
  Validation Loss: 0.5511156320571899
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5651989877223969
  Validation Loss: 0.5511050224304199
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5614840984344482
  Validation Loss: 0.5511093139648438
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5538630783557892
  Validation Loss: 0.5511107444763184
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5603982210159302
  Validation Loss: 0.5510985851287842
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5616941452026367
  Validation Loss: 0.5510808825492859
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5669224858283997
  Validation Loss: 0.5510540008544922
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5564319789409637
  Validation Loss: 0.5510498881340027
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5550010502338409
  Validation Loss: 0.5510410666465759
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5564671456813812
  Validation Loss: 0.5509950518608093
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5574551224708557
  Validation Loss: 0.5509251952171326
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5625618994235992
  Validation Loss: 0.5508712530136108
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5513997226953506
  Validation Loss: 0.5508098006248474
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5553146600723267
  Validation Loss: 0.5507757663726807
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5562010407447815
  Validation Loss: 0.5507906079292297
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5607350170612335
  Validation Loss: 0.550806999206543
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5600678026676178
  Validation Loss: 0.550853967666626
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5553948879241943
  Validation Loss: 0.5509012341499329
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5531430840492249
  Validation Loss: 0.5509385466575623
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5606646835803986
  Validation Loss: 0.5509613156318665
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5531140565872192
  Validation Loss: 0.5509905815124512
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5621304214000702
  Validation Loss: 0.5509803891181946
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5545120537281036
  Validation Loss: 0.5509849190711975
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5664015114307404
  Validation Loss: 0.5509738922119141
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.557755172252655
  Validation Loss: 0.5509764552116394
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5527747273445129
  Validation Loss: 0.550995409488678
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5621463656425476
  Validation Loss: 0.5509975552558899
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5678771734237671
  Validation Loss: 0.550963282585144
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5619769394397736
  Validation Loss: 0.5509158372879028
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5569288730621338
  Validation Loss: 0.5508562922477722
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5588433742523193
  Validation Loss: 0.5508118867874146
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5644668340682983
  Validation Loss: 0.5508321523666382
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5527973473072052
  Validation Loss: 0.5508401393890381
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5607716739177704
  Validation Loss: 0.5508268475532532
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:43:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:48:INFO:
[92mINFO [0m:      Received: evaluate message 89995b46-cb8e-420a-9da5-340cd0e14cc2
02/07/2025 22:35:48:INFO:Received: evaluate message 89995b46-cb8e-420a-9da5-340cd0e14cc2
[92mINFO [0m:      Sent reply
02/07/2025 22:35:48:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:48:INFO:
[92mINFO [0m:      Received: train message 6b773754-db00-45f3-804a-5f24361fd5c0
02/07/2025 22:35:48:INFO:Received: train message 6b773754-db00-45f3-804a-5f24361fd5c0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.5539033114910126
  Validation Loss: 0.550764262676239
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5634479224681854
  Validation Loss: 0.5506975054740906
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.552836000919342
  Validation Loss: 0.5506364107131958
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5579035878181458
  Validation Loss: 0.550606369972229
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5618813931941986
  Validation Loss: 0.5505613088607788
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5578646063804626
  Validation Loss: 0.5505084991455078
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5616408586502075
  Validation Loss: 0.5504709482192993
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5570603013038635
  Validation Loss: 0.5504258275032043
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5508946776390076
  Validation Loss: 0.5503879189491272
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5570110380649567
  Validation Loss: 0.5503268837928772
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5522217452526093
  Validation Loss: 0.550247311592102
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5603532195091248
  Validation Loss: 0.550186812877655
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5596854388713837
  Validation Loss: 0.5501363277435303
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5560025870800018
  Validation Loss: 0.5500874519348145
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5479718893766403
  Validation Loss: 0.5500350594520569
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5595894753932953
  Validation Loss: 0.5500021576881409
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.555680513381958
  Validation Loss: 0.549954354763031
  Val ROC-AUC: 0.7272727272727273
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.555680513381958, 'val_roc_auc': 0.7272727272727273, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.549954354763031}
 ROC_AUC: 0.7273|| Accuracy 0.5385 || Train Loss: 0.5557
 Val Loss: 0.5500 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.576377045445972
Test ROC-AUC: 0.7314285714285714
Test Accuracy: 0.5333333333333333
test_loss: 0.576377045445972
test_roc_auc: 0.7314285714285714
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5611816346645355
  Validation Loss: 0.5661819577217102
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 2/64:
  Train Loss: 0.5574482381343842
  Validation Loss: 0.5661746859550476
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 3/64:
  Train Loss: 0.5554840564727783
  Validation Loss: 0.5661699175834656
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 4/64:
  Train Loss: 0.5578367114067078
  Validation Loss: 0.5661453008651733
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 5/64:
  Train Loss: 0.5652815997600555
  Validation Loss: 0.5661277174949646
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 6/64:
  Train Loss: 0.5562865138053894
  Validation Loss: 0.5661230087280273
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 7/64:
  Train Loss: 0.5607860088348389
  Validation Loss: 0.5661282539367676
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 8/64:
  Train Loss: 0.5639672875404358
  Validation Loss: 0.566148579120636
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 9/64:
  Train Loss: 0.5558227598667145
  Validation Loss: 0.5661687254905701
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 10/64:
  Train Loss: 0.5593508780002594
  Validation Loss: 0.5661880373954773
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 11/64:
  Train Loss: 0.5525619685649872
  Validation Loss: 0.5661863088607788
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 12/64:
  Train Loss: 0.5526992678642273
  Validation Loss: 0.5661807060241699
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 13/64:
  Train Loss: 0.5571553409099579
  Validation Loss: 0.5661735534667969
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 14/64:
  Train Loss: 0.5619168281555176
  Validation Loss: 0.5661653876304626
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 15/64:
  Train Loss: 0.5569223165512085
  Validation Loss: 0.566161572933197
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 16/64:
  Train Loss: 0.5526883602142334
  Validation Loss: 0.5661401748657227
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 17/64:
  Train Loss: 0.5640162825584412
  Validation Loss: 0.5661167502403259
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 18/64:
  Train Loss: 0.5497125089168549
  Validation Loss: 0.5661116242408752
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 19/64:
  Train Loss: 0.5589420199394226
  Validation Loss: 0.5660858154296875
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 20/64:
  Train Loss: 0.5566416680812836
  Validation Loss: 0.5660663843154907
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 21/64:
  Train Loss: 0.5585478246212006
  Validation Loss: 0.5660460591316223
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 22/64:
  Train Loss: 0.5575167834758759
  Validation Loss: 0.5660347938537598
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 23/64:
  Train Loss: 0.5631715655326843
  Validation Loss: 0.5660359859466553
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 24/64:
  Train Loss: 0.5535924732685089
  Validation Loss: 0.5660510659217834
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 25/64:
  Train Loss: 0.5610148012638092
  Validation Loss: 0.5660528540611267
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 26/64:
  Train Loss: 0.5606125593185425
  Validation Loss: 0.5660385489463806
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 27/64:
  Train Loss: 0.5582376420497894
  Validation Loss: 0.5660306215286255
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 28/64:
  Train Loss: 0.557061642408371
  Validation Loss: 0.5660333633422852
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 29/64:
  Train Loss: 0.5587101876735687
  Validation Loss: 0.5660193562507629
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 30/64:
  Train Loss: 0.5520253777503967
  Validation Loss: 0.5660282373428345
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 31/64:
  Train Loss: 0.5528101921081543
  Validation Loss: 0.5660707354545593
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 32/64:
  Train Loss: 0.5539513230323792
  Validation Loss: 0.5661178231239319
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 33/64:
  Train Loss: 0.5523720681667328
  Validation Loss: 0.5661776065826416
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 34/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:00:INFO:
[92mINFO [0m:      Received: evaluate message 877d1d34-9d3c-47a4-b6d2-aa63f2cd68a8
02/07/2025 22:36:00:INFO:Received: evaluate message 877d1d34-9d3c-47a4-b6d2-aa63f2cd68a8
[92mINFO [0m:      Sent reply
02/07/2025 22:36:02:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:03:INFO:
[92mINFO [0m:      Received: train message 6a527cbc-7f21-4df1-a771-1a5e0523452c
02/07/2025 22:36:03:INFO:Received: train message 6a527cbc-7f21-4df1-a771-1a5e0523452c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.5576468110084534
  Validation Loss: 0.56622713804245
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 35/64:
  Train Loss: 0.5570633411407471
  Validation Loss: 0.5662606358528137
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 36/64:
  Train Loss: 0.5549091398715973
  Validation Loss: 0.5663043260574341
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 37/64:
  Train Loss: 0.5596241354942322
  Validation Loss: 0.566331684589386
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 38/64:
  Train Loss: 0.5585557520389557
  Validation Loss: 0.5663536787033081
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 39/64:
  Train Loss: 0.5478959679603577
  Validation Loss: 0.5663778185844421
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 40/64:
  Train Loss: 0.550218015909195
  Validation Loss: 0.5663947463035583
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5444788932800293
  Validation Loss: 0.5664039254188538
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5529779195785522
  Validation Loss: 0.5663867592811584
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5556338429450989
  Validation Loss: 0.5663794279098511
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.5576438009738922
  Validation Loss: 0.5663535594940186
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5633629560470581
  Validation Loss: 0.5663400292396545
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5565572082996368
  Validation Loss: 0.5663573741912842
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5662680566310883
  Validation Loss: 0.566366970539093
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5546794533729553
  Validation Loss: 0.5663726925849915
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5554501116275787
  Validation Loss: 0.566398561000824
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5566657185554504
  Validation Loss: 0.5663954615592957
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5514569580554962
  Validation Loss: 0.5663931369781494
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5579622685909271
  Validation Loss: 0.5663845539093018
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5484296679496765
  Validation Loss: 0.566347062587738
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.5517998039722443
  Validation Loss: 0.5663200616836548
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5547213554382324
  Validation Loss: 0.5662784576416016
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5563600361347198
  Validation Loss: 0.5662429928779602
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.552430272102356
  Validation Loss: 0.5662044882774353
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5517829060554504
  Validation Loss: 0.5661651492118835
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.5578421354293823
  Validation Loss: 0.5661336183547974
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5507838428020477
  Validation Loss: 0.5661066770553589
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5537866353988647
  Validation Loss: 0.5660684704780579
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5566944777965546
  Validation Loss: 0.5660151839256287
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5508537292480469
  Validation Loss: 0.5659819841384888
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
Epoch 64/64:
  Train Loss: 0.557245522737503
  Validation Loss: 0.5659616589546204
  Val ROC-AUC: 0.7000000000000001
  Val Accuracy: 0.692307710647583
{'train_loss': 0.557245522737503, 'val_roc_auc': 0.7000000000000001, 'val_accuracy': 0.692307710647583, 'val_loss': 0.5659616589546204}
 ROC_AUC: 0.7000|| Accuracy 0.6923 || Train Loss: 0.5572
 Val Loss: 0.5660 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.576381246248881
Test ROC-AUC: 0.7314285714285714
Test Accuracy: 0.5333333333333333
test_loss: 0.576381246248881
test_roc_auc: 0.7314285714285714
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.568102240562439
  Validation Loss: 0.5251495242118835
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 2/64:
  Train Loss: 0.5696134567260742
  Validation Loss: 0.525032103061676
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 3/64:
  Train Loss: 0.5602420270442963
  Validation Loss: 0.5249208211898804
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 4/64:
  Train Loss: 0.563115119934082
  Validation Loss: 0.5248009562492371
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 5/64:
  Train Loss: 0.5647227466106415
  Validation Loss: 0.5246891975402832
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 6/64:
  Train Loss: 0.5747943818569183
  Validation Loss: 0.5245949625968933
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5633451044559479
  Validation Loss: 0.5245038866996765
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5636807382106781
  Validation Loss: 0.5244411826133728
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5662457346916199
  Validation Loss: 0.5243725776672363
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5734129250049591
  Validation Loss: 0.5243054032325745
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5716873407363892
  Validation Loss: 0.5242593288421631
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.567378968000412
  Validation Loss: 0.5241896510124207
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5526382774114609
  Validation Loss: 0.5241231918334961
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5716358721256256
  Validation Loss: 0.52403324842453
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5686631202697754
  Validation Loss: 0.5239424705505371
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5658194422721863
  Validation Loss: 0.5238523483276367
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5577563345432281
  Validation Loss: 0.523783802986145
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5657703280448914
  Validation Loss: 0.5237172842025757
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5644233524799347
  Validation Loss: 0.5236324071884155
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5706576406955719
  Validation Loss: 0.5235539078712463
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5581907033920288
  Validation Loss: 0.5234847068786621
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:12:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:13:INFO:
[92mINFO [0m:      Received: evaluate message d9b91dd9-e365-4a86-9ec6-acccbad22afe
02/07/2025 22:36:13:INFO:Received: evaluate message d9b91dd9-e365-4a86-9ec6-acccbad22afe
[92mINFO [0m:      Sent reply
02/07/2025 22:36:16:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:18:INFO:
[92mINFO [0m:      Received: train message aa9dc225-0229-4ee0-9e7b-655c65267462
02/07/2025 22:36:18:INFO:Received: train message aa9dc225-0229-4ee0-9e7b-655c65267462
  Train Loss: 0.5662947297096252
  Validation Loss: 0.5234437584877014
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5688483715057373
  Validation Loss: 0.5234257578849792
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5642386674880981
  Validation Loss: 0.5234052538871765
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5613368153572083
  Validation Loss: 0.5233733654022217
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5572990775108337
  Validation Loss: 0.5233377814292908
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5618355572223663
  Validation Loss: 0.5232852697372437
  Val ROC-AUC: 1.0
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5672657489776611
  Validation Loss: 0.5232046842575073
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 29/64:
  Train Loss: 0.5651881992816925
  Validation Loss: 0.5230982899665833
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 30/64:
  Train Loss: 0.5679286122322083
  Validation Loss: 0.5230048298835754
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 31/64:
  Train Loss: 0.5611833333969116
  Validation Loss: 0.5229136347770691
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 32/64:
  Train Loss: 0.5603470206260681
  Validation Loss: 0.5228209495544434
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 33/64:
  Train Loss: 0.5626983046531677
  Validation Loss: 0.5227113962173462
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 34/64:
  Train Loss: 0.5622144639492035
  Validation Loss: 0.5225828289985657
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 35/64:
  Train Loss: 0.5660034418106079
  Validation Loss: 0.5224602818489075
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 36/64:
  Train Loss: 0.5616894364356995
  Validation Loss: 0.5223634839057922
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 37/64:
  Train Loss: 0.5634326338768005
  Validation Loss: 0.522262692451477
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 38/64:
  Train Loss: 0.5639820098876953
  Validation Loss: 0.5222110152244568
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 39/64:
  Train Loss: 0.5700027644634247
  Validation Loss: 0.5221738815307617
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 40/64:
  Train Loss: 0.5633838474750519
  Validation Loss: 0.5220893025398254
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 41/64:
  Train Loss: 0.569014847278595
  Validation Loss: 0.5220175981521606
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 42/64:
  Train Loss: 0.5660532414913177
  Validation Loss: 0.5219393968582153
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 43/64:
  Train Loss: 0.5611509382724762
  Validation Loss: 0.5218533873558044
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 44/64:
  Train Loss: 0.5652231872081757
  Validation Loss: 0.5217844843864441
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 45/64:
  Train Loss: 0.5651097893714905
  Validation Loss: 0.5217220783233643
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 46/64:
  Train Loss: 0.5677536129951477
  Validation Loss: 0.521658182144165
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 47/64:
  Train Loss: 0.5729846060276031
  Validation Loss: 0.521579384803772
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 48/64:
  Train Loss: 0.5573735237121582
  Validation Loss: 0.5215243697166443
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 49/64:
  Train Loss: 0.5713181495666504
  Validation Loss: 0.5214585065841675
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 50/64:
  Train Loss: 0.5648148059844971
  Validation Loss: 0.5213891267776489
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 51/64:
  Train Loss: 0.5581545531749725
  Validation Loss: 0.5213271975517273
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 52/64:
  Train Loss: 0.5703639090061188
  Validation Loss: 0.5212539434432983
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 53/64:
  Train Loss: 0.5612892210483551
  Validation Loss: 0.5212056040763855
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 54/64:
  Train Loss: 0.5620779395103455
  Validation Loss: 0.5211735367774963
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 55/64:
  Train Loss: 0.5624417662620544
  Validation Loss: 0.5211119651794434
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 56/64:
  Train Loss: 0.568971186876297
  Validation Loss: 0.5210708379745483
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 57/64:
  Train Loss: 0.5596112906932831
  Validation Loss: 0.5210219025611877
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 58/64:
  Train Loss: 0.5641849637031555
  Validation Loss: 0.520957350730896
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 59/64:
  Train Loss: 0.5674211978912354
  Validation Loss: 0.5208923816680908
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 60/64:
  Train Loss: 0.5666922628879547
  Validation Loss: 0.5208120346069336
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 61/64:
  Train Loss: 0.5656622350215912
  Validation Loss: 0.5207179188728333
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 62/64:
  Train Loss: 0.5581018924713135
  Validation Loss: 0.5206351280212402
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 63/64:
  Train Loss: 0.567234605550766
  Validation Loss: 0.5205625295639038
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
Epoch 64/64:
  Train Loss: 0.5717031061649323
  Validation Loss: 0.5205186009407043
  Val ROC-AUC: 1.0
  Val Accuracy: 0.46153849363327026
{'train_loss': 0.5717031061649323, 'val_roc_auc': 1.0, 'val_accuracy': 0.46153849363327026, 'val_loss': 0.5205186009407043}
 ROC_AUC: 1.0000|| Accuracy 0.4615 || Train Loss: 0.5717
 Val Loss: 0.5205 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.576329955789778
Test ROC-AUC: 0.7371428571428571
Test Accuracy: 0.5111111111111111
test_loss: 0.576329955789778
test_roc_auc: 0.7371428571428571
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5668226778507233
  Validation Loss: 0.5361568331718445
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5628103017807007
  Validation Loss: 0.5360397100448608
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5615686476230621
  Validation Loss: 0.53596031665802
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.5664689838886261
  Validation Loss: 0.5359123945236206
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.5648389756679535
  Validation Loss: 0.5358833074569702
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.560234934091568
  Validation Loss: 0.5358570218086243
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5634027719497681
  Validation Loss: 0.5358057618141174
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5672651529312134
  Validation Loss: 0.5357573628425598
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.5665895044803619
  Validation Loss: 0.5357343554496765
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.5679337084293365
  Validation Loss: 0.5357030630111694
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.5624914169311523
  Validation Loss: 0.5356441736221313
  Val ROC-AUC: 0.8636363636363636
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5582664310932159
  Validation Loss: 0.5355944633483887
  Val ROC-AUC: 0.8636363636363636
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5697685480117798
  Validation Loss: 0.5355507135391235
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5663637816905975
  Validation Loss: 0.5355302691459656
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 15/64:
  Train Loss: 0.5678389370441437
  Validation Loss: 0.5355146527290344
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.6153846383094788
Epoch 16/64:
  Train Loss: 0.567929744720459
  Validation Loss: 0.5354961156845093
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5606074333190918
  Validation Loss: 0.5354813933372498
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5630461275577545
  Validation Loss: 0.5354728102684021
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5702366530895233
  Validation Loss: 0.5354468822479248
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5648321211338043
  Validation Loss: 0.5354211330413818
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5679743885993958
  Validation Loss: 0.5353960394859314
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5689549148082733
  Validation Loss: 0.5353437662124634
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5756456255912781
  Validation Loss: 0.5352932214736938
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5623672008514404
  Validation Loss: 0.5352413654327393
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5673078894615173
  Validation Loss: 0.5351958870887756
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5614455342292786
  Validation Loss: 0.5351828932762146
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.56309774518013
  Validation Loss: 0.5351560711860657
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5641151368618011
  Validation Loss: 0.5351365804672241
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5696941018104553
  Validation Loss: 0.5351186394691467
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5634095668792725
  Validation Loss: 0.5350978970527649
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5617515742778778
  Validation Loss: 0.5350649952888489
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.569904088973999
  Validation Loss: 0.5350323915481567
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5702850818634033
  Validation Loss: 0.5350126028060913
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.563510924577713
  Validation Loss: 0.5349645614624023
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5602448582649231
  Validation Loss: 0.5349218249320984
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5640910565853119
  Validation Loss: 0.5349047780036926
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5660083591938019
  Validation Loss: 0.5348803997039795
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5680420696735382
  Validation Loss: 0.5348449349403381
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5651138424873352
  Validation Loss: 0.5348108410835266
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5598947405815125
  Validation Loss: 0.5348187685012817
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5749098658561707
  Validation Loss: 0.5348146557807922
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5689519345760345
  Validation Loss: 0.5348125696182251
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5614646077156067
  Validation Loss: 0.5347949266433716
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5609376132488251
  Validation Loss: 0.5347901582717896
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5578135251998901
  Validation Loss: 0.5347895622253418
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.558459997177124
  Validation Loss: 0.5347878336906433
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5590192377567291
  Validation Loss: 0.5347803235054016
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5572570264339447
  Validation Loss: 0.5347789525985718
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5626978576183319
  Validation Loss: 0.5347549319267273
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5598787665367126
  Validation Loss: 0.5347187519073486
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5679991245269775
  Validation Loss: 0.5346740484237671
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5652506947517395
  Validation Loss: 0.5346361398696899
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5617021918296814
  Validation Loss: 0.5346009135246277
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5654547214508057
  Validation Loss: 0.534572422504425
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.562600702047348
  Validation Loss: 0.5345433354377747
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.559485912322998
  Validation Loss: 0.5345033407211304
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5557989180088043
  Validation Loss: 0.5344753265380859
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5616920292377472
  Validation Loss: 0.5344409346580505
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5620651245117188
  Validation Loss: 0.5344300270080566
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5631581246852875
  Validation Loss: 0.534386157989502
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5596464574337006
  Validation Loss: 0.5343576073646545
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5633776187896729
  Validation Loss: 0.5343190431594849
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5653984248638153
  Validation Loss: 0.5342771410942078
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.563838928937912
  Validation Loss: 0.5342308878898621
  Val ROC-AUC: 0.9090909090909091
  Val Accuracy: 0.5384615659713745
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:24:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:29:INFO:
[92mINFO [0m:      Received: evaluate message c2073db8-55be-4f87-b815-937c7985cfe9
02/07/2025 22:36:29:INFO:Received: evaluate message c2073db8-55be-4f87-b815-937c7985cfe9
[92mINFO [0m:      Sent reply
02/07/2025 22:36:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:30:INFO:
[92mINFO [0m:      Received: train message 6af5365f-cd36-448c-82b8-b0dea761cbd7
02/07/2025 22:36:30:INFO:Received: train message 6af5365f-cd36-448c-82b8-b0dea761cbd7
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
{'train_loss': 0.563838928937912, 'val_roc_auc': 0.9090909090909091, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5342308878898621}
 ROC_AUC: 0.9091|| Accuracy 0.5385 || Train Loss: 0.5638
 Val Loss: 0.5342 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5762816362910801
Test ROC-AUC: 0.74
Test Accuracy: 0.5111111111111111
test_loss: 0.5762816362910801
test_roc_auc: 0.74
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5626047551631927
  Validation Loss: 0.5537678003311157
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5541208982467651
  Validation Loss: 0.5537253618240356
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5638213753700256
  Validation Loss: 0.5536189675331116
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.5625042915344238
  Validation Loss: 0.5535070300102234
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.5595274865627289
  Validation Loss: 0.5534457564353943
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 6/64:
  Train Loss: 0.5577331185340881
  Validation Loss: 0.553374171257019
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 7/64:
  Train Loss: 0.5594573020935059
  Validation Loss: 0.5533164143562317
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 8/64:
  Train Loss: 0.5621289908885956
  Validation Loss: 0.5532536506652832
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 9/64:
  Train Loss: 0.5646380186080933
  Validation Loss: 0.5531706213951111
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 10/64:
  Train Loss: 0.5604522824287415
  Validation Loss: 0.5531036853790283
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.5581169128417969
  Validation Loss: 0.5530506372451782
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 12/64:
  Train Loss: 0.5620894730091095
  Validation Loss: 0.5529716610908508
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 13/64:
  Train Loss: 0.5679758489131927
  Validation Loss: 0.5528988242149353
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 14/64:
  Train Loss: 0.5623108744621277
  Validation Loss: 0.552847683429718
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 15/64:
  Train Loss: 0.5645829737186432
  Validation Loss: 0.5528163909912109
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 16/64:
  Train Loss: 0.5575185716152191
  Validation Loss: 0.5527960062026978
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 17/64:
  Train Loss: 0.5613854825496674
  Validation Loss: 0.5527675747871399
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 18/64:
  Train Loss: 0.5591811835765839
  Validation Loss: 0.5527370572090149
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 19/64:
  Train Loss: 0.5614326596260071
  Validation Loss: 0.5527108311653137
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 20/64:
  Train Loss: 0.5582816004753113
  Validation Loss: 0.5526652336120605
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 21/64:
  Train Loss: 0.5574035942554474
  Validation Loss: 0.5526036024093628
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 22/64:
  Train Loss: 0.5608561635017395
  Validation Loss: 0.5525593757629395
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 23/64:
  Train Loss: 0.5636812150478363
  Validation Loss: 0.5525177121162415
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 24/64:
  Train Loss: 0.5677445530891418
  Validation Loss: 0.5524700284004211
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 25/64:
  Train Loss: 0.5648781955242157
  Validation Loss: 0.5524333715438843
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 26/64:
  Train Loss: 0.5543792545795441
  Validation Loss: 0.5523934960365295
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 27/64:
  Train Loss: 0.5575458407402039
  Validation Loss: 0.552350640296936
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 28/64:
  Train Loss: 0.5585915744304657
  Validation Loss: 0.5523067116737366
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 29/64:
  Train Loss: 0.5611848533153534
  Validation Loss: 0.552269458770752
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 30/64:
  Train Loss: 0.5501111447811127
  Validation Loss: 0.5522390604019165
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 31/64:
  Train Loss: 0.5636391043663025
  Validation Loss: 0.5522210597991943
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 32/64:
  Train Loss: 0.5556365251541138
  Validation Loss: 0.5522129535675049
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 33/64:
  Train Loss: 0.5563232600688934
  Validation Loss: 0.5522008538246155
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 34/64:
  Train Loss: 0.5646754503250122
  Validation Loss: 0.5521722435951233
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 35/64:
  Train Loss: 0.5644723176956177
  Validation Loss: 0.5521423816680908
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 36/64:
  Train Loss: 0.5675537288188934
  Validation Loss: 0.5521262884140015
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 37/64:
  Train Loss: 0.5585256516933441
  Validation Loss: 0.5521270632743835
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 38/64:
  Train Loss: 0.5611689686775208
  Validation Loss: 0.5521458387374878
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 39/64:
  Train Loss: 0.5625979602336884
  Validation Loss: 0.5521531105041504
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 40/64:
  Train Loss: 0.5549570620059967
  Validation Loss: 0.5521299242973328
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 41/64:
  Train Loss: 0.5666472017765045
  Validation Loss: 0.5520869493484497
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 42/64:
  Train Loss: 0.5635736286640167
  Validation Loss: 0.5520502328872681
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 43/64:
  Train Loss: 0.557758629322052
  Validation Loss: 0.5519981384277344
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 44/64:
  Train Loss: 0.5539122521877289
  Validation Loss: 0.5519640445709229
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 45/64:
  Train Loss: 0.5650011003017426
  Validation Loss: 0.5519231557846069
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 46/64:
  Train Loss: 0.5583968460559845
  Validation Loss: 0.551885724067688
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 47/64:
  Train Loss: 0.5670632719993591
  Validation Loss: 0.5518243908882141
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 48/64:
  Train Loss: 0.5569993257522583
  Validation Loss: 0.5517660975456238
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 49/64:
  Train Loss: 0.5632960796356201
  Validation Loss: 0.5517057180404663
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 50/64:
  Train Loss: 0.5589923560619354
  Validation Loss: 0.5516423583030701
  Val ROC-AUC: 0.6818181818181819
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:39:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:42:INFO:
[92mINFO [0m:      Received: evaluate message 32fe7d42-d425-4fb2-bcac-235d39d854d6
02/07/2025 22:36:42:INFO:Received: evaluate message 32fe7d42-d425-4fb2-bcac-235d39d854d6
[92mINFO [0m:      Sent reply
02/07/2025 22:36:45:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:46:INFO:
[92mINFO [0m:      Received: train message a39871cd-b161-400d-9e5d-a878faa49acb
02/07/2025 22:36:46:INFO:Received: train message a39871cd-b161-400d-9e5d-a878faa49acb
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.6153846383094788
Epoch 51/64:
  Train Loss: 0.5575242340564728
  Validation Loss: 0.5515835285186768
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 52/64:
  Train Loss: 0.5625291764736176
  Validation Loss: 0.5515377521514893
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 53/64:
  Train Loss: 0.5603368878364563
  Validation Loss: 0.5514992475509644
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 54/64:
  Train Loss: 0.5549578070640564
  Validation Loss: 0.5514634847640991
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 55/64:
  Train Loss: 0.5599761009216309
  Validation Loss: 0.5514108538627625
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 56/64:
  Train Loss: 0.5576050281524658
  Validation Loss: 0.5513535737991333
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 57/64:
  Train Loss: 0.5573671162128448
  Validation Loss: 0.5513049364089966
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 58/64:
  Train Loss: 0.5558436214923859
  Validation Loss: 0.551261842250824
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 59/64:
  Train Loss: 0.5591593384742737
  Validation Loss: 0.5511966347694397
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 60/64:
  Train Loss: 0.5576779842376709
  Validation Loss: 0.5511436462402344
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 61/64:
  Train Loss: 0.5580527186393738
  Validation Loss: 0.551084041595459
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 62/64:
  Train Loss: 0.5603455901145935
  Validation Loss: 0.5510191917419434
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.5615352392196655
  Validation Loss: 0.5509428977966309
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5611355602741241
  Validation Loss: 0.5508805513381958
  Val ROC-AUC: 0.6818181818181819
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5611355602741241, 'val_roc_auc': 0.6818181818181819, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.5508805513381958}
 ROC_AUC: 0.6818|| Accuracy 0.6154 || Train Loss: 0.5611
 Val Loss: 0.5509 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5762323048379686
Test ROC-AUC: 0.7428571428571429
Test Accuracy: 0.5111111111111111
test_loss: 0.5762323048379686
test_roc_auc: 0.7428571428571429
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5839380919933319
  Validation Loss: 0.4533449411392212
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 2/64:
  Train Loss: 0.5813060104846954
  Validation Loss: 0.4533707797527313
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 3/64:
  Train Loss: 0.5920295119285583
  Validation Loss: 0.45337140560150146
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 4/64:
  Train Loss: 0.5840731561183929
  Validation Loss: 0.4533897340297699
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 5/64:
  Train Loss: 0.5908511579036713
  Validation Loss: 0.4533836841583252
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5835991501808167
  Validation Loss: 0.45335322618484497
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5761799216270447
  Validation Loss: 0.45333826541900635
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5822442770004272
  Validation Loss: 0.4533158242702484
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5878009796142578
  Validation Loss: 0.4532719850540161
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5806813836097717
  Validation Loss: 0.4532236158847809
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 11/64:
  Train Loss: 0.5851781070232391
  Validation Loss: 0.45317474007606506
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5882667601108551
  Validation Loss: 0.45313191413879395
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5857730209827423
  Validation Loss: 0.45307838916778564
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.5884422957897186
  Validation Loss: 0.45301318168640137
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5880683362483978
  Validation Loss: 0.4529455006122589
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5899919271469116
  Validation Loss: 0.4528789818286896
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5854811072349548
  Validation Loss: 0.4528251886367798
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.5834972858428955
  Validation Loss: 0.4527566134929657
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5787349939346313
  Validation Loss: 0.452684611082077
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5869199335575104
  Validation Loss: 0.45260459184646606
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5824225842952728
  Validation Loss: 0.45255112648010254
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5858889222145081
  Validation Loss: 0.45248591899871826
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5844601094722748
  Validation Loss: 0.4524102807044983
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5904413163661957
  Validation Loss: 0.452338308095932
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5890279412269592
  Validation Loss: 0.4522845447063446
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5905167758464813
  Validation Loss: 0.452219694852829
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5917304158210754
  Validation Loss: 0.4521240293979645
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5871470868587494
  Validation Loss: 0.45202821493148804
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5790958106517792
  Validation Loss: 0.4519331455230713
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.5845561027526855
  Validation Loss: 0.45186978578567505
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5854060649871826
  Validation Loss: 0.4518064558506012
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5876074731349945
  Validation Loss: 0.4517301321029663
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5921353399753571
  Validation Loss: 0.45167285203933716
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5823618769645691
  Validation Loss: 0.451643705368042
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5818575024604797
  Validation Loss: 0.45160984992980957
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5881929397583008
  Validation Loss: 0.4515875577926636
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5836331844329834
  Validation Loss: 0.45158615708351135
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5862627327442169
  Validation Loss: 0.4515649378299713
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.5880590975284576
  Validation Loss: 0.451528936624527
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless
  warnings.warn(
[92mINFO [0m:      Sent reply
02/07/2025 22:36:55:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:59:INFO:
[92mINFO [0m:      Received: evaluate message 3c07bd13-dd14-468c-87ca-7f60517a5414
02/07/2025 22:36:59:INFO:Received: evaluate message 3c07bd13-dd14-468c-87ca-7f60517a5414
[92mINFO [0m:      Sent reply
02/07/2025 22:37:00:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:01:INFO:
[92mINFO [0m:      Received: train message d0f7bb2b-df59-4126-be46-66e31b348ae4
02/07/2025 22:37:01:INFO:Received: train message d0f7bb2b-df59-4126-be46-66e31b348ae4
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.5896442830562592
  Validation Loss: 0.4514911472797394
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.583000510931015
  Validation Loss: 0.4514385163784027
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5858815312385559
  Validation Loss: 0.4513798952102661
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5906471312046051
  Validation Loss: 0.4513203799724579
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5847179591655731
  Validation Loss: 0.45124122500419617
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5851086676120758
  Validation Loss: 0.451149582862854
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5826732814311981
  Validation Loss: 0.4510968327522278
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.5795505344867706
  Validation Loss: 0.4510365426540375
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5840710401535034
  Validation Loss: 0.4509674310684204
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.580447793006897
  Validation Loss: 0.4508854150772095
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5836149156093597
  Validation Loss: 0.45084089040756226
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5777473151683807
  Validation Loss: 0.4507896602153778
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.581048309803009
  Validation Loss: 0.45073753595352173
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5902267098426819
  Validation Loss: 0.4506852328777313
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5811876356601715
  Validation Loss: 0.4506186246871948
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5844632685184479
  Validation Loss: 0.4505535662174225
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5857784152030945
  Validation Loss: 0.4505038559436798
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5885575115680695
  Validation Loss: 0.4504610300064087
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5830930173397064
  Validation Loss: 0.45042258501052856
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5829043984413147
  Validation Loss: 0.45038798451423645
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5800085663795471
  Validation Loss: 0.4503611922264099
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5863594114780426
  Validation Loss: 0.4503832757472992
  Val ROC-AUC: nan
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5837391316890717
  Validation Loss: 0.45037564635276794
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 63/64:
  Train Loss: 0.582812488079071
  Validation Loss: 0.4503661096096039
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5744765400886536
  Validation Loss: 0.4503615200519562
  Val ROC-AUC: nan
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5744765400886536, 'val_roc_auc': nan, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.4503615200519562}
 ROC_AUC: nan|| Accuracy 0.6154 || Train Loss: 0.5745
 Val Loss: 0.4504 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5762203865581088
Test ROC-AUC: 0.7428571428571429
Test Accuracy: 0.5111111111111111
test_loss: 0.5762203865581088
test_roc_auc: 0.7428571428571429
test_accuracy: 0.5111111111111111
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5519201457500458
  Validation Loss: 0.5933022499084473
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 2/64:
  Train Loss: 0.5494045615196228
  Validation Loss: 0.5932425856590271
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 3/64:
  Train Loss: 0.5541629195213318
  Validation Loss: 0.5932292342185974
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 4/64:
  Train Loss: 0.5541179180145264
  Validation Loss: 0.5932183861732483
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 5/64:
  Train Loss: 0.54913130402565
  Validation Loss: 0.5932044982910156
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 6/64:
  Train Loss: 0.5514423549175262
  Validation Loss: 0.5931997299194336
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 7/64:
  Train Loss: 0.5520656108856201
  Validation Loss: 0.5931911468505859
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 8/64:
  Train Loss: 0.5547389090061188
  Validation Loss: 0.593174934387207
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 9/64:
  Train Loss: 0.5485122203826904
  Validation Loss: 0.5931383371353149
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 10/64:
  Train Loss: 0.5542774498462677
  Validation Loss: 0.5931165814399719
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 11/64:
  Train Loss: 0.5561012029647827
  Validation Loss: 0.5931002497673035
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 12/64:
  Train Loss: 0.5531958341598511
  Validation Loss: 0.5930771231651306
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 13/64:
  Train Loss: 0.5553091168403625
  Validation Loss: 0.5930671691894531
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 14/64:
  Train Loss: 0.550119936466217
  Validation Loss: 0.5930688977241516
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 15/64:
  Train Loss: 0.5552225708961487
  Validation Loss: 0.5930625200271606
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 16/64:
  Train Loss: 0.5511981844902039
  Validation Loss: 0.5930633544921875
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 17/64:
  Train Loss: 0.5561404526233673
  Validation Loss: 0.5930525064468384
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 18/64:
  Train Loss: 0.558211624622345
  Validation Loss: 0.5930334329605103
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 19/64:
  Train Loss: 0.5511458814144135
  Validation Loss: 0.5930234789848328
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 20/64:
  Train Loss: 0.5458905398845673
  Validation Loss: 0.5930107235908508
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 21/64:
  Train Loss: 0.5470947921276093
  Validation Loss: 0.5929756760597229
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 22/64:
  Train Loss: 0.5584715306758881
  Validation Loss: 0.5929471850395203
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 23/64:
  Train Loss: 0.5472907423973083
  Validation Loss: 0.5929195284843445
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 24/64:
  Train Loss: 0.5460066497325897
  Validation Loss: 0.5928794145584106
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 25/64:
  Train Loss: 0.5532999932765961
  Validation Loss: 0.592849612236023
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 26/64:
  Train Loss: 0.5563182234764099
  Validation Loss: 0.5928285717964172
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 27/64:
  Train Loss: 0.5526977777481079
  Validation Loss: 0.5927912592887878
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 28/64:
  Train Loss: 0.5478409230709076
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:37:09:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:14:INFO:
[92mINFO [0m:      Received: evaluate message e377e1a0-d0d9-451e-a076-a9b77c11d25d
02/07/2025 22:37:14:INFO:Received: evaluate message e377e1a0-d0d9-451e-a076-a9b77c11d25d
[92mINFO [0m:      Sent reply
02/07/2025 22:37:14:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:14:INFO:
[92mINFO [0m:      Received: train message 673518de-bc43-4a74-9141-f975c8ffb64d
02/07/2025 22:37:14:INFO:Received: train message 673518de-bc43-4a74-9141-f975c8ffb64d
  Validation Loss: 0.5927593111991882
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 29/64:
  Train Loss: 0.5478939712047577
  Validation Loss: 0.59272700548172
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 30/64:
  Train Loss: 0.549479216337204
  Validation Loss: 0.592695415019989
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 31/64:
  Train Loss: 0.5520715117454529
  Validation Loss: 0.5926632881164551
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 32/64:
  Train Loss: 0.5553142726421356
  Validation Loss: 0.592648446559906
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 33/64:
  Train Loss: 0.5510503351688385
  Validation Loss: 0.5926477313041687
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 34/64:
  Train Loss: 0.5499025881290436
  Validation Loss: 0.592636227607727
  Val ROC-AUC: 0.6666666666666666
  Val Accuracy: 0.5384615659713745
Epoch 35/64:
  Train Loss: 0.5526143610477448
  Validation Loss: 0.5926215648651123
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 36/64:
  Train Loss: 0.5518155097961426
  Validation Loss: 0.5926350355148315
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 37/64:
  Train Loss: 0.5488843023777008
  Validation Loss: 0.5926591157913208
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 38/64:
  Train Loss: 0.5538580119609833
  Validation Loss: 0.5926738977432251
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 39/64:
  Train Loss: 0.549699068069458
  Validation Loss: 0.5926764011383057
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 40/64:
  Train Loss: 0.5542190074920654
  Validation Loss: 0.5926834344863892
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 41/64:
  Train Loss: 0.5518703162670135
  Validation Loss: 0.5926834940910339
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 42/64:
  Train Loss: 0.5559443235397339
  Validation Loss: 0.5926784873008728
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 43/64:
  Train Loss: 0.5554322004318237
  Validation Loss: 0.5926662683486938
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 44/64:
  Train Loss: 0.5544897317886353
  Validation Loss: 0.5926445722579956
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 45/64:
  Train Loss: 0.5527017712593079
  Validation Loss: 0.5926375985145569
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 46/64:
  Train Loss: 0.5488912463188171
  Validation Loss: 0.5926422476768494
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 47/64:
  Train Loss: 0.545309990644455
  Validation Loss: 0.5926464200019836
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 48/64:
  Train Loss: 0.5492392480373383
  Validation Loss: 0.5926427245140076
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 49/64:
  Train Loss: 0.5503682196140289
  Validation Loss: 0.5926348567008972
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 50/64:
  Train Loss: 0.5516349077224731
  Validation Loss: 0.5926133990287781
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 51/64:
  Train Loss: 0.5566821396350861
  Validation Loss: 0.5926027894020081
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 52/64:
  Train Loss: 0.5521405041217804
  Validation Loss: 0.5926019549369812
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 53/64:
  Train Loss: 0.5468772053718567
  Validation Loss: 0.5925953984260559
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 54/64:
  Train Loss: 0.5503410398960114
  Validation Loss: 0.5925812721252441
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 55/64:
  Train Loss: 0.5557563304901123
  Validation Loss: 0.5925620198249817
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 56/64:
  Train Loss: 0.5455303490161896
  Validation Loss: 0.5925405025482178
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 57/64:
  Train Loss: 0.5526419579982758
  Validation Loss: 0.5925082564353943
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 58/64:
  Train Loss: 0.5497657358646393
  Validation Loss: 0.5924698710441589
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 59/64:
  Train Loss: 0.5437569916248322
  Validation Loss: 0.5924272537231445
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 60/64:
  Train Loss: 0.5423000454902649
  Validation Loss: 0.5923848748207092
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 61/64:
  Train Loss: 0.5502774715423584
  Validation Loss: 0.5923663973808289
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 62/64:
  Train Loss: 0.5418384522199631
  Validation Loss: 0.5923541784286499
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 63/64:
  Train Loss: 0.5503337681293488
  Validation Loss: 0.5923448801040649
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
Epoch 64/64:
  Train Loss: 0.5438774228096008
  Validation Loss: 0.5923261642456055
  Val ROC-AUC: 0.6333333333333333
  Val Accuracy: 0.5384615659713745
{'train_loss': 0.5438774228096008, 'val_roc_auc': 0.6333333333333333, 'val_accuracy': 0.5384615659713745, 'val_loss': 0.5923261642456055}
 ROC_AUC: 0.6333|| Accuracy 0.5385 || Train Loss: 0.5439
 Val Loss: 0.5923 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5761891656451755
Test ROC-AUC: 0.7457142857142857
Test Accuracy: 0.5333333333333333
test_loss: 0.5761891656451755
test_roc_auc: 0.7457142857142857
test_accuracy: 0.5333333333333333
eval_cid: 3
[Client 3] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.5718741714954376
  Validation Loss: 0.5429734587669373
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 2/64:
  Train Loss: 0.5680563747882843
  Validation Loss: 0.5431588292121887
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 3/64:
  Train Loss: 0.5666247010231018
  Validation Loss: 0.5433211326599121
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 4/64:
  Train Loss: 0.5666820406913757
  Validation Loss: 0.543483316898346
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 5/64:
  Train Loss: 0.5682468116283417
  Validation Loss: 0.5436167120933533
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 6/64:
  Train Loss: 0.5675953924655914
  Validation Loss: 0.5437564849853516
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 7/64:
  Train Loss: 0.5624961853027344
  Validation Loss: 0.5438961386680603
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 8/64:
  Train Loss: 0.5626316964626312
  Validation Loss: 0.5440516471862793
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 9/64:
  Train Loss: 0.5670326948165894
  Validation Loss: 0.5441803932189941
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 10/64:
  Train Loss: 0.5673461854457855
  Validation Loss: 0.5443057417869568
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 11/64:
  Train Loss: 0.5630424916744232
  Validation Loss: 0.5444150567054749
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 12/64:
  Train Loss: 0.5687209963798523
  Validation Loss: 0.5445464849472046
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 13/64:
  Train Loss: 0.5638715326786041
  Validation Loss: 0.5446643829345703
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 14/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:37:22:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:28:INFO:
[92mINFO [0m:      Received: evaluate message ffac5791-2217-43c8-8ad8-10126ce28679
02/07/2025 22:37:28:INFO:Received: evaluate message ffac5791-2217-43c8-8ad8-10126ce28679
  Train Loss: 0.567405492067337
  Validation Loss: 0.5447818040847778
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 15/64:
  Train Loss: 0.5607822239398956
  Validation Loss: 0.5449082255363464
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 16/64:
  Train Loss: 0.5620094537734985
  Validation Loss: 0.5450277328491211
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 17/64:
  Train Loss: 0.5579065382480621
  Validation Loss: 0.5451537370681763
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 18/64:
  Train Loss: 0.5650117099285126
  Validation Loss: 0.5452641248703003
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 19/64:
  Train Loss: 0.5719142556190491
  Validation Loss: 0.5453864932060242
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 20/64:
  Train Loss: 0.5674071907997131
  Validation Loss: 0.5455050468444824
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 21/64:
  Train Loss: 0.5718067586421967
  Validation Loss: 0.5456249117851257
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 22/64:
  Train Loss: 0.5731092989444733
  Validation Loss: 0.545746386051178
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 23/64:
  Train Loss: 0.5623571276664734
  Validation Loss: 0.5458703637123108
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 24/64:
  Train Loss: 0.5650395750999451
  Validation Loss: 0.5459948778152466
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 25/64:
  Train Loss: 0.5701208412647247
  Validation Loss: 0.5461078882217407
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 26/64:
  Train Loss: 0.567653626203537
  Validation Loss: 0.5462239384651184
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 27/64:
  Train Loss: 0.5669328570365906
  Validation Loss: 0.5463413000106812
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 28/64:
  Train Loss: 0.5665006935596466
  Validation Loss: 0.5464481115341187
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 29/64:
  Train Loss: 0.5569167733192444
  Validation Loss: 0.5465734601020813
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 30/64:
  Train Loss: 0.5669324398040771
  Validation Loss: 0.5466883778572083
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 31/64:
  Train Loss: 0.5604385137557983
  Validation Loss: 0.5468175411224365
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 32/64:
  Train Loss: 0.5623679161071777
  Validation Loss: 0.5469509363174438
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 33/64:
  Train Loss: 0.565238744020462
  Validation Loss: 0.5470660924911499
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 34/64:
  Train Loss: 0.5622465312480927
  Validation Loss: 0.5471919178962708
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 35/64:
  Train Loss: 0.5620631277561188
  Validation Loss: 0.5473041534423828
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 36/64:
  Train Loss: 0.5594980716705322
  Validation Loss: 0.5474222302436829
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 37/64:
  Train Loss: 0.5559298098087311
  Validation Loss: 0.5475478768348694
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 38/64:
  Train Loss: 0.5598448216915131
  Validation Loss: 0.5476686358451843
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 39/64:
  Train Loss: 0.5671395659446716
  Validation Loss: 0.5477843284606934
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.7692307829856873
Epoch 40/64:
  Train Loss: 0.5616284012794495
  Validation Loss: 0.547897458076477
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 41/64:
  Train Loss: 0.5705697238445282
  Validation Loss: 0.5480051040649414
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 42/64:
  Train Loss: 0.5640105903148651
  Validation Loss: 0.5481241941452026
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 43/64:
  Train Loss: 0.5614696741104126
  Validation Loss: 0.548240065574646
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 44/64:
  Train Loss: 0.560009777545929
  Validation Loss: 0.5483528971672058
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 45/64:
  Train Loss: 0.5583880245685577
  Validation Loss: 0.5484647154808044
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 46/64:
  Train Loss: 0.5616211891174316
  Validation Loss: 0.5485895276069641
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 47/64:
  Train Loss: 0.5587417185306549
  Validation Loss: 0.5487070679664612
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 48/64:
  Train Loss: 0.5560901761054993
  Validation Loss: 0.5488241910934448
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 49/64:
  Train Loss: 0.5565787553787231
  Validation Loss: 0.5489423871040344
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 50/64:
  Train Loss: 0.5522485375404358
  Validation Loss: 0.5490596890449524
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 51/64:
  Train Loss: 0.5623101890087128
  Validation Loss: 0.5491812229156494
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 52/64:
  Train Loss: 0.5609121918678284
  Validation Loss: 0.5492940545082092
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 53/64:
  Train Loss: 0.5591458976268768
  Validation Loss: 0.5494136214256287
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 54/64:
  Train Loss: 0.564717710018158
  Validation Loss: 0.5495225787162781
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 55/64:
  Train Loss: 0.5614176988601685
  Validation Loss: 0.549653947353363
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 56/64:
  Train Loss: 0.5572790503501892
  Validation Loss: 0.5497727990150452
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 57/64:
  Train Loss: 0.5612799525260925
  Validation Loss: 0.5498788952827454
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 58/64:
  Train Loss: 0.5586747527122498
  Validation Loss: 0.5499932169914246
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 59/64:
  Train Loss: 0.558563619852066
  Validation Loss: 0.5501054525375366
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 60/64:
  Train Loss: 0.5627347826957703
  Validation Loss: 0.5502222180366516
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 61/64:
  Train Loss: 0.5595754683017731
  Validation Loss: 0.5503409504890442
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 62/64:
  Train Loss: 0.5583166778087616
  Validation Loss: 0.5504596829414368
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.692307710647583
Epoch 63/64:
  Train Loss: 0.5566220283508301
  Validation Loss: 0.5505691170692444
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.6153846383094788
Epoch 64/64:
  Train Loss: 0.5634168684482574
  Validation Loss: 0.5506750345230103
  Val ROC-AUC: 0.8666666666666667
  Val Accuracy: 0.6153846383094788
{'train_loss': 0.5634168684482574, 'val_roc_auc': 0.8666666666666667, 'val_accuracy': 0.6153846383094788, 'val_loss': 0.5506750345230103}
 ROC_AUC: 0.8667|| Accuracy 0.6154 || Train Loss: 0.5634
 Val Loss: 0.5507 
[Client 3] evaluate, config: {'batch_size': 1}
Test Loss: 0.5761951227982839
Test ROC-AUC: 0.7428571428571429
Test Accuracy: 0.5333333333333333
test_loss: 0.5761951227982839
test_roc_auc: 0.7428571428571429
[92mINFO [0m:      Sent reply
02/07/2025 22:37:29:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:30:INFO:
[92mINFO [0m:      Received: reconnect message e9674d7b-bb4c-40f9-ab19-851d15e8bb67
02/07/2025 22:37:30:INFO:Received: reconnect message e9674d7b-bb4c-40f9-ab19-851d15e8bb67
02/07/2025 22:37:30:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/07/2025 22:37:30:INFO:Disconnect and shut down
test_accuracy: 0.5333333333333333
eval_cid: 3
CPU Time: 130.539661 seconds
Elapsed Time: 317.49035716056824 seconds
RAM Usage: 0.3716888427734375 megabytes
Logs saved in current directory
