nohup: ignoring input
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:32:16:WARNING:DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
02/07/2025 22:32:16:DEBUG:Opened insecure gRPC connection (no certificates were passed)
02/07/2025 22:32:16:DEBUG:ChannelConnectivity.IDLE
02/07/2025 22:32:16:DEBUG:ChannelConnectivity.READY
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1738996336.956577 1760045 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers
[92mINFO [0m:      
02/07/2025 22:32:17:INFO:
[92mINFO [0m:      Received: train message 07e38732-b887-4a50-aad6-b4c00cf9c53b
02/07/2025 22:32:17:INFO:Received: train message 07e38732-b887-4a50-aad6-b4c00cf9c53b
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours/1.0', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/heart_disease/ours']
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.761338472366333
  Validation Loss: 0.794563889503479
  Val ROC-AUC: 0.5617283950617284
  Val Accuracy: 0.5185185074806213
Epoch 2/64:
  Train Loss: 0.759972482919693
  Validation Loss: 0.7938392758369446
  Val ROC-AUC: 0.5617283950617284
  Val Accuracy: 0.5185185074806213
Epoch 3/64:
  Train Loss: 0.7656005024909973
  Validation Loss: 0.7931259870529175
  Val ROC-AUC: 0.5679012345679013
  Val Accuracy: 0.5185185074806213
Epoch 4/64:
  Train Loss: 0.7725087702274323
  Validation Loss: 0.7922989130020142
  Val ROC-AUC: 0.5679012345679013
  Val Accuracy: 0.5185185074806213
Epoch 5/64:
  Train Loss: 0.7628340274095535
  Validation Loss: 0.7913916110992432
  Val ROC-AUC: 0.5802469135802468
  Val Accuracy: 0.5185185074806213
Epoch 6/64:
  Train Loss: 0.765512228012085
  Validation Loss: 0.7906950116157532
  Val ROC-AUC: 0.5864197530864197
  Val Accuracy: 0.5185185074806213
Epoch 7/64:
  Train Loss: 0.7636595666408539
  Validation Loss: 0.7898971438407898
  Val ROC-AUC: 0.5925925925925926
  Val Accuracy: 0.5185185074806213
Epoch 8/64:
  Train Loss: 0.7658543586730957
  Validation Loss: 0.7891654372215271
  Val ROC-AUC: 0.5987654320987654
  Val Accuracy: 0.5185185074806213
Epoch 9/64:
  Train Loss: 0.7525933384895325
  Validation Loss: 0.7883068323135376
  Val ROC-AUC: 0.6049382716049383
  Val Accuracy: 0.5185185074806213
Epoch 10/64:
  Train Loss: 0.7538862079381943
  Validation Loss: 0.7873936295509338
  Val ROC-AUC: 0.6049382716049383
  Val Accuracy: 0.5555555820465088
Epoch 11/64:
  Train Loss: 0.7557423412799835
  Validation Loss: 0.7864959239959717
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.5555555820465088
Epoch 12/64:
  Train Loss: 0.7695499062538147
  Validation Loss: 0.7856539487838745
  Val ROC-AUC: 0.6111111111111112
  Val Accuracy: 0.5555555820465088
Epoch 13/64:
  Train Loss: 0.7562433630228043
  Validation Loss: 0.7846924662590027
  Val ROC-AUC: 0.6234567901234568
  Val Accuracy: 0.5555555820465088
Epoch 14/64:
  Train Loss: 0.751613587141037
  Validation Loss: 0.7836563587188721
  Val ROC-AUC: 0.6358024691358024
  Val Accuracy: 0.5555555820465088
Epoch 15/64:
  Train Loss: 0.7517666220664978
  Validation Loss: 0.7827324867248535
  Val ROC-AUC: 0.6419753086419753
  Val Accuracy: 0.5555555820465088
Epoch 16/64:
  Train Loss: 0.7532873302698135
  Validation Loss: 0.7818809747695923
  Val ROC-AUC: 0.654320987654321
  Val Accuracy: 0.5555555820465088
Epoch 17/64:
  Train Loss: 0.7529100477695465
  Validation Loss: 0.7809943556785583
  Val ROC-AUC: 0.654320987654321
  Val Accuracy: 0.5925925970077515
Epoch 18/64:
  Train Loss: 0.7437074035406113
  Validation Loss: 0.7800738215446472
  Val ROC-AUC: 0.654320987654321
  Val Accuracy: 0.5925925970077515
Epoch 19/64:
  Train Loss: 0.7496337890625
  Validation Loss: 0.7791517376899719
  Val ROC-AUC: 0.6604938271604939
  Val Accuracy: 0.5925925970077515
Epoch 20/64:
  Train Loss: 0.7362340688705444
  Validation Loss: 0.7783637046813965
  Val ROC-AUC: 0.6728395061728395
  Val Accuracy: 0.5925925970077515
Epoch 21/64:
  Train Loss: 0.745075598359108
  Validation Loss: 0.7776482105255127
  Val ROC-AUC: 0.6851851851851851
  Val Accuracy: 0.5925925970077515
Epoch 22/64:
  Train Loss: 0.7368363291025162
  Validation Loss: 0.7770106792449951
  Val ROC-AUC: 0.6851851851851851
  Val Accuracy: 0.5925925970077515
Epoch 23/64:
  Train Loss: 0.7428712248802185
  Validation Loss: 0.7763594388961792
  Val ROC-AUC: 0.6851851851851851
  Val Accuracy: 0.5925925970077515
Epoch 24/64:
  Train Loss: 0.7405426800251007
  Validation Loss: 0.7757107615470886
  Val ROC-AUC: 0.691358024691358
  Val Accuracy: 0.6296296119689941
Epoch 25/64:
  Train Loss: 0.728610172867775
  Validation Loss: 0.7749998569488525
  Val ROC-AUC: 0.7037037037037037
  Val Accuracy: 0.6296296119689941
Epoch 26/64:
  Train Loss: 0.7276338636875153
  Validation Loss: 0.7742666602134705
  Val ROC-AUC: 0.7037037037037037
  Val Accuracy: 0.6666666865348816
Epoch 27/64:
  Train Loss: 0.7310343384742737
  Validation Loss: 0.773450493812561
  Val ROC-AUC: 0.7098765432098766
  Val Accuracy: 0.6666666865348816
Epoch 28/64:
  Train Loss: 0.7329677045345306
  Validation Loss: 0.7726110816001892
  Val ROC-AUC: 0.7098765432098766
  Val Accuracy: 0.6666666865348816
Epoch 29/64:
  Train Loss: 0.7330284267663956
  Validation Loss: 0.7718603610992432
  Val ROC-AUC: 0.7345679012345678
  Val Accuracy: 0.6666666865348816
Epoch 30/64:
  Train Loss: 0.7407693713903427
  Validation Loss: 0.7712132334709167
  Val ROC-AUC: 0.7407407407407407
  Val Accuracy: 0.6666666865348816
Epoch 31/64:
  Train Loss: 0.727482482790947
  Validation Loss: 0.7705807685852051
  Val ROC-AUC: 0.7407407407407407
  Val Accuracy: 0.7037037014961243
Epoch 32/64:
  Train Loss: 0.7402191162109375
  Validation Loss: 0.7699955105781555
  Val ROC-AUC: 0.7407407407407407
  Val Accuracy: 0.7037037014961243
Epoch 33/64:
  Train Loss: 0.7381059676408768
  Validation Loss: 0.7693967819213867
  Val ROC-AUC: 0.7407407407407407
  Val Accuracy: 0.7037037014961243
Epoch 34/64:
  Train Loss: 0.7268314957618713
  Validation Loss: 0.7686910629272461
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.7407407760620117
Epoch 35/64:
  Train Loss: 0.7316914051771164
  Validation Loss: 0.7680050730705261
  Val ROC-AUC: 0.7530864197530864
  Val Accuracy: 0.7407407760620117
Epoch 36/64:
  Train Loss: 0.7357101291418076
  Validation Loss: 0.7672099471092224
  Val ROC-AUC: 0.7592592592592593
  Val Accuracy: 0.7407407760620117
Epoch 37/64:
  Train Loss: 0.7307728826999664
  Validation Loss: 0.766455888748169
  Val ROC-AUC: 0.7654320987654322
  Val Accuracy: 0.7407407760620117
Epoch 38/64:
  Train Loss: 0.7327282875776291
  Validation Loss: 0.7657749056816101
  Val ROC-AUC: 0.7654320987654322
  Val Accuracy: 0.7407407760620117
Epoch 39/64:
  Train Loss: 0.7156975716352463
  Validation Loss: 0.7651179432868958
  Val ROC-AUC: 0.7654320987654322
  Val Accuracy: 0.7407407760620117
Epoch 40/64:
  Train Loss: 0.7333778738975525
  Validation Loss: 0.7645760774612427
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7407407760620117
Epoch 41/64:
  Train Loss: 0.7233959883451462
  Validation Loss: 0.7639532089233398
  Val ROC-AUC: 0.7777777777777778
  Val Accuracy: 0.7407407760620117
Epoch 42/64:
  Train Loss: 0.7307872176170349
  Validation Loss: 0.7633177042007446
  Val ROC-AUC: 0.7839506172839505
  Val Accuracy: 0.7407407760620117
Epoch 43/64:
  Train Loss: 0.7300771027803421
  Validation Loss: 0.7627409100532532
  Val ROC-AUC: 0.7901234567901234
  Val Accuracy: 0.7407407760620117
Epoch 44/64:
  Train Loss: 0.7370245903730392
  Validation Loss: 0.7622718811035156
  Val ROC-AUC: 0.7901234567901234
  Val Accuracy: 0.7407407760620117
Epoch 45/64:
  Train Loss: 0.715298131108284
  Validation Loss: 0.7618457674980164
  Val ROC-AUC: 0.7901234567901234
  Val Accuracy: 0.7407407760620117
Epoch 46/64:
  Train Loss: 0.7163313329219818
  Validation Loss: 0.7613958716392517
  Val ROC-AUC: 0.7962962962962963
  Val Accuracy: 0.7037037014961243
Epoch 47/64:
  Train Loss: 0.7258116155862808
  Validation Loss: 0.7608950734138489
  Val ROC-AUC: 0.8024691358024691
  Val Accuracy: 0.7037037014961243
Epoch 48/64:
  Train Loss: 0.7203596532344818
  Validation Loss: 0.7602585554122925
  Val ROC-AUC: 0.808641975308642
  Val Accuracy: 0.7037037014961243
Epoch 49/64:
  Train Loss: 0.7256586104631424
  Validation Loss: 0.7596021890640259
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7037037014961243
Epoch 50/64:
  Train Loss: 0.7060172110795975
  Validation Loss: 0.758927583694458
  Val ROC-AUC: 0.8148148148148148
  Val Accuracy: 0.7037037014961243
Epoch 51/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:32:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:29:INFO:
[92mINFO [0m:      Received: evaluate message 1d959d96-c4b0-442b-a8ed-c5dec3390ef7
02/07/2025 22:32:29:INFO:Received: evaluate message 1d959d96-c4b0-442b-a8ed-c5dec3390ef7
[92mINFO [0m:      Sent reply
02/07/2025 22:32:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:33:INFO:
[92mINFO [0m:      Received: train message 3e365d34-5dd6-4151-978f-6ca42ea3ef1a
02/07/2025 22:32:33:INFO:Received: train message 3e365d34-5dd6-4151-978f-6ca42ea3ef1a
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.7064450234174728
  Validation Loss: 0.7582685947418213
  Val ROC-AUC: 0.8209876543209876
  Val Accuracy: 0.7407407760620117
Epoch 52/64:
  Train Loss: 0.7171834409236908
  Validation Loss: 0.7576373219490051
  Val ROC-AUC: 0.8209876543209876
  Val Accuracy: 0.7407407760620117
Epoch 53/64:
  Train Loss: 0.710198774933815
  Validation Loss: 0.7570002675056458
  Val ROC-AUC: 0.8209876543209876
  Val Accuracy: 0.7407407760620117
Epoch 54/64:
  Train Loss: 0.7158321142196655
  Validation Loss: 0.7563907504081726
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7407407760620117
Epoch 55/64:
  Train Loss: 0.7205722630023956
  Validation Loss: 0.7558364868164062
  Val ROC-AUC: 0.8209876543209876
  Val Accuracy: 0.7407407760620117
Epoch 56/64:
  Train Loss: 0.7147150784730911
  Validation Loss: 0.7552722096443176
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7407407760620117
Epoch 57/64:
  Train Loss: 0.7055595070123672
  Validation Loss: 0.7546876072883606
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7777777910232544
Epoch 58/64:
  Train Loss: 0.7149255126714706
  Validation Loss: 0.7540944218635559
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7777777910232544
Epoch 59/64:
  Train Loss: 0.7163265198469162
  Validation Loss: 0.7534045577049255
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7777777910232544
Epoch 60/64:
  Train Loss: 0.6976091116666794
  Validation Loss: 0.7527099251747131
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7777777910232544
Epoch 61/64:
  Train Loss: 0.7034284174442291
  Validation Loss: 0.7520015835762024
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.7777777910232544
Epoch 62/64:
  Train Loss: 0.7167774438858032
  Validation Loss: 0.7512844204902649
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.7073739469051361
  Validation Loss: 0.7506499886512756
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.7044035196304321
  Validation Loss: 0.7500759959220886
  Val ROC-AUC: 0.845679012345679
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.7044035196304321, 'val_roc_auc': 0.845679012345679, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.7500759959220886}
 ROC_AUC: 0.8457|| Accuracy 0.8148 || Train Loss: 0.7044
 Val Loss: 0.7501 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7787098342113281
Test ROC-AUC: 0.6866883116883117
Test Accuracy: 0.5617977528089888
test_loss: 0.7787098342113281
test_roc_auc: 0.6866883116883117
test_accuracy: 0.5617977528089888
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.7565901428461075
  Validation Loss: 0.8264078497886658
  Val ROC-AUC: 0.6052631578947368
  Val Accuracy: 0.5555555820465088
Epoch 2/64:
  Train Loss: 0.7557229250669479
  Validation Loss: 0.8253437876701355
  Val ROC-AUC: 0.611842105263158
  Val Accuracy: 0.5555555820465088
Epoch 3/64:
  Train Loss: 0.7525150328874588
  Validation Loss: 0.8244897127151489
  Val ROC-AUC: 0.611842105263158
  Val Accuracy: 0.5555555820465088
Epoch 4/64:
  Train Loss: 0.7496767938137054
  Validation Loss: 0.8235511779785156
  Val ROC-AUC: 0.625
  Val Accuracy: 0.5555555820465088
Epoch 5/64:
  Train Loss: 0.7462553083896637
  Validation Loss: 0.8226050138473511
  Val ROC-AUC: 0.6447368421052632
  Val Accuracy: 0.5555555820465088
Epoch 6/64:
  Train Loss: 0.7410644590854645
  Validation Loss: 0.8217014670372009
  Val ROC-AUC: 0.6513157894736843
  Val Accuracy: 0.5555555820465088
Epoch 7/64:
  Train Loss: 0.7410122603178024
  Validation Loss: 0.8209730982780457
  Val ROC-AUC: 0.6513157894736843
  Val Accuracy: 0.5555555820465088
Epoch 8/64:
  Train Loss: 0.7386389225721359
  Validation Loss: 0.8202692866325378
  Val ROC-AUC: 0.6513157894736843
  Val Accuracy: 0.5555555820465088
Epoch 9/64:
  Train Loss: 0.7489165514707565
  Validation Loss: 0.8196101188659668
  Val ROC-AUC: 0.6513157894736843
  Val Accuracy: 0.5555555820465088
Epoch 10/64:
  Train Loss: 0.7563641369342804
  Validation Loss: 0.8189795613288879
  Val ROC-AUC: 0.6513157894736843
  Val Accuracy: 0.5555555820465088
Epoch 11/64:
  Train Loss: 0.7411656975746155
  Validation Loss: 0.8182001709938049
  Val ROC-AUC: 0.6710526315789473
  Val Accuracy: 0.5925925970077515
Epoch 12/64:
  Train Loss: 0.7427541464567184
  Validation Loss: 0.8173646926879883
  Val ROC-AUC: 0.6842105263157895
  Val Accuracy: 0.5925925970077515
Epoch 13/64:
  Train Loss: 0.7323785573244095
  Validation Loss: 0.8165376782417297
  Val ROC-AUC: 0.6973684210526316
  Val Accuracy: 0.5925925970077515
Epoch 14/64:
  Train Loss: 0.7500278055667877
  Validation Loss: 0.8158645629882812
  Val ROC-AUC: 0.7039473684210527
  Val Accuracy: 0.6296296119689941
Epoch 15/64:
  Train Loss: 0.7550000101327896
  Validation Loss: 0.8152152299880981
  Val ROC-AUC: 0.7105263157894737
  Val Accuracy: 0.6296296119689941
Epoch 16/64:
  Train Loss: 0.7581754177808762
  Validation Loss: 0.8147430419921875
  Val ROC-AUC: 0.7171052631578947
  Val Accuracy: 0.6296296119689941
Epoch 17/64:
  Train Loss: 0.7473000138998032
  Validation Loss: 0.8141905069351196
  Val ROC-AUC: 0.7171052631578947
  Val Accuracy: 0.6296296119689941
Epoch 18/64:
  Train Loss: 0.7359184473752975
  Validation Loss: 0.8135692477226257
  Val ROC-AUC: 0.7236842105263158
  Val Accuracy: 0.6296296119689941
Epoch 19/64:
  Train Loss: 0.7314614057540894
  Validation Loss: 0.8127660751342773
  Val ROC-AUC: 0.743421052631579
  Val Accuracy: 0.6296296119689941
Epoch 20/64:
  Train Loss: 0.7590645104646683
  Validation Loss: 0.8119446039199829
  Val ROC-AUC: 0.75
  Val Accuracy: 0.6296296119689941
Epoch 21/64:
  Train Loss: 0.7430465072393417
  Validation Loss: 0.8112001419067383
  Val ROC-AUC: 0.7697368421052633
  Val Accuracy: 0.6666666865348816
Epoch 22/64:
  Train Loss: 0.7293942272663116
  Validation Loss: 0.8104521036148071
  Val ROC-AUC: 0.7763157894736843
  Val Accuracy: 0.6666666865348816
Epoch 23/64:
  Train Loss: 0.7343676537275314
  Validation Loss: 0.8096889853477478
  Val ROC-AUC: 0.7894736842105263
  Val Accuracy: 0.6666666865348816
Epoch 24/64:
  Train Loss: 0.7453317940235138
  Validation Loss: 0.808839738368988
  Val ROC-AUC: 0.7960526315789475
  Val Accuracy: 0.6666666865348816
Epoch 25/64:
  Train Loss: 0.7370544970035553
  Validation Loss: 0.8080931901931763
  Val ROC-AUC: 0.8026315789473685
  Val Accuracy: 0.6666666865348816
Epoch 26/64:
  Train Loss: 0.7436521798372269
  Validation Loss: 0.8073504567146301
  Val ROC-AUC: 0.8157894736842105
  Val Accuracy: 0.6666666865348816
Epoch 27/64:
  Train Loss: 0.7371614426374435
  Validation Loss: 0.8066192269325256
  Val ROC-AUC: 0.8289473684210527
  Val Accuracy: 0.6666666865348816
Epoch 28/64:
  Train Loss: 0.7449590861797333
  Validation Loss: 0.8058921098709106
  Val ROC-AUC: 0.8421052631578947
  Val Accuracy: 0.6666666865348816
Epoch 29/64:
  Train Loss: 0.7271029055118561
  Validation Loss: 0.8053359389305115
  Val ROC-AUC: 0.8486842105263158
  Val Accuracy: 0.7037037014961243
Epoch 30/64:
  Train Loss: 0.7302906960248947
  Validation Loss: 0.8047188520431519
  Val ROC-AUC: 0.861842105263158
  Val Accuracy: 0.7037037014961243
Epoch 31/64:
  Train Loss: 0.7366417497396469
  Validation Loss: 0.804162323474884
  Val ROC-AUC: 0.861842105263158
  Val Accuracy: 0.7037037014961243
Epoch 32/64:
  Train Loss: 0.7318546622991562
  Validation Loss: 0.8036224842071533
  Val ROC-AUC: 0.8684210526315789
  Val Accuracy: 0.7037037014961243
Epoch 33/64:
  Train Loss: 0.7265647649765015
  Validation Loss: 0.8030310869216919
  Val ROC-AUC: 0.875
  Val Accuracy: 0.7037037014961243
Epoch 34/64:
  Train Loss: 0.733433797955513
  Validation Loss: 0.8021576404571533
  Val ROC-AUC: 0.875
  Val Accuracy: 0.7037037014961243
Epoch 35/64:
  Train Loss: 0.7318248748779297
  Validation Loss: 0.8013458251953125
  Val ROC-AUC: 0.875
  Val Accuracy: 0.7037037014961243
Epoch 36/64:
  Train Loss: 0.7283777296543121
  Validation Loss: 0.8008460402488708
  Val ROC-AUC: 0.881578947368421
  Val Accuracy: 0.7037037014961243
Epoch 37/64:
  Train Loss: 0.7182021886110306
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:32:41:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:43:INFO:
[92mINFO [0m:      Received: evaluate message 0ca49b3a-ed50-4a2a-8b3a-d6e144a87076
02/07/2025 22:32:43:INFO:Received: evaluate message 0ca49b3a-ed50-4a2a-8b3a-d6e144a87076
[92mINFO [0m:      Sent reply
02/07/2025 22:32:45:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:45:INFO:
[92mINFO [0m:      Received: train message ccb441ba-b4ec-4e42-aba3-c2b4fce44de8
02/07/2025 22:32:45:INFO:Received: train message ccb441ba-b4ec-4e42-aba3-c2b4fce44de8
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.8004443645477295
  Val ROC-AUC: 0.888157894736842
  Val Accuracy: 0.7037037014961243
Epoch 38/64:
  Train Loss: 0.7172499746084213
  Validation Loss: 0.7998669147491455
  Val ROC-AUC: 0.888157894736842
  Val Accuracy: 0.7037037014961243
Epoch 39/64:
  Train Loss: 0.7242433428764343
  Validation Loss: 0.7992312908172607
  Val ROC-AUC: 0.888157894736842
  Val Accuracy: 0.7037037014961243
Epoch 40/64:
  Train Loss: 0.7214885354042053
  Validation Loss: 0.7987574934959412
  Val ROC-AUC: 0.8947368421052632
  Val Accuracy: 0.7407407760620117
Epoch 41/64:
  Train Loss: 0.7115720212459564
  Validation Loss: 0.7981345057487488
  Val ROC-AUC: 0.8947368421052632
  Val Accuracy: 0.7407407760620117
Epoch 42/64:
  Train Loss: 0.739843562245369
  Validation Loss: 0.7974026799201965
  Val ROC-AUC: 0.8947368421052632
  Val Accuracy: 0.7407407760620117
Epoch 43/64:
  Train Loss: 0.7227902710437775
  Validation Loss: 0.7966716885566711
  Val ROC-AUC: 0.8947368421052632
  Val Accuracy: 0.7407407760620117
Epoch 44/64:
  Train Loss: 0.7237312346696854
  Validation Loss: 0.7958458662033081
  Val ROC-AUC: 0.8947368421052632
  Val Accuracy: 0.7407407760620117
Epoch 45/64:
  Train Loss: 0.7323858439922333
  Validation Loss: 0.7949949502944946
  Val ROC-AUC: 0.8947368421052632
  Val Accuracy: 0.7407407760620117
Epoch 46/64:
  Train Loss: 0.7233826518058777
  Validation Loss: 0.794277012348175
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 47/64:
  Train Loss: 0.7270734757184982
  Validation Loss: 0.7934772968292236
  Val ROC-AUC: 0.9210526315789473
  Val Accuracy: 0.7777777910232544
Epoch 48/64:
  Train Loss: 0.6995751559734344
  Validation Loss: 0.7925459742546082
  Val ROC-AUC: 0.9210526315789473
  Val Accuracy: 0.7777777910232544
Epoch 49/64:
  Train Loss: 0.710533007979393
  Validation Loss: 0.7917423844337463
  Val ROC-AUC: 0.9210526315789473
  Val Accuracy: 0.7777777910232544
Epoch 50/64:
  Train Loss: 0.7129706293344498
  Validation Loss: 0.7909576296806335
  Val ROC-AUC: 0.9210526315789473
  Val Accuracy: 0.7777777910232544
Epoch 51/64:
  Train Loss: 0.715985968708992
  Validation Loss: 0.7901374697685242
  Val ROC-AUC: 0.9210526315789473
  Val Accuracy: 0.7777777910232544
Epoch 52/64:
  Train Loss: 0.7231127768754959
  Validation Loss: 0.7894123196601868
  Val ROC-AUC: 0.9210526315789473
  Val Accuracy: 0.7777777910232544
Epoch 53/64:
  Train Loss: 0.7329553514719009
  Validation Loss: 0.7887053489685059
  Val ROC-AUC: 0.9210526315789473
  Val Accuracy: 0.7777777910232544
Epoch 54/64:
  Train Loss: 0.7095780968666077
  Validation Loss: 0.7879940867424011
  Val ROC-AUC: 0.9276315789473684
  Val Accuracy: 0.7777777910232544
Epoch 55/64:
  Train Loss: 0.7231975197792053
  Validation Loss: 0.7872589826583862
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.7777777910232544
Epoch 56/64:
  Train Loss: 0.7167847007513046
  Validation Loss: 0.78662109375
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.7777777910232544
Epoch 57/64:
  Train Loss: 0.7094273120164871
  Validation Loss: 0.7860301733016968
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.7777777910232544
Epoch 58/64:
  Train Loss: 0.7297997027635574
  Validation Loss: 0.7853735685348511
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.7777777910232544
Epoch 59/64:
  Train Loss: 0.7078841924667358
  Validation Loss: 0.7848404049873352
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.7777777910232544
Epoch 60/64:
  Train Loss: 0.7130916863679886
  Validation Loss: 0.7843295931816101
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.7777777910232544
Epoch 61/64:
  Train Loss: 0.7098988890647888
  Validation Loss: 0.7837561368942261
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.7777777910232544
Epoch 62/64:
  Train Loss: 0.7098157852888107
  Validation Loss: 0.7831247448921204
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.7777777910232544
Epoch 63/64:
  Train Loss: 0.7138465940952301
  Validation Loss: 0.7826453447341919
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.7777777910232544
Epoch 64/64:
  Train Loss: 0.7051846086978912
  Validation Loss: 0.7820687294006348
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.7777777910232544
{'train_loss': 0.7051846086978912, 'val_roc_auc': 0.9407894736842106, 'val_accuracy': 0.7777777910232544, 'val_loss': 0.7820687294006348}
 ROC_AUC: 0.9408|| Accuracy 0.7778 || Train Loss: 0.7052
 Val Loss: 0.7821 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7746289891473362
Test ROC-AUC: 0.7148268398268398
Test Accuracy: 0.5842696629213483
test_loss: 0.7746289891473362
test_roc_auc: 0.7148268398268398
test_accuracy: 0.5842696629213483
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.7597270756959915
  Validation Loss: 0.7835221290588379
  Val ROC-AUC: 0.7901234567901234
  Val Accuracy: 0.6666666865348816
Epoch 2/64:
  Train Loss: 0.7482925355434418
  Validation Loss: 0.7825746536254883
  Val ROC-AUC: 0.7901234567901234
  Val Accuracy: 0.6666666865348816
Epoch 3/64:
  Train Loss: 0.748080387711525
  Validation Loss: 0.7813778519630432
  Val ROC-AUC: 0.8024691358024691
  Val Accuracy: 0.6666666865348816
Epoch 4/64:
  Train Loss: 0.7588663101196289
  Validation Loss: 0.7800711989402771
  Val ROC-AUC: 0.808641975308642
  Val Accuracy: 0.7037037014961243
Epoch 5/64:
  Train Loss: 0.7528098672628403
  Validation Loss: 0.7788464426994324
  Val ROC-AUC: 0.808641975308642
  Val Accuracy: 0.7037037014961243
Epoch 6/64:
  Train Loss: 0.7636587172746658
  Validation Loss: 0.7777923941612244
  Val ROC-AUC: 0.808641975308642
  Val Accuracy: 0.6666666865348816
Epoch 7/64:
  Train Loss: 0.7412118911743164
  Validation Loss: 0.7767837643623352
  Val ROC-AUC: 0.808641975308642
  Val Accuracy: 0.6666666865348816
Epoch 8/64:
  Train Loss: 0.7494619637727737
  Validation Loss: 0.7757707834243774
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.6666666865348816
Epoch 9/64:
  Train Loss: 0.7340270131826401
  Validation Loss: 0.7747964859008789
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.6666666865348816
Epoch 10/64:
  Train Loss: 0.7571847587823868
  Validation Loss: 0.7738422751426697
  Val ROC-AUC: 0.8395061728395061
  Val Accuracy: 0.6666666865348816
Epoch 11/64:
  Train Loss: 0.7495735883712769
  Validation Loss: 0.7728103995323181
  Val ROC-AUC: 0.8456790123456791
  Val Accuracy: 0.6666666865348816
Epoch 12/64:
  Train Loss: 0.7320174127817154
  Validation Loss: 0.7716715931892395
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.6666666865348816
Epoch 13/64:
  Train Loss: 0.749890923500061
  Validation Loss: 0.7704126834869385
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.7037037014961243
Epoch 14/64:
  Train Loss: 0.7466942965984344
  Validation Loss: 0.7691407203674316
  Val ROC-AUC: 0.8641975308641976
  Val Accuracy: 0.7407407760620117
Epoch 15/64:
  Train Loss: 0.7468205094337463
  Validation Loss: 0.767857015132904
  Val ROC-AUC: 0.8641975308641976
  Val Accuracy: 0.7407407760620117
Epoch 16/64:
  Train Loss: 0.7410893142223358
  Validation Loss: 0.766759991645813
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 17/64:
  Train Loss: 0.7463225573301315
  Validation Loss: 0.7656581401824951
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 18/64:
  Train Loss: 0.7397679835557938
  Validation Loss: 0.7645702958106995
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7407407760620117
Epoch 19/64:
  Train Loss: 0.7271345853805542
  Validation Loss: 0.7636675238609314
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.7348594069480896
  Validation Loss: 0.7626990079879761
  Val ROC-AUC: 0.8765432098765433
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.7476944774389267
  Validation Loss: 0.761768639087677
  Val ROC-AUC: 0.882716049382716
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.7470900267362595
  Validation Loss: 0.760793149471283
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:32:55:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:55:INFO:
[92mINFO [0m:      Received: evaluate message 2894424f-012e-4c78-b8a7-7403510442c3
02/07/2025 22:32:55:INFO:Received: evaluate message 2894424f-012e-4c78-b8a7-7403510442c3
[92mINFO [0m:      Sent reply
02/07/2025 22:32:56:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:32:56:INFO:
[92mINFO [0m:      Received: train message 24954963-c24d-4a4d-8c2a-01fb2201aed9
02/07/2025 22:32:56:INFO:Received: train message 24954963-c24d-4a4d-8c2a-01fb2201aed9
  Train Loss: 0.7240211069583893
  Validation Loss: 0.7596781253814697
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.7361990958452225
  Validation Loss: 0.7587114572525024
  Val ROC-AUC: 0.8888888888888888
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.724011093378067
  Validation Loss: 0.7578725814819336
  Val ROC-AUC: 0.8950617283950617
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.7203177511692047
  Validation Loss: 0.7570608258247375
  Val ROC-AUC: 0.8950617283950617
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.7341710478067398
  Validation Loss: 0.7562175393104553
  Val ROC-AUC: 0.8950617283950617
  Val Accuracy: 0.7777777910232544
Epoch 28/64:
  Train Loss: 0.7335777133703232
  Validation Loss: 0.755305290222168
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.7777777910232544
Epoch 29/64:
  Train Loss: 0.728811576962471
  Validation Loss: 0.7543705701828003
  Val ROC-AUC: 0.9012345679012346
  Val Accuracy: 0.7777777910232544
Epoch 30/64:
  Train Loss: 0.7366996258497238
  Validation Loss: 0.753447949886322
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.7777777910232544
Epoch 31/64:
  Train Loss: 0.7212835550308228
  Validation Loss: 0.7523956894874573
  Val ROC-AUC: 0.9074074074074074
  Val Accuracy: 0.7777777910232544
Epoch 32/64:
  Train Loss: 0.7258289158344269
  Validation Loss: 0.751250147819519
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.7777777910232544
Epoch 33/64:
  Train Loss: 0.7178541272878647
  Validation Loss: 0.750184953212738
  Val ROC-AUC: 0.9135802469135803
  Val Accuracy: 0.7777777910232544
Epoch 34/64:
  Train Loss: 0.7242767959833145
  Validation Loss: 0.7491320967674255
  Val ROC-AUC: 0.9259259259259259
  Val Accuracy: 0.7777777910232544
Epoch 35/64:
  Train Loss: 0.7386090904474258
  Validation Loss: 0.7481932044029236
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.7777777910232544
Epoch 36/64:
  Train Loss: 0.7223283052444458
  Validation Loss: 0.7473204731941223
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.7777777910232544
Epoch 37/64:
  Train Loss: 0.7298394292593002
  Validation Loss: 0.7462500333786011
  Val ROC-AUC: 0.9382716049382716
  Val Accuracy: 0.7777777910232544
Epoch 38/64:
  Train Loss: 0.7294940948486328
  Validation Loss: 0.7452322244644165
  Val ROC-AUC: 0.9382716049382716
  Val Accuracy: 0.7777777910232544
Epoch 39/64:
  Train Loss: 0.718166172504425
  Validation Loss: 0.7442333102226257
  Val ROC-AUC: 0.9382716049382716
  Val Accuracy: 0.7777777910232544
Epoch 40/64:
  Train Loss: 0.7278580367565155
  Validation Loss: 0.7432974576950073
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.7777777910232544
Epoch 41/64:
  Train Loss: 0.7331202775239944
  Validation Loss: 0.742514431476593
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.7777777910232544
Epoch 42/64:
  Train Loss: 0.7246745079755783
  Validation Loss: 0.7417418956756592
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.7777777910232544
Epoch 43/64:
  Train Loss: 0.7124571800231934
  Validation Loss: 0.7410154342651367
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.7777777910232544
Epoch 44/64:
  Train Loss: 0.7283283472061157
  Validation Loss: 0.7401952147483826
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.7192967534065247
  Validation Loss: 0.7393116354942322
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.7139938771724701
  Validation Loss: 0.7383430004119873
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.7120752334594727
  Validation Loss: 0.7374197244644165
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.7070540338754654
  Validation Loss: 0.7365542650222778
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.7151875346899033
  Validation Loss: 0.7357044219970703
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.7299915701150894
  Validation Loss: 0.7349250316619873
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.7110637426376343
  Validation Loss: 0.7341376543045044
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.7069345861673355
  Validation Loss: 0.7333689332008362
  Val ROC-AUC: 0.9629629629629629
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.7070514261722565
  Validation Loss: 0.7326717972755432
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.7052424401044846
  Validation Loss: 0.7320054173469543
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.7159544378519058
  Validation Loss: 0.7312698364257812
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.7144287377595901
  Validation Loss: 0.7305039763450623
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.7024055272340775
  Validation Loss: 0.7297342419624329
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6990988403558731
  Validation Loss: 0.7290785908699036
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.7032522708177567
  Validation Loss: 0.7283852696418762
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.7128635346889496
  Validation Loss: 0.7277282476425171
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.7069934159517288
  Validation Loss: 0.7271007895469666
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.714695081114769
  Validation Loss: 0.7264925837516785
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6990196853876114
  Validation Loss: 0.7258154153823853
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.7024896591901779
  Validation Loss: 0.7250880002975464
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.7024896591901779, 'val_roc_auc': 0.962962962962963, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.7250880002975464}
 ROC_AUC: 0.9630|| Accuracy 0.9259 || Train Loss: 0.7025
 Val Loss: 0.7251 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7698675327086717
Test ROC-AUC: 0.7413419913419914
Test Accuracy: 0.5955056179775281
test_loss: 0.7698675327086717
test_roc_auc: 0.7413419913419914
test_accuracy: 0.5955056179775281
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.7614056318998337
  Validation Loss: 0.723036527633667
  Val ROC-AUC: 0.9318181818181819
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7677979171276093
  Validation Loss: 0.7218559980392456
  Val ROC-AUC: 0.9375
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7627297341823578
  Validation Loss: 0.7208440899848938
  Val ROC-AUC: 0.9431818181818181
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7499974817037582
  Validation Loss: 0.7200949788093567
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.7594747245311737
  Validation Loss: 0.7194269299507141
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.7652396261692047
  Validation Loss: 0.7188290357589722
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 7/64:
  Train Loss: 0.7568113505840302
  Validation Loss: 0.7181628346443176
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 8/64:
  Train Loss: 0.7573433518409729
  Validation Loss: 0.7175138592720032
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)

Epoch 9/64:
  Train Loss: 0.7669814676046371
  Validation Loss: 0.7168644666671753
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 10/64:
  Train Loss: 0.7598515003919601
  Validation Loss: 0.7162621021270752
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.7777777910232544
Epoch 11/64:
  Train Loss: 0.771802082657814
  Validation Loss: 0.7156150341033936
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.7777777910232544
Epoch 12/64:
  Train Loss: 0.7578553110361099
  Validation Loss: 0.7148705124855042
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.7777777910232544
Epoch 13/64:
  Train Loss: 0.772344559431076
  Validation Loss: 0.7140400409698486
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.7777777910232544
Epoch 14/64:
  Train Loss: 0.7591199278831482
  Validation Loss: 0.7130225896835327
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.7777777910232544
Epoch 15/64:
  Train Loss: 0.737215206027031
  Validation Loss: 0.7121792435646057
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.7777777910232544
Epoch 16/64:
  Train Loss: 0.7670091837644577
  Validation Loss: 0.7114627957344055
  Val ROC-AUC: 0.9659090909090908
  Val Accuracy: 0.7777777910232544
Epoch 17/64:
  Train Loss: 0.7453628033399582
  Validation Loss: 0.7105735540390015
  Val ROC-AUC: 0.9715909090909091
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.7417612969875336
  Validation Loss: 0.7096991539001465
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.7569988667964935
  Validation Loss: 0.708962619304657
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.7453684955835342
  Validation Loss: 0.7083162665367126
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.7385033220052719
  Validation Loss: 0.707772433757782
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.7605854421854019
  Validation Loss: 0.7072518467903137
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.7557075917720795
  Validation Loss: 0.7067883610725403
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.7641005367040634
  Validation Loss: 0.7063673138618469
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.7562112808227539
  Validation Loss: 0.7059085369110107
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.7526727914810181
  Validation Loss: 0.7053927183151245
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.7515293955802917
  Validation Loss: 0.7047736644744873
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.7665912955999374
  Validation Loss: 0.7041285037994385
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.7323334366083145
  Validation Loss: 0.7034242749214172
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.7467553317546844
  Validation Loss: 0.7027380466461182
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.7371390014886856
  Validation Loss: 0.7020512819290161
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.7372057437896729
  Validation Loss: 0.7013555765151978
  Val ROC-AUC: 0.9886363636363636
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.7406255900859833
  Validation Loss: 0.7006878852844238
  Val ROC-AUC: 0.9943181818181818
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.73884217441082
  Validation Loss: 0.7001242637634277
  Val ROC-AUC: 0.9943181818181818
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.7351256310939789
  Validation Loss: 0.6995726823806763
  Val ROC-AUC: 0.9943181818181818
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.7388817369937897
  Validation Loss: 0.6990681290626526
  Val ROC-AUC: 0.9943181818181818
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.7354470491409302
  Validation Loss: 0.6983612179756165
  Val ROC-AUC: 0.9943181818181818
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.7496588826179504
  Validation Loss: 0.6976391673088074
  Val ROC-AUC: 0.9943181818181818
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.7424232363700867
  Validation Loss: 0.6970558166503906
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.7434801161289215
  Validation Loss: 0.6963416934013367
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.7439283281564713
  Validation Loss: 0.6957594156265259
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.7290380746126175
  Validation Loss: 0.695223331451416
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.7318078577518463
  Validation Loss: 0.694692850112915
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.7426717430353165
  Validation Loss: 0.6940982341766357
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.7399581372737885
  Validation Loss: 0.6934933066368103
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.7367200553417206
  Validation Loss: 0.692918598651886
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.7354536205530167
  Validation Loss: 0.6922581791877747
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.7351542264223099
  Validation Loss: 0.691666305065155
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.7349368333816528
  Validation Loss: 0.6909883618354797
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.7352245897054672
  Validation Loss: 0.690339982509613
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.7217140197753906
  Validation Loss: 0.6897982954978943
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.7303337305784225
  Validation Loss: 0.6893985271453857
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.7306988090276718
  Validation Loss: 0.6890197396278381
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.7228438705205917
  Validation Loss: 0.6886120438575745
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.7212873548269272
  Validation Loss: 0.6880295276641846
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.7325421422719955
  Validation Loss: 0.6875571012496948
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.7311992794275284
  Validation Loss: 0.6872605681419373
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.7344797700643539
  Validation Loss: 0.6868410706520081
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.7346361577510834
  Validation Loss: 0.6864708662033081
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.735808327794075
  Validation Loss: 0.6861415505409241
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.7315507680177689
  Validation Loss: 0.6857808232307434
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.7295311391353607
  Validation Loss: 0.6854443550109863
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.7272708863019943
  Validation Loss: 0.68496173620224
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.716639518737793
  Validation Loss: 0.6845532059669495
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:05:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:07:INFO:
[92mINFO [0m:      Received: evaluate message 537c7042-f59d-4a33-97c8-371bc7cd842c
02/07/2025 22:33:07:INFO:Received: evaluate message 537c7042-f59d-4a33-97c8-371bc7cd842c
[92mINFO [0m:      Sent reply
02/07/2025 22:33:10:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:10:INFO:
[92mINFO [0m:      Received: train message 44e826c3-263c-45ca-b180-5c102a9963b2
02/07/2025 22:33:10:INFO:Received: train message 44e826c3-263c-45ca-b180-5c102a9963b2
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
{'train_loss': 0.716639518737793, 'val_roc_auc': 1.0, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6845532059669495}
 ROC_AUC: 1.0000|| Accuracy 0.9630 || Train Loss: 0.7166
 Val Loss: 0.6846 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7647531719020243
Test ROC-AUC: 0.7656926406926406
Test Accuracy: 0.6292134831460674
test_loss: 0.7647531719020243
test_roc_auc: 0.7656926406926406
test_accuracy: 0.6292134831460674
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.7536605000495911
  Validation Loss: 0.7366417646408081
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.7407407760620117
Epoch 2/64:
  Train Loss: 0.7400597184896469
  Validation Loss: 0.7352316379547119
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.7407407760620117
Epoch 3/64:
  Train Loss: 0.7526849210262299
  Validation Loss: 0.7336985468864441
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7377899587154388
  Validation Loss: 0.7322105169296265
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.7496003806591034
  Validation Loss: 0.7307929992675781
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.7465255260467529
  Validation Loss: 0.7295164465904236
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.7777777910232544
Epoch 7/64:
  Train Loss: 0.7552543729543686
  Validation Loss: 0.728357195854187
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7433233708143234
  Validation Loss: 0.7271565794944763
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7466169148683548
  Validation Loss: 0.72603440284729
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.7351444661617279
  Validation Loss: 0.7250399589538574
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7347240597009659
  Validation Loss: 0.7240279912948608
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7522674053907394
  Validation Loss: 0.7230823040008545
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.7281137555837631
  Validation Loss: 0.7221277356147766
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.7398803681135178
  Validation Loss: 0.7210018038749695
  Val ROC-AUC: 0.9470588235294117
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7319624871015549
  Validation Loss: 0.7198581099510193
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7216423898935318
  Validation Loss: 0.7187883853912354
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.73888199031353
  Validation Loss: 0.7177730202674866
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.7351278066635132
  Validation Loss: 0.7168121337890625
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.7350711226463318
  Validation Loss: 0.7159186601638794
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.7456735074520111
  Validation Loss: 0.7149612903594971
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.7260179370641708
  Validation Loss: 0.7139666676521301
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.7319161593914032
  Validation Loss: 0.7130043506622314
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.7265557795763016
  Validation Loss: 0.7121261358261108
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.7397714257240295
  Validation Loss: 0.7112410068511963
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.7192471921443939
  Validation Loss: 0.7103372812271118
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.7401172369718552
  Validation Loss: 0.7094085216522217
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.7235657423734665
  Validation Loss: 0.7085103392601013
  Val ROC-AUC: 0.9529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.7233256846666336
  Validation Loss: 0.7075749635696411
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.7095178961753845
  Validation Loss: 0.7066004276275635
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.7076302319765091
  Validation Loss: 0.7055712938308716
  Val ROC-AUC: 0.9588235294117646
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.7394849210977554
  Validation Loss: 0.7045210599899292
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.715682327747345
  Validation Loss: 0.7034803628921509
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.7316822856664658
  Validation Loss: 0.7025755047798157
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.7339667081832886
  Validation Loss: 0.701745331287384
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.7247648984193802
  Validation Loss: 0.700908362865448
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7198356837034225
  Validation Loss: 0.6999359130859375
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.7126922160387039
  Validation Loss: 0.698998749256134
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.7106571942567825
  Validation Loss: 0.6980293989181519
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.7154531925916672
  Validation Loss: 0.6972060203552246
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.7143758535385132
  Validation Loss: 0.6964206099510193
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.7187703847885132
  Validation Loss: 0.6955013871192932
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.7128861993551254
  Validation Loss: 0.6945933699607849
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.712751179933548
  Validation Loss: 0.6937979459762573
  Val ROC-AUC: 0.9705882352941175
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.7045304030179977
  Validation Loss: 0.6930426359176636
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.7094514071941376
  Validation Loss: 0.6923521757125854
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.715792641043663
  Validation Loss: 0.6915978193283081
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.7068625241518021
  Validation Loss: 0.6908783912658691
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.710358515381813
  Validation Loss: 0.6902400851249695
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.7106261551380157
  Validation Loss: 0.689599871635437
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.7083079814910889
  Validation Loss: 0.6890246868133545
  Val ROC-AUC: 0.9764705882352941
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:21:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:22:INFO:
[92mINFO [0m:      Received: evaluate message a940587a-7487-41df-b167-7ad156373309
02/07/2025 22:33:22:INFO:Received: evaluate message a940587a-7487-41df-b167-7ad156373309
[92mINFO [0m:      Sent reply
02/07/2025 22:33:22:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:22:INFO:
[92mINFO [0m:      Received: train message 3955dd72-60d7-4404-b652-6db4fc93d83d
02/07/2025 22:33:22:INFO:Received: train message 3955dd72-60d7-4404-b652-6db4fc93d83d
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.7228097468614578
  Validation Loss: 0.6884753108024597
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.7114616930484772
  Validation Loss: 0.6879239082336426
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.7071907818317413
  Validation Loss: 0.687335193157196
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.7041251510381699
  Validation Loss: 0.6867001056671143
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.70207579433918
  Validation Loss: 0.6860293745994568
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.7142943739891052
  Validation Loss: 0.6853390336036682
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.7140924334526062
  Validation Loss: 0.6847012639045715
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.7067834734916687
  Validation Loss: 0.6841034889221191
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6988492012023926
  Validation Loss: 0.6834753155708313
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6984178870916367
  Validation Loss: 0.6829163432121277
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.7046878486871719
  Validation Loss: 0.6822938323020935
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.7005243450403214
  Validation Loss: 0.6817257404327393
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.7120465934276581
  Validation Loss: 0.6811611652374268
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6985691636800766
  Validation Loss: 0.6805727481842041
  Val ROC-AUC: 0.9764705882352941
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6985691636800766, 'val_roc_auc': 0.9764705882352941, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6805727481842041}
 ROC_AUC: 0.9765|| Accuracy 0.8889 || Train Loss: 0.6986
 Val Loss: 0.6806 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7594453103086921
Test ROC-AUC: 0.7851731601731602
Test Accuracy: 0.6741573033707865
test_loss: 0.7594453103086921
test_roc_auc: 0.7851731601731602
test_accuracy: 0.6741573033707865
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.7351400554180145
  Validation Loss: 0.7803674936294556
  Val ROC-AUC: 0.9013157894736841
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.748056560754776
  Validation Loss: 0.7795726656913757
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7204318791627884
  Validation Loss: 0.7787358164787292
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7356614917516708
  Validation Loss: 0.7779082655906677
  Val ROC-AUC: 0.9078947368421053
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.7207114845514297
  Validation Loss: 0.7770984768867493
  Val ROC-AUC: 0.9144736842105263
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.7276486903429031
  Validation Loss: 0.7762930393218994
  Val ROC-AUC: 0.9144736842105263
  Val Accuracy: 0.7777777910232544
Epoch 7/64:
  Train Loss: 0.7374013662338257
  Validation Loss: 0.7754920721054077
  Val ROC-AUC: 0.9210526315789475
  Val Accuracy: 0.7777777910232544
Epoch 8/64:
  Train Loss: 0.7313236147165298
  Validation Loss: 0.7745591402053833
  Val ROC-AUC: 0.9210526315789475
  Val Accuracy: 0.7777777910232544
Epoch 9/64:
  Train Loss: 0.7311281859874725
  Validation Loss: 0.7737323641777039
  Val ROC-AUC: 0.9276315789473685
  Val Accuracy: 0.7777777910232544
Epoch 10/64:
  Train Loss: 0.7318395376205444
  Validation Loss: 0.7729923725128174
  Val ROC-AUC: 0.9276315789473685
  Val Accuracy: 0.7777777910232544
Epoch 11/64:
  Train Loss: 0.7317352294921875
  Validation Loss: 0.7721673250198364
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7329914569854736
  Validation Loss: 0.7713111639022827
  Val ROC-AUC: 0.9342105263157895
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.730706974864006
  Validation Loss: 0.7703735828399658
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.7162390202283859
  Validation Loss: 0.7694788575172424
  Val ROC-AUC: 0.9407894736842106
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7199238687753677
  Validation Loss: 0.768478512763977
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7289083153009415
  Validation Loss: 0.7676031589508057
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7132476568222046
  Validation Loss: 0.7666691541671753
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.733367532491684
  Validation Loss: 0.7656200528144836
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.7204472720623016
  Validation Loss: 0.7645636796951294
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.7273396998643875
  Validation Loss: 0.7635775208473206
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.727125734090805
  Validation Loss: 0.7625288367271423
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.7179956138134003
  Validation Loss: 0.7614567279815674
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.7236143350601196
  Validation Loss: 0.7605316042900085
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.7221420407295227
  Validation Loss: 0.759709894657135
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.7091369926929474
  Validation Loss: 0.7589167356491089
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.7181456983089447
  Validation Loss: 0.758101761341095
  Val ROC-AUC: 0.9605263157894737
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.7271017581224442
  Validation Loss: 0.7572265863418579
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.7241492420434952
  Validation Loss: 0.7563888430595398
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.7204270213842392
  Validation Loss: 0.755569577217102
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.7223352640867233
  Validation Loss: 0.7547667026519775
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.710773155093193
  Validation Loss: 0.7538785934448242
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.7099555879831314
  Validation Loss: 0.7530508041381836
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8518518805503845
Epoch 33/64:
  Train Loss: 0.7024701684713364
  Validation Loss: 0.7521838545799255
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8518518805503845
Epoch 34/64:
  Train Loss: 0.709838017821312
  Validation Loss: 0.751397430896759
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8518518805503845
Epoch 35/64:
  Train Loss: 0.7058226019144058
  Validation Loss: 0.7506780624389648
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8518518805503845
Epoch 36/64:
  Train Loss: 0.7117680460214615
  Validation Loss: 0.7498339414596558
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:32:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:33:INFO:
[92mINFO [0m:      Received: evaluate message 896c1a87-fd7a-4cf2-a43a-db70bd6cc6e7
02/07/2025 22:33:33:INFO:Received: evaluate message 896c1a87-fd7a-4cf2-a43a-db70bd6cc6e7
[92mINFO [0m:      Sent reply
02/07/2025 22:33:34:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:34:INFO:
[92mINFO [0m:      Received: train message ed0487cf-af1a-4f43-8706-9008d99b7d6c
02/07/2025 22:33:34:INFO:Received: train message ed0487cf-af1a-4f43-8706-9008d99b7d6c
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8518518805503845
Epoch 37/64:
  Train Loss: 0.718147337436676
  Validation Loss: 0.7490487098693848
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.8518518805503845
Epoch 38/64:
  Train Loss: 0.7151997536420822
  Validation Loss: 0.748319149017334
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8518518805503845
Epoch 39/64:
  Train Loss: 0.6878945529460907
  Validation Loss: 0.7475754618644714
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8518518805503845
Epoch 40/64:
  Train Loss: 0.7084341794252396
  Validation Loss: 0.7468692064285278
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8518518805503845
Epoch 41/64:
  Train Loss: 0.7111717462539673
  Validation Loss: 0.7463675737380981
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8518518805503845
Epoch 42/64:
  Train Loss: 0.7083404213190079
  Validation Loss: 0.7458740472793579
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8518518805503845
Epoch 43/64:
  Train Loss: 0.725438728928566
  Validation Loss: 0.7452720999717712
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.7011218816041946
  Validation Loss: 0.7444915771484375
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.7115401476621628
  Validation Loss: 0.7437840700149536
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.702272430062294
  Validation Loss: 0.743120551109314
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6975014209747314
  Validation Loss: 0.7425167560577393
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.7176284790039062
  Validation Loss: 0.7419227957725525
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.7122189551591873
  Validation Loss: 0.7412285208702087
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.7022491842508316
  Validation Loss: 0.7406500577926636
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.7136076390743256
  Validation Loss: 0.7401008605957031
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6967614442110062
  Validation Loss: 0.739521324634552
  Val ROC-AUC: 0.9736842105263157
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6955409497022629
  Validation Loss: 0.7388855218887329
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.7080197036266327
  Validation Loss: 0.7384063005447388
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.704520046710968
  Validation Loss: 0.7379391193389893
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.694463238120079
  Validation Loss: 0.7372996211051941
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.7035728991031647
  Validation Loss: 0.7365280985832214
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6979666650295258
  Validation Loss: 0.7358614206314087
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.7111123502254486
  Validation Loss: 0.735174834728241
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6959023028612137
  Validation Loss: 0.7344642877578735
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.7080469727516174
  Validation Loss: 0.7337111234664917
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.7013821303844452
  Validation Loss: 0.7328739166259766
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6951557248830795
  Validation Loss: 0.7320210337638855
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.7133506536483765
  Validation Loss: 0.7310928106307983
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.7133506536483765, 'val_roc_auc': 0.993421052631579, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.7310928106307983}
 ROC_AUC: 0.9934|| Accuracy 0.9259 || Train Loss: 0.7134
 Val Loss: 0.7311 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7541150581300928
Test ROC-AUC: 0.7976190476190477
Test Accuracy: 0.7078651685393258
test_loss: 0.7541150581300928
test_roc_auc: 0.7976190476190477
test_accuracy: 0.7078651685393258
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.7141626328229904
  Validation Loss: 0.7458429932594299
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.7407407760620117
Epoch 2/64:
  Train Loss: 0.7320323884487152
  Validation Loss: 0.7455164790153503
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7376659214496613
  Validation Loss: 0.7451532483100891
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.7777777910232544
Epoch 4/64:
  Train Loss: 0.7292053699493408
  Validation Loss: 0.744655191898346
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.7777777910232544
Epoch 5/64:
  Train Loss: 0.7249521315097809
  Validation Loss: 0.7442324161529541
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.7777777910232544
Epoch 6/64:
  Train Loss: 0.7236050516366959
  Validation Loss: 0.7439143657684326
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.7777777910232544
Epoch 7/64:
  Train Loss: 0.7445526570081711
  Validation Loss: 0.7435599565505981
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.7777777910232544
Epoch 8/64:
  Train Loss: 0.7281538546085358
  Validation Loss: 0.7431067228317261
  Val ROC-AUC: 0.8705882352941177
  Val Accuracy: 0.7777777910232544
Epoch 9/64:
  Train Loss: 0.7378556877374649
  Validation Loss: 0.7426274418830872
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.7777777910232544
Epoch 10/64:
  Train Loss: 0.7410265207290649
  Validation Loss: 0.7420374751091003
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.7777777910232544
Epoch 11/64:
  Train Loss: 0.735261857509613
  Validation Loss: 0.7414753437042236
  Val ROC-AUC: 0.8823529411764706
  Val Accuracy: 0.7777777910232544
Epoch 12/64:
  Train Loss: 0.7097467184066772
  Validation Loss: 0.7408584356307983
  Val ROC-AUC: 0.8882352941176471
  Val Accuracy: 0.7777777910232544
Epoch 13/64:
  Train Loss: 0.7317420840263367
  Validation Loss: 0.7404562830924988
  Val ROC-AUC: 0.8882352941176471
  Val Accuracy: 0.7777777910232544
Epoch 14/64:
  Train Loss: 0.7289983779191971
  Validation Loss: 0.7402541637420654
  Val ROC-AUC: 0.8882352941176471
  Val Accuracy: 0.7777777910232544
Epoch 15/64:
  Train Loss: 0.7344474941492081
  Validation Loss: 0.7400542497634888
  Val ROC-AUC: 0.8882352941176471
  Val Accuracy: 0.7777777910232544
Epoch 16/64:
  Train Loss: 0.7276549935340881
  Validation Loss: 0.7397284507751465
  Val ROC-AUC: 0.8882352941176471
  Val Accuracy: 0.7777777910232544
Epoch 17/64:
  Train Loss: 0.7221335172653198
  Validation Loss: 0.7392712235450745
  Val ROC-AUC: 0.8882352941176471
  Val Accuracy: 0.7777777910232544
Epoch 18/64:
  Train Loss: 0.7344140410423279
  Validation Loss: 0.7386688590049744
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 19/64:
  Train Loss: 0.7303049117326736
  Validation Loss: 0.7381529808044434
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 20/64:
  Train Loss: 0.7341859340667725
  Validation Loss: 0.7378023266792297
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 21/64:
  Train Loss: 0.7501873970031738
  Validation Loss: 0.7375711798667908
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 22/64:
  Train Loss: 0.7227685153484344
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:43:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:44:INFO:
[92mINFO [0m:      Received: evaluate message b2550557-90b6-4c63-9567-2ef41674f5be
02/07/2025 22:33:44:INFO:Received: evaluate message b2550557-90b6-4c63-9567-2ef41674f5be
[92mINFO [0m:      Sent reply
02/07/2025 22:33:46:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:46:INFO:
[92mINFO [0m:      Received: train message d8ed929e-fa4e-4fcb-b34c-a83060e485b1
02/07/2025 22:33:46:INFO:Received: train message d8ed929e-fa4e-4fcb-b34c-a83060e485b1
  Validation Loss: 0.7370802760124207
  Val ROC-AUC: 0.8941176470588236
  Val Accuracy: 0.7777777910232544
Epoch 23/64:
  Train Loss: 0.7397538274526596
  Validation Loss: 0.7365694642066956
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 24/64:
  Train Loss: 0.7164349555969238
  Validation Loss: 0.7360739707946777
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 25/64:
  Train Loss: 0.7242086976766586
  Validation Loss: 0.7355988025665283
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 26/64:
  Train Loss: 0.7264632880687714
  Validation Loss: 0.7352011203765869
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 27/64:
  Train Loss: 0.7335681766271591
  Validation Loss: 0.7348235249519348
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 28/64:
  Train Loss: 0.7082909345626831
  Validation Loss: 0.7343690991401672
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 29/64:
  Train Loss: 0.7119046896696091
  Validation Loss: 0.7339352965354919
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 30/64:
  Train Loss: 0.7159449756145477
  Validation Loss: 0.7335906028747559
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 31/64:
  Train Loss: 0.724435105919838
  Validation Loss: 0.7332598567008972
  Val ROC-AUC: 0.9
  Val Accuracy: 0.7777777910232544
Epoch 32/64:
  Train Loss: 0.7309679388999939
  Validation Loss: 0.732842743396759
  Val ROC-AUC: 0.9
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.7264612466096878
  Validation Loss: 0.7324094176292419
  Val ROC-AUC: 0.9
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.7138881683349609
  Validation Loss: 0.7318845987319946
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.722413644194603
  Validation Loss: 0.7314252257347107
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.7247568368911743
  Validation Loss: 0.7309653759002686
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8518518805503845
Epoch 37/64:
  Train Loss: 0.7218329459428787
  Validation Loss: 0.7304260730743408
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8518518805503845
Epoch 38/64:
  Train Loss: 0.7258141487836838
  Validation Loss: 0.7298939824104309
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8518518805503845
Epoch 39/64:
  Train Loss: 0.73100546002388
  Validation Loss: 0.7295146584510803
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8518518805503845
Epoch 40/64:
  Train Loss: 0.7059568017721176
  Validation Loss: 0.7292851805686951
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8518518805503845
Epoch 41/64:
  Train Loss: 0.7146512269973755
  Validation Loss: 0.7289476990699768
  Val ROC-AUC: 0.9058823529411765
  Val Accuracy: 0.8518518805503845
Epoch 42/64:
  Train Loss: 0.7014862596988678
  Validation Loss: 0.7284934520721436
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 43/64:
  Train Loss: 0.7291086465120316
  Validation Loss: 0.728082001209259
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 44/64:
  Train Loss: 0.731684684753418
  Validation Loss: 0.727651834487915
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 45/64:
  Train Loss: 0.7083956897258759
  Validation Loss: 0.7272223234176636
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 46/64:
  Train Loss: 0.702154129743576
  Validation Loss: 0.7267451882362366
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 47/64:
  Train Loss: 0.7168765813112259
  Validation Loss: 0.7262014746665955
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.7176271677017212
  Validation Loss: 0.7255927324295044
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.7108129560947418
  Validation Loss: 0.7250716090202332
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.7227692753076553
  Validation Loss: 0.7246982455253601
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.7021596133708954
  Validation Loss: 0.7243062257766724
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.7117371559143066
  Validation Loss: 0.7238731384277344
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.7241516560316086
  Validation Loss: 0.7234770059585571
  Val ROC-AUC: 0.9117647058823529
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.7188345789909363
  Validation Loss: 0.7230628728866577
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.7222449481487274
  Validation Loss: 0.7227069735527039
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.7140279859304428
  Validation Loss: 0.7224062085151672
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.7132472395896912
  Validation Loss: 0.7220464944839478
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.71548792719841
  Validation Loss: 0.7216847538948059
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.7160625159740448
  Validation Loss: 0.7213371992111206
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.7081109881401062
  Validation Loss: 0.7209195494651794
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.7065170705318451
  Validation Loss: 0.7206467390060425
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.7177317142486572
  Validation Loss: 0.7202655076980591
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.714050218462944
  Validation Loss: 0.719826340675354
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.7047787308692932
  Validation Loss: 0.7193560004234314
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
{'train_loss': 0.7047787308692932, 'val_roc_auc': 0.9176470588235294, 'val_accuracy': 0.8518518805503845, 'val_loss': 0.7193560004234314}
 ROC_AUC: 0.9176|| Accuracy 0.8519 || Train Loss: 0.7048
 Val Loss: 0.7194 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7489223945676611
Test ROC-AUC: 0.8106060606060607
Test Accuracy: 0.7191011235955056
test_loss: 0.7489223945676611
test_roc_auc: 0.8106060606060607
test_accuracy: 0.7191011235955056
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.7314611375331879
  Validation Loss: 0.7379197478294373
  Val ROC-AUC: 0.8999999999999999
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.7108414322137833
  Validation Loss: 0.7368237376213074
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.7148213684558868
  Validation Loss: 0.7357428073883057
  Val ROC-AUC: 0.9058823529411764
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.7139278948307037
  Validation Loss: 0.7347285747528076
  Val ROC-AUC: 0.9117647058823528
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.7150648385286331
  Validation Loss: 0.7337108254432678
  Val ROC-AUC: 0.9117647058823528
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7203668057918549
  Validation Loss: 0.732719898223877
  Val ROC-AUC: 0.9117647058823528
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7205885350704193
  Validation Loss: 0.731726348400116
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.7183229029178619
  Validation Loss: 0.7308258414268494
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.7232553213834763
  Validation Loss: 0.7299883365631104
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.7013801038265228
  Validation Loss: 0.7291179299354553
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.7079414129257202
  Validation Loss: 0.728258490562439
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.7108289301395416
  Validation Loss: 0.7274575233459473
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.7126555293798447
  Validation Loss: 0.7266586422920227
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.7208009362220764
  Validation Loss: 0.7258812189102173
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.7054237723350525
  Validation Loss: 0.7250866889953613
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.7109692990779877
  Validation Loss: 0.7243387699127197
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.7051215916872025
  Validation Loss: 0.7235205769538879
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.7115569561719894
  Validation Loss: 0.722686767578125
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.7056323885917664
  Validation Loss: 0.7218782901763916
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.7026362121105194
  Validation Loss: 0.7210888862609863
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6917040944099426
  Validation Loss: 0.7203150987625122
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.7105563282966614
  Validation Loss: 0.7195690870285034
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.6908254325389862
  Validation Loss: 0.7187603712081909
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.6954252421855927
  Validation Loss: 0.7179558277130127
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.709452360868454
  Validation Loss: 0.7171980142593384
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6965083479881287
  Validation Loss: 0.7164090275764465
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.7023579925298691
  Validation Loss: 0.7156086564064026
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.7005269378423691
  Validation Loss: 0.7147995233535767
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6984441578388214
  Validation Loss: 0.714152455329895
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6794844418764114
  Validation Loss: 0.7135978937149048
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6978636682033539
  Validation Loss: 0.713030993938446
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6915720850229263
  Validation Loss: 0.7124075889587402
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6879449039697647
  Validation Loss: 0.711707353591919
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.7013656944036484
  Validation Loss: 0.7110043168067932
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6884332150220871
  Validation Loss: 0.7103111147880554
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.6963365077972412
  Validation Loss: 0.709621250629425
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6799692511558533
  Validation Loss: 0.7089840769767761
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.700281634926796
  Validation Loss: 0.7084141969680786
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6849025636911392
  Validation Loss: 0.7078713178634644
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6956021785736084
  Validation Loss: 0.7073296308517456
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6918024271726608
  Validation Loss: 0.7067622542381287
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6939748376607895
  Validation Loss: 0.7061705589294434
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.702115386724472
  Validation Loss: 0.7056110501289368
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6783324629068375
  Validation Loss: 0.7050395011901855
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.6864464581012726
  Validation Loss: 0.7044327259063721
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6970933675765991
  Validation Loss: 0.7038010358810425
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.6865881085395813
  Validation Loss: 0.703162431716919
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.6838956773281097
  Validation Loss: 0.7026253342628479
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.6777348220348358
  Validation Loss: 0.7020223736763
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.6859614998102188
  Validation Loss: 0.7013737559318542
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.6877490878105164
  Validation Loss: 0.7007977366447449
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6686627417802811
  Validation Loss: 0.700237512588501
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.6833629310131073
  Validation Loss: 0.6997379660606384
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.681218683719635
  Validation Loss: 0.6992000937461853
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.67392498254776
  Validation Loss: 0.6986972689628601
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.6853421181440353
  Validation Loss: 0.6982051134109497
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.679795891046524
  Validation Loss: 0.6977260708808899
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.6862745583057404
  Validation Loss: 0.6971839070320129
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.6827309727668762
  Validation Loss: 0.6966240406036377
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.6757572740316391
  Validation Loss: 0.6960393190383911
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6759122312068939
  Validation Loss: 0.6954118013381958
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.690113440155983
  Validation Loss: 0.6948546171188354
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:33:55:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:33:58:INFO:
[92mINFO [0m:      Received: evaluate message b5454cae-d402-47b7-a2ff-78eb82c58ce2
02/07/2025 22:33:58:INFO:Received: evaluate message b5454cae-d402-47b7-a2ff-78eb82c58ce2
[92mINFO [0m:      Sent reply
02/07/2025 22:34:02:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:02:INFO:
[92mINFO [0m:      Received: train message 986235ab-6bf6-4ce5-841a-0ad778589218
02/07/2025 22:34:02:INFO:Received: train message 986235ab-6bf6-4ce5-841a-0ad778589218
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.6781215369701385
  Validation Loss: 0.6943579912185669
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.6719309091567993
  Validation Loss: 0.693893313407898
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
{'train_loss': 0.6719309091567993, 'val_roc_auc': 0.9352941176470588, 'val_accuracy': 0.8518518805503845, 'val_loss': 0.693893313407898}
 ROC_AUC: 0.9353|| Accuracy 0.8519 || Train Loss: 0.6719
 Val Loss: 0.6939 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7438685900709602
Test ROC-AUC: 0.8198051948051949
Test Accuracy: 0.7191011235955056
test_loss: 0.7438685900709602
test_roc_auc: 0.8198051948051949
test_accuracy: 0.7191011235955056
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.7377317547798157
  Validation Loss: 0.6400443315505981
  Val ROC-AUC: 0.9065934065934066
  Val Accuracy: 0.7777777910232544
Epoch 2/64:
  Train Loss: 0.7351545095443726
  Validation Loss: 0.6396160125732422
  Val ROC-AUC: 0.9065934065934066
  Val Accuracy: 0.7777777910232544
Epoch 3/64:
  Train Loss: 0.7391936630010605
  Validation Loss: 0.6391642689704895
  Val ROC-AUC: 0.9065934065934066
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.7352182418107986
  Validation Loss: 0.6387819647789001
  Val ROC-AUC: 0.9065934065934066
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.73761847615242
  Validation Loss: 0.6383472681045532
  Val ROC-AUC: 0.9065934065934066
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7387499958276749
  Validation Loss: 0.6377852559089661
  Val ROC-AUC: 0.9065934065934066
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7499905228614807
  Validation Loss: 0.6371753811836243
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7424526810646057
  Validation Loss: 0.6367131471633911
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7372026294469833
  Validation Loss: 0.6362763047218323
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.7248109877109528
  Validation Loss: 0.635776937007904
  Val ROC-AUC: 0.9120879120879121
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7334758639335632
  Validation Loss: 0.6351714134216309
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.7426490187644958
  Validation Loss: 0.6345500349998474
  Val ROC-AUC: 0.9175824175824175
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.7419041395187378
  Validation Loss: 0.6340158581733704
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.734203964471817
  Validation Loss: 0.6335695385932922
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.7244881391525269
  Validation Loss: 0.633151650428772
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7383546382188797
  Validation Loss: 0.632723331451416
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7273658514022827
  Validation Loss: 0.6323443055152893
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.7275971621274948
  Validation Loss: 0.6319578289985657
  Val ROC-AUC: 0.9230769230769231
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.7244438230991364
  Validation Loss: 0.6316259503364563
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.7199787795543671
  Validation Loss: 0.631345272064209
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.7370278835296631
  Validation Loss: 0.6310942769050598
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.7227702140808105
  Validation Loss: 0.6308515667915344
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.734088733792305
  Validation Loss: 0.6306297779083252
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.7288353890180588
  Validation Loss: 0.6304720044136047
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.726213201880455
  Validation Loss: 0.630418062210083
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.7334094941616058
  Validation Loss: 0.6304466724395752
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.7221269458532333
  Validation Loss: 0.6304107904434204
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.7448979765176773
  Validation Loss: 0.6303505897521973
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.7146880924701691
  Validation Loss: 0.6303600668907166
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.7268845438957214
  Validation Loss: 0.630216121673584
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.7231296598911285
  Validation Loss: 0.6299108862876892
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.7204046845436096
  Validation Loss: 0.6294212937355042
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.7318041026592255
  Validation Loss: 0.6289969682693481
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.7320627719163895
  Validation Loss: 0.628644585609436
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.734888032078743
  Validation Loss: 0.6283618807792664
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.7232215702533722
  Validation Loss: 0.6281405091285706
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.7191767245531082
  Validation Loss: 0.62795090675354
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.7373880445957184
  Validation Loss: 0.6277545690536499
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.7270919382572174
  Validation Loss: 0.6274039149284363
  Val ROC-AUC: 0.9285714285714286
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.7239912450313568
  Validation Loss: 0.627000093460083
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.7461065500974655
  Validation Loss: 0.6265900135040283
  Val ROC-AUC: 0.9340659340659341
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.7180490791797638
  Validation Loss: 0.626087486743927
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.7259766310453415
  Validation Loss: 0.6255443692207336
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.7291310131549835
  Validation Loss: 0.6249842047691345
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.7247137129306793
  Validation Loss: 0.624418318271637
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.7342473864555359
  Validation Loss: 0.6240214109420776
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.7222967147827148
  Validation Loss: 0.6236560940742493
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.7216140776872635
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:10:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:10:INFO:
[92mINFO [0m:      Received: evaluate message 6c22147a-4e55-423b-af1d-04cbaa9bf1bd
02/07/2025 22:34:10:INFO:Received: evaluate message 6c22147a-4e55-423b-af1d-04cbaa9bf1bd
[92mINFO [0m:      Sent reply
02/07/2025 22:34:10:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:11:INFO:
[92mINFO [0m:      Received: train message dd007864-0c6f-462a-bf5e-0cb129234334
02/07/2025 22:34:11:INFO:Received: train message dd007864-0c6f-462a-bf5e-0cb129234334
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6232784390449524
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.7195673733949661
  Validation Loss: 0.6228259205818176
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.7322433590888977
  Validation Loss: 0.6223140358924866
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.7338026762008667
  Validation Loss: 0.6218395829200745
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.7101985514163971
  Validation Loss: 0.6213167309761047
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.7216890007257462
  Validation Loss: 0.6208294630050659
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.7245591282844543
  Validation Loss: 0.6204342246055603
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.7325225323438644
  Validation Loss: 0.6200531721115112
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.7329165786504745
  Validation Loss: 0.6195854544639587
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.7115903943777084
  Validation Loss: 0.6191198825836182
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.7272421717643738
  Validation Loss: 0.618602991104126
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.7202113568782806
  Validation Loss: 0.6180762052536011
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.7189461290836334
  Validation Loss: 0.6175576448440552
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.7350423336029053
  Validation Loss: 0.6170505285263062
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.7102217674255371
  Validation Loss: 0.6166835427284241
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.7200376242399216
  Validation Loss: 0.6162109375
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.7192982286214828
  Validation Loss: 0.615811824798584
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.7192982286214828, 'val_roc_auc': 0.9505494505494505, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.615811824798584}
 ROC_AUC: 0.9505|| Accuracy 0.8889 || Train Loss: 0.7193
 Val Loss: 0.6158 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7391329002514314
Test ROC-AUC: 0.8322510822510824
Test Accuracy: 0.7303370786516854
test_loss: 0.7391329002514314
test_roc_auc: 0.8322510822510824
test_accuracy: 0.7303370786516854
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.7124081999063492
  Validation Loss: 0.7260574102401733
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.7119787633419037
  Validation Loss: 0.7250569462776184
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.719461515545845
  Validation Loss: 0.7241016626358032
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.7102292329072952
  Validation Loss: 0.7231720685958862
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.7098278999328613
  Validation Loss: 0.7221266031265259
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6928432732820511
  Validation Loss: 0.7210530638694763
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.7199290841817856
  Validation Loss: 0.7200778722763062
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.7188087105751038
  Validation Loss: 0.7192440629005432
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6903506368398666
  Validation Loss: 0.7183659672737122
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.7172654718160629
  Validation Loss: 0.7175702452659607
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.7085283994674683
  Validation Loss: 0.7168522477149963
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6939754784107208
  Validation Loss: 0.7161291241645813
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6946729570627213
  Validation Loss: 0.7153241038322449
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.7001441866159439
  Validation Loss: 0.7143910527229309
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6969299018383026
  Validation Loss: 0.7132887840270996
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6920932084321976
  Validation Loss: 0.7122505903244019
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.7000073790550232
  Validation Loss: 0.7113321423530579
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6972445100545883
  Validation Loss: 0.710529625415802
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.7057505548000336
  Validation Loss: 0.7097248435020447
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.693174347281456
  Validation Loss: 0.7088217735290527
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.7087433785200119
  Validation Loss: 0.7079376578330994
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6967234760522842
  Validation Loss: 0.707111656665802
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6972153633832932
  Validation Loss: 0.7064095139503479
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.7026300877332687
  Validation Loss: 0.7057739496231079
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6873702257871628
  Validation Loss: 0.7052325010299683
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6915616393089294
  Validation Loss: 0.7045904397964478
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6949577629566193
  Validation Loss: 0.7039082646369934
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.690985843539238
  Validation Loss: 0.7031276822090149
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6940160393714905
  Validation Loss: 0.7024004459381104
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.688002273440361
  Validation Loss: 0.7016655206680298
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6834354102611542
  Validation Loss: 0.7009291648864746
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6948097497224808
  Validation Loss: 0.7002310752868652
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6775576174259186
  Validation Loss: 0.6995835304260254
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6881347447633743
  Validation Loss: 0.6988563537597656
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.7042163163423538
  Validation Loss: 0.698188841342926
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6981386244297028
  Validation Loss: 0.6975294947624207
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.690204992890358
  Validation Loss: 0.6969162821769714
  Val ROC-AUC: 1.0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:17:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:18:INFO:
[92mINFO [0m:      Received: evaluate message 1b6a1a10-dba6-4ed1-b490-dc9474856ebc
02/07/2025 22:34:18:INFO:Received: evaluate message 1b6a1a10-dba6-4ed1-b490-dc9474856ebc
[92mINFO [0m:      Sent reply
02/07/2025 22:34:19:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:19:INFO:
[92mINFO [0m:      Received: train message 44c5b760-e0dd-4b7c-900b-4a12c7829e08
02/07/2025 22:34:19:INFO:Received: train message 44c5b760-e0dd-4b7c-900b-4a12c7829e08
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6745001822710037
  Validation Loss: 0.6962051391601562
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.683863490819931
  Validation Loss: 0.6955952048301697
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6837454438209534
  Validation Loss: 0.6951247453689575
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6861562281847
  Validation Loss: 0.6947078108787537
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6708395630121231
  Validation Loss: 0.6942787170410156
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6884485632181168
  Validation Loss: 0.6938773393630981
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6975989490747452
  Validation Loss: 0.6935147643089294
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6811434179544449
  Validation Loss: 0.6931125521659851
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.677036464214325
  Validation Loss: 0.692608654499054
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.69240503013134
  Validation Loss: 0.6920173764228821
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6808065921068192
  Validation Loss: 0.6914039254188538
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6758869290351868
  Validation Loss: 0.6908226013183594
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6892580389976501
  Validation Loss: 0.6903528571128845
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6749033480882645
  Validation Loss: 0.6899163126945496
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6689080744981766
  Validation Loss: 0.6894553303718567
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6799732893705368
  Validation Loss: 0.6889849901199341
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6699680238962173
  Validation Loss: 0.6885530948638916
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6808451563119888
  Validation Loss: 0.6881104707717896
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6726782321929932
  Validation Loss: 0.6877276301383972
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 57/64:
  Train Loss: 0.675737276673317
  Validation Loss: 0.6873739957809448
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 58/64:
  Train Loss: 0.6758303791284561
  Validation Loss: 0.687035858631134
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 59/64:
  Train Loss: 0.6679234951734543
  Validation Loss: 0.6867139935493469
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.669198676943779
  Validation Loss: 0.6864608526229858
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 61/64:
  Train Loss: 0.6789228618144989
  Validation Loss: 0.6861910223960876
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 62/64:
  Train Loss: 0.6883931457996368
  Validation Loss: 0.6858364939689636
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 63/64:
  Train Loss: 0.6724071800708771
  Validation Loss: 0.6854904890060425
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
Epoch 64/64:
  Train Loss: 0.6767228096723557
  Validation Loss: 0.6851494312286377
  Val ROC-AUC: 1.0
  Val Accuracy: 1.0
{'train_loss': 0.6767228096723557, 'val_roc_auc': 1.0, 'val_accuracy': 1.0, 'val_loss': 0.6851494312286377}
 ROC_AUC: 1.0000|| Accuracy 1.0000 || Train Loss: 0.6767
 Val Loss: 0.6851 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.734626973278067
Test ROC-AUC: 0.8392857142857143
Test Accuracy: 0.7303370786516854
test_loss: 0.734626973278067
test_roc_auc: 0.8392857142857143
test_accuracy: 0.7303370786516854
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.7140375375747681
  Validation Loss: 0.6963993906974792
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.7044136971235275
  Validation Loss: 0.6958140730857849
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.7158150374889374
  Validation Loss: 0.6952041387557983
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.7096640020608902
  Validation Loss: 0.6945255994796753
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.698151558637619
  Validation Loss: 0.6938837170600891
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7047459632158279
  Validation Loss: 0.6932427287101746
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.70539990067482
  Validation Loss: 0.6925934553146362
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.6932793855667114
  Validation Loss: 0.6919068098068237
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.7103082835674286
  Validation Loss: 0.6912601590156555
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.7112022340297699
  Validation Loss: 0.690604031085968
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.7009105682373047
  Validation Loss: 0.6899523735046387
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6961584538221359
  Validation Loss: 0.6892773509025574
  Val ROC-AUC: 0.911764705882353
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.7089759856462479
  Validation Loss: 0.688627302646637
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.6917677670717239
  Validation Loss: 0.6880047917366028
  Val ROC-AUC: 0.9176470588235295
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.7014290243387222
  Validation Loss: 0.6874446272850037
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.7016255408525467
  Validation Loss: 0.6869055032730103
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6996088474988937
  Validation Loss: 0.6863601207733154
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.7047976702451706
  Validation Loss: 0.6858263611793518
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.695965439081192
  Validation Loss: 0.6853235363960266
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.7024734318256378
  Validation Loss: 0.6848018765449524
  Val ROC-AUC: 0.9235294117647059
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6965350061655045
  Validation Loss: 0.6842966675758362
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.7046294063329697
  Validation Loss: 0.6837884187698364
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6993653625249863
  Validation Loss: 0.6833053827285767
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6831551641225815
  Validation Loss: 0.682917058467865
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6950133144855499
  Validation Loss: 0.682564377784729
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6972160786390305
  Validation Loss: 0.6820534467697144
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6923151612281799
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:26:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:26:INFO:
[92mINFO [0m:      Received: evaluate message 42968cef-2a49-404d-bb52-afa96179b74c
02/07/2025 22:34:26:INFO:Received: evaluate message 42968cef-2a49-404d-bb52-afa96179b74c
[92mINFO [0m:      Sent reply
02/07/2025 22:34:28:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:28:INFO:
[92mINFO [0m:      Received: train message 326cd31c-340e-422e-b217-317eb5092ed5
02/07/2025 22:34:28:INFO:Received: train message 326cd31c-340e-422e-b217-317eb5092ed5
  Validation Loss: 0.6815489530563354
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6874322444200516
  Validation Loss: 0.6811404824256897
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6977170258760452
  Validation Loss: 0.6807230114936829
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6984705179929733
  Validation Loss: 0.6802668571472168
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6809144765138626
  Validation Loss: 0.6798803806304932
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6980167925357819
  Validation Loss: 0.679495096206665
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6898922175168991
  Validation Loss: 0.6791507005691528
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6894500404596329
  Validation Loss: 0.6787556409835815
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6853771656751633
  Validation Loss: 0.6784075498580933
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6983290463685989
  Validation Loss: 0.6780045032501221
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6997215449810028
  Validation Loss: 0.677553117275238
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6930107772350311
  Validation Loss: 0.677130401134491
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.684015080332756
  Validation Loss: 0.6767632365226746
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6675058603286743
  Validation Loss: 0.6763362288475037
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6793687492609024
  Validation Loss: 0.6758556962013245
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.687082901597023
  Validation Loss: 0.6753756999969482
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6864250153303146
  Validation Loss: 0.674950897693634
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6792685240507126
  Validation Loss: 0.6745436191558838
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6844801306724548
  Validation Loss: 0.674062967300415
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6875875443220139
  Validation Loss: 0.673651397228241
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6902659684419632
  Validation Loss: 0.673276960849762
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6901441812515259
  Validation Loss: 0.6728949546813965
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6767303794622421
  Validation Loss: 0.6725825071334839
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6852400898933411
  Validation Loss: 0.67227703332901
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6771073788404465
  Validation Loss: 0.6719235777854919
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6812085807323456
  Validation Loss: 0.6715890169143677
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.683340460062027
  Validation Loss: 0.6712393760681152
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6768684089183807
  Validation Loss: 0.6709150671958923
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6892774552106857
  Validation Loss: 0.6706041693687439
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6828357875347137
  Validation Loss: 0.6702490448951721
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.684120699763298
  Validation Loss: 0.6698939800262451
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6754694133996964
  Validation Loss: 0.6695412397384644
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6705889403820038
  Validation Loss: 0.6692429184913635
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6741954982280731
  Validation Loss: 0.6689700484275818
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6787719875574112
  Validation Loss: 0.6686884164810181
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6833261549472809
  Validation Loss: 0.6683788299560547
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6757001578807831
  Validation Loss: 0.6680184602737427
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6797046810388565
  Validation Loss: 0.6676627993583679
  Val ROC-AUC: 0.9411764705882353
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6797046810388565, 'val_roc_auc': 0.9411764705882353, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6676627993583679}
 ROC_AUC: 0.9412|| Accuracy 0.8889 || Train Loss: 0.6797
 Val Loss: 0.6677 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.730233228273606
Test ROC-AUC: 0.8484848484848484
Test Accuracy: 0.7415730337078652
test_loss: 0.730233228273606
test_roc_auc: 0.8484848484848484
test_accuracy: 0.7415730337078652
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6912648230791092
  Validation Loss: 0.7208424806594849
  Val ROC-AUC: 0.9276315789473684
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.7090471684932709
  Validation Loss: 0.7198961973190308
  Val ROC-AUC: 0.9276315789473684
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.7088735550642014
  Validation Loss: 0.7190091013908386
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6966619789600372
  Validation Loss: 0.7181341648101807
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.7002037018537521
  Validation Loss: 0.71733158826828
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6817695796489716
  Validation Loss: 0.7164339423179626
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6951334774494171
  Validation Loss: 0.7156645059585571
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6938792169094086
  Validation Loss: 0.7148970365524292
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6862279921770096
  Validation Loss: 0.7142173051834106
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6791886538267136
  Validation Loss: 0.7135117650032043
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6972771286964417
  Validation Loss: 0.7127335071563721
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6982524693012238
  Validation Loss: 0.7120067477226257
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:33:INFO:
[92mINFO [0m:      Received: evaluate message 97c557d3-1d46-4361-bd85-98dc1d413c90
02/07/2025 22:34:33:INFO:Received: evaluate message 97c557d3-1d46-4361-bd85-98dc1d413c90
  Train Loss: 0.6839849948883057
  Validation Loss: 0.7113826870918274
  Val ROC-AUC: 0.9407894736842105
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6973181813955307
  Validation Loss: 0.7106872200965881
  Val ROC-AUC: 0.9473684210526316
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6883320957422256
  Validation Loss: 0.7099243998527527
  Val ROC-AUC: 0.9473684210526316
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6908978074789047
  Validation Loss: 0.7092201113700867
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6853711754083633
  Validation Loss: 0.7085304260253906
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6876951307058334
  Validation Loss: 0.7078469395637512
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6853991001844406
  Validation Loss: 0.7071388959884644
  Val ROC-AUC: 0.9539473684210527
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6855685263872147
  Validation Loss: 0.7065219283103943
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6866578161716461
  Validation Loss: 0.7059014439582825
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6780676692724228
  Validation Loss: 0.7053058743476868
  Val ROC-AUC: 0.9671052631578947
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6893507689237595
  Validation Loss: 0.7046937346458435
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6806164234876633
  Validation Loss: 0.7041199207305908
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6802688837051392
  Validation Loss: 0.7035473585128784
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6871937364339828
  Validation Loss: 0.7029408812522888
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6764010637998581
  Validation Loss: 0.70252525806427
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6769073158502579
  Validation Loss: 0.7021196484565735
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6829299330711365
  Validation Loss: 0.7016587257385254
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6921557933092117
  Validation Loss: 0.701121985912323
  Val ROC-AUC: 0.9736842105263158
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6824739128351212
  Validation Loss: 0.7006500363349915
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6701239794492722
  Validation Loss: 0.7001099586486816
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6889620125293732
  Validation Loss: 0.6995372772216797
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.685849666595459
  Validation Loss: 0.6988961100578308
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6815723478794098
  Validation Loss: 0.6982951760292053
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.690191239118576
  Validation Loss: 0.6978338956832886
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6765351742506027
  Validation Loss: 0.6973575353622437
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6693231761455536
  Validation Loss: 0.6968640089035034
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.674637034535408
  Validation Loss: 0.6963802576065063
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6762050539255142
  Validation Loss: 0.6958448886871338
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6657633483409882
  Validation Loss: 0.6952885389328003
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6715173572301865
  Validation Loss: 0.6946902871131897
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6627348065376282
  Validation Loss: 0.6941264271736145
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6717630326747894
  Validation Loss: 0.6936286687850952
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6744764745235443
  Validation Loss: 0.6931467652320862
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6738240271806717
  Validation Loss: 0.69263756275177
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6806588470935822
  Validation Loss: 0.6920856833457947
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6818989515304565
  Validation Loss: 0.6916435360908508
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6651841253042221
  Validation Loss: 0.6911686658859253
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6779238134622574
  Validation Loss: 0.6906681656837463
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6775281876325607
  Validation Loss: 0.6902025938034058
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6800276637077332
  Validation Loss: 0.6897426247596741
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6792622804641724
  Validation Loss: 0.6891943216323853
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.675719827413559
  Validation Loss: 0.6886543035507202
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6687410175800323
  Validation Loss: 0.6880527138710022
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6747227013111115
  Validation Loss: 0.687436044216156
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6642832309007645
  Validation Loss: 0.6869104504585266
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6759780496358871
  Validation Loss: 0.6864863634109497
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.665199339389801
  Validation Loss: 0.6862121224403381
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6734740138053894
  Validation Loss: 0.6860308647155762
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6789810955524445
  Validation Loss: 0.6857731938362122
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6785445958375931
  Validation Loss: 0.6854373216629028
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6653703153133392
  Validation Loss: 0.6850268244743347
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6766586601734161
  Validation Loss: 0.6846011281013489
  Val ROC-AUC: 0.993421052631579
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6766586601734161, 'val_roc_auc': 0.993421052631579, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6846011281013489}
 ROC_AUC: 0.9934|| Accuracy 0.9259 || Train Loss: 0.6767
 Val Loss: 0.6846 
[Client 1] evaluate, config: {'batch_size': 1}
[92mINFO [0m:      Sent reply
02/07/2025 22:34:33:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:33:INFO:
[92mINFO [0m:      Received: train message 62a54a18-0265-4620-a43a-48b9176ffd43
02/07/2025 22:34:33:INFO:Received: train message 62a54a18-0265-4620-a43a-48b9176ffd43
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
Test Loss: 0.7259134124504046
Test ROC-AUC: 0.8555194805194805
Test Accuracy: 0.7528089887640449
test_loss: 0.7259134124504046
test_roc_auc: 0.8555194805194805
test_accuracy: 0.7528089887640449
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6812966465950012
  Validation Loss: 0.7078470587730408
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6724199652671814
  Validation Loss: 0.7072098255157471
  Val ROC-AUC: 0.9506172839506173
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6912189275026321
  Validation Loss: 0.7066386342048645
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6937463134527206
  Validation Loss: 0.7060642838478088
  Val ROC-AUC: 0.9567901234567902
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6908070743083954
  Validation Loss: 0.705583393573761
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6993225663900375
  Validation Loss: 0.7051818370819092
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6937073469161987
  Validation Loss: 0.7047299742698669
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6845364421606064
  Validation Loss: 0.7043485045433044
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.7004264146089554
  Validation Loss: 0.7040505409240723
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6917456984519958
  Validation Loss: 0.7037271857261658
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.7011630535125732
  Validation Loss: 0.703457772731781
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6980659365653992
  Validation Loss: 0.7031344175338745
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.7057837098836899
  Validation Loss: 0.7028419971466064
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6958575248718262
  Validation Loss: 0.7023860216140747
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.687974289059639
  Validation Loss: 0.7019592523574829
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.683124914765358
  Validation Loss: 0.7015480399131775
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6905850768089294
  Validation Loss: 0.7011454105377197
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6904754340648651
  Validation Loss: 0.7007023692131042
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6994214355945587
  Validation Loss: 0.7002972960472107
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6937829703092575
  Validation Loss: 0.7000154852867126
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6971600204706192
  Validation Loss: 0.6997866630554199
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6866784989833832
  Validation Loss: 0.6995488405227661
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6904713809490204
  Validation Loss: 0.6993275284767151
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6874149143695831
  Validation Loss: 0.6991196870803833
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.692577674984932
  Validation Loss: 0.6988205313682556
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6952659785747528
  Validation Loss: 0.69853675365448
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6830542832612991
  Validation Loss: 0.698235809803009
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6883148849010468
  Validation Loss: 0.6978722810745239
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6910863667726517
  Validation Loss: 0.697481632232666
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6898596882820129
  Validation Loss: 0.697155773639679
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6870474964380264
  Validation Loss: 0.6967920660972595
  Val ROC-AUC: 0.962962962962963
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6886753737926483
  Validation Loss: 0.6964473128318787
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6747107654809952
  Validation Loss: 0.6961432695388794
  Val ROC-AUC: 0.9753086419753085
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6881652623414993
  Validation Loss: 0.6957340240478516
  Val ROC-AUC: 0.9753086419753085
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6829485893249512
  Validation Loss: 0.6953324675559998
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6863747239112854
  Validation Loss: 0.6949549317359924
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6756157726049423
  Validation Loss: 0.6946738958358765
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6912975162267685
  Validation Loss: 0.6943811774253845
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6832327246665955
  Validation Loss: 0.694154679775238
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6767995953559875
  Validation Loss: 0.6938934922218323
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6888295710086823
  Validation Loss: 0.6936549544334412
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.674126386642456
  Validation Loss: 0.6934005618095398
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6837917417287827
  Validation Loss: 0.6932060718536377
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6708455681800842
  Validation Loss: 0.6930251717567444
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6745090931653976
  Validation Loss: 0.6928433179855347
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6708255410194397
  Validation Loss: 0.6926170587539673
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6807381063699722
  Validation Loss: 0.692461371421814
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.6769300103187561
  Validation Loss: 0.6922747492790222
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.669238418340683
  Validation Loss: 0.691981852054596
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6769617795944214
  Validation Loss: 0.6916602849960327
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6632999777793884
  Validation Loss: 0.6913462281227112
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6667636781930923
  Validation Loss: 0.6910740733146667
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:38:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:38:INFO:
[92mINFO [0m:      Received: evaluate message 8f499ec0-6426-4f45-a37e-c96b527777bf
02/07/2025 22:34:38:INFO:Received: evaluate message 8f499ec0-6426-4f45-a37e-c96b527777bf
[92mINFO [0m:      Sent reply
02/07/2025 22:34:39:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:39:INFO:
[92mINFO [0m:      Received: train message 832d62bc-3a01-4fd7-a5ef-cf9f009fc0fb
02/07/2025 22:34:39:INFO:Received: train message 832d62bc-3a01-4fd7-a5ef-cf9f009fc0fb
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6755456179380417
  Validation Loss: 0.6908761262893677
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6821523308753967
  Validation Loss: 0.6906786561012268
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6740660965442657
  Validation Loss: 0.6904257535934448
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6835041642189026
  Validation Loss: 0.6901671886444092
  Val ROC-AUC: 0.9814814814814814
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6794561147689819
  Validation Loss: 0.6899144053459167
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6703558713197708
  Validation Loss: 0.6896950006484985
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6679748147726059
  Validation Loss: 0.6894532442092896
  Val ROC-AUC: 0.9876543209876543
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6723981499671936
  Validation Loss: 0.6893077492713928
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6861999034881592
  Validation Loss: 0.6890730261802673
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6718375980854034
  Validation Loss: 0.6888570189476013
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6667604446411133
  Validation Loss: 0.6886142492294312
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6660209894180298
  Validation Loss: 0.688417911529541
  Val ROC-AUC: 0.9938271604938271
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6660209894180298, 'val_roc_auc': 0.9938271604938271, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.688417911529541}
 ROC_AUC: 0.9938|| Accuracy 0.9259 || Train Loss: 0.6660
 Val Loss: 0.6884 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7220005496834101
Test ROC-AUC: 0.8614718614718615
Test Accuracy: 0.7528089887640449
test_loss: 0.7220005496834101
test_roc_auc: 0.8614718614718615
test_accuracy: 0.7528089887640449
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.7112238556146622
  Validation Loss: 0.6305651664733887
  Val ROC-AUC: 0.9395604395604396
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.7132014781236649
  Validation Loss: 0.630196750164032
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.7131711393594742
  Validation Loss: 0.6297842264175415
  Val ROC-AUC: 0.945054945054945
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.7030544281005859
  Validation Loss: 0.6295017600059509
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.6970780342817307
  Validation Loss: 0.6292152404785156
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.7125114798545837
  Validation Loss: 0.6289070844650269
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.7137562036514282
  Validation Loss: 0.6286003589630127
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.7124465703964233
  Validation Loss: 0.6284416317939758
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.7113290876150131
  Validation Loss: 0.6283934116363525
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.6987385153770447
  Validation Loss: 0.6282232999801636
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.7070767432451248
  Validation Loss: 0.6279694437980652
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.711811438202858
  Validation Loss: 0.6276363134384155
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.7173273712396622
  Validation Loss: 0.6272911429405212
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.699900358915329
  Validation Loss: 0.6269820332527161
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.6992545276880264
  Validation Loss: 0.6266616582870483
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.7001162618398666
  Validation Loss: 0.6263037919998169
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.7127849161624908
  Validation Loss: 0.6259815692901611
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.7066231966018677
  Validation Loss: 0.6257761716842651
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.7147442400455475
  Validation Loss: 0.6255379319190979
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.7043459862470627
  Validation Loss: 0.6252543926239014
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.7021844238042831
  Validation Loss: 0.6248800754547119
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.7067317366600037
  Validation Loss: 0.624534547328949
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.7092509567737579
  Validation Loss: 0.624130129814148
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.7052028924226761
  Validation Loss: 0.6236891746520996
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.7003356218338013
  Validation Loss: 0.623232364654541
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.7023522853851318
  Validation Loss: 0.6229000687599182
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.7105116248130798
  Validation Loss: 0.6226004362106323
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.7016938626766205
  Validation Loss: 0.6223040819168091
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.7034765481948853
  Validation Loss: 0.62200927734375
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.703926295042038
  Validation Loss: 0.6216495037078857
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6917260736227036
  Validation Loss: 0.6213726997375488
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6931108385324478
  Validation Loss: 0.6211768388748169
  Val ROC-AUC: 0.9505494505494505
  Val Accuracy: 0.8518518805503845
Epoch 33/64:
  Train Loss: 0.7023457586765289
  Validation Loss: 0.6210170984268188
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 34/64:
  Train Loss: 0.6995078772306442
  Validation Loss: 0.6207853555679321
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8518518805503845
Epoch 35/64:
  Train Loss: 0.7107694894075394
  Validation Loss: 0.6204256415367126
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.7075860649347305
  Validation Loss: 0.6201368570327759
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.7088707387447357
  Validation Loss: 0.619833767414093
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6925319284200668
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:44:INFO:
[92mINFO [0m:      Received: evaluate message 44280a72-c251-493a-b658-0f6f1b84135b
02/07/2025 22:34:44:INFO:Received: evaluate message 44280a72-c251-493a-b658-0f6f1b84135b
[92mINFO [0m:      Sent reply
02/07/2025 22:34:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:44:INFO:
[92mINFO [0m:      Received: train message 12bfae5d-9315-4364-9560-597af8c852bb
02/07/2025 22:34:44:INFO:Received: train message 12bfae5d-9315-4364-9560-597af8c852bb
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6195605397224426
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6962035447359085
  Validation Loss: 0.6191952228546143
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.706317275762558
  Validation Loss: 0.6187319159507751
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6918262243270874
  Validation Loss: 0.6182724237442017
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.7020933479070663
  Validation Loss: 0.6178835034370422
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6887224018573761
  Validation Loss: 0.6175172924995422
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6878426820039749
  Validation Loss: 0.6170845031738281
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6889746487140656
  Validation Loss: 0.6167530417442322
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6825247555971146
  Validation Loss: 0.6164622902870178
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6926748007535934
  Validation Loss: 0.6161463260650635
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6986283361911774
  Validation Loss: 0.6158145070075989
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6954513341188431
  Validation Loss: 0.6154638528823853
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6892715245485306
  Validation Loss: 0.6151983737945557
  Val ROC-AUC: 0.956043956043956
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6817541271448135
  Validation Loss: 0.6149279475212097
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6955144256353378
  Validation Loss: 0.6146113276481628
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6895819753408432
  Validation Loss: 0.6142619252204895
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6849021762609482
  Validation Loss: 0.6138548254966736
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6863439232110977
  Validation Loss: 0.613467276096344
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6906183362007141
  Validation Loss: 0.613166332244873
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.693325400352478
  Validation Loss: 0.6129352450370789
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6911526471376419
  Validation Loss: 0.6127918362617493
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6953592002391815
  Validation Loss: 0.6125931739807129
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6926395893096924
  Validation Loss: 0.6123113036155701
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6837761849164963
  Validation Loss: 0.6119595170021057
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6946098357439041
  Validation Loss: 0.6115325093269348
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6897813081741333
  Validation Loss: 0.6112820506095886
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6845919638872147
  Validation Loss: 0.6109890341758728
  Val ROC-AUC: 0.9615384615384615
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6845919638872147, 'val_roc_auc': 0.9615384615384615, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6109890341758728}
 ROC_AUC: 0.9615|| Accuracy 0.9259 || Train Loss: 0.6846
 Val Loss: 0.6110 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7184105157182458
Test ROC-AUC: 0.8668831168831169
Test Accuracy: 0.7865168539325843
test_loss: 0.7184105157182458
test_roc_auc: 0.8668831168831169
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6984632313251495
  Validation Loss: 0.6758944392204285
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 2/64:
  Train Loss: 0.7006864696741104
  Validation Loss: 0.6756002902984619
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 3/64:
  Train Loss: 0.6864229589700699
  Validation Loss: 0.6753250360488892
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 4/64:
  Train Loss: 0.7013976722955704
  Validation Loss: 0.6750702857971191
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 5/64:
  Train Loss: 0.6888284385204315
  Validation Loss: 0.6747406721115112
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 6/64:
  Train Loss: 0.700142428278923
  Validation Loss: 0.6744587421417236
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.6856817454099655
  Validation Loss: 0.6741152405738831
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.6963820159435272
  Validation Loss: 0.673770010471344
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.6886346936225891
  Validation Loss: 0.6733080148696899
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.6731290817260742
  Validation Loss: 0.6728017926216125
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.6922646909952164
  Validation Loss: 0.672407865524292
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.6848111897706985
  Validation Loss: 0.6721633672714233
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.6853309124708176
  Validation Loss: 0.6719151139259338
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.6734873801469803
  Validation Loss: 0.6716666221618652
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6910266876220703
  Validation Loss: 0.6713876128196716
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.6858758181333542
  Validation Loss: 0.67105633020401
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6933174431324005
  Validation Loss: 0.6707030534744263
  Val ROC-AUC: 0.9647058823529411
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.680671289563179
  Validation Loss: 0.6704124212265015
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6790023446083069
  Validation Loss: 0.6701319813728333
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6903834193944931
  Validation Loss: 0.66977459192276
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6852252632379532
  Validation Loss: 0.6694071888923645
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.6794323474168777
  Validation Loss: 0.6690753102302551
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6847662925720215
  Validation Loss: 0.66873699426651
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:48:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:48:INFO:
[92mINFO [0m:      Received: evaluate message 8fd491f3-7815-4c28-9846-d6f5e0a7a4df
02/07/2025 22:34:48:INFO:Received: evaluate message 8fd491f3-7815-4c28-9846-d6f5e0a7a4df
[92mINFO [0m:      Sent reply
02/07/2025 22:34:49:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:49:INFO:
[92mINFO [0m:      Received: train message 788b8c28-c9a5-4bfb-b677-de1f74381886
02/07/2025 22:34:49:INFO:Received: train message 788b8c28-c9a5-4bfb-b677-de1f74381886
  Train Loss: 0.6864283233880997
  Validation Loss: 0.6683874726295471
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.697848916053772
  Validation Loss: 0.6680662631988525
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6896886080503464
  Validation Loss: 0.6678215265274048
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6815299540758133
  Validation Loss: 0.667566180229187
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6726506948471069
  Validation Loss: 0.6673372983932495
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6710630357265472
  Validation Loss: 0.6669976115226746
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6859086453914642
  Validation Loss: 0.666633129119873
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6863899827003479
  Validation Loss: 0.6663478016853333
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6818886399269104
  Validation Loss: 0.6660735607147217
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6845533549785614
  Validation Loss: 0.6657937169075012
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6821199208498001
  Validation Loss: 0.6654459834098816
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6809512823820114
  Validation Loss: 0.6650048494338989
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6937914788722992
  Validation Loss: 0.6645610928535461
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6819593608379364
  Validation Loss: 0.6641314625740051
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6801714450120926
  Validation Loss: 0.6637450456619263
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.676510214805603
  Validation Loss: 0.6634230017662048
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6731457859277725
  Validation Loss: 0.6631089448928833
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6574900150299072
  Validation Loss: 0.6628196239471436
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6866730451583862
  Validation Loss: 0.6626173853874207
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6683921664953232
  Validation Loss: 0.6623675227165222
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6784276515245438
  Validation Loss: 0.6621047258377075
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6669411808252335
  Validation Loss: 0.6618759036064148
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6660407930612564
  Validation Loss: 0.6616401076316833
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6690506339073181
  Validation Loss: 0.6614283919334412
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6731552332639694
  Validation Loss: 0.6613176465034485
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6825989633798599
  Validation Loss: 0.6612128615379333
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.677104115486145
  Validation Loss: 0.6611160635948181
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6653038710355759
  Validation Loss: 0.661023736000061
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6746767908334732
  Validation Loss: 0.6609067320823669
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6836570352315903
  Validation Loss: 0.6607588529586792
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6638754457235336
  Validation Loss: 0.6605989933013916
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6799758672714233
  Validation Loss: 0.6604045629501343
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6707908809185028
  Validation Loss: 0.6602141857147217
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6696356981992722
  Validation Loss: 0.6600863337516785
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6728587299585342
  Validation Loss: 0.6599112749099731
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6680053174495697
  Validation Loss: 0.6597123146057129
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6721532791852951
  Validation Loss: 0.6595105528831482
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.668224960565567
  Validation Loss: 0.6592578291893005
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6593149602413177
  Validation Loss: 0.659089982509613
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6722308248281479
  Validation Loss: 0.6589668393135071
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6762881428003311
  Validation Loss: 0.6588592529296875
  Val ROC-AUC: 0.9588235294117647
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6762881428003311, 'val_roc_auc': 0.9588235294117647, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6588592529296875}
 ROC_AUC: 0.9588|| Accuracy 0.9630 || Train Loss: 0.6763
 Val Loss: 0.6589 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7151254626472344
Test ROC-AUC: 0.8690476190476191
Test Accuracy: 0.7752808988764045
test_loss: 0.7151254626472344
test_roc_auc: 0.8690476190476191
test_accuracy: 0.7752808988764045
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.674669086933136
  Validation Loss: 0.6865237951278687
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6945331394672394
  Validation Loss: 0.6863489747047424
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6823610961437225
  Validation Loss: 0.6860899925231934
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6930693984031677
  Validation Loss: 0.6857730150222778
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6831826865673065
  Validation Loss: 0.6854650974273682
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.6761691272258759
  Validation Loss: 0.6850956082344055
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.691377267241478
  Validation Loss: 0.684698224067688
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6945166140794754
  Validation Loss: 0.6843804121017456
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.685447946190834
  Validation Loss: 0.684114933013916
  Val ROC-AUC: 0.9176470588235294
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6753244549036026
  Validation Loss: 0.6838882565498352
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6857882589101791
  Validation Loss: 0.6836692690849304
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6926632970571518
  Validation Loss: 0.683486819267273
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.6751253455877304
  Validation Loss: 0.6832875609397888
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.6885380893945694
  Validation Loss: 0.6830646991729736
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.6721780300140381
  Validation Loss: 0.6828439831733704
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.6778941005468369
  Validation Loss: 0.6825881600379944
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.6762265712022781
  Validation Loss: 0.6823621988296509
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6972904354333878
  Validation Loss: 0.6821434497833252
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.6854434013366699
  Validation Loss: 0.6818504333496094
  Val ROC-AUC: 0.9176470588235294
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.6689274460077286
  Validation Loss: 0.6814805269241333
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6736979931592941
  Validation Loss: 0.6810764670372009
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.6791937947273254
  Validation Loss: 0.6807646751403809
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.6765569895505905
  Validation Loss: 0.6804694533348083
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.6752146035432816
  Validation Loss: 0.680210530757904
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.6772745102643967
  Validation Loss: 0.679920494556427
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.6901857405900955
  Validation Loss: 0.679573655128479
  Val ROC-AUC: 0.9235294117647058
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.685000017285347
  Validation Loss: 0.6792483925819397
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.6814547032117844
  Validation Loss: 0.6789105534553528
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.6710198670625687
  Validation Loss: 0.6785915493965149
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 30/64:
  Train Loss: 0.6845761239528656
  Validation Loss: 0.6783232092857361
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 31/64:
  Train Loss: 0.6798585653305054
  Validation Loss: 0.6780697107315063
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.6804078221321106
  Validation Loss: 0.6778318881988525
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 33/64:
  Train Loss: 0.6670599430799484
  Validation Loss: 0.6776608228683472
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 34/64:
  Train Loss: 0.6688263714313507
  Validation Loss: 0.6774746775627136
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 35/64:
  Train Loss: 0.6814717352390289
  Validation Loss: 0.6772311925888062
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 36/64:
  Train Loss: 0.6759798526763916
  Validation Loss: 0.6769483685493469
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 37/64:
  Train Loss: 0.6809820681810379
  Validation Loss: 0.6766336560249329
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 38/64:
  Train Loss: 0.685486376285553
  Validation Loss: 0.6762721538543701
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 39/64:
  Train Loss: 0.6762870997190475
  Validation Loss: 0.6759633421897888
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 40/64:
  Train Loss: 0.6571051478385925
  Validation Loss: 0.675666093826294
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 41/64:
  Train Loss: 0.6829981058835983
  Validation Loss: 0.6754742860794067
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 42/64:
  Train Loss: 0.6762259751558304
  Validation Loss: 0.6752411723136902
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 43/64:
  Train Loss: 0.6812764704227448
  Validation Loss: 0.6750223636627197
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 44/64:
  Train Loss: 0.6659791022539139
  Validation Loss: 0.6748197674751282
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 45/64:
  Train Loss: 0.675447016954422
  Validation Loss: 0.6745761036872864
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 46/64:
  Train Loss: 0.666456550359726
  Validation Loss: 0.6742023229598999
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 47/64:
  Train Loss: 0.6644151359796524
  Validation Loss: 0.6738330721855164
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.6787363439798355
  Validation Loss: 0.6735547184944153
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.6718617379665375
  Validation Loss: 0.6733556985855103
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.658764585852623
  Validation Loss: 0.6731981635093689
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6745790839195251
  Validation Loss: 0.673086404800415
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.6656610518693924
  Validation Loss: 0.6729263067245483
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.685461089015007
  Validation Loss: 0.672751247882843
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6765289753675461
  Validation Loss: 0.6726292967796326
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.6834257692098618
  Validation Loss: 0.6724151372909546
  Val ROC-AUC: 0.9294117647058824
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.6704706251621246
  Validation Loss: 0.6721581220626831
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.6876997351646423
  Validation Loss: 0.6719704270362854
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.6790021061897278
  Validation Loss: 0.671830415725708
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.6658356636762619
  Validation Loss: 0.6717241406440735
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.6710646897554398
  Validation Loss: 0.6716529130935669
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6691566556692123
  Validation Loss: 0.6715759634971619
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.6654362082481384
  Validation Loss: 0.6714685559272766
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.6705386638641357
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:52:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:53:INFO:
[92mINFO [0m:      Received: evaluate message c092758d-2d52-413d-a7ba-769afdd499ad
02/07/2025 22:34:53:INFO:Received: evaluate message c092758d-2d52-413d-a7ba-769afdd499ad
[92mINFO [0m:      Sent reply
02/07/2025 22:34:53:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:53:INFO:
[92mINFO [0m:      Received: train message 720f5734-6018-4f84-9e0b-ad95bd6063b3
02/07/2025 22:34:53:INFO:Received: train message 720f5734-6018-4f84-9e0b-ad95bd6063b3
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Validation Loss: 0.6714164018630981
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.6686849594116211
  Validation Loss: 0.6713225841522217
  Val ROC-AUC: 0.9352941176470588
  Val Accuracy: 0.8518518805503845
{'train_loss': 0.6686849594116211, 'val_roc_auc': 0.9352941176470588, 'val_accuracy': 0.8518518805503845, 'val_loss': 0.6713225841522217}
 ROC_AUC: 0.9353|| Accuracy 0.8519 || Train Loss: 0.6687
 Val Loss: 0.6713 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7120896949526969
Test ROC-AUC: 0.8706709956709957
Test Accuracy: 0.7752808988764045
test_loss: 0.7120896949526969
test_roc_auc: 0.8706709956709957
test_accuracy: 0.7752808988764045
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6672404557466507
  Validation Loss: 0.7802627086639404
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 2/64:
  Train Loss: 0.6331863030791283
  Validation Loss: 0.7802143096923828
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 3/64:
  Train Loss: 0.6600721627473831
  Validation Loss: 0.7801194190979004
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 4/64:
  Train Loss: 0.6528462171554565
  Validation Loss: 0.7801596522331238
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 5/64:
  Train Loss: 0.6506773084402084
  Validation Loss: 0.7801887392997742
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 6/64:
  Train Loss: 0.6533472985029221
  Validation Loss: 0.7801322937011719
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 7/64:
  Train Loss: 0.6415805071592331
  Validation Loss: 0.7799177169799805
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 8/64:
  Train Loss: 0.6640031337738037
  Validation Loss: 0.7797648310661316
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 9/64:
  Train Loss: 0.6586879789829254
  Validation Loss: 0.7795882225036621
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 10/64:
  Train Loss: 0.6416494101285934
  Validation Loss: 0.7795142531394958
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 11/64:
  Train Loss: 0.6556382477283478
  Validation Loss: 0.7795367240905762
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 12/64:
  Train Loss: 0.665552482008934
  Validation Loss: 0.779525876045227
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 13/64:
  Train Loss: 0.6543036997318268
  Validation Loss: 0.779566764831543
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 14/64:
  Train Loss: 0.6432443410158157
  Validation Loss: 0.7795021533966064
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 15/64:
  Train Loss: 0.6656757295131683
  Validation Loss: 0.7792966961860657
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 16/64:
  Train Loss: 0.6614171415567398
  Validation Loss: 0.7791976928710938
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 17/64:
  Train Loss: 0.6607802212238312
  Validation Loss: 0.7791140675544739
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 18/64:
  Train Loss: 0.6517358422279358
  Validation Loss: 0.778957724571228
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 19/64:
  Train Loss: 0.6654447168111801
  Validation Loss: 0.7787570953369141
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 20/64:
  Train Loss: 0.6536695212125778
  Validation Loss: 0.7786551713943481
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 21/64:
  Train Loss: 0.6588894724845886
  Validation Loss: 0.7786022424697876
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 22/64:
  Train Loss: 0.6533392369747162
  Validation Loss: 0.7784412503242493
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 23/64:
  Train Loss: 0.6556904762983322
  Validation Loss: 0.7781136631965637
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 24/64:
  Train Loss: 0.653841570019722
  Validation Loss: 0.7778868675231934
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 25/64:
  Train Loss: 0.6473736464977264
  Validation Loss: 0.7778437733650208
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 26/64:
  Train Loss: 0.6589113473892212
  Validation Loss: 0.7778065204620361
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7407407760620117
Epoch 27/64:
  Train Loss: 0.6610861122608185
  Validation Loss: 0.7776445746421814
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 28/64:
  Train Loss: 0.6501777023077011
  Validation Loss: 0.7774196267127991
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 29/64:
  Train Loss: 0.6594996005296707
  Validation Loss: 0.7774201035499573
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 30/64:
  Train Loss: 0.6599554568529129
  Validation Loss: 0.7772942781448364
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 31/64:
  Train Loss: 0.6470960378646851
  Validation Loss: 0.777123749256134
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 32/64:
  Train Loss: 0.652183473110199
  Validation Loss: 0.7768909335136414
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 33/64:
  Train Loss: 0.6545949131250381
  Validation Loss: 0.7765779495239258
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 34/64:
  Train Loss: 0.6588683277368546
  Validation Loss: 0.7764323353767395
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 35/64:
  Train Loss: 0.6548619717359543
  Validation Loss: 0.7762725353240967
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 36/64:
  Train Loss: 0.6534096002578735
  Validation Loss: 0.7760401368141174
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 37/64:
  Train Loss: 0.6469849944114685
  Validation Loss: 0.775780975818634
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 38/64:
  Train Loss: 0.6454192847013474
  Validation Loss: 0.7754729986190796
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 39/64:
  Train Loss: 0.6466208398342133
  Validation Loss: 0.7753050327301025
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 40/64:
  Train Loss: 0.6653258353471756
  Validation Loss: 0.7752608060836792
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 41/64:
  Train Loss: 0.6508313715457916
  Validation Loss: 0.7752348184585571
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 42/64:
  Train Loss: 0.6511078923940659
  Validation Loss: 0.7751282453536987
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 43/64:
  Train Loss: 0.6501593738794327
  Validation Loss: 0.7748973965644836
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 44/64:
  Train Loss: 0.6502295583486557
  Validation Loss: 0.7746517062187195
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 45/64:
  Train Loss: 0.6493661403656006
  Validation Loss: 0.7745596170425415
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 46/64:
  Train Loss: 0.6344150602817535
  Validation Loss: 0.7744314670562744
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 47/64:
  Train Loss: 0.6383409202098846
  Validation Loss: 0.7742842435836792
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 48/64:
  Train Loss: 0.6550778299570084
  Validation Loss: 0.7741469144821167
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 49/64:/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:34:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:57:INFO:
[92mINFO [0m:      Received: evaluate message 2122b98f-964b-40d6-bdad-1c3e8747e79f
02/07/2025 22:34:57:INFO:Received: evaluate message 2122b98f-964b-40d6-bdad-1c3e8747e79f
[92mINFO [0m:      Sent reply
02/07/2025 22:34:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:34:58:INFO:
[92mINFO [0m:      Received: train message 4852c1b1-c2fa-4c28-9798-7433ceed2f9f
02/07/2025 22:34:58:INFO:Received: train message 4852c1b1-c2fa-4c28-9798-7433ceed2f9f
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)

  Train Loss: 0.6421726942062378
  Validation Loss: 0.7739623785018921
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 50/64:
  Train Loss: 0.6553271859884262
  Validation Loss: 0.7738419771194458
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 51/64:
  Train Loss: 0.6527085900306702
  Validation Loss: 0.7737100720405579
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 52/64:
  Train Loss: 0.6370337903499603
  Validation Loss: 0.7735821008682251
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 53/64:
  Train Loss: 0.6538930684328079
  Validation Loss: 0.7734476923942566
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 54/64:
  Train Loss: 0.6482589840888977
  Validation Loss: 0.7732764482498169
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 55/64:
  Train Loss: 0.6486199498176575
  Validation Loss: 0.7729500532150269
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 56/64:
  Train Loss: 0.6336562037467957
  Validation Loss: 0.7726796269416809
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 57/64:
  Train Loss: 0.6527523994445801
  Validation Loss: 0.7725338339805603
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 58/64:
  Train Loss: 0.6464421600103378
  Validation Loss: 0.7723684310913086
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 59/64:
  Train Loss: 0.6448313742876053
  Validation Loss: 0.7722217440605164
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 60/64:
  Train Loss: 0.6578426659107208
  Validation Loss: 0.7720905542373657
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 61/64:
  Train Loss: 0.6418091356754303
  Validation Loss: 0.7718592882156372
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 62/64:
  Train Loss: 0.6390342861413956
  Validation Loss: 0.7715830206871033
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 63/64:
  Train Loss: 0.6313502192497253
  Validation Loss: 0.7712259292602539
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
Epoch 64/64:
  Train Loss: 0.649371325969696
  Validation Loss: 0.7709816694259644
  Val ROC-AUC: 0.6031746031746031
  Val Accuracy: 0.7777777910232544
{'train_loss': 0.649371325969696, 'val_roc_auc': 0.6031746031746031, 'val_accuracy': 0.7777777910232544, 'val_loss': 0.7709816694259644}
 ROC_AUC: 0.6032|| Accuracy 0.7778 || Train Loss: 0.6494
 Val Loss: 0.7710 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7092696374721741
Test ROC-AUC: 0.8717532467532468
Test Accuracy: 0.7865168539325843
test_loss: 0.7092696374721741
test_roc_auc: 0.8717532467532468
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6764650344848633
  Validation Loss: 0.689803957939148
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6777548342943192
  Validation Loss: 0.6895685791969299
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6747111976146698
  Validation Loss: 0.6892935037612915
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6790265142917633
  Validation Loss: 0.6890702247619629
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.676122710108757
  Validation Loss: 0.6887567639350891
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.675985649228096
  Validation Loss: 0.6883739233016968
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6734934896230698
  Validation Loss: 0.6879552006721497
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6663577407598495
  Validation Loss: 0.6875537633895874
  Val ROC-AUC: 0.8411764705882353
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6812111437320709
  Validation Loss: 0.6871548891067505
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.65962715446949
  Validation Loss: 0.6868040561676025
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6612964123487473
  Validation Loss: 0.6864492893218994
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6709806770086288
  Validation Loss: 0.686207115650177
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6731550991535187
  Validation Loss: 0.6859964728355408
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6749856323003769
  Validation Loss: 0.6857777237892151
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6693822592496872
  Validation Loss: 0.6854933500289917
  Val ROC-AUC: 0.8529411764705882
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6633256673812866
  Validation Loss: 0.6852325201034546
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6758666187524796
  Validation Loss: 0.6849474310874939
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6666713058948517
  Validation Loss: 0.6846207976341248
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6705625504255295
  Validation Loss: 0.6842630505561829
  Val ROC-AUC: 0.8470588235294118
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6640578210353851
  Validation Loss: 0.6838544011116028
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6685623675584793
  Validation Loss: 0.6834732890129089
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.678638681769371
  Validation Loss: 0.6830370426177979
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6622973531484604
  Validation Loss: 0.6826633810997009
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6702278703451157
  Validation Loss: 0.6823641657829285
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6766547709703445
  Validation Loss: 0.6821454167366028
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6652798056602478
  Validation Loss: 0.6819414496421814
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6741266697645187
  Validation Loss: 0.6816716194152832
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6611663103103638
  Validation Loss: 0.6814364194869995
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6682033687829971
  Validation Loss: 0.6812296509742737
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.657596543431282
  Validation Loss: 0.6810526251792908
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6588154286146164
  Validation Loss: 0.6808992624282837
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6765853017568588
  Validation Loss: 0.6807821393013
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6674567312002182
  Validation Loss: 0.6806341409683228
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6635255962610245
  Validation Loss: 0.6804322004318237
  Val ROC-AUC: 0.8588235294117647
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:02:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:02:INFO:
[92mINFO [0m:      Received: evaluate message 10729c47-f73d-4c88-b5d7-4c71a8487507
02/07/2025 22:35:02:INFO:Received: evaluate message 10729c47-f73d-4c88-b5d7-4c71a8487507
[92mINFO [0m:      Sent reply
02/07/2025 22:35:03:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:03:INFO:
[92mINFO [0m:      Received: train message c9861537-1c3d-43a0-8ddc-3156af061ed9
02/07/2025 22:35:03:INFO:Received: train message c9861537-1c3d-43a0-8ddc-3156af061ed9
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6689424365758896
  Validation Loss: 0.6801521182060242
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6694980561733246
  Validation Loss: 0.679916501045227
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.664609357714653
  Validation Loss: 0.6797575950622559
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6716998964548111
  Validation Loss: 0.679519534111023
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6595791578292847
  Validation Loss: 0.6792721152305603
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6702192723751068
  Validation Loss: 0.6789841055870056
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6646520495414734
  Validation Loss: 0.6787077784538269
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6715360283851624
  Validation Loss: 0.6785111427307129
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6626034826040268
  Validation Loss: 0.6783715486526489
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6678411215543747
  Validation Loss: 0.6783110499382019
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6601803600788116
  Validation Loss: 0.6782695651054382
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6576945036649704
  Validation Loss: 0.6781302690505981
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6717872619628906
  Validation Loss: 0.6779395341873169
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6691840887069702
  Validation Loss: 0.6776803135871887
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6688220798969269
  Validation Loss: 0.6773790717124939
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6657619774341583
  Validation Loss: 0.677045464515686
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6633972376585007
  Validation Loss: 0.6767008900642395
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6718787103891373
  Validation Loss: 0.6764301657676697
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.649206206202507
  Validation Loss: 0.6762151122093201
  Val ROC-AUC: 0.8588235294117647
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.654015839099884
  Validation Loss: 0.6760069131851196
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6634162068367004
  Validation Loss: 0.6758198738098145
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6618403643369675
  Validation Loss: 0.6755821704864502
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.653494119644165
  Validation Loss: 0.675279974937439
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6761703938245773
  Validation Loss: 0.675001859664917
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6524872332811356
  Validation Loss: 0.6747550368309021
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6621903479099274
  Validation Loss: 0.6745768785476685
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6542591452598572
  Validation Loss: 0.67442786693573
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6600013077259064
  Validation Loss: 0.6742483377456665
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6527999341487885
  Validation Loss: 0.674066960811615
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6591552048921585
  Validation Loss: 0.6739054918289185
  Val ROC-AUC: 0.8647058823529411
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6591552048921585, 'val_roc_auc': 0.8647058823529411, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6739054918289185}
 ROC_AUC: 0.8647|| Accuracy 0.8889 || Train Loss: 0.6592
 Val Loss: 0.6739 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7066454184189271
Test ROC-AUC: 0.875
Test Accuracy: 0.7865168539325843
test_loss: 0.7066454184189271
test_roc_auc: 0.875
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6568913757801056
  Validation Loss: 0.6927924752235413
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6836348921060562
  Validation Loss: 0.6925507187843323
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6821175664663315
  Validation Loss: 0.6924429535865784
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6684525310993195
  Validation Loss: 0.6922085881233215
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6648615598678589
  Validation Loss: 0.6920594573020935
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6788209825754166
  Validation Loss: 0.6919383406639099
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6733041107654572
  Validation Loss: 0.6918248534202576
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6681714206933975
  Validation Loss: 0.691679060459137
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6721706390380859
  Validation Loss: 0.6914752721786499
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6684885770082474
  Validation Loss: 0.6912479996681213
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6652649343013763
  Validation Loss: 0.6910770535469055
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6651530861854553
  Validation Loss: 0.6909757852554321
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6769195795059204
  Validation Loss: 0.690841555595398
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6774589717388153
  Validation Loss: 0.6906872391700745
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6781761199235916
  Validation Loss: 0.690597653388977
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6687674522399902
  Validation Loss: 0.6905105113983154
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6701358407735825
  Validation Loss: 0.6904346346855164
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6695833504199982
  Validation Loss: 0.6903427839279175
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6744678020477295
  Validation Loss: 0.690109133720398
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.665208712220192
  Validation Loss: 0.6897353529930115
  Val ROC-AUC: 0.9691358024691358
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:07:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:08:INFO:
[92mINFO [0m:      Received: evaluate message ee856ece-a568-446c-b00c-e9da10c2d6c8
02/07/2025 22:35:08:INFO:Received: evaluate message ee856ece-a568-446c-b00c-e9da10c2d6c8
[92mINFO [0m:      Sent reply
02/07/2025 22:35:09:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:09:INFO:
[92mINFO [0m:      Received: train message 2111c2e4-7b14-4c66-bd49-8181ed8207ed
02/07/2025 22:35:09:INFO:Received: train message 2111c2e4-7b14-4c66-bd49-8181ed8207ed
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6688509434461594
  Validation Loss: 0.6892622709274292
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6658000349998474
  Validation Loss: 0.6887786388397217
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6668826788663864
  Validation Loss: 0.6883864402770996
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6819633841514587
  Validation Loss: 0.6880813837051392
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.662515327334404
  Validation Loss: 0.6878475546836853
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6675256341695786
  Validation Loss: 0.6877104043960571
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6713300496339798
  Validation Loss: 0.6875912547111511
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.665413573384285
  Validation Loss: 0.687467098236084
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6646776646375656
  Validation Loss: 0.687376081943512
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.67667655646801
  Validation Loss: 0.6872171759605408
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6675916165113449
  Validation Loss: 0.687088131904602
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6695639938116074
  Validation Loss: 0.6869983077049255
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6665138304233551
  Validation Loss: 0.6868969202041626
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6638202518224716
  Validation Loss: 0.6867343187332153
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.673614501953125
  Validation Loss: 0.6864668130874634
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6680915802717209
  Validation Loss: 0.6862038373947144
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.66701640188694
  Validation Loss: 0.6859747171401978
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6731141060590744
  Validation Loss: 0.6857920289039612
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6683077216148376
  Validation Loss: 0.6856597661972046
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6676789224147797
  Validation Loss: 0.6855724453926086
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6659648418426514
  Validation Loss: 0.6855420470237732
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6748304665088654
  Validation Loss: 0.6854134798049927
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6530231684446335
  Validation Loss: 0.6852555274963379
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6614463925361633
  Validation Loss: 0.6849913001060486
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6747834980487823
  Validation Loss: 0.6848735809326172
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6703360825777054
  Validation Loss: 0.684805691242218
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6754510700702667
  Validation Loss: 0.6847648620605469
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6570755839347839
  Validation Loss: 0.684770941734314
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6669742912054062
  Validation Loss: 0.6847705841064453
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6638853251934052
  Validation Loss: 0.6846405863761902
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6607950925827026
  Validation Loss: 0.6845096945762634
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6602016687393188
  Validation Loss: 0.6843875646591187
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6723397374153137
  Validation Loss: 0.6842575073242188
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6551913768053055
  Validation Loss: 0.6841320395469666
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6661907136440277
  Validation Loss: 0.6840373873710632
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6648637354373932
  Validation Loss: 0.6839076280593872
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6560042649507523
  Validation Loss: 0.6836755871772766
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6744818240404129
  Validation Loss: 0.6834676861763
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6680509597063065
  Validation Loss: 0.6832298040390015
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6565125584602356
  Validation Loss: 0.6829987168312073
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6552138030529022
  Validation Loss: 0.6828439831733704
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.666158065199852
  Validation Loss: 0.6826808452606201
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6592150777578354
  Validation Loss: 0.6825634837150574
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6633603721857071
  Validation Loss: 0.682374894618988
  Val ROC-AUC: 0.9691358024691358
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6633603721857071, 'val_roc_auc': 0.9691358024691358, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.682374894618988}
 ROC_AUC: 0.9691|| Accuracy 0.8889 || Train Loss: 0.6634
 Val Loss: 0.6824 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7043048759524742
Test ROC-AUC: 0.8782467532467532
Test Accuracy: 0.7865168539325843
test_loss: 0.7043048759524742
test_roc_auc: 0.8782467532467532
test_accuracy: 0.7865168539325843
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.652272030711174
  Validation Loss: 0.7093697786331177
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6651618182659149
  Validation Loss: 0.7089250683784485
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6604418605566025
  Validation Loss: 0.7086254954338074
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6673529297113419
  Validation Loss: 0.7083751559257507
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6653027236461639
  Validation Loss: 0.7079847455024719
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6605513542890549
  Validation Loss: 0.7075684070587158
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6703218370676041
  Validation Loss: 0.7072643637657166
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6562703102827072
  Validation Loss: 0.7070236802101135
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6555257439613342
  Validation Loss: 0.706810712814331
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6497717350721359
  Validation Loss: 0.706581711769104
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6520193815231323
  Validation Loss: 0.7064467668533325
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6531659364700317
  Validation Loss: 0.7064155340194702
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6640893071889877
  Validation Loss: 0.7063604593276978
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6620128750801086
  Validation Loss: 0.7062434554100037
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6646260172128677
  Validation Loss: 0.7060511708259583
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6623650640249252
  Validation Loss: 0.705806314945221
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6548320204019547
  Validation Loss: 0.7056872248649597
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6611512899398804
  Validation Loss: 0.7055948376655579
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6610313355922699
  Validation Loss: 0.7054935097694397
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6575086265802383
  Validation Loss: 0.7053925395011902
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6604246348142624
  Validation Loss: 0.7051478028297424
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6458355933427811
  Validation Loss: 0.7049155235290527
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6547224372625351
  Validation Loss: 0.7047781944274902
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6653590053319931
  Validation Loss: 0.7046574950218201
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6592566668987274
  Validation Loss: 0.7045073509216309
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6544812172651291
  Validation Loss: 0.7043847441673279
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6616836190223694
  Validation Loss: 0.7043329477310181
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6572859734296799
  Validation Loss: 0.7042972445487976
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6570616811513901
  Validation Loss: 0.7043338418006897
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6516726166009903
  Validation Loss: 0.7043472528457642
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6474746912717819
  Validation Loss: 0.7043730020523071
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6639804840087891
  Validation Loss: 0.704335629940033
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.660646915435791
  Validation Loss: 0.7043392658233643
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6500964611768723
  Validation Loss: 0.7043544054031372
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6537268161773682
  Validation Loss: 0.7043513655662537
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.655108630657196
  Validation Loss: 0.7042574286460876
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6638927757740021
  Validation Loss: 0.7041652798652649
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6576211005449295
  Validation Loss: 0.7041211128234863
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6509899497032166
  Validation Loss: 0.7040505409240723
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6630527675151825
  Validation Loss: 0.7039366960525513
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6529144644737244
  Validation Loss: 0.7038019895553589
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6551063060760498
  Validation Loss: 0.7036247253417969
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6445506513118744
  Validation Loss: 0.7035301923751831
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6671821475028992
  Validation Loss: 0.7035288214683533
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.659085676074028
  Validation Loss: 0.7034913301467896
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6733038872480392
  Validation Loss: 0.7033634185791016
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6617938876152039
  Validation Loss: 0.7032298445701599
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6533802449703217
  Validation Loss: 0.703083872795105
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6425348222255707
  Validation Loss: 0.7029522657394409
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6675846874713898
  Validation Loss: 0.7027815580368042
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6598068624734879
  Validation Loss: 0.7026565074920654
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6565837413072586
  Validation Loss: 0.7025386691093445
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6623261272907257
  Validation Loss: 0.7024257779121399
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6606446504592896
  Validation Loss: 0.7023482322692871
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6615968197584152
  Validation Loss: 0.7023870944976807
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6589959561824799
  Validation Loss: 0.7022789716720581
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6534234881401062
  Validation Loss: 0.7021068930625916
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6557256728410721
  Validation Loss: 0.7020021677017212
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6498034745454788
  Validation Loss: 0.7019099593162537
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:13:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:15:INFO:
[92mINFO [0m:      Received: evaluate message eb884b7b-1cb4-4236-961e-e8b9373a90b3
02/07/2025 22:35:15:INFO:Received: evaluate message eb884b7b-1cb4-4236-961e-e8b9373a90b3
[92mINFO [0m:      Sent reply
02/07/2025 22:35:16:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:16:INFO:
[92mINFO [0m:      Received: train message f28f7231-4357-4f35-ad4d-3cb3e914230e
02/07/2025 22:35:16:INFO:Received: train message f28f7231-4357-4f35-ad4d-3cb3e914230e
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6516553461551666
  Validation Loss: 0.701732337474823
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6602082699537277
  Validation Loss: 0.7015076875686646
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6542062908411026
  Validation Loss: 0.701287567615509
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6487777382135391
  Validation Loss: 0.7010924220085144
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6515145897865295
  Validation Loss: 0.700962483882904
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6515145897865295, 'val_roc_auc': 0.9868421052631579, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.700962483882904}
 ROC_AUC: 0.9868|| Accuracy 0.8889 || Train Loss: 0.6515
 Val Loss: 0.7010 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7022464151462812
Test ROC-AUC: 0.8777056277056278
Test Accuracy: 0.797752808988764
test_loss: 0.7022464151462812
test_roc_auc: 0.8777056277056278
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.673453688621521
  Validation Loss: 0.6809250116348267
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6703451573848724
  Validation Loss: 0.6806663870811462
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6716158241033554
  Validation Loss: 0.6803981065750122
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6617622226476669
  Validation Loss: 0.680081844329834
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6669881194829941
  Validation Loss: 0.6796683073043823
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6728346645832062
  Validation Loss: 0.6792944073677063
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6667046546936035
  Validation Loss: 0.6789422035217285
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6811658293008804
  Validation Loss: 0.6786133050918579
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.6716623157262802
  Validation Loss: 0.6782979369163513
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.6594147831201553
  Validation Loss: 0.6780699491500854
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.6534697115421295
  Validation Loss: 0.6778902411460876
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.6551989167928696
  Validation Loss: 0.6777807474136353
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.6664600372314453
  Validation Loss: 0.6776849031448364
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.6633486896753311
  Validation Loss: 0.6776022911071777
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6660881340503693
  Validation Loss: 0.6774818301200867
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.6649318486452103
  Validation Loss: 0.6772862076759338
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6555974036455154
  Validation Loss: 0.6771343350410461
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.6570767611265182
  Validation Loss: 0.6769588589668274
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6610683649778366
  Validation Loss: 0.6767356991767883
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6649208962917328
  Validation Loss: 0.6765475869178772
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6619323343038559
  Validation Loss: 0.6763735413551331
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.651916891336441
  Validation Loss: 0.6762425303459167
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.661487266421318
  Validation Loss: 0.6760724186897278
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6552200168371201
  Validation Loss: 0.6758959293365479
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6482884734869003
  Validation Loss: 0.6756052374839783
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.6556258946657181
  Validation Loss: 0.6753646731376648
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6595468074083328
  Validation Loss: 0.6751651167869568
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6686438173055649
  Validation Loss: 0.6751145720481873
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.6636296361684799
  Validation Loss: 0.6750803589820862
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6530875861644745
  Validation Loss: 0.6750707030296326
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6685711145401001
  Validation Loss: 0.6750545501708984
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6628382802009583
  Validation Loss: 0.6750357151031494
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6479776501655579
  Validation Loss: 0.6749312281608582
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6595900356769562
  Validation Loss: 0.6748298406600952
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.667387917637825
  Validation Loss: 0.6747005581855774
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6632476896047592
  Validation Loss: 0.6745163798332214
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.645901083946228
  Validation Loss: 0.6743879914283752
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.642575204372406
  Validation Loss: 0.674227774143219
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.6682901084423065
  Validation Loss: 0.6740378141403198
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6659484058618546
  Validation Loss: 0.6738114356994629
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6456636339426041
  Validation Loss: 0.6735844016075134
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6457410007715225
  Validation Loss: 0.673351526260376
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6624210178852081
  Validation Loss: 0.6732145547866821
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.6624865233898163
  Validation Loss: 0.6731601357460022
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6546579897403717
  Validation Loss: 0.6730899214744568
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6502723693847656
  Validation Loss: 0.6729521751403809
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6501500159502029
  Validation Loss: 0.67291259765625
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6490930914878845
  Validation Loss: 0.6729427576065063
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6640037447214127
  Validation Loss: 0.6729287505149841
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6638039201498032
  Validation Loss: 0.6728867292404175
  Val ROC-AUC: 1.0
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:23:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:24:INFO:
[92mINFO [0m:      Received: evaluate message aacceab3-37dc-4e34-a1c8-aa973afcd35f
02/07/2025 22:35:24:INFO:Received: evaluate message aacceab3-37dc-4e34-a1c8-aa973afcd35f
[92mINFO [0m:      Sent reply
02/07/2025 22:35:24:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:24:INFO:
[92mINFO [0m:      Received: train message 3a20a016-fe60-4019-9059-07641ee88d89
02/07/2025 22:35:24:INFO:Received: train message 3a20a016-fe60-4019-9059-07641ee88d89
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6443298906087875
  Validation Loss: 0.6727963089942932
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6514452397823334
  Validation Loss: 0.6726986765861511
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6624048799276352
  Validation Loss: 0.6725472807884216
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6339820921421051
  Validation Loss: 0.6723774075508118
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6600882112979889
  Validation Loss: 0.6722556352615356
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6538705080747604
  Validation Loss: 0.6721510291099548
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6545771956443787
  Validation Loss: 0.6720832586288452
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6648851335048676
  Validation Loss: 0.6720495820045471
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6607348173856735
  Validation Loss: 0.6720229983329773
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.649291068315506
  Validation Loss: 0.6719843745231628
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6644986122846603
  Validation Loss: 0.6719027161598206
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6577950417995453
  Validation Loss: 0.6718823313713074
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6574514359235764
  Validation Loss: 0.6718751192092896
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.6511584371328354
  Validation Loss: 0.6718379855155945
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.6511584371328354, 'val_roc_auc': 1.0, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.6718379855155945}
 ROC_AUC: 1.0000|| Accuracy 0.9630 || Train Loss: 0.6512
 Val Loss: 0.6718 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.7004564943608274
Test ROC-AUC: 0.8793290043290043
Test Accuracy: 0.797752808988764
test_loss: 0.7004564943608274
test_roc_auc: 0.8793290043290043
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6682977080345154
  Validation Loss: 0.6991427540779114
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.6507751792669296
  Validation Loss: 0.6988358497619629
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.6748868227005005
  Validation Loss: 0.6985854506492615
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.6608162820339203
  Validation Loss: 0.6983105540275574
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.6602126508951187
  Validation Loss: 0.6981028914451599
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.655816376209259
  Validation Loss: 0.6979610323905945
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.6659326255321503
  Validation Loss: 0.6977387070655823
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.6575735658407211
  Validation Loss: 0.6975060701370239
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.6665255427360535
  Validation Loss: 0.6972996592521667
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.6644255071878433
  Validation Loss: 0.6970526576042175
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.6533933132886887
  Validation Loss: 0.6968298554420471
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.6550539433956146
  Validation Loss: 0.6965813636779785
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.6644014120101929
  Validation Loss: 0.6963908076286316
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.6523505002260208
  Validation Loss: 0.696165144443512
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.669251099228859
  Validation Loss: 0.695907473564148
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.6527461409568787
  Validation Loss: 0.6957098841667175
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.654911607503891
  Validation Loss: 0.6955047845840454
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.6560970544815063
  Validation Loss: 0.6952812075614929
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.6658236980438232
  Validation Loss: 0.6950771808624268
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.6495411247014999
  Validation Loss: 0.6948918700218201
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.6513962745666504
  Validation Loss: 0.6946941614151001
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.6624292135238647
  Validation Loss: 0.6945155262947083
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.6462059170007706
  Validation Loss: 0.6942830085754395
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.6499359905719757
  Validation Loss: 0.694058895111084
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.64446821808815
  Validation Loss: 0.6938986778259277
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.660841315984726
  Validation Loss: 0.6937193870544434
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6498087048530579
  Validation Loss: 0.6934940218925476
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6550662815570831
  Validation Loss: 0.6933424472808838
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6525043547153473
  Validation Loss: 0.6932357549667358
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.65325066447258
  Validation Loss: 0.6930492520332336
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6614660918712616
  Validation Loss: 0.6928503513336182
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6624128818511963
  Validation Loss: 0.6926434636116028
  Val ROC-AUC: 0.9197530864197531
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6524788588285446
  Validation Loss: 0.6924908757209778
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6454182416200638
  Validation Loss: 0.6923686861991882
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6596627086400986
  Validation Loss: 0.692245602607727
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.6519762724637985
  Validation Loss: 0.6921966671943665
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6486656367778778
  Validation Loss: 0.6921659708023071
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:36:INFO:
[92mINFO [0m:      Received: evaluate message cbdc2ce6-80d3-4858-a541-734d6575b24f
02/07/2025 22:35:36:INFO:Received: evaluate message cbdc2ce6-80d3-4858-a541-734d6575b24f
[92mINFO [0m:      Sent reply
02/07/2025 22:35:36:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:36:INFO:
[92mINFO [0m:      Received: train message d459e187-0755-4e14-a1b7-247767c642ca
02/07/2025 22:35:36:INFO:Received: train message d459e187-0755-4e14-a1b7-247767c642ca
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6544215977191925
  Validation Loss: 0.6920619010925293
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6450289487838745
  Validation Loss: 0.6919013261795044
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6551665514707565
  Validation Loss: 0.6917400360107422
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6589122414588928
  Validation Loss: 0.691604495048523
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6482739895582199
  Validation Loss: 0.6914886236190796
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6661034524440765
  Validation Loss: 0.6913796663284302
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6607842147350311
  Validation Loss: 0.6912488341331482
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.6405749619007111
  Validation Loss: 0.691081166267395
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6603266298770905
  Validation Loss: 0.6909013986587524
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.6401109546422958
  Validation Loss: 0.6907171607017517
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.6463740319013596
  Validation Loss: 0.690578281879425
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.6465982645750046
  Validation Loss: 0.6904419660568237
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.6539811342954636
  Validation Loss: 0.6903438568115234
  Val ROC-AUC: 0.925925925925926
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.655863493680954
  Validation Loss: 0.6902205944061279
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6349316537380219
  Validation Loss: 0.6901208162307739
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.6517250686883926
  Validation Loss: 0.6900262236595154
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.6448312103748322
  Validation Loss: 0.6899290680885315
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.6473595798015594
  Validation Loss: 0.6898372769355774
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.652052104473114
  Validation Loss: 0.6897613406181335
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.6344259828329086
  Validation Loss: 0.6897020936012268
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.6559400111436844
  Validation Loss: 0.6896360516548157
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.6598152071237564
  Validation Loss: 0.6895114779472351
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6475254744291306
  Validation Loss: 0.6893980503082275
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.658611610531807
  Validation Loss: 0.6892818808555603
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.6534625589847565
  Validation Loss: 0.6891807317733765
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.6612082570791245
  Validation Loss: 0.6890237927436829
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.6435378938913345
  Validation Loss: 0.6888195276260376
  Val ROC-AUC: 0.9320987654320988
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.6435378938913345, 'val_roc_auc': 0.9320987654320988, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.6888195276260376}
 ROC_AUC: 0.9321|| Accuracy 0.8148 || Train Loss: 0.6435
 Val Loss: 0.6888 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6988352178857568
Test ROC-AUC: 0.8809523809523809
Test Accuracy: 0.797752808988764
test_loss: 0.6988352178857568
test_roc_auc: 0.8809523809523809
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6829197108745575
  Validation Loss: 0.6266915202140808
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6876958310604095
  Validation Loss: 0.6264643669128418
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6727425754070282
  Validation Loss: 0.6263467073440552
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6752808392047882
  Validation Loss: 0.62611985206604
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6722774505615234
  Validation Loss: 0.6259952783584595
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6642664968967438
  Validation Loss: 0.625853955745697
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6770467460155487
  Validation Loss: 0.6256493330001831
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6678760051727295
  Validation Loss: 0.6254132390022278
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6689600795507431
  Validation Loss: 0.6252083778381348
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6753550916910172
  Validation Loss: 0.62498939037323
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6865338087081909
  Validation Loss: 0.6247577667236328
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6788459420204163
  Validation Loss: 0.6245535612106323
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6681758314371109
  Validation Loss: 0.6244152188301086
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6733835637569427
  Validation Loss: 0.6242937445640564
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6778884530067444
  Validation Loss: 0.6241461038589478
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6803901642560959
  Validation Loss: 0.6240153908729553
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6682485193014145
  Validation Loss: 0.6238986253738403
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6626395136117935
  Validation Loss: 0.6238608360290527
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6837347000837326
  Validation Loss: 0.6238095164299011
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.6721079498529434
  Validation Loss: 0.6237555146217346
  Val ROC-AUC: 0.9444444444444444
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6716697067022324
  Validation Loss: 0.623737633228302
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6779503524303436
  Validation Loss: 0.6237178444862366
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.6651708036661148
  Validation Loss: 0.6236481666564941
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:44:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:48:INFO:
[92mINFO [0m:      Received: evaluate message 4fc84fc1-125e-48e4-a684-9eeadda4fb92
02/07/2025 22:35:48:INFO:Received: evaluate message 4fc84fc1-125e-48e4-a684-9eeadda4fb92
[92mINFO [0m:      Sent reply
02/07/2025 22:35:48:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:35:48:INFO:
[92mINFO [0m:      Received: train message 34f3c61b-e119-4dbb-9f3d-fcb878040722
02/07/2025 22:35:48:INFO:Received: train message 34f3c61b-e119-4dbb-9f3d-fcb878040722
  Train Loss: 0.6728928834199905
  Validation Loss: 0.62353515625
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6657006293535233
  Validation Loss: 0.623481810092926
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.663576602935791
  Validation Loss: 0.6233530640602112
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.6822531223297119
  Validation Loss: 0.6232414245605469
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6718083918094635
  Validation Loss: 0.623195469379425
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6709664016962051
  Validation Loss: 0.6230732798576355
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6737566441297531
  Validation Loss: 0.6229433417320251
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6873330771923065
  Validation Loss: 0.6228039860725403
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6649354547262192
  Validation Loss: 0.6226626038551331
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.6611945033073425
  Validation Loss: 0.6224716305732727
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6907652169466019
  Validation Loss: 0.6223686337471008
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6750972867012024
  Validation Loss: 0.6222801804542542
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.6781148463487625
  Validation Loss: 0.6222152709960938
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6667677611112595
  Validation Loss: 0.6221935153007507
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6742092370986938
  Validation Loss: 0.6220899820327759
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6646109372377396
  Validation Loss: 0.6219215393066406
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6749075800180435
  Validation Loss: 0.6217026710510254
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6773402839899063
  Validation Loss: 0.621461033821106
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6664531379938126
  Validation Loss: 0.6212752461433411
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.6664681136608124
  Validation Loss: 0.6211684942245483
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6827006489038467
  Validation Loss: 0.6210804581642151
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6709255427122116
  Validation Loss: 0.6210335493087769
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6772127449512482
  Validation Loss: 0.6209716200828552
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.674027144908905
  Validation Loss: 0.6208712458610535
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.670070230960846
  Validation Loss: 0.6208341717720032
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6708341687917709
  Validation Loss: 0.6208686828613281
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.672670841217041
  Validation Loss: 0.6208205223083496
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6671709716320038
  Validation Loss: 0.6207615733146667
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6847692131996155
  Validation Loss: 0.6205883622169495
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.6766922622919083
  Validation Loss: 0.6204591989517212
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.6555511802434921
  Validation Loss: 0.6202822923660278
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.6661631166934967
  Validation Loss: 0.6201088428497314
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6681764721870422
  Validation Loss: 0.6199584007263184
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6805733144283295
  Validation Loss: 0.6198161840438843
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6682392209768295
  Validation Loss: 0.6196649670600891
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.665551632642746
  Validation Loss: 0.6194590926170349
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6733861416578293
  Validation Loss: 0.6192929148674011
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6689642071723938
  Validation Loss: 0.6191791892051697
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6656444370746613
  Validation Loss: 0.6191211342811584
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6767195016145706
  Validation Loss: 0.6189931035041809
  Val ROC-AUC: 0.95
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.6797597408294678
  Validation Loss: 0.6187971234321594
  Val ROC-AUC: 0.9555555555555556
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.6797597408294678, 'val_roc_auc': 0.9555555555555556, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6187971234321594}
 ROC_AUC: 0.9556|| Accuracy 0.9259 || Train Loss: 0.6798
 Val Loss: 0.6188 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6973753591601768
Test ROC-AUC: 0.8820346320346321
Test Accuracy: 0.797752808988764
test_loss: 0.6973753591601768
test_roc_auc: 0.8820346320346321
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6764020770788193
  Validation Loss: 0.628762423992157
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 2/64:
  Train Loss: 0.6752203404903412
  Validation Loss: 0.6283961534500122
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 3/64:
  Train Loss: 0.6772433072328568
  Validation Loss: 0.6280534863471985
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 4/64:
  Train Loss: 0.6730023622512817
  Validation Loss: 0.627791166305542
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 5/64:
  Train Loss: 0.6753046363592148
  Validation Loss: 0.6275912523269653
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 6/64:
  Train Loss: 0.674251452088356
  Validation Loss: 0.6273684501647949
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 7/64:
  Train Loss: 0.6635114848613739
  Validation Loss: 0.6271718144416809
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 8/64:
  Train Loss: 0.6748763769865036
  Validation Loss: 0.6270323991775513
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 9/64:
  Train Loss: 0.6773346811532974
  Validation Loss: 0.6268649697303772
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 10/64:
  Train Loss: 0.6683437824249268
  Validation Loss: 0.6266981363296509
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 11/64:
  Train Loss: 0.6685986816883087
  Validation Loss: 0.6265760660171509
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 12/64:
  Train Loss: 0.6650221794843674
  Validation Loss: 0.6263994574546814
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 13/64:
  Train Loss: 0.676549032330513
  Validation Loss: 0.6262251138687134
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 14/64:
  Train Loss: 0.666320875287056
  Validation Loss: 0.6260274052619934
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 15/64:
  Train Loss: 0.6651088893413544
  Validation Loss: 0.6258096098899841
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 16/64:
  Train Loss: 0.6702415496110916
  Validation Loss: 0.6256098747253418
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 17/64:
  Train Loss: 0.6745995879173279
  Validation Loss: 0.6254367232322693
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 18/64:
  Train Loss: 0.6806607991456985
  Validation Loss: 0.6252425312995911
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 19/64:
  Train Loss: 0.6687663048505783
  Validation Loss: 0.6250743269920349
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 20/64:
  Train Loss: 0.6761845052242279
  Validation Loss: 0.6248837113380432
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 21/64:
  Train Loss: 0.6648042052984238
  Validation Loss: 0.6247155070304871
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 22/64:
  Train Loss: 0.6644433885812759
  Validation Loss: 0.6245466470718384
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 23/64:
  Train Loss: 0.6709106266498566
  Validation Loss: 0.6242653131484985
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 24/64:
  Train Loss: 0.6800198704004288
  Validation Loss: 0.6240234971046448
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 25/64:
  Train Loss: 0.6628372222185135
  Validation Loss: 0.6238701343536377
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 26/64:
  Train Loss: 0.6670626252889633
  Validation Loss: 0.6237543225288391
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 27/64:
  Train Loss: 0.6801833063364029
  Validation Loss: 0.6235594153404236
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 28/64:
  Train Loss: 0.6765562444925308
  Validation Loss: 0.6233760118484497
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 29/64:
  Train Loss: 0.6533911973237991
  Validation Loss: 0.6232060790061951
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 30/64:
  Train Loss: 0.6764105409383774
  Validation Loss: 0.6230239868164062
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 31/64:
  Train Loss: 0.6693974733352661
  Validation Loss: 0.6228359937667847
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8518518805503845
Epoch 32/64:
  Train Loss: 0.6661224812269211
  Validation Loss: 0.6226891279220581
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6624221801757812
  Validation Loss: 0.6225858926773071
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6819542050361633
  Validation Loss: 0.6224604845046997
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6614765971899033
  Validation Loss: 0.62227863073349
  Val ROC-AUC: 0.9722222222222223
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.6716917902231216
  Validation Loss: 0.6221781373023987
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6698047816753387
  Validation Loss: 0.6220038533210754
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6745705008506775
  Validation Loss: 0.6217792630195618
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6738860160112381
  Validation Loss: 0.6216029524803162
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.665168046951294
  Validation Loss: 0.6214438080787659
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6736787110567093
  Validation Loss: 0.6213217973709106
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6686826348304749
  Validation Loss: 0.6212002635002136
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6712352335453033
  Validation Loss: 0.6210678219795227
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.661724254488945
  Validation Loss: 0.6209719777107239
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6745187789201736
  Validation Loss: 0.6208794116973877
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6706914454698563
  Validation Loss: 0.6207812428474426
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6632198691368103
  Validation Loss: 0.6206996440887451
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6676155626773834
  Validation Loss: 0.6206251382827759
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6767204999923706
  Validation Loss: 0.6205702424049377
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6788484901189804
  Validation Loss: 0.6204516291618347
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6773184090852737
  Validation Loss: 0.6203036904335022
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6569622159004211
  Validation Loss: 0.620159387588501
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6583440452814102
  Validation Loss: 0.6200462579727173
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6645928621292114
  Validation Loss: 0.6199602484703064
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6747944504022598
  Validation Loss: 0.6198391318321228
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.675917387008667
  Validation Loss: 0.6196235418319702
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6620037853717804
  Validation Loss: 0.619375467300415
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6751936823129654
  Validation Loss: 0.619178831577301
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6665737926959991
  Validation Loss: 0.6191028952598572
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6652332097291946
  Validation Loss: 0.6190069317817688
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.663681834936142
  Validation Loss: 0.6189000010490417
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6656145304441452
  Validation Loss: 0.6187412738800049
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6663058996200562
  Validation Loss: 0.6185336112976074
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6696992367506027
  Validation Loss: 0.6183434724807739
  Val ROC-AUC: 0.9777777777777779
  Val Accuracy: 0.8888888955116272
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:35:58:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:00:INFO:
[92mINFO [0m:      Received: evaluate message 512f82e5-3fbe-4908-bc42-e38f722e1300
02/07/2025 22:36:00:INFO:Received: evaluate message 512f82e5-3fbe-4908-bc42-e38f722e1300
[92mINFO [0m:      Sent reply
02/07/2025 22:36:03:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:03:INFO:
[92mINFO [0m:      Received: train message 2ded28c0-cc3c-43c4-b4bb-c13cedf95f82
02/07/2025 22:36:03:INFO:Received: train message 2ded28c0-cc3c-43c4-b4bb-c13cedf95f82
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
{'train_loss': 0.6696992367506027, 'val_roc_auc': 0.9777777777777779, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6183434724807739}
 ROC_AUC: 0.9778|| Accuracy 0.8889 || Train Loss: 0.6697
 Val Loss: 0.6183 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6960252925251307
Test ROC-AUC: 0.8809523809523809
Test Accuracy: 0.8089887640449438
test_loss: 0.6960252925251307
test_roc_auc: 0.8809523809523809
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6705595105886459
  Validation Loss: 0.6546528339385986
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6678643673658371
  Validation Loss: 0.6542423963546753
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6608588546514511
  Validation Loss: 0.6539645791053772
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6681924760341644
  Validation Loss: 0.6537405252456665
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6652229279279709
  Validation Loss: 0.6535057425498962
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6598822325468063
  Validation Loss: 0.6532057523727417
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6729356199502945
  Validation Loss: 0.6528266072273254
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6619545519351959
  Validation Loss: 0.6525114178657532
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6634006351232529
  Validation Loss: 0.6522741913795471
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6653539687395096
  Validation Loss: 0.6520587205886841
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6705188900232315
  Validation Loss: 0.651872992515564
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6587084978818893
  Validation Loss: 0.6517489552497864
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6654778271913528
  Validation Loss: 0.6516318321228027
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6692592352628708
  Validation Loss: 0.6514626145362854
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6651212573051453
  Validation Loss: 0.6513451337814331
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.6504012793302536
  Validation Loss: 0.6512898802757263
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6596780717372894
  Validation Loss: 0.651252806186676
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6615073382854462
  Validation Loss: 0.6511709690093994
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.660797581076622
  Validation Loss: 0.6510599255561829
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.673302412033081
  Validation Loss: 0.6510096192359924
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6629335731267929
  Validation Loss: 0.650833785533905
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6565728336572647
  Validation Loss: 0.6505343317985535
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6534658968448639
  Validation Loss: 0.6501877307891846
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6631069183349609
  Validation Loss: 0.6499043107032776
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6648795455694199
  Validation Loss: 0.6497218608856201
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6775475442409515
  Validation Loss: 0.6495208144187927
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6532724797725677
  Validation Loss: 0.6492307782173157
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6682166904211044
  Validation Loss: 0.6490002274513245
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6551413089036942
  Validation Loss: 0.6488147377967834
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6617666333913803
  Validation Loss: 0.6486751437187195
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6638601422309875
  Validation Loss: 0.6484941840171814
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6551158577203751
  Validation Loss: 0.64822918176651
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6588846445083618
  Validation Loss: 0.6480490565299988
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6608904451131821
  Validation Loss: 0.6478955149650574
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6688347309827805
  Validation Loss: 0.6477496027946472
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.662942111492157
  Validation Loss: 0.6475802063941956
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6590497344732285
  Validation Loss: 0.6474052667617798
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6589380651712418
  Validation Loss: 0.6472464203834534
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6587720215320587
  Validation Loss: 0.6470808982849121
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6547697633504868
  Validation Loss: 0.6469566226005554
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6642279922962189
  Validation Loss: 0.64690101146698
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6664324551820755
  Validation Loss: 0.6468217968940735
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6614158004522324
  Validation Loss: 0.6466670632362366
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6630080044269562
  Validation Loss: 0.6464130282402039
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6664035767316818
  Validation Loss: 0.6461631655693054
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6695319265127182
  Validation Loss: 0.645987331867218
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6584513187408447
  Validation Loss: 0.6459221839904785
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6630084365606308
  Validation Loss: 0.6458605527877808
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6532890498638153
  Validation Loss: 0.6457328200340271
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.660751074552536
  Validation Loss: 0.6455470323562622
  Val ROC-AUC: 0.8863636363636364
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:12:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:13:INFO:
[92mINFO [0m:      Received: evaluate message 0455c8bd-03f7-4a08-8b24-7d5f839578cb
02/07/2025 22:36:13:INFO:Received: evaluate message 0455c8bd-03f7-4a08-8b24-7d5f839578cb
[92mINFO [0m:      Sent reply
02/07/2025 22:36:17:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:18:INFO:
[92mINFO [0m:      Received: train message 7b55196e-c45b-46dc-bbfb-a4ac309f10a6
02/07/2025 22:36:18:INFO:Received: train message 7b55196e-c45b-46dc-bbfb-a4ac309f10a6
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6567902863025665
  Validation Loss: 0.6453142762184143
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6571093648672104
  Validation Loss: 0.6450469493865967
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6531699299812317
  Validation Loss: 0.6448752284049988
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6579892188310623
  Validation Loss: 0.644764244556427
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6672955006361008
  Validation Loss: 0.644670844078064
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6508603692054749
  Validation Loss: 0.6446760892868042
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6570037454366684
  Validation Loss: 0.6447190642356873
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6599075794219971
  Validation Loss: 0.644655704498291
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6677488535642624
  Validation Loss: 0.6446568369865417
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6524057984352112
  Validation Loss: 0.6446787714958191
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 61/64:
  Train Loss: 0.6529626995325089
  Validation Loss: 0.6446468234062195
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 62/64:
  Train Loss: 0.6553501188755035
  Validation Loss: 0.6446475386619568
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 63/64:
  Train Loss: 0.6622119843959808
  Validation Loss: 0.6446235775947571
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
Epoch 64/64:
  Train Loss: 0.6556054204702377
  Validation Loss: 0.6446097493171692
  Val ROC-AUC: 0.8863636363636364
  Val Accuracy: 0.8888888955116272
{'train_loss': 0.6556054204702377, 'val_roc_auc': 0.8863636363636364, 'val_accuracy': 0.8888888955116272, 'val_loss': 0.6446097493171692}
 ROC_AUC: 0.8864|| Accuracy 0.8889 || Train Loss: 0.6556
 Val Loss: 0.6446 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6948041581036
Test ROC-AUC: 0.880952380952381
Test Accuracy: 0.797752808988764
test_loss: 0.6948041581036
test_roc_auc: 0.880952380952381
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6701725721359253
  Validation Loss: 0.6369684338569641
  Val ROC-AUC: 0.9431818181818181
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6690035313367844
  Validation Loss: 0.6366345286369324
  Val ROC-AUC: 0.9431818181818181
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
  Train Loss: 0.6680519729852676
  Validation Loss: 0.6364840865135193
  Val ROC-AUC: 0.9431818181818181
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.6628827303647995
  Validation Loss: 0.636343777179718
  Val ROC-AUC: 0.9431818181818181
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6744321435689926
  Validation Loss: 0.6362116932868958
  Val ROC-AUC: 0.9431818181818181
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6550325602293015
  Validation Loss: 0.6360741257667542
  Val ROC-AUC: 0.9431818181818181
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6703146696090698
  Validation Loss: 0.6359525918960571
  Val ROC-AUC: 0.9431818181818181
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6739515364170074
  Validation Loss: 0.6358001232147217
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6660598516464233
  Validation Loss: 0.6356850862503052
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6603420078754425
  Validation Loss: 0.6355445384979248
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6652129143476486
  Validation Loss: 0.6353895664215088
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.670163944363594
  Validation Loss: 0.6352734565734863
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6685359328985214
  Validation Loss: 0.635142982006073
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6778985857963562
  Validation Loss: 0.6349695324897766
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6657832860946655
  Validation Loss: 0.6348015069961548
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.657684251666069
  Validation Loss: 0.6345744729042053
  Val ROC-AUC: 0.9488636363636364
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6573753654956818
  Validation Loss: 0.6343337297439575
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6635840386152267
  Validation Loss: 0.634158194065094
  Val ROC-AUC: 0.9545454545454546
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6603804230690002
  Validation Loss: 0.6340447664260864
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6709262132644653
  Validation Loss: 0.6339298486709595
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6792349070310593
  Validation Loss: 0.6337525248527527
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.6571732014417648
  Validation Loss: 0.6335922479629517
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.663853719830513
  Validation Loss: 0.63340824842453
  Val ROC-AUC: 0.9602272727272727
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6698938310146332
  Validation Loss: 0.6332519054412842
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6607731133699417
  Validation Loss: 0.6331137418746948
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6742130666971207
  Validation Loss: 0.6329268217086792
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6682592779397964
  Validation Loss: 0.6327738165855408
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6590796858072281
  Validation Loss: 0.6326522827148438
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6604673117399216
  Validation Loss: 0.6324752569198608
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6640212088823318
  Validation Loss: 0.6322859525680542
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6574452519416809
  Validation Loss: 0.6321111917495728
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6590112596750259
  Validation Loss: 0.6320356726646423
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6694980412721634
  Validation Loss: 0.6319244503974915
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6600994616746902
  Validation Loss: 0.6318194270133972
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6716239601373672
  Validation Loss: 0.6317092180252075
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.663680225610733
  Validation Loss: 0.631613552570343
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:27:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:29:INFO:
[92mINFO [0m:      Received: evaluate message 7faa3a6a-e81c-44a4-8af5-3da46649314c
02/07/2025 22:36:29:INFO:Received: evaluate message 7faa3a6a-e81c-44a4-8af5-3da46649314c
[92mINFO [0m:      Sent reply
02/07/2025 22:36:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:30:INFO:
[92mINFO [0m:      Received: train message cd36e476-c94d-45ba-897e-31bf1583dbf4
02/07/2025 22:36:30:INFO:Received: train message cd36e476-c94d-45ba-897e-31bf1583dbf4
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.665464386343956
  Validation Loss: 0.6314846873283386
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.6669830828905106
  Validation Loss: 0.6313603520393372
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6677237749099731
  Validation Loss: 0.6312046647071838
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6705613732337952
  Validation Loss: 0.6311171650886536
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6648907214403152
  Validation Loss: 0.6310286521911621
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6710276156663895
  Validation Loss: 0.6309522986412048
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.657550498843193
  Validation Loss: 0.6308863759040833
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6645343154668808
  Validation Loss: 0.6308028101921082
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6688636988401413
  Validation Loss: 0.6306796073913574
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6575120091438293
  Validation Loss: 0.6305721402168274
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6560220867395401
  Validation Loss: 0.6304378509521484
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 48/64:
  Train Loss: 0.6609452068805695
  Validation Loss: 0.6303109526634216
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 49/64:
  Train Loss: 0.6568576395511627
  Validation Loss: 0.630192220211029
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 50/64:
  Train Loss: 0.6687445193529129
  Validation Loss: 0.6300933361053467
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 51/64:
  Train Loss: 0.6709054857492447
  Validation Loss: 0.629951000213623
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 52/64:
  Train Loss: 0.6618105173110962
  Validation Loss: 0.6298114657402039
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 53/64:
  Train Loss: 0.6588212996721268
  Validation Loss: 0.6296744346618652
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 54/64:
  Train Loss: 0.6752078086137772
  Validation Loss: 0.6295436024665833
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 55/64:
  Train Loss: 0.6729386448860168
  Validation Loss: 0.6295123100280762
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 56/64:
  Train Loss: 0.6633997857570648
  Validation Loss: 0.6294690370559692
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 57/64:
  Train Loss: 0.6556526124477386
  Validation Loss: 0.6294220089912415
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 58/64:
  Train Loss: 0.6578060388565063
  Validation Loss: 0.6292830109596252
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 59/64:
  Train Loss: 0.6624215841293335
  Validation Loss: 0.6291492581367493
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8888888955116272
Epoch 60/64:
  Train Loss: 0.6613268554210663
  Validation Loss: 0.6290196776390076
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6576969474554062
  Validation Loss: 0.6289171576499939
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.6593172550201416
  Validation Loss: 0.6288501620292664
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.6563561707735062
  Validation Loss: 0.6287930607795715
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.648146465420723
  Validation Loss: 0.6287030577659607
  Val ROC-AUC: 0.9659090909090909
  Val Accuracy: 0.8518518805503845
{'train_loss': 0.648146465420723, 'val_roc_auc': 0.9659090909090909, 'val_accuracy': 0.8518518805503845, 'val_loss': 0.6287030577659607}
 ROC_AUC: 0.9659|| Accuracy 0.8519 || Train Loss: 0.6481
 Val Loss: 0.6287 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6937404435672118
Test ROC-AUC: 0.8825757575757576
Test Accuracy: 0.797752808988764
test_loss: 0.6937404435672118
test_roc_auc: 0.8825757575757576
test_accuracy: 0.797752808988764
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6596308201551437
  Validation Loss: 0.7059474587440491
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6618045419454575
  Validation Loss: 0.7055026888847351
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6649652123451233
  Validation Loss: 0.7051243185997009
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6728308796882629
  Validation Loss: 0.7047581672668457
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6535224467515945
  Validation Loss: 0.7044818997383118
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6590536534786224
  Validation Loss: 0.7042297124862671
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 7/64:
  Train Loss: 0.6495880633592606
  Validation Loss: 0.7039840221405029
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 8/64:
  Train Loss: 0.6473649591207504
  Validation Loss: 0.7037971019744873
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 9/64:
  Train Loss: 0.6432580351829529
  Validation Loss: 0.7036285400390625
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 10/64:
  Train Loss: 0.6507239043712616
  Validation Loss: 0.703458309173584
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 11/64:
  Train Loss: 0.6442155241966248
  Validation Loss: 0.7033012509346008
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 12/64:
  Train Loss: 0.6530967354774475
  Validation Loss: 0.703141987323761
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 13/64:
  Train Loss: 0.6505657285451889
  Validation Loss: 0.7029661536216736
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 14/64:
  Train Loss: 0.6522576957941055
  Validation Loss: 0.7027483582496643
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 15/64:
  Train Loss: 0.6392323076725006
  Validation Loss: 0.7025214433670044
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 16/64:
  Train Loss: 0.6515678465366364
  Validation Loss: 0.7023287415504456
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 17/64:
  Train Loss: 0.6562598943710327
  Validation Loss: 0.7021292448043823
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 18/64:
  Train Loss: 0.6293853670358658
  Validation Loss: 0.7018977999687195
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 19/64:
  Train Loss: 0.6526132375001907
  Validation Loss: 0.7017348408699036
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 20/64:
  Train Loss: 0.64560467004776
  Validation Loss: 0.7015808820724487
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 21/64:
  Train Loss: 0.6399208456277847
  Validation Loss: 0.70139080286026
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 22/64:
  Train Loss: 0.6618970185518265
  Validation Loss: 0.7011958956718445
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 23/64:
  Train Loss: 0.636215940117836
  Validation Loss: 0.7009493708610535
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 24/64:
  Train Loss: 0.6454586237668991
  Validation Loss: 0.700702965259552
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:41:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:42:INFO:
[92mINFO [0m:      Received: evaluate message 33aac867-b083-4cb9-ac1b-c8a5a939d43c
02/07/2025 22:36:42:INFO:Received: evaluate message 33aac867-b083-4cb9-ac1b-c8a5a939d43c
[92mINFO [0m:      Sent reply
02/07/2025 22:36:46:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:46:INFO:
[92mINFO [0m:      Received: train message 88722782-7fe8-4ff4-bb89-9dd0f19f138d
02/07/2025 22:36:46:INFO:Received: train message 88722782-7fe8-4ff4-bb89-9dd0f19f138d
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 25/64:
  Train Loss: 0.6421561539173126
  Validation Loss: 0.7005909085273743
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 26/64:
  Train Loss: 0.6520085334777832
  Validation Loss: 0.7004925608634949
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 27/64:
  Train Loss: 0.650898665189743
  Validation Loss: 0.7003757357597351
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 28/64:
  Train Loss: 0.6522792875766754
  Validation Loss: 0.7002585530281067
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 29/64:
  Train Loss: 0.6547239422798157
  Validation Loss: 0.7001365423202515
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 30/64:
  Train Loss: 0.6459255218505859
  Validation Loss: 0.6999768614768982
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 31/64:
  Train Loss: 0.6423984616994858
  Validation Loss: 0.6998439431190491
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 32/64:
  Train Loss: 0.6423991322517395
  Validation Loss: 0.6997024416923523
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 33/64:
  Train Loss: 0.641575276851654
  Validation Loss: 0.6994855999946594
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 34/64:
  Train Loss: 0.6412222683429718
  Validation Loss: 0.6992361545562744
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 35/64:
  Train Loss: 0.6392938494682312
  Validation Loss: 0.6990272402763367
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 36/64:
  Train Loss: 0.648852065205574
  Validation Loss: 0.6988398432731628
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 37/64:
  Train Loss: 0.6358152776956558
  Validation Loss: 0.6986895799636841
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 38/64:
  Train Loss: 0.6603701263666153
  Validation Loss: 0.6986120939254761
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 39/64:
  Train Loss: 0.6426268368959427
  Validation Loss: 0.6985107064247131
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 40/64:
  Train Loss: 0.6466068625450134
  Validation Loss: 0.6984236240386963
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 41/64:
  Train Loss: 0.6518804728984833
  Validation Loss: 0.6983163952827454
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 42/64:
  Train Loss: 0.6407032012939453
  Validation Loss: 0.6981254816055298
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 43/64:
  Train Loss: 0.642730250954628
  Validation Loss: 0.6979402899742126
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 44/64:
  Train Loss: 0.6446939557790756
  Validation Loss: 0.6978171467781067
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 45/64:
  Train Loss: 0.6464266926050186
  Validation Loss: 0.6976794004440308
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 46/64:
  Train Loss: 0.6421950608491898
  Validation Loss: 0.697533369064331
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 47/64:
  Train Loss: 0.6436056792736053
  Validation Loss: 0.6974188685417175
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 48/64:
  Train Loss: 0.636622279882431
  Validation Loss: 0.6973549127578735
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 49/64:
  Train Loss: 0.6454355418682098
  Validation Loss: 0.6972842216491699
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 50/64:
  Train Loss: 0.6474403142929077
  Validation Loss: 0.6971846222877502
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 51/64:
  Train Loss: 0.6304488331079483
  Validation Loss: 0.6970626711845398
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 52/64:
  Train Loss: 0.6338116824626923
  Validation Loss: 0.6970294713973999
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 53/64:
  Train Loss: 0.645371675491333
  Validation Loss: 0.6970018744468689
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 54/64:
  Train Loss: 0.646010085940361
  Validation Loss: 0.6969419717788696
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 55/64:
  Train Loss: 0.642241507768631
  Validation Loss: 0.696880042552948
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 56/64:
  Train Loss: 0.6356117725372314
  Validation Loss: 0.6968237161636353
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 57/64:
  Train Loss: 0.6538777202367783
  Validation Loss: 0.6968032717704773
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 58/64:
  Train Loss: 0.6326256096363068
  Validation Loss: 0.6967724561691284
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 59/64:
  Train Loss: 0.6511801034212112
  Validation Loss: 0.6967411637306213
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 60/64:
  Train Loss: 0.6349344104528427
  Validation Loss: 0.6966773271560669
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 61/64:
  Train Loss: 0.6316867768764496
  Validation Loss: 0.6965566873550415
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 62/64:
  Train Loss: 0.6403855681419373
  Validation Loss: 0.6964337229728699
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 63/64:
  Train Loss: 0.6469828635454178
  Validation Loss: 0.6964136958122253
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9259259104728699
Epoch 64/64:
  Train Loss: 0.643680065870285
  Validation Loss: 0.6964001655578613
  Val ROC-AUC: 0.9928571428571428
  Val Accuracy: 0.9259259104728699
{'train_loss': 0.643680065870285, 'val_roc_auc': 0.9928571428571428, 'val_accuracy': 0.9259259104728699, 'val_loss': 0.6964001655578613}
 ROC_AUC: 0.9929|| Accuracy 0.9259 || Train Loss: 0.6437
 Val Loss: 0.6964 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6928363700261276
Test ROC-AUC: 0.8831168831168831
Test Accuracy: 0.8089887640449438
test_loss: 0.6928363700261276
test_roc_auc: 0.8831168831168831
test_accuracy: 0.8089887640449438
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.681861087679863
  Validation Loss: 0.6003226637840271
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 2/64:
  Train Loss: 0.6770240813493729
  Validation Loss: 0.6001033782958984
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 3/64:
  Train Loss: 0.6884995549917221
  Validation Loss: 0.5999085307121277
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 4/64:
  Train Loss: 0.6735929399728775
  Validation Loss: 0.5996913313865662
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 5/64:
  Train Loss: 0.6862175166606903
  Validation Loss: 0.5995007157325745
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9259259104728699
Epoch 6/64:
  Train Loss: 0.6661510020494461
  Validation Loss: 0.5993168354034424
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 7/64:
  Train Loss: 0.6633298397064209
  Validation Loss: 0.5990994572639465
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 8/64:
  Train Loss: 0.6812734007835388
  Validation Loss: 0.5989068150520325
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 9/64:
  Train Loss: 0.6672303080558777
  Validation Loss: 0.598686158657074
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 10/64:
  Train Loss: 0.6682534217834473
  Validation Loss: 0.598508358001709
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 11/64:
  Train Loss: 0.6836941689252853
  Validation Loss: 0.5983067154884338
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 12/64:
  Train Loss: 0.6675054579973221
  Validation Loss: 0.5981386303901672
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 13/64:
  Train Loss: 0.6804988980293274
  Validation Loss: 0.5979330539703369
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 14/64:
  Train Loss: 0.6682794839143753/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:36:57:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:36:59:INFO:
[92mINFO [0m:      Received: evaluate message 631c0e48-0a21-4509-b39f-8f76a1afad86
02/07/2025 22:36:59:INFO:Received: evaluate message 631c0e48-0a21-4509-b39f-8f76a1afad86
[92mINFO [0m:      Sent reply
02/07/2025 22:37:00:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:01:INFO:
[92mINFO [0m:      Received: train message 006c882c-f618-4686-9aaa-9f1308b8d968
02/07/2025 22:37:01:INFO:Received: train message 006c882c-f618-4686-9aaa-9f1308b8d968

  Validation Loss: 0.5977554321289062
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 15/64:
  Train Loss: 0.6807494014501572
  Validation Loss: 0.5976139903068542
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 16/64:
  Train Loss: 0.6545059531927109
  Validation Loss: 0.5974838137626648
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 17/64:
  Train Loss: 0.6781820058822632
  Validation Loss: 0.5973674058914185
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 18/64:
  Train Loss: 0.6696217507123947
  Validation Loss: 0.5972784161567688
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 19/64:
  Train Loss: 0.6773948669433594
  Validation Loss: 0.597185492515564
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 20/64:
  Train Loss: 0.6677789390087128
  Validation Loss: 0.597083330154419
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 21/64:
  Train Loss: 0.6756051629781723
  Validation Loss: 0.5969773530960083
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 22/64:
  Train Loss: 0.6734903752803802
  Validation Loss: 0.5968713164329529
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 23/64:
  Train Loss: 0.6713452786207199
  Validation Loss: 0.5967284440994263
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 24/64:
  Train Loss: 0.6839775890111923
  Validation Loss: 0.5965995788574219
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 25/64:
  Train Loss: 0.6697204560041428
  Validation Loss: 0.5965259075164795
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 26/64:
  Train Loss: 0.667502298951149
  Validation Loss: 0.5964588522911072
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 27/64:
  Train Loss: 0.6822405457496643
  Validation Loss: 0.5963960886001587
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 28/64:
  Train Loss: 0.6620669513940811
  Validation Loss: 0.5963245034217834
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 29/64:
  Train Loss: 0.681774690747261
  Validation Loss: 0.5962691903114319
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 30/64:
  Train Loss: 0.6690196245908737
  Validation Loss: 0.5961856245994568
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 31/64:
  Train Loss: 0.6691137552261353
  Validation Loss: 0.5961005091667175
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 32/64:
  Train Loss: 0.6661674827337265
  Validation Loss: 0.5960550904273987
  Val ROC-AUC: 0.9945054945054945
  Val Accuracy: 0.9629629850387573
Epoch 33/64:
  Train Loss: 0.6648746579885483
  Validation Loss: 0.5959751009941101
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 34/64:
  Train Loss: 0.6834440380334854
  Validation Loss: 0.595871090888977
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 35/64:
  Train Loss: 0.6650096923112869
  Validation Loss: 0.5957722067832947
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 36/64:
  Train Loss: 0.6777211874723434
  Validation Loss: 0.5956763029098511
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 37/64:
  Train Loss: 0.6688774973154068
  Validation Loss: 0.5955711603164673
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 38/64:
  Train Loss: 0.6683604866266251
  Validation Loss: 0.5955241322517395
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 39/64:
  Train Loss: 0.671543151140213
  Validation Loss: 0.5954481363296509
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 40/64:
  Train Loss: 0.6717525869607925
  Validation Loss: 0.5953953862190247
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 41/64:
  Train Loss: 0.6677114963531494
  Validation Loss: 0.5953312516212463
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 42/64:
  Train Loss: 0.6593793034553528
  Validation Loss: 0.5952562689781189
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 43/64:
  Train Loss: 0.6636290997266769
  Validation Loss: 0.5951655507087708
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 44/64:
  Train Loss: 0.670021116733551
  Validation Loss: 0.5951004028320312
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 45/64:
  Train Loss: 0.6575587689876556
  Validation Loss: 0.5950615406036377
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 46/64:
  Train Loss: 0.6694857776165009
  Validation Loss: 0.5950255393981934
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 47/64:
  Train Loss: 0.6648323088884354
  Validation Loss: 0.5949581861495972
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 48/64:
  Train Loss: 0.6570097953081131
  Validation Loss: 0.5948773622512817
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 49/64:
  Train Loss: 0.6448598802089691
  Validation Loss: 0.5948063731193542
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 50/64:
  Train Loss: 0.6678198128938675
  Validation Loss: 0.5947337746620178
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 51/64:
  Train Loss: 0.6763618141412735
  Validation Loss: 0.5947131514549255
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 52/64:
  Train Loss: 0.6720162332057953
  Validation Loss: 0.5947282910346985
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 53/64:
  Train Loss: 0.6771944314241409
  Validation Loss: 0.5946959257125854
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 54/64:
  Train Loss: 0.6622610092163086
  Validation Loss: 0.5946314334869385
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 55/64:
  Train Loss: 0.6633866280317307
  Validation Loss: 0.5945261120796204
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 56/64:
  Train Loss: 0.6748163104057312
  Validation Loss: 0.5944677591323853
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 57/64:
  Train Loss: 0.6617911010980606
  Validation Loss: 0.5944255590438843
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 58/64:
  Train Loss: 0.6486794650554657
  Validation Loss: 0.5943787693977356
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 59/64:
  Train Loss: 0.6557877212762833
  Validation Loss: 0.5943676829338074
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 60/64:
  Train Loss: 0.6696559637784958
  Validation Loss: 0.5943604707717896
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 61/64:
  Train Loss: 0.6614378839731216
  Validation Loss: 0.5943406224250793
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 62/64:
  Train Loss: 0.6612148433923721
  Validation Loss: 0.5942991971969604
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 63/64:
  Train Loss: 0.6663790792226791
  Validation Loss: 0.5942727327346802
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
Epoch 64/64:
  Train Loss: 0.662945955991745
  Validation Loss: 0.5942496061325073
  Val ROC-AUC: 1.0
  Val Accuracy: 0.9629629850387573
{'train_loss': 0.662945955991745, 'val_roc_auc': 1.0, 'val_accuracy': 0.9629629850387573, 'val_loss': 0.5942496061325073}
 ROC_AUC: 1.0000|| Accuracy 0.9630 || Train Loss: 0.6629
 Val Loss: 0.5942 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6921776225057881
Test ROC-AUC: 0.8831168831168832
Test Accuracy: 0.8202247191011236
test_loss: 0.6921776225057881
test_roc_auc: 0.8831168831168832
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6531698852777481
  Validation Loss: 0.6882854104042053
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 2/64:
  Train Loss: 0.6618931740522385
  Validation Loss: 0.6879717707633972
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 3/64:
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Train Loss: 0.6454889327287674
  Validation Loss: 0.6877284646034241
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 4/64:
  Train Loss: 0.654281809926033
  Validation Loss: 0.6875225305557251
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 5/64:
  Train Loss: 0.6561410278081894
  Validation Loss: 0.6873183250427246
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 6/64:
  Train Loss: 0.6534570604562759
  Validation Loss: 0.6871283650398254
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 7/64:
  Train Loss: 0.6458131074905396
  Validation Loss: 0.6869587302207947
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 8/64:
  Train Loss: 0.6526132971048355
  Validation Loss: 0.6867789030075073
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 9/64:
  Train Loss: 0.6494359225034714
  Validation Loss: 0.686592161655426
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 10/64:
  Train Loss: 0.6490628868341446
  Validation Loss: 0.6864295601844788
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 11/64:
  Train Loss: 0.6513354629278183
  Validation Loss: 0.6863088011741638
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 12/64:
  Train Loss: 0.6505764424800873
  Validation Loss: 0.6861885786056519
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 13/64:
  Train Loss: 0.6558157205581665
  Validation Loss: 0.686054527759552
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 14/64:
  Train Loss: 0.6606582999229431
  Validation Loss: 0.6859186291694641
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 15/64:
  Train Loss: 0.6550268977880478
  Validation Loss: 0.6858028769493103
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 16/64:
  Train Loss: 0.642408475279808
  Validation Loss: 0.6856650114059448
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 17/64:
  Train Loss: 0.6459923684597015
  Validation Loss: 0.685559868812561
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 18/64:
  Train Loss: 0.6457473188638687
  Validation Loss: 0.6854605674743652
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 19/64:
  Train Loss: 0.6510759145021439
  Validation Loss: 0.6853576898574829
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 20/64:
  Train Loss: 0.6539143025875092
  Validation Loss: 0.6852955222129822
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 21/64:
  Train Loss: 0.6600354909896851
  Validation Loss: 0.6851932406425476
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 22/64:
  Train Loss: 0.631279319524765
  Validation Loss: 0.6850506663322449
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 23/64:
  Train Loss: 0.6511583626270294
  Validation Loss: 0.684973955154419
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 24/64:
  Train Loss: 0.6379028856754303
  Validation Loss: 0.6849024295806885
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 25/64:
  Train Loss: 0.6574059128761292
  Validation Loss: 0.6848114728927612
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 26/64:
  Train Loss: 0.6499640345573425
  Validation Loss: 0.6847285032272339
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 27/64:
  Train Loss: 0.6540195196866989
  Validation Loss: 0.6846837401390076
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 28/64:
  Train Loss: 0.6442655622959137
  Validation Loss: 0.684629499912262
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 29/64:
  Train Loss: 0.6553796678781509
  Validation Loss: 0.684561014175415
  Val ROC-AUC: 0.9868421052631579
  Val Accuracy: 0.8888888955116272
Epoch 30/64:
  Train Loss: 0.6427116692066193
  Validation Loss: 0.684502363204956
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 31/64:
  Train Loss: 0.6505281627178192
  Validation Loss: 0.684434711933136
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 32/64:
  Train Loss: 0.6460397094488144
  Validation Loss: 0.6843840479850769
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 33/64:
  Train Loss: 0.6477939039468765
  Validation Loss: 0.6842970252037048
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 34/64:
  Train Loss: 0.6480859667062759
  Validation Loss: 0.6842082142829895
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 35/64:
  Train Loss: 0.6462426036596298
  Validation Loss: 0.6841347217559814
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 36/64:
  Train Loss: 0.642528310418129
  Validation Loss: 0.6840881705284119
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 37/64:
  Train Loss: 0.6404716968536377
  Validation Loss: 0.6840707063674927
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 38/64:
  Train Loss: 0.648960217833519
  Validation Loss: 0.6840544939041138
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 39/64:
  Train Loss: 0.6478883177042007
  Validation Loss: 0.6840575933456421
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 40/64:
  Train Loss: 0.6466743499040604
  Validation Loss: 0.6840483546257019
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 41/64:
  Train Loss: 0.6543007344007492
  Validation Loss: 0.6840458512306213
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 42/64:
  Train Loss: 0.6360657215118408
  Validation Loss: 0.684019148349762
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 43/64:
  Train Loss: 0.6421833485364914
  Validation Loss: 0.6839749217033386
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 44/64:
  Train Loss: 0.6294869184494019
  Validation Loss: 0.6839233636856079
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 45/64:
  Train Loss: 0.6348661780357361
  Validation Loss: 0.683905303478241
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 46/64:
  Train Loss: 0.6386366784572601
  Validation Loss: 0.6838833689689636
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8888888955116272
Epoch 47/64:
  Train Loss: 0.6458723247051239
  Validation Loss: 0.6838846802711487
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 48/64:
  Train Loss: 0.652787059545517
  Validation Loss: 0.6838527917861938
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 49/64:
  Train Loss: 0.6432903558015823
  Validation Loss: 0.6838147044181824
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 50/64:
  Train Loss: 0.6362568885087967
  Validation Loss: 0.6838344931602478
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 51/64:
  Train Loss: 0.6429369449615479
  Validation Loss: 0.6838439702987671
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 52/64:
  Train Loss: 0.644777461886406
  Validation Loss: 0.6838345527648926
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 53/64:
  Train Loss: 0.6449380069971085
  Validation Loss: 0.6838047504425049
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 54/64:
  Train Loss: 0.6430139988660812
  Validation Loss: 0.6838013529777527
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 55/64:
  Train Loss: 0.6455196589231491
  Validation Loss: 0.6838107109069824
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 56/64:
  Train Loss: 0.6521753817796707
  Validation Loss: 0.6838038563728333
  Val ROC-AUC: 0.9802631578947367
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:37:11:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:14:INFO:
[92mINFO [0m:      Received: evaluate message 05716253-79ce-425e-8ee4-f95927519045
02/07/2025 22:37:14:INFO:Received: evaluate message 05716253-79ce-425e-8ee4-f95927519045
[92mINFO [0m:      Sent reply
02/07/2025 22:37:14:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:14:INFO:
[92mINFO [0m:      Received: train message 216f2e20-5c75-4859-a53e-a1011ee81a74
02/07/2025 22:37:14:INFO:Received: train message 216f2e20-5c75-4859-a53e-a1011ee81a74
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
  Val Accuracy: 0.8518518805503845
Epoch 57/64:
  Train Loss: 0.641327753663063
  Validation Loss: 0.68376225233078
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 58/64:
  Train Loss: 0.6496347934007645
  Validation Loss: 0.6837046146392822
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 59/64:
  Train Loss: 0.6373046785593033
  Validation Loss: 0.6836803555488586
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 60/64:
  Train Loss: 0.649366483092308
  Validation Loss: 0.6836477518081665
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 61/64:
  Train Loss: 0.6472504287958145
  Validation Loss: 0.6836357116699219
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 62/64:
  Train Loss: 0.643888995051384
  Validation Loss: 0.683614194393158
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 63/64:
  Train Loss: 0.6459530740976334
  Validation Loss: 0.6835993528366089
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
Epoch 64/64:
  Train Loss: 0.645083025097847
  Validation Loss: 0.6835812926292419
  Val ROC-AUC: 0.9802631578947367
  Val Accuracy: 0.8518518805503845
{'train_loss': 0.645083025097847, 'val_roc_auc': 0.9802631578947367, 'val_accuracy': 0.8518518805503845, 'val_loss': 0.6835812926292419}
 ROC_AUC: 0.9803|| Accuracy 0.8519 || Train Loss: 0.6451
 Val Loss: 0.6836 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6916690478833873
Test ROC-AUC: 0.8836580086580087
Test Accuracy: 0.8202247191011236
test_loss: 0.6916690478833873
test_roc_auc: 0.8836580086580087
test_accuracy: 0.8202247191011236
eval_cid: 1
[Client 1] fit, config: {'batch_size': 1, 'optimizer': 'adam', 'num_epochs': 70, 'lr': 0.001}
base noise multiplier:  5.46875
Epoch 1/64:
  Train Loss: 0.6649440228939056
  Validation Loss: 0.6937160491943359
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.8148148059844971
Epoch 2/64:
  Train Loss: 0.6526329666376114
  Validation Loss: 0.6934270262718201
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.8148148059844971
Epoch 3/64:
  Train Loss: 0.6605106890201569
  Validation Loss: 0.6931496858596802
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.8148148059844971
Epoch 4/64:
  Train Loss: 0.660514622926712
  Validation Loss: 0.6928494572639465
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.8148148059844971
Epoch 5/64:
  Train Loss: 0.6674774289131165
  Validation Loss: 0.6925514936447144
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.8148148059844971
Epoch 6/64:
  Train Loss: 0.6378179341554642
  Validation Loss: 0.692260205745697
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 7/64:
  Train Loss: 0.6452994048595428
  Validation Loss: 0.691972553730011
  Val ROC-AUC: 0.8271604938271606
  Val Accuracy: 0.8148148059844971
Epoch 8/64:
  Train Loss: 0.6556916534900665
  Validation Loss: 0.6917297840118408
  Val ROC-AUC: 0.8271604938271606
  Val Accuracy: 0.8148148059844971
Epoch 9/64:
  Train Loss: 0.65501768887043
  Validation Loss: 0.691461443901062
  Val ROC-AUC: 0.8271604938271606
  Val Accuracy: 0.8148148059844971
Epoch 10/64:
  Train Loss: 0.6559488326311111
  Validation Loss: 0.6912203431129456
  Val ROC-AUC: 0.8271604938271606
  Val Accuracy: 0.8148148059844971
Epoch 11/64:
  Train Loss: 0.6538943648338318
  Validation Loss: 0.6909603476524353
  Val ROC-AUC: 0.8271604938271606
  Val Accuracy: 0.8148148059844971
Epoch 12/64:
  Train Loss: 0.6449990123510361
  Validation Loss: 0.6907126307487488
  Val ROC-AUC: 0.8271604938271606
  Val Accuracy: 0.8148148059844971
Epoch 13/64:
  Train Loss: 0.653971329331398
  Validation Loss: 0.6904873251914978
  Val ROC-AUC: 0.8271604938271606
  Val Accuracy: 0.8148148059844971
Epoch 14/64:
  Train Loss: 0.6416010111570358
  Validation Loss: 0.6902634501457214
  Val ROC-AUC: 0.8271604938271606
  Val Accuracy: 0.8148148059844971
Epoch 15/64:
  Train Loss: 0.6557900607585907
  Validation Loss: 0.6900470852851868
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.8148148059844971
Epoch 16/64:
  Train Loss: 0.6519764065742493
  Validation Loss: 0.6898036599159241
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.8148148059844971
Epoch 17/64:
  Train Loss: 0.6462865918874741
  Validation Loss: 0.6895834803581238
  Val ROC-AUC: 0.8271604938271605
  Val Accuracy: 0.8148148059844971
Epoch 18/64:
  Train Loss: 0.6431230157613754
  Validation Loss: 0.6893642544746399
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 19/64:
  Train Loss: 0.6499155610799789
  Validation Loss: 0.6891620755195618
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 20/64:
  Train Loss: 0.6469440907239914
  Validation Loss: 0.6889516115188599
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 21/64:
  Train Loss: 0.6475309282541275
  Validation Loss: 0.6887449622154236
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 22/64:
  Train Loss: 0.6327560245990753
  Validation Loss: 0.688555896282196
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 23/64:
  Train Loss: 0.6425541639328003
  Validation Loss: 0.6883738040924072
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 24/64:
  Train Loss: 0.6468473076820374
  Validation Loss: 0.6881945729255676
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 25/64:
  Train Loss: 0.6456916779279709
  Validation Loss: 0.6880087852478027
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 26/64:
  Train Loss: 0.6439230740070343
  Validation Loss: 0.6878406405448914
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 27/64:
  Train Loss: 0.6486833393573761
  Validation Loss: 0.6876826882362366
  Val ROC-AUC: 0.8333333333333334
  Val Accuracy: 0.8148148059844971
Epoch 28/64:
  Train Loss: 0.6407795548439026
  Validation Loss: 0.6875256299972534
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 29/64:
  Train Loss: 0.6525595784187317
  Validation Loss: 0.6873800754547119
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 30/64:
  Train Loss: 0.6506907790899277
  Validation Loss: 0.6872370839118958
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 31/64:
  Train Loss: 0.6395993679761887
  Validation Loss: 0.6870802640914917
  Val ROC-AUC: 0.8395061728395062
  Val Accuracy: 0.8148148059844971
Epoch 32/64:
  Train Loss: 0.6531111598014832
  Validation Loss: 0.6869300603866577
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 33/64:
  Train Loss: 0.6481225490570068
  Validation Loss: 0.6867770552635193
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 34/64:
  Train Loss: 0.6355700939893723
  Validation Loss: 0.6866288185119629
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 35/64:
  Train Loss: 0.6427214443683624
  Validation Loss: 0.6865001320838928
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 36/64:
  Train Loss: 0.644462913274765
  Validation Loss: 0.6863747835159302
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 37/64:
  Train Loss: 0.6343660354614258
  Validation Loss: 0.6862280368804932
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 38/64:
  Train Loss: 0.6434278041124344
  Validation Loss: 0.6861132979393005
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 39/64:
  Train Loss: 0.6388502717018127
  Validation Loss: 0.6859950423240662
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 40/64:
  Train Loss: 0.6417525857686996
  Validation Loss: 0.6858841776847839
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 41/64:
  Train Loss: 0.6466026455163956
  Validation Loss: 0.6857723593711853
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 42/64:
  Train Loss: 0.6411329507827759
  Validation Loss: 0.6856564879417419
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
02/07/2025 22:37:25:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:28:INFO:
[92mINFO [0m:      Received: evaluate message 2f7cc8ff-08a5-490d-a18e-73dc82e76b3b
02/07/2025 22:37:28:INFO:Received: evaluate message 2f7cc8ff-08a5-490d-a18e-73dc82e76b3b
[92mINFO [0m:      Sent reply
02/07/2025 22:37:30:INFO:Sent reply
[92mINFO [0m:      
02/07/2025 22:37:30:INFO:
[92mINFO [0m:      Received: reconnect message dca72a6e-7991-4771-a191-2d3dc336d313
02/07/2025 22:37:30:INFO:Received: reconnect message dca72a6e-7991-4771-a191-2d3dc336d313
02/07/2025 22:37:30:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
02/07/2025 22:37:30:INFO:Disconnect and shut down
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 43/64:
  Train Loss: 0.6417879909276962
  Validation Loss: 0.685562014579773
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 44/64:
  Train Loss: 0.6547107249498367
  Validation Loss: 0.6854673624038696
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 45/64:
  Train Loss: 0.6514227837324142
  Validation Loss: 0.6853556036949158
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 46/64:
  Train Loss: 0.6378561109304428
  Validation Loss: 0.6852493286132812
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 47/64:
  Train Loss: 0.6324812471866608
  Validation Loss: 0.6851538419723511
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 48/64:
  Train Loss: 0.6498807519674301
  Validation Loss: 0.6850643754005432
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 49/64:
  Train Loss: 0.6408181935548782
  Validation Loss: 0.6849805116653442
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 50/64:
  Train Loss: 0.6410112828016281
  Validation Loss: 0.684908390045166
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 51/64:
  Train Loss: 0.6283673346042633
  Validation Loss: 0.6848303079605103
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 52/64:
  Train Loss: 0.6386870741844177
  Validation Loss: 0.6847490668296814
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 53/64:
  Train Loss: 0.6456668078899384
  Validation Loss: 0.6846593022346497
  Val ROC-AUC: 0.8518518518518519
  Val Accuracy: 0.8148148059844971
Epoch 54/64:
  Train Loss: 0.6501091569662094
  Validation Loss: 0.6845909357070923
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.8148148059844971
Epoch 55/64:
  Train Loss: 0.6326266378164291
  Validation Loss: 0.6844996809959412
  Val ROC-AUC: 0.8580246913580247
  Val Accuracy: 0.8148148059844971
Epoch 56/64:
  Train Loss: 0.6433315873146057
  Validation Loss: 0.684420645236969
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
Epoch 57/64:
  Train Loss: 0.6368476003408432
  Validation Loss: 0.6843442320823669
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
Epoch 58/64:
  Train Loss: 0.6332450658082962
  Validation Loss: 0.6842854619026184
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
Epoch 59/64:
  Train Loss: 0.6344494819641113
  Validation Loss: 0.6841992735862732
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
Epoch 60/64:
  Train Loss: 0.6414283812046051
  Validation Loss: 0.6841373443603516
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
Epoch 61/64:
  Train Loss: 0.6378965228796005
  Validation Loss: 0.6840819120407104
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
Epoch 62/64:
  Train Loss: 0.6321687698364258
  Validation Loss: 0.6840278506278992
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
Epoch 63/64:
  Train Loss: 0.63974629342556
  Validation Loss: 0.683971107006073
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
Epoch 64/64:
  Train Loss: 0.6466387808322906
  Validation Loss: 0.6839256286621094
  Val ROC-AUC: 0.8703703703703703
  Val Accuracy: 0.8148148059844971
{'train_loss': 0.6466387808322906, 'val_roc_auc': 0.8703703703703703, 'val_accuracy': 0.8148148059844971, 'val_loss': 0.6839256286621094}
 ROC_AUC: 0.8704|| Accuracy 0.8148 || Train Loss: 0.6466
 Val Loss: 0.6839 
[Client 1] evaluate, config: {'batch_size': 1}
Test Loss: 0.6912928391038702
Test ROC-AUC: 0.8820346320346321
Test Accuracy: 0.8089887640449438
test_loss: 0.6912928391038702
test_roc_auc: 0.8820346320346321
test_accuracy: 0.8089887640449438
eval_cid: 1
CPU Time: 175.788023 seconds
Elapsed Time: 316.3614192008972 seconds
RAM Usage: 0.3731842041015625 megabytes
Logs saved in current directory
