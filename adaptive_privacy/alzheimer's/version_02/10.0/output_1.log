nohup: ignoring input
01/31/2025 07:00:17:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 07:00:17:DEBUG:ChannelConnectivity.IDLE
01/31/2025 07:00:17:DEBUG:ChannelConnectivity.CONNECTING
01/31/2025 07:00:18:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 07:00:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:00:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0fcafa26-c3fa-4115-a1f0-1e2df3f348c2
01/31/2025 07:00:47:INFO:Received: train message 0fcafa26-c3fa-4115-a1f0-1e2df3f348c2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:01:24:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:01:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:01:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 659a70b1-00ae-4594-a583-a76b35bc87f9
01/31/2025 07:01:51:INFO:Received: evaluate message 659a70b1-00ae-4594-a583-a76b35bc87f9
[92mINFO [0m:      Sent reply
01/31/2025 07:01:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:02:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:02:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9f7412a3-b6ea-40b5-b7ea-fa0369740c9e
01/31/2025 07:02:51:INFO:Received: train message 9f7412a3-b6ea-40b5-b7ea-fa0369740c9e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:03:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:03:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:03:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b97b1856-34ab-4755-b841-76907732ea8e
01/31/2025 07:03:55:INFO:Received: evaluate message b97b1856-34ab-4755-b841-76907732ea8e
[92mINFO [0m:      Sent reply
01/31/2025 07:03:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:04:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:04:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9ab8052d-44d8-4438-a4b5-f4e8c21bd7ad
01/31/2025 07:04:38:INFO:Received: train message 9ab8052d-44d8-4438-a4b5-f4e8c21bd7ad
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:05:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:05:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:05:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0c222f1d-a993-4035-80e6-2645e3df27c8
01/31/2025 07:05:45:INFO:Received: evaluate message 0c222f1d-a993-4035-80e6-2645e3df27c8
[92mINFO [0m:      Sent reply
01/31/2025 07:05:47:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:06:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:06:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a00fda81-fac6-4da8-937d-b4ee043eee05
01/31/2025 07:06:24:INFO:Received: train message a00fda81-fac6-4da8-937d-b4ee043eee05
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:06:52:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:07:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:07:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a8dc19ae-d4e2-4283-8754-3bc22ab85646
01/31/2025 07:07:28:INFO:Received: evaluate message a8dc19ae-d4e2-4283-8754-3bc22ab85646
[92mINFO [0m:      Sent reply
01/31/2025 07:07:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:08:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:08:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 03c0e032-f51b-47c1-9c5d-067625ed0c4c
01/31/2025 07:08:01:INFO:Received: train message 03c0e032-f51b-47c1-9c5d-067625ed0c4c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:08:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:08:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:08:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 23a82e8b-67a8-4b08-af6c-6bc986997660
01/31/2025 07:08:59:INFO:Received: evaluate message 23a82e8b-67a8-4b08-af6c-6bc986997660
[92mINFO [0m:      Sent reply
01/31/2025 07:09:01:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:09:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:09:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 51a10b13-3960-4be9-8047-73b26e489e6e
01/31/2025 07:09:50:INFO:Received: train message 51a10b13-3960-4be9-8047-73b26e489e6e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:10:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:11:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:11:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b0416b52-427d-422c-b650-56681207f405
01/31/2025 07:11:20:INFO:Received: evaluate message b0416b52-427d-422c-b650-56681207f405
[92mINFO [0m:      Sent reply
01/31/2025 07:11:24:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:12:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:12:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c4425f16-d0b0-4bf7-b228-7126ded29eae
01/31/2025 07:12:02:INFO:Received: train message c4425f16-d0b0-4bf7-b228-7126ded29eae
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:12:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:13:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:13:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1db1614e-9841-407c-9a67-b3400a9191b1
01/31/2025 07:13:25:INFO:Received: evaluate message 1db1614e-9841-407c-9a67-b3400a9191b1
[92mINFO [0m:      Sent reply
01/31/2025 07:13:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:14:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:14:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4aeb4b20-384e-40e1-9a1d-c7167cf79722
01/31/2025 07:14:11:INFO:Received: train message 4aeb4b20-384e-40e1-9a1d-c7167cf79722
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:14:50:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:15:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:15:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4d5d988c-1d78-450d-b77d-c2de0c8119c5
01/31/2025 07:15:24:INFO:Received: evaluate message 4d5d988c-1d78-450d-b77d-c2de0c8119c5
[92mINFO [0m:      Sent reply
01/31/2025 07:15:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:16:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:16:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 705e8735-af0f-4c0c-9461-22b1ca295555
01/31/2025 07:16:03:INFO:Received: train message 705e8735-af0f-4c0c-9461-22b1ca295555
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:16:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:17:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:17:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 90314945-ad20-4c76-b181-6445a45da0cd
01/31/2025 07:17:20:INFO:Received: evaluate message 90314945-ad20-4c76-b181-6445a45da0cd
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 10.0, target_epsilon: 10.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148], 'accuracy': [0.5207193119624707], 'auc': [0.7293562379614749]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048], 'accuracy': [0.5207193119624707, 0.5254104769351056], 'auc': [0.7293562379614749, 0.7490635742179705]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:17:23:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:17:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:17:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f856cad4-ab91-4906-bab8-4d899457efa5
01/31/2025 07:17:39:INFO:Received: train message f856cad4-ab91-4906-bab8-4d899457efa5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:18:11:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:18:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:18:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4055c890-8bde-42a4-baf8-a1464d02ecb0
01/31/2025 07:18:57:INFO:Received: evaluate message 4055c890-8bde-42a4-baf8-a1464d02ecb0
[92mINFO [0m:      Sent reply
01/31/2025 07:19:01:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:19:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:19:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0201a8aa-4f08-4fca-9519-f6c69cdf27cc
01/31/2025 07:19:26:INFO:Received: train message 0201a8aa-4f08-4fca-9519-f6c69cdf27cc
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:19:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:20:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:20:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message dc66fa09-a4a5-4c30-8743-f04a74aeb4db
01/31/2025 07:20:39:INFO:Received: evaluate message dc66fa09-a4a5-4c30-8743-f04a74aeb4db
[92mINFO [0m:      Sent reply
01/31/2025 07:20:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:21:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:21:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message dc17a95a-9583-4b4c-ac78-a2a4b5ccec2d
01/31/2025 07:21:14:INFO:Received: train message dc17a95a-9583-4b4c-ac78-a2a4b5ccec2d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:21:43:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:22:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:22:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d3de8853-0c6a-4223-b9c7-d310715040bf
01/31/2025 07:22:22:INFO:Received: evaluate message d3de8853-0c6a-4223-b9c7-d310715040bf
[92mINFO [0m:      Sent reply
01/31/2025 07:22:24:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:22:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:22:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e530c57f-b7bd-4769-ab07-077b0ed6c10a
01/31/2025 07:22:58:INFO:Received: train message e530c57f-b7bd-4769-ab07-077b0ed6c10a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:23:27:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:24:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:24:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 472d15dd-d6c9-43b8-9139-00eca4680d3b
01/31/2025 07:24:03:INFO:Received: evaluate message 472d15dd-d6c9-43b8-9139-00eca4680d3b
[92mINFO [0m:      Sent reply
01/31/2025 07:24:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:24:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:24:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cf433532-2bf4-45d5-a2e7-c9e520d5d70f
01/31/2025 07:24:31:INFO:Received: train message cf433532-2bf4-45d5-a2e7-c9e520d5d70f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:25:09:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:26:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:26:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3f848c29-3290-448a-865d-f572adb8742a
01/31/2025 07:26:06:INFO:Received: evaluate message 3f848c29-3290-448a-865d-f572adb8742a
[92mINFO [0m:      Sent reply
01/31/2025 07:26:09:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:26:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:26:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6b43c09a-77a9-460f-9bbe-968ad3c4e9eb
01/31/2025 07:26:42:INFO:Received: train message 6b43c09a-77a9-460f-9bbe-968ad3c4e9eb
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:27:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:27:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:27:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7975ac57-4c2b-4b72-91d9-88b512c09b41
01/31/2025 07:27:56:INFO:Received: evaluate message 7975ac57-4c2b-4b72-91d9-88b512c09b41

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:27:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:28:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:28:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c26463d4-11e9-48e9-94c4-cbd6f26de458
01/31/2025 07:28:54:INFO:Received: train message c26463d4-11e9-48e9-94c4-cbd6f26de458
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:29:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:30:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:30:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 695aaaae-50f9-4f05-a48e-1d271a58d15b
01/31/2025 07:30:02:INFO:Received: evaluate message 695aaaae-50f9-4f05-a48e-1d271a58d15b
[92mINFO [0m:      Sent reply
01/31/2025 07:30:05:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:30:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:30:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 594565f7-5ff5-48eb-91dc-58958fc75fd8
01/31/2025 07:30:32:INFO:Received: train message 594565f7-5ff5-48eb-91dc-58958fc75fd8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:31:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:31:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:31:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ced45eba-669d-46ad-a11d-adcd5d2f82d4
01/31/2025 07:31:51:INFO:Received: evaluate message ced45eba-669d-46ad-a11d-adcd5d2f82d4
[92mINFO [0m:      Sent reply
01/31/2025 07:31:53:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:32:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:32:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0543f57e-765a-4093-8eae-a3402a77cd12
01/31/2025 07:32:37:INFO:Received: train message 0543f57e-765a-4093-8eae-a3402a77cd12
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:33:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:33:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:33:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 65d932c8-6ef2-4fb5-a027-61cb638242a0
01/31/2025 07:33:41:INFO:Received: evaluate message 65d932c8-6ef2-4fb5-a027-61cb638242a0
[92mINFO [0m:      Sent reply
01/31/2025 07:33:43:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:34:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:34:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5ace1455-1f4e-4c39-a061-2303ce536560
01/31/2025 07:34:10:INFO:Received: train message 5ace1455-1f4e-4c39-a061-2303ce536560
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:34:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:34:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:34:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 41900236-bcd6-40af-9b67-e9c8194a7e17
01/31/2025 07:34:59:INFO:Received: evaluate message 41900236-bcd6-40af-9b67-e9c8194a7e17
[92mINFO [0m:      Sent reply
01/31/2025 07:35:01:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:35:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:35:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1a221829-c0ba-4f7f-b9fc-0a215ee16028
01/31/2025 07:35:51:INFO:Received: train message 1a221829-c0ba-4f7f-b9fc-0a215ee16028
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:36:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:36:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:36:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 660580bc-d103-4879-b056-18458dd614b5
01/31/2025 07:36:57:INFO:Received: evaluate message 660580bc-d103-4879-b056-18458dd614b5

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:36:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:37:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:37:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6c2d3264-ea06-4ec9-a5b6-006965e2a2c2
01/31/2025 07:37:32:INFO:Received: train message 6c2d3264-ea06-4ec9-a5b6-006965e2a2c2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:37:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:38:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:38:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9c8ef62e-4418-43d6-a470-d5f5411fc65b
01/31/2025 07:38:32:INFO:Received: evaluate message 9c8ef62e-4418-43d6-a470-d5f5411fc65b
[92mINFO [0m:      Sent reply
01/31/2025 07:38:35:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:39:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:39:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 03e15cc9-333a-4308-a8ce-6cb19450a190
01/31/2025 07:39:14:INFO:Received: train message 03e15cc9-333a-4308-a8ce-6cb19450a190
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:39:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:40:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:40:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 225a862b-8631-4e89-9e67-0d3bf615d3e5
01/31/2025 07:40:15:INFO:Received: evaluate message 225a862b-8631-4e89-9e67-0d3bf615d3e5
[92mINFO [0m:      Sent reply
01/31/2025 07:40:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:41:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:41:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ad65e475-7ed1-458d-926a-86bbb9c1c4ea
01/31/2025 07:41:00:INFO:Received: train message ad65e475-7ed1-458d-926a-86bbb9c1c4ea
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:41:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:42:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:42:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message db555a18-6202-48f0-9dd0-87d2ce330c0a
01/31/2025 07:42:05:INFO:Received: evaluate message db555a18-6202-48f0-9dd0-87d2ce330c0a
[92mINFO [0m:      Sent reply
01/31/2025 07:42:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:42:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:42:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3258da42-9fd9-4521-a8b3-b7e85fc63ee4
01/31/2025 07:42:37:INFO:Received: train message 3258da42-9fd9-4521-a8b3-b7e85fc63ee4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:43:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:44:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:44:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2c1bf77c-8075-439b-beb8-354bc20b965e
01/31/2025 07:44:00:INFO:Received: evaluate message 2c1bf77c-8075-439b-beb8-354bc20b965e

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 07:44:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:44:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:44:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message da20f34f-f586-47f4-b445-2146ff496502
01/31/2025 07:44:28:INFO:Received: train message da20f34f-f586-47f4-b445-2146ff496502
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:45:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:45:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:45:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e0bb7a44-169a-429e-82e5-6fae223f1878
01/31/2025 07:45:48:INFO:Received: evaluate message e0bb7a44-169a-429e-82e5-6fae223f1878
[92mINFO [0m:      Sent reply
01/31/2025 07:45:52:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:46:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:46:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ac2f830e-45e3-4666-bb6c-376568af3000
01/31/2025 07:46:45:INFO:Received: train message ac2f830e-45e3-4666-bb6c-376568af3000
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:47:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:48:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:48:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ac7ee3f1-9288-4e27-8c01-8dc8343f4a28
01/31/2025 07:48:10:INFO:Received: evaluate message ac7ee3f1-9288-4e27-8c01-8dc8343f4a28
[92mINFO [0m:      Sent reply
01/31/2025 07:48:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:48:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:48:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b9903fd7-f5ab-43fe-abd2-1e7c9c1e6c1c
01/31/2025 07:48:51:INFO:Received: train message b9903fd7-f5ab-43fe-abd2-1e7c9c1e6c1c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:49:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:50:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:50:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e576d1a1-68ca-4f8f-bf1c-6de1b62e84c8
01/31/2025 07:50:07:INFO:Received: evaluate message e576d1a1-68ca-4f8f-bf1c-6de1b62e84c8
[92mINFO [0m:      Sent reply
01/31/2025 07:50:09:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:50:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:50:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message aacf17e0-2e80-4155-8e27-4c34abe5be50
01/31/2025 07:50:50:INFO:Received: train message aacf17e0-2e80-4155-8e27-4c34abe5be50

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:51:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:51:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:51:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 47466aee-37f3-4fc2-a706-60b7efc23930
01/31/2025 07:51:55:INFO:Received: evaluate message 47466aee-37f3-4fc2-a706-60b7efc23930
[92mINFO [0m:      Sent reply
01/31/2025 07:51:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:52:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:52:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 41528de5-d79e-4e48-8ac4-772e2ec21dd7
01/31/2025 07:52:45:INFO:Received: train message 41528de5-d79e-4e48-8ac4-772e2ec21dd7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:53:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:53:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:53:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2691d2c8-a970-48a8-8b1a-eab889657fe2
01/31/2025 07:53:57:INFO:Received: evaluate message 2691d2c8-a970-48a8-8b1a-eab889657fe2
[92mINFO [0m:      Sent reply
01/31/2025 07:54:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:54:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:54:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c492e76d-4b9a-41b6-a3d6-2f136de3c0e1
01/31/2025 07:54:33:INFO:Received: train message c492e76d-4b9a-41b6-a3d6-2f136de3c0e1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 07:55:01:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:55:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:55:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 454deb3b-d668-4942-9b8e-7356b6b6b68d
01/31/2025 07:55:35:INFO:Received: evaluate message 454deb3b-d668-4942-9b8e-7356b6b6b68d
[92mINFO [0m:      Sent reply
01/31/2025 07:55:38:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 07:55:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 07:55:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message 67cb49c8-f2e2-4f65-88aa-78f30ea18012
01/31/2025 07:55:41:INFO:Received: reconnect message 67cb49c8-f2e2-4f65-88aa-78f30ea18012
01/31/2025 07:55:41:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 07:55:41:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1806, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348, 1.0159809038543999], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286, 0.5989053948397185], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871, 0.8120961426383593]}



Final client history:
{'loss': [1.0714133925229148, 1.1433138056972048, 1.1443595897415078, 1.0891743268325424, 1.0625010216208153, 1.0859563886606665, 1.081820030478969, 1.077057950192825, 1.0769549944234882, 1.0751863186763915, 1.0108165281931807, 1.0523598829780918, 1.0347849803571127, 1.0421926367553163, 1.0468270918463616, 1.0455649126964774, 1.0702908814559233, 1.01790773174183, 1.0405050258882536, 1.106826137433861, 1.0391728530366315, 1.0422610729536663, 1.0371296816826612, 1.0382036509879218, 0.9888424875682178, 1.0889605326611516, 1.0357900751671631, 1.0085574072538828, 1.009393268539348, 1.0159809038543999], 'accuracy': [0.5207193119624707, 0.5254104769351056, 0.5340109460516028, 0.544175136825645, 0.5488663017982799, 0.5559030492572322, 0.5559030492572322, 0.5527756059421423, 0.565285379202502, 0.563721657544957, 0.5676309616888194, 0.5699765441751369, 0.5801407349491791, 0.5707584050039093, 0.5840500390930414, 0.581704456606724, 0.5762314308053167, 0.581704456606724, 0.5887412040656763, 0.5746677091477717, 0.5770132916340891, 0.5809225957779516, 0.5863956215793589, 0.5879593432369038, 0.599687255668491, 0.5793588741204065, 0.5879593432369038, 0.5957779515246286, 0.5957779515246286, 0.5989053948397185], 'auc': [0.7293562379614749, 0.7490635742179705, 0.7592713324992499, 0.7689369432900592, 0.774452520617057, 0.7778252102704238, 0.7807736641494487, 0.782997701960592, 0.7842480690701639, 0.7868229864307842, 0.7910555379974404, 0.7933015065657656, 0.7935060442707331, 0.792812276596959, 0.794619576919031, 0.7962525666236506, 0.7979231343435254, 0.7994336167044205, 0.7990243112220722, 0.7997743321755959, 0.8030130072849428, 0.8035551513188014, 0.8039593552097188, 0.8049911841168098, 0.8087692278686957, 0.8087532481085512, 0.8101110881156719, 0.8111429830985284, 0.8100623570190871, 0.8120961426383593]}

