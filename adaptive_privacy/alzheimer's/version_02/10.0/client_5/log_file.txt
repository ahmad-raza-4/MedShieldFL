Initial Train Dataset Size: 1088 Sample rate: 0.17
Global Epoch (Round): 1, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0827, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0714, Accuracy: 0.5207, AUC: 0.7294
Global Epoch (Round): 2, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0406, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.1433, Accuracy: 0.5254, AUC: 0.7491
Global Epoch (Round): 3, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0928, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.1444, Accuracy: 0.5340, AUC: 0.7593
Global Epoch (Round): 4, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0687, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0892, Accuracy: 0.5442, AUC: 0.7689
Global Epoch (Round): 5, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0180, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0625, Accuracy: 0.5489, AUC: 0.7745
Global Epoch (Round): 6, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0458, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0860, Accuracy: 0.5559, AUC: 0.7778
Global Epoch (Round): 7, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0582, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0818, Accuracy: 0.5559, AUC: 0.7808
Global Epoch (Round): 8, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9774, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0771, Accuracy: 0.5528, AUC: 0.7830
Global Epoch (Round): 9, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0571, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0770, Accuracy: 0.5653, AUC: 0.7842
Global Epoch (Round): 10, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0121, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0752, Accuracy: 0.5637, AUC: 0.7868
Global Epoch (Round): 11, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0435, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0108, Accuracy: 0.5676, AUC: 0.7911
Global Epoch (Round): 12, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9950, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0524, Accuracy: 0.5700, AUC: 0.7933
Global Epoch (Round): 13, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0289, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0348, Accuracy: 0.5801, AUC: 0.7935
Global Epoch (Round): 14, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0075, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0422, Accuracy: 0.5708, AUC: 0.7928
Global Epoch (Round): 15, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9853, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0468, Accuracy: 0.5841, AUC: 0.7946
Global Epoch (Round): 16, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0420, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0456, Accuracy: 0.5817, AUC: 0.7963
Global Epoch (Round): 17, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9921, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0703, Accuracy: 0.5762, AUC: 0.7979
Global Epoch (Round): 18, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0316, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0179, Accuracy: 0.5817, AUC: 0.7994
Global Epoch (Round): 19, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0179, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0405, Accuracy: 0.5887, AUC: 0.7990
Global Epoch (Round): 20, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9427, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.1068, Accuracy: 0.5747, AUC: 0.7998
Global Epoch (Round): 21, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0175, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0392, Accuracy: 0.5770, AUC: 0.8030
Global Epoch (Round): 22, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9416, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0423, Accuracy: 0.5809, AUC: 0.8036
Global Epoch (Round): 23, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9613, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0371, Accuracy: 0.5864, AUC: 0.8040
Global Epoch (Round): 24, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0012, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0382, Accuracy: 0.5880, AUC: 0.8050
Global Epoch (Round): 25, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9527, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 0.9888, Accuracy: 0.5997, AUC: 0.8088
Global Epoch (Round): 26, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9551, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0890, Accuracy: 0.5794, AUC: 0.8088
Global Epoch (Round): 27, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0087, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0358, Accuracy: 0.5880, AUC: 0.8101
Global Epoch (Round): 28, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9884, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0086, Accuracy: 0.5958, AUC: 0.8111
Global Epoch (Round): 29, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9439, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0094, Accuracy: 0.5958, AUC: 0.8101
Global Epoch (Round): 30, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9234, Epsilon: 10.0000, Dynamic Noise Multiplier: 0.0002
Loss: 1.0160, Accuracy: 0.5989, AUC: 0.8121
