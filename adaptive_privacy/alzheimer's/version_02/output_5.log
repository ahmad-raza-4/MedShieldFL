nohup: ignoring input
01/31/2025 07:59:39:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 07:59:39:DEBUG:ChannelConnectivity.IDLE
01/31/2025 07:59:39:DEBUG:ChannelConnectivity.CONNECTING
01/31/2025 07:59:39:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 08:00:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:00:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7f3a4e71-0de8-47e6-a60c-35ff54c7ef4b
01/31/2025 08:00:10:INFO:Received: train message 7f3a4e71-0de8-47e6-a60c-35ff54c7ef4b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:00:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:01:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:01:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b665bb5b-4c1f-44dc-87cc-e8875d50d89d
01/31/2025 08:01:27:INFO:Received: evaluate message b665bb5b-4c1f-44dc-87cc-e8875d50d89d
[92mINFO [0m:      Sent reply
01/31/2025 08:01:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:01:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:01:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 85c96634-16ba-41d8-acd7-ad3db1ff5d39
01/31/2025 08:01:56:INFO:Received: train message 85c96634-16ba-41d8-acd7-ad3db1ff5d39
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:02:32:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:03:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:03:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 36515be6-3702-4251-8612-a7dbaddb2fc3
01/31/2025 08:03:02:INFO:Received: evaluate message 36515be6-3702-4251-8612-a7dbaddb2fc3
[92mINFO [0m:      Sent reply
01/31/2025 08:03:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:03:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:03:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a4b466ba-490c-4a97-b6c0-6038b3586e62
01/31/2025 08:03:49:INFO:Received: train message a4b466ba-490c-4a97-b6c0-6038b3586e62
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:04:18:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:04:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:04:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4305162b-b849-4d45-899c-d32003ee75b7
01/31/2025 08:04:53:INFO:Received: evaluate message 4305162b-b849-4d45-899c-d32003ee75b7
[92mINFO [0m:      Sent reply
01/31/2025 08:04:55:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:05:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:05:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cfbc8030-8174-41a2-ac83-9eb0d54dfa11
01/31/2025 08:05:32:INFO:Received: train message cfbc8030-8174-41a2-ac83-9eb0d54dfa11
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:05:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:06:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:06:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5cdc4f36-2837-46b9-94e3-c588349cfd3c
01/31/2025 08:06:11:INFO:Received: evaluate message 5cdc4f36-2837-46b9-94e3-c588349cfd3c
[92mINFO [0m:      Sent reply
01/31/2025 08:06:13:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:07:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:07:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 79856fa5-d56e-4414-9a77-9212da2be482
01/31/2025 08:07:05:INFO:Received: train message 79856fa5-d56e-4414-9a77-9212da2be482
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:07:35:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:08:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:08:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5d5875ce-7916-4a93-98d1-dcd41664251d
01/31/2025 08:08:17:INFO:Received: evaluate message 5d5875ce-7916-4a93-98d1-dcd41664251d
[92mINFO [0m:      Sent reply
01/31/2025 08:08:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:08:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:08:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 775e006d-c886-4131-a0f6-38d6e99573ec
01/31/2025 08:08:52:INFO:Received: train message 775e006d-c886-4131-a0f6-38d6e99573ec
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:09:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:09:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:09:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3e202297-1329-45fd-9c5a-cb1fcac7610a
01/31/2025 08:09:44:INFO:Received: evaluate message 3e202297-1329-45fd-9c5a-cb1fcac7610a
[92mINFO [0m:      Sent reply
01/31/2025 08:09:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:10:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:10:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fa7e71c8-3111-43dd-bf95-ee1817a81efe
01/31/2025 08:10:43:INFO:Received: train message fa7e71c8-3111-43dd-bf95-ee1817a81efe
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:11:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:11:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:11:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6302c73a-5f10-4c79-8375-2bbdaa87a137
01/31/2025 08:11:38:INFO:Received: evaluate message 6302c73a-5f10-4c79-8375-2bbdaa87a137
[92mINFO [0m:      Sent reply
01/31/2025 08:11:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:12:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:12:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 350ca5f5-d9f8-4c47-9f7a-21afd748bfe1
01/31/2025 08:12:07:INFO:Received: train message 350ca5f5-d9f8-4c47-9f7a-21afd748bfe1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:12:35:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:13:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:13:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 71421047-15a6-47ff-adf5-26cae97e3df0
01/31/2025 08:13:31:INFO:Received: evaluate message 71421047-15a6-47ff-adf5-26cae97e3df0
[92mINFO [0m:      Sent reply
01/31/2025 08:13:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:13:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:13:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 12daf55b-195d-4cf6-9655-fed9c71b51a8
01/31/2025 08:13:47:INFO:Received: train message 12daf55b-195d-4cf6-9655-fed9c71b51a8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:14:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:15:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:15:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c674fbd1-6cb6-4d6f-be52-e23831c51ef3
01/31/2025 08:15:06:INFO:Received: evaluate message c674fbd1-6cb6-4d6f-be52-e23831c51ef3
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 20.0, target_epsilon: 20.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969], 'accuracy': [0.5183737294761532], 'auc': [0.7379489183581498]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479], 'accuracy': [0.5183737294761532, 0.5222830336200156], 'auc': [0.7379489183581498, 0.7546630873005361]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:15:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:15:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:15:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7f32a43e-40fb-4e84-a239-7066f892114f
01/31/2025 08:15:31:INFO:Received: train message 7f32a43e-40fb-4e84-a239-7066f892114f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:16:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:17:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:17:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c3e21597-bcf7-411a-8b0a-6506b1c6a7bd
01/31/2025 08:17:01:INFO:Received: evaluate message c3e21597-bcf7-411a-8b0a-6506b1c6a7bd
[92mINFO [0m:      Sent reply
01/31/2025 08:17:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:17:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:17:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8a0a276c-8c83-478b-acd7-4ee746f99955
01/31/2025 08:17:39:INFO:Received: train message 8a0a276c-8c83-478b-acd7-4ee746f99955
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:18:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:18:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:18:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fabf80ef-491a-468e-bc9f-c99d500d3ca4
01/31/2025 08:18:41:INFO:Received: evaluate message fabf80ef-491a-468e-bc9f-c99d500d3ca4
[92mINFO [0m:      Sent reply
01/31/2025 08:18:44:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:19:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:19:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 85aef24c-0a7b-48d7-86f3-4247b7d6daf9
01/31/2025 08:19:46:INFO:Received: train message 85aef24c-0a7b-48d7-86f3-4247b7d6daf9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:20:23:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:21:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:21:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b0480dcb-971a-45cc-9f49-902a1d3e741d
01/31/2025 08:21:13:INFO:Received: evaluate message b0480dcb-971a-45cc-9f49-902a1d3e741d
[92mINFO [0m:      Sent reply
01/31/2025 08:21:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:21:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:21:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 97487667-a831-4384-9502-87f17cc3a32a
01/31/2025 08:21:47:INFO:Received: train message 97487667-a831-4384-9502-87f17cc3a32a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:22:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:22:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:22:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c8d133d4-8dbc-4485-8742-d6d9d9587d5d
01/31/2025 08:22:50:INFO:Received: evaluate message c8d133d4-8dbc-4485-8742-d6d9d9587d5d
[92mINFO [0m:      Sent reply
01/31/2025 08:22:52:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:23:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:23:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 800388f3-1306-4849-8041-65b1c9580d93
01/31/2025 08:23:11:INFO:Received: train message 800388f3-1306-4849-8041-65b1c9580d93
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:23:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:24:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:24:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3f63844b-6398-4812-8876-98ef6456fabd
01/31/2025 08:24:28:INFO:Received: evaluate message 3f63844b-6398-4812-8876-98ef6456fabd
[92mINFO [0m:      Sent reply
01/31/2025 08:24:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:25:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:25:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 43769619-6edd-4ee1-a2bc-6e2f9a43fa9a
01/31/2025 08:25:03:INFO:Received: train message 43769619-6edd-4ee1-a2bc-6e2f9a43fa9a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:25:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:26:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:26:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9113ca35-bef2-4873-9251-f07aa03b8e74
01/31/2025 08:26:05:INFO:Received: evaluate message 9113ca35-bef2-4873-9251-f07aa03b8e74

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:26:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:26:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:26:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message bc4f1e72-5fc8-47b8-b5b4-58f9a10333b1
01/31/2025 08:26:18:INFO:Received: train message bc4f1e72-5fc8-47b8-b5b4-58f9a10333b1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:26:55:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:27:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:27:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e9c9cb83-2912-4f24-8d89-62b1ba436f3b
01/31/2025 08:27:43:INFO:Received: evaluate message e9c9cb83-2912-4f24-8d89-62b1ba436f3b
[92mINFO [0m:      Sent reply
01/31/2025 08:27:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:28:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:28:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b067ed9f-451e-435b-90ec-316f195ede65
01/31/2025 08:28:19:INFO:Received: train message b067ed9f-451e-435b-90ec-316f195ede65
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:28:43:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:29:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:29:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 79da5749-031d-408d-ae13-4d661770e1dc
01/31/2025 08:29:17:INFO:Received: evaluate message 79da5749-031d-408d-ae13-4d661770e1dc
[92mINFO [0m:      Sent reply
01/31/2025 08:29:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:30:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:30:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e194a5d3-caf1-4736-9f3e-5f4d68217a8e
01/31/2025 08:30:02:INFO:Received: train message e194a5d3-caf1-4736-9f3e-5f4d68217a8e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:30:27:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:30:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:30:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 21fcaf04-b0ea-4700-aa99-1c741f546669
01/31/2025 08:30:50:INFO:Received: evaluate message 21fcaf04-b0ea-4700-aa99-1c741f546669
[92mINFO [0m:      Sent reply
01/31/2025 08:30:53:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:31:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:31:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e7b3a438-c026-4bab-9b5a-8b9d4a24dede
01/31/2025 08:31:28:INFO:Received: train message e7b3a438-c026-4bab-9b5a-8b9d4a24dede
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:31:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:32:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:32:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 14a22e29-7358-4eae-8921-520042cfa65a
01/31/2025 08:32:37:INFO:Received: evaluate message 14a22e29-7358-4eae-8921-520042cfa65a
[92mINFO [0m:      Sent reply
01/31/2025 08:32:39:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:33:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:33:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1aa26556-ab5b-4de6-a433-80c00188fb6d
01/31/2025 08:33:12:INFO:Received: train message 1aa26556-ab5b-4de6-a433-80c00188fb6d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:33:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:34:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:34:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0ccbfcc5-5003-49ea-b650-e1234b3b3286
01/31/2025 08:34:27:INFO:Received: evaluate message 0ccbfcc5-5003-49ea-b650-e1234b3b3286

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:34:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:35:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:35:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7465237c-bc74-4f40-8028-c9c5044ce2af
01/31/2025 08:35:15:INFO:Received: train message 7465237c-bc74-4f40-8028-c9c5044ce2af
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:35:53:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:36:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:36:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9828db4c-a597-4227-bb6b-3dde84579ceb
01/31/2025 08:36:58:INFO:Received: evaluate message 9828db4c-a597-4227-bb6b-3dde84579ceb
[92mINFO [0m:      Sent reply
01/31/2025 08:37:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:37:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:37:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 710d94b7-8876-4bfd-9c13-a077588e0d9e
01/31/2025 08:37:39:INFO:Received: train message 710d94b7-8876-4bfd-9c13-a077588e0d9e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:38:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:38:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:38:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fb3b81b9-379a-48a1-9e40-92f6a3527ac7
01/31/2025 08:38:41:INFO:Received: evaluate message fb3b81b9-379a-48a1-9e40-92f6a3527ac7
[92mINFO [0m:      Sent reply
01/31/2025 08:38:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:39:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:39:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e228cbaf-6f72-4447-a62b-ab8d1216364a
01/31/2025 08:39:04:INFO:Received: train message e228cbaf-6f72-4447-a62b-ab8d1216364a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:39:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:40:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:40:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fea87acc-7134-4b2d-bb9d-6d75ca26b9c7
01/31/2025 08:40:17:INFO:Received: evaluate message fea87acc-7134-4b2d-bb9d-6d75ca26b9c7
[92mINFO [0m:      Sent reply
01/31/2025 08:40:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:40:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:40:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 90f5aa46-d8a6-40a2-9d33-7045ff5d83de
01/31/2025 08:40:40:INFO:Received: train message 90f5aa46-d8a6-40a2-9d33-7045ff5d83de
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:41:05:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:41:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:41:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 18c560b7-811b-4807-8e1c-0cb6052d12f1
01/31/2025 08:41:51:INFO:Received: evaluate message 18c560b7-811b-4807-8e1c-0cb6052d12f1

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:41:53:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:42:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:42:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d6bcba7b-e041-48a2-aa08-558981892b44
01/31/2025 08:42:21:INFO:Received: train message d6bcba7b-e041-48a2-aa08-558981892b44
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:42:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:43:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:43:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c605753a-0364-4d66-8b65-78c5c0fcb208
01/31/2025 08:43:29:INFO:Received: evaluate message c605753a-0364-4d66-8b65-78c5c0fcb208
[92mINFO [0m:      Sent reply
01/31/2025 08:43:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:43:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:43:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5ab93b53-771c-4364-a46f-472a457b8e27
01/31/2025 08:43:45:INFO:Received: train message 5ab93b53-771c-4364-a46f-472a457b8e27
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:44:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:45:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:45:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 24b204cf-884e-49a1-96d1-c825110d1d2a
01/31/2025 08:45:02:INFO:Received: evaluate message 24b204cf-884e-49a1-96d1-c825110d1d2a
[92mINFO [0m:      Sent reply
01/31/2025 08:45:05:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:45:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:45:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 93ba6a85-2cc2-4086-a1c6-033cf1210d24
01/31/2025 08:45:45:INFO:Received: train message 93ba6a85-2cc2-4086-a1c6-033cf1210d24
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:46:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:46:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:46:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e3df9dd0-a64f-4f3a-a0df-d5184f2728c6
01/31/2025 08:46:48:INFO:Received: evaluate message e3df9dd0-a64f-4f3a-a0df-d5184f2728c6
[92mINFO [0m:      Sent reply
01/31/2025 08:46:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:47:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:47:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3fca04f6-2c50-4b59-9fd7-3a518518ecea
01/31/2025 08:47:31:INFO:Received: train message 3fca04f6-2c50-4b59-9fd7-3a518518ecea

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:48:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:48:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:48:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message cc42f40b-ea51-4319-90d5-711c9cd500e8
01/31/2025 08:48:52:INFO:Received: evaluate message cc42f40b-ea51-4319-90d5-711c9cd500e8
[92mINFO [0m:      Sent reply
01/31/2025 08:48:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:49:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:49:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9ba0312a-d475-4e28-a941-7e2fea0cc0ff
01/31/2025 08:49:56:INFO:Received: train message 9ba0312a-d475-4e28-a941-7e2fea0cc0ff
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:50:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:51:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:51:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a9150251-b98e-4e0a-997c-0d420a760264
01/31/2025 08:51:25:INFO:Received: evaluate message a9150251-b98e-4e0a-997c-0d420a760264
[92mINFO [0m:      Sent reply
01/31/2025 08:51:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:51:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:51:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e53e6223-f6ba-4708-8176-22b29a9d903c
01/31/2025 08:51:57:INFO:Received: train message e53e6223-f6ba-4708-8176-22b29a9d903c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:52:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:52:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:52:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f88d0f08-5893-49ce-b9ee-c8cf54bf171e
01/31/2025 08:52:47:INFO:Received: evaluate message f88d0f08-5893-49ce-b9ee-c8cf54bf171e
[92mINFO [0m:      Sent reply
01/31/2025 08:52:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:53:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:53:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message 09c5abef-d564-4719-8e0e-849ed965458a
01/31/2025 08:53:07:INFO:Received: reconnect message 09c5abef-d564-4719-8e0e-849ed965458a
01/31/2025 08:53:07:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 08:53:07:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399, 1.0146706239891947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817, 0.8129905939058173]}



Final client history:
{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399, 1.0146706239891947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817, 0.8129905939058173]}

