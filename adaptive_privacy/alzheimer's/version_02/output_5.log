nohup: ignoring input
01/30/2025 05:28:21:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/30/2025 05:28:21:DEBUG:ChannelConnectivity.IDLE
01/30/2025 05:28:21:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/30/2025 05:29:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:29:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f71a3046-6d22-45da-b6e7-35df87a46ba4
01/30/2025 05:29:09:INFO:Received: train message f71a3046-6d22-45da-b6e7-35df87a46ba4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:29:51:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:30:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:30:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e2362544-bb5b-4743-9645-fae90a0c52ae
01/30/2025 05:30:51:INFO:Received: evaluate message e2362544-bb5b-4743-9645-fae90a0c52ae
[92mINFO [0m:      Sent reply
01/30/2025 05:30:55:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:31:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:31:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 34de6c62-deb4-4709-9aeb-2fc34157a697
01/30/2025 05:31:43:INFO:Received: train message 34de6c62-deb4-4709-9aeb-2fc34157a697
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:32:26:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:33:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:33:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6875998d-7b54-4c43-827a-cb86e25463bf
01/30/2025 05:33:54:INFO:Received: evaluate message 6875998d-7b54-4c43-827a-cb86e25463bf
[92mINFO [0m:      Sent reply
01/30/2025 05:33:59:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:34:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:34:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1a221166-0861-4d17-9b91-3577e2feb26f
01/30/2025 05:34:24:INFO:Received: train message 1a221166-0861-4d17-9b91-3577e2feb26f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:35:17:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:36:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:36:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4173cd1d-b7b6-4e63-a64c-23783c80cb44
01/30/2025 05:36:44:INFO:Received: evaluate message 4173cd1d-b7b6-4e63-a64c-23783c80cb44
[92mINFO [0m:      Sent reply
01/30/2025 05:36:50:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:37:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:37:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7276098b-ec4b-490d-96a3-4dd9fdd5ddf2
01/30/2025 05:37:34:INFO:Received: train message 7276098b-ec4b-490d-96a3-4dd9fdd5ddf2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:38:25:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:39:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:39:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 32c2d14b-ecf4-4716-ae72-3f8d4eac20c7
01/30/2025 05:39:31:INFO:Received: evaluate message 32c2d14b-ecf4-4716-ae72-3f8d4eac20c7
[92mINFO [0m:      Sent reply
01/30/2025 05:39:36:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:40:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:40:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 309f1960-bd8c-4614-b2f0-26566faab5b2
01/30/2025 05:40:30:INFO:Received: train message 309f1960-bd8c-4614-b2f0-26566faab5b2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:41:14:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:42:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:42:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7518207e-a1f8-4ccb-9d7f-06ba532d7f2c
01/30/2025 05:42:12:INFO:Received: evaluate message 7518207e-a1f8-4ccb-9d7f-06ba532d7f2c
[92mINFO [0m:      Sent reply
01/30/2025 05:42:17:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:43:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:43:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e4762d76-e7ea-40df-b5a2-cbf3e07e172e
01/30/2025 05:43:13:INFO:Received: train message e4762d76-e7ea-40df-b5a2-cbf3e07e172e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:43:57:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:44:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:44:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0b04c327-0d31-4455-b5a9-51cae1bf5b09
01/30/2025 05:44:48:INFO:Received: evaluate message 0b04c327-0d31-4455-b5a9-51cae1bf5b09
[92mINFO [0m:      Sent reply
01/30/2025 05:44:54:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:45:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:45:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b7f5921c-66d3-4650-b31e-f4215bb5ac6b
01/30/2025 05:45:41:INFO:Received: train message b7f5921c-66d3-4650-b31e-f4215bb5ac6b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:46:18:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:47:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:47:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 95c8a1a6-a9d2-4dc7-850d-d78df35a1566
01/30/2025 05:47:44:INFO:Received: evaluate message 95c8a1a6-a9d2-4dc7-850d-d78df35a1566
[92mINFO [0m:      Sent reply
01/30/2025 05:47:49:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:48:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:48:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 75e3511f-54c1-496f-83cd-e44dd77d2fc6
01/30/2025 05:48:20:INFO:Received: train message 75e3511f-54c1-496f-83cd-e44dd77d2fc6
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:49:01:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:49:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:49:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5d09b5e8-df78-4a7c-8a13-5a4d1784abe3
01/30/2025 05:49:53:INFO:Received: evaluate message 5d09b5e8-df78-4a7c-8a13-5a4d1784abe3
[92mINFO [0m:      Sent reply
01/30/2025 05:49:57:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:50:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:50:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7e3b577d-a705-45d4-8477-60490cefd07b
01/30/2025 05:50:57:INFO:Received: train message 7e3b577d-a705-45d4-8477-60490cefd07b
