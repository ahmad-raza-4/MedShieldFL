nohup: ignoring input
01/31/2025 05:19:19:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 05:19:19:DEBUG:ChannelConnectivity.IDLE
01/31/2025 05:19:19:DEBUG:ChannelConnectivity.CONNECTING
01/31/2025 05:19:19:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 05:19:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:19:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6b296701-b89d-486f-ab32-eeed31dc2213
01/31/2025 05:19:56:INFO:Received: train message 6b296701-b89d-486f-ab32-eeed31dc2213
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:20:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:20:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:20:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 70cbbb3b-a428-417b-860b-10f88ef3bf53
01/31/2025 05:20:45:INFO:Received: evaluate message 70cbbb3b-a428-417b-860b-10f88ef3bf53
[92mINFO [0m:      Sent reply
01/31/2025 05:20:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:21:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:21:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 812e2654-9540-4552-a7e9-7fac93c9727b
01/31/2025 05:21:30:INFO:Received: train message 812e2654-9540-4552-a7e9-7fac93c9727b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:21:47:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:22:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:22:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message be207cb9-13fc-42ed-8015-b5a26be5c778
01/31/2025 05:22:24:INFO:Received: evaluate message be207cb9-13fc-42ed-8015-b5a26be5c778
[92mINFO [0m:      Sent reply
01/31/2025 05:22:26:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:23:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:23:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a9567914-67e0-42a0-98f4-c72ead5e636b
01/31/2025 05:23:07:INFO:Received: train message a9567914-67e0-42a0-98f4-c72ead5e636b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:23:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:24:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:24:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 150a831d-6222-4c30-8066-08395ddb40fb
01/31/2025 05:24:07:INFO:Received: evaluate message 150a831d-6222-4c30-8066-08395ddb40fb
[92mINFO [0m:      Sent reply
01/31/2025 05:24:10:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:24:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:24:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5e009f8e-e786-4ce3-b679-9cc625f33df2
01/31/2025 05:24:47:INFO:Received: train message 5e009f8e-e786-4ce3-b679-9cc625f33df2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:25:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:25:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:25:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c3f72b4d-66f4-412a-b966-af883d48db47
01/31/2025 05:25:49:INFO:Received: evaluate message c3f72b4d-66f4-412a-b966-af883d48db47
[92mINFO [0m:      Sent reply
01/31/2025 05:25:53:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:26:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:26:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7cf273e1-2864-4e93-8525-5a50b798212c
01/31/2025 05:26:18:INFO:Received: train message 7cf273e1-2864-4e93-8525-5a50b798212c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:26:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:27:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:27:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3c3f7033-9e78-4822-93c6-ec2d80eb3653
01/31/2025 05:27:21:INFO:Received: evaluate message 3c3f7033-9e78-4822-93c6-ec2d80eb3653
[92mINFO [0m:      Sent reply
01/31/2025 05:27:23:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:28:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:28:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9e35ce50-aed4-4360-89d0-d1d7a7780db9
01/31/2025 05:28:03:INFO:Received: train message 9e35ce50-aed4-4360-89d0-d1d7a7780db9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:28:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:29:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:29:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 42110dc2-d47a-4fa3-b180-b348a111fe1f
01/31/2025 05:29:05:INFO:Received: evaluate message 42110dc2-d47a-4fa3-b180-b348a111fe1f
[92mINFO [0m:      Sent reply
01/31/2025 05:29:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:29:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:29:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ee730476-3fc2-484b-9742-0c5a16576bda
01/31/2025 05:29:39:INFO:Received: train message ee730476-3fc2-484b-9742-0c5a16576bda
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:29:55:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:30:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:30:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2f9c79c4-e934-4344-a5da-658dcb9b06b2
01/31/2025 05:30:56:INFO:Received: evaluate message 2f9c79c4-e934-4344-a5da-658dcb9b06b2
[92mINFO [0m:      Sent reply
01/31/2025 05:30:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:31:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:31:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 08f91444-aeee-4f87-a013-7ffa8736353a
01/31/2025 05:31:30:INFO:Received: train message 08f91444-aeee-4f87-a013-7ffa8736353a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:31:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:32:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:32:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 784a5786-f044-4cce-9428-dfc5d42eb51d
01/31/2025 05:32:30:INFO:Received: evaluate message 784a5786-f044-4cce-9428-dfc5d42eb51d
[92mINFO [0m:      Sent reply
01/31/2025 05:32:32:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:33:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:33:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4a009ad0-0195-4d4f-8d9a-96c84c97edb5
01/31/2025 05:33:06:INFO:Received: train message 4a009ad0-0195-4d4f-8d9a-96c84c97edb5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:33:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:33:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:33:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fee21163-ac67-43da-933e-f5983f3e6080
01/31/2025 05:33:55:INFO:Received: evaluate message fee21163-ac67-43da-933e-f5983f3e6080
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 1.0, target_epsilon: 1.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118], 'accuracy': [0.5175918686473807], 'auc': [0.737810384411014]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651], 'accuracy': [0.5175918686473807, 0.5215011727912432], 'auc': [0.737810384411014, 0.754622171691574]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:33:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:34:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:34:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 794a50de-4ed9-4911-a8ed-77c5592cb5ae
01/31/2025 05:34:26:INFO:Received: train message 794a50de-4ed9-4911-a8ed-77c5592cb5ae
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:34:37:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:36:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:36:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6d5dbcc7-e053-4ecf-9b3d-235e1a31164f
01/31/2025 05:36:03:INFO:Received: evaluate message 6d5dbcc7-e053-4ecf-9b3d-235e1a31164f
[92mINFO [0m:      Sent reply
01/31/2025 05:36:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:36:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:36:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cf3af258-eea6-41f5-bd6f-e990c0ef06a7
01/31/2025 05:36:33:INFO:Received: train message cf3af258-eea6-41f5-bd6f-e990c0ef06a7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:36:50:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:37:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:37:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0da9c917-7520-4f2c-b615-de599d61b97a
01/31/2025 05:37:44:INFO:Received: evaluate message 0da9c917-7520-4f2c-b615-de599d61b97a
[92mINFO [0m:      Sent reply
01/31/2025 05:37:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:38:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:38:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a21ff116-fb2e-4538-b5fa-3982fbf76a69
01/31/2025 05:38:33:INFO:Received: train message a21ff116-fb2e-4538-b5fa-3982fbf76a69
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:38:51:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:39:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:39:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 086e086c-c50b-4db8-aa25-09217d497a1f
01/31/2025 05:39:48:INFO:Received: evaluate message 086e086c-c50b-4db8-aa25-09217d497a1f
[92mINFO [0m:      Sent reply
01/31/2025 05:39:50:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:40:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:40:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 340dd509-0460-4c19-a6cb-33fe076e0b5c
01/31/2025 05:40:20:INFO:Received: train message 340dd509-0460-4c19-a6cb-33fe076e0b5c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:40:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:41:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:41:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 694d8a7a-04a2-4f10-9936-88c1ba180746
01/31/2025 05:41:34:INFO:Received: evaluate message 694d8a7a-04a2-4f10-9936-88c1ba180746
[92mINFO [0m:      Sent reply
01/31/2025 05:41:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:42:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:42:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3714e95d-72ce-4679-8089-0a20beef10ac
01/31/2025 05:42:04:INFO:Received: train message 3714e95d-72ce-4679-8089-0a20beef10ac
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:42:18:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:42:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:42:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 81471793-1787-4dc9-b48b-bed6d665cf60
01/31/2025 05:42:59:INFO:Received: evaluate message 81471793-1787-4dc9-b48b-bed6d665cf60
[92mINFO [0m:      Sent reply
01/31/2025 05:43:01:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:43:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:43:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b9fd6194-bca3-4857-8bc7-11b3decccdc9
01/31/2025 05:43:52:INFO:Received: train message b9fd6194-bca3-4857-8bc7-11b3decccdc9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:44:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:44:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:44:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8ec27e3b-15fe-4369-b204-be57bcb91db8
01/31/2025 05:44:40:INFO:Received: evaluate message 8ec27e3b-15fe-4369-b204-be57bcb91db8

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:44:43:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:45:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:45:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c839707b-1407-449c-8bf9-4f3eb682c762
01/31/2025 05:45:19:INFO:Received: train message c839707b-1407-449c-8bf9-4f3eb682c762
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:45:32:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:46:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:46:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6254da34-5c51-4360-bea2-c20a4fcaa06b
01/31/2025 05:46:05:INFO:Received: evaluate message 6254da34-5c51-4360-bea2-c20a4fcaa06b
[92mINFO [0m:      Sent reply
01/31/2025 05:46:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:46:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:46:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 07c1043a-5f40-4a97-bf9d-d4c3849f4d59
01/31/2025 05:46:43:INFO:Received: train message 07c1043a-5f40-4a97-bf9d-d4c3849f4d59
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:47:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:47:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:47:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 47c72c5a-68d4-49f0-9cac-37dfcb119df9
01/31/2025 05:47:39:INFO:Received: evaluate message 47c72c5a-68d4-49f0-9cac-37dfcb119df9
[92mINFO [0m:      Sent reply
01/31/2025 05:47:41:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:48:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:48:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f5df8400-ba9f-499f-a824-7328ccc2536c
01/31/2025 05:48:14:INFO:Received: train message f5df8400-ba9f-499f-a824-7328ccc2536c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:48:25:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:49:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:49:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message cd2019d3-2483-4c30-b1bc-cee0f266e56a
01/31/2025 05:49:00:INFO:Received: evaluate message cd2019d3-2483-4c30-b1bc-cee0f266e56a
[92mINFO [0m:      Sent reply
01/31/2025 05:49:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:49:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:49:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7a57c14c-84b1-4312-ba75-3f6410e4b0c8
01/31/2025 05:49:36:INFO:Received: train message 7a57c14c-84b1-4312-ba75-3f6410e4b0c8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:49:52:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:50:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:50:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 879ef47b-7dfc-4a2d-8779-4327c7cc0cad
01/31/2025 05:50:21:INFO:Received: evaluate message 879ef47b-7dfc-4a2d-8779-4327c7cc0cad
[92mINFO [0m:      Sent reply
01/31/2025 05:50:23:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:50:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:50:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6a9f0628-3112-4997-9139-b11f00f2c1b4
01/31/2025 05:50:59:INFO:Received: train message 6a9f0628-3112-4997-9139-b11f00f2c1b4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:51:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:51:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:51:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a46e0d9d-8ca5-4d20-bdbd-f466f9713aa7
01/31/2025 05:51:51:INFO:Received: evaluate message a46e0d9d-8ca5-4d20-bdbd-f466f9713aa7

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:51:53:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:52:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:52:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d47cca6f-df36-4492-9670-caf06969affe
01/31/2025 05:52:33:INFO:Received: train message d47cca6f-df36-4492-9670-caf06969affe
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:52:47:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:53:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:53:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8ab8460e-094e-40c3-a771-a3b2af32f275
01/31/2025 05:53:25:INFO:Received: evaluate message 8ab8460e-094e-40c3-a771-a3b2af32f275
[92mINFO [0m:      Sent reply
01/31/2025 05:53:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:54:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:54:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 66a28f62-bf7a-48a9-bc25-56def3fad317
01/31/2025 05:54:02:INFO:Received: train message 66a28f62-bf7a-48a9-bc25-56def3fad317
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:54:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:54:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:54:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6f376ad0-646d-42e8-8222-2088d1c40f74
01/31/2025 05:54:59:INFO:Received: evaluate message 6f376ad0-646d-42e8-8222-2088d1c40f74
[92mINFO [0m:      Sent reply
01/31/2025 05:55:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:55:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:55:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 03b500a6-d56a-4528-86f2-867da4170ceb
01/31/2025 05:55:42:INFO:Received: train message 03b500a6-d56a-4528-86f2-867da4170ceb
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:55:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:56:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:56:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7bcb3aa8-f016-46ef-9435-f0cc99ebdeb5
01/31/2025 05:56:34:INFO:Received: evaluate message 7bcb3aa8-f016-46ef-9435-f0cc99ebdeb5
[92mINFO [0m:      Sent reply
01/31/2025 05:56:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:57:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:57:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d555fdff-43f9-4057-b484-a98ffaf3e548
01/31/2025 05:57:14:INFO:Received: train message d555fdff-43f9-4057-b484-a98ffaf3e548
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:57:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:57:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:57:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c606e03a-1eb0-400c-89b2-a7ec597e9d94
01/31/2025 05:57:54:INFO:Received: evaluate message c606e03a-1eb0-400c-89b2-a7ec597e9d94

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:57:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:58:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:58:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b5abf3bf-a1bb-47e1-be39-d41fe4b97b00
01/31/2025 05:58:52:INFO:Received: train message b5abf3bf-a1bb-47e1-be39-d41fe4b97b00
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:59:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:59:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:59:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4897d209-29a7-4bf9-ab19-58b17daf1f80
01/31/2025 05:59:47:INFO:Received: evaluate message 4897d209-29a7-4bf9-ab19-58b17daf1f80
[92mINFO [0m:      Sent reply
01/31/2025 05:59:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:00:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:00:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d1395498-c327-48ad-a184-a10f3a61a844
01/31/2025 06:00:26:INFO:Received: train message d1395498-c327-48ad-a184-a10f3a61a844
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:00:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:00:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:00:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b745f557-546d-4ef9-b561-0f45ee46cf03
01/31/2025 06:00:57:INFO:Received: evaluate message b745f557-546d-4ef9-b561-0f45ee46cf03
[92mINFO [0m:      Sent reply
01/31/2025 06:00:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:01:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:01:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8cf976fa-5513-49a1-b32d-84a3135a17aa
01/31/2025 06:01:33:INFO:Received: train message 8cf976fa-5513-49a1-b32d-84a3135a17aa
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:01:43:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:02:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:02:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8515bf2a-2b5b-4104-8435-ffe34b86d307
01/31/2025 06:02:40:INFO:Received: evaluate message 8515bf2a-2b5b-4104-8435-ffe34b86d307
[92mINFO [0m:      Sent reply
01/31/2025 06:02:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:03:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:03:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f65aec43-480d-44ce-b932-df274b239d54
01/31/2025 06:03:13:INFO:Received: train message f65aec43-480d-44ce-b932-df274b239d54

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:03:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:04:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:04:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 35d4517d-c421-4667-9b40-0990d1ddc30d
01/31/2025 06:04:37:INFO:Received: evaluate message 35d4517d-c421-4667-9b40-0990d1ddc30d
[92mINFO [0m:      Sent reply
01/31/2025 06:04:41:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:05:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:05:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message bdfe1122-5460-42eb-b4a2-a2f1556f31a4
01/31/2025 06:05:17:INFO:Received: train message bdfe1122-5460-42eb-b4a2-a2f1556f31a4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:05:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:06:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:06:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9c149ac3-8386-4777-802e-b78c09eea10e
01/31/2025 06:06:27:INFO:Received: evaluate message 9c149ac3-8386-4777-802e-b78c09eea10e
[92mINFO [0m:      Sent reply
01/31/2025 06:06:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:07:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:07:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ee9115d9-567d-49e9-84b3-566794c964d7
01/31/2025 06:07:04:INFO:Received: train message ee9115d9-567d-49e9-84b3-566794c964d7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:07:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:08:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:08:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ad999d8c-4c3d-47d8-ba77-230c40513252
01/31/2025 06:08:03:INFO:Received: evaluate message ad999d8c-4c3d-47d8-ba77-230c40513252
[92mINFO [0m:      Sent reply
01/31/2025 06:08:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:08:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:08:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message 18271ce1-f37e-47bb-a2f5-391baca473ed
01/31/2025 06:08:23:INFO:Received: reconnect message 18271ce1-f37e-47bb-a2f5-391baca473ed
01/31/2025 06:08:23:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 06:08:23:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 1088, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678, 1.014726576626161], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409, 0.8129799795083197]}



Final client history:
{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678, 1.014726576626161], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409, 0.8129799795083197]}

