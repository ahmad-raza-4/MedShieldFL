nohup: ignoring input
01/31/2025 05:19:18:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 05:19:18:DEBUG:ChannelConnectivity.IDLE
01/31/2025 05:19:18:DEBUG:ChannelConnectivity.CONNECTING
01/31/2025 05:19:18:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 05:19:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:19:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 69d23a37-5922-4207-afee-cb00688baa32
01/31/2025 05:19:56:INFO:Received: train message 69d23a37-5922-4207-afee-cb00688baa32
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:20:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:20:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:20:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message dd7e08fd-3941-4139-a2e3-d130aef74f0a
01/31/2025 05:20:55:INFO:Received: evaluate message dd7e08fd-3941-4139-a2e3-d130aef74f0a
[92mINFO [0m:      Sent reply
01/31/2025 05:20:58:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:21:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:21:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b151db44-1aa4-4427-b97e-227cc16085d8
01/31/2025 05:21:33:INFO:Received: train message b151db44-1aa4-4427-b97e-227cc16085d8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:21:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:22:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:22:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 71eebc97-cd5e-464f-a62c-8f3dd5f332ab
01/31/2025 05:22:31:INFO:Received: evaluate message 71eebc97-cd5e-464f-a62c-8f3dd5f332ab
[92mINFO [0m:      Sent reply
01/31/2025 05:22:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:23:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:23:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3b18f74f-26bf-4b66-86ac-9e167612c101
01/31/2025 05:23:13:INFO:Received: train message 3b18f74f-26bf-4b66-86ac-9e167612c101
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:23:24:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:24:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:24:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4dcd72d3-c640-4f06-a5a1-7d6c91aa3439
01/31/2025 05:24:12:INFO:Received: evaluate message 4dcd72d3-c640-4f06-a5a1-7d6c91aa3439
[92mINFO [0m:      Sent reply
01/31/2025 05:24:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:24:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:24:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0d7caf98-d7a8-4a98-a994-897ee85164f5
01/31/2025 05:24:34:INFO:Received: train message 0d7caf98-d7a8-4a98-a994-897ee85164f5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:24:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:25:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:25:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0ab78093-d308-4c96-8e7f-7855c20d5924
01/31/2025 05:25:31:INFO:Received: evaluate message 0ab78093-d308-4c96-8e7f-7855c20d5924
[92mINFO [0m:      Sent reply
01/31/2025 05:25:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:26:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:26:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3cb4d402-79f1-45ae-a443-16fd5b6362d0
01/31/2025 05:26:23:INFO:Received: train message 3cb4d402-79f1-45ae-a443-16fd5b6362d0
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:26:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:27:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:27:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7e4861d5-04f7-48c8-b3d9-043f010dd956
01/31/2025 05:27:17:INFO:Received: evaluate message 7e4861d5-04f7-48c8-b3d9-043f010dd956
[92mINFO [0m:      Sent reply
01/31/2025 05:27:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:27:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:27:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e97f0168-9b2b-4e66-a036-15dd6d59313d
01/31/2025 05:27:52:INFO:Received: train message e97f0168-9b2b-4e66-a036-15dd6d59313d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:28:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:29:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:29:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8fc36b18-8f43-4efe-9c8f-1a711b937514
01/31/2025 05:29:00:INFO:Received: evaluate message 8fc36b18-8f43-4efe-9c8f-1a711b937514
[92mINFO [0m:      Sent reply
01/31/2025 05:29:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:29:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:29:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 07683b0f-17c9-464b-8f7f-3e70603f79c9
01/31/2025 05:29:22:INFO:Received: train message 07683b0f-17c9-464b-8f7f-3e70603f79c9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:29:33:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:30:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:30:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ad2c5e6e-87ba-4f53-af41-f557183fff97
01/31/2025 05:30:53:INFO:Received: evaluate message ad2c5e6e-87ba-4f53-af41-f557183fff97
[92mINFO [0m:      Sent reply
01/31/2025 05:30:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:31:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:31:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8b4d34c8-1bcb-41a6-a3c7-aa8f1b127bc9
01/31/2025 05:31:27:INFO:Received: train message 8b4d34c8-1bcb-41a6-a3c7-aa8f1b127bc9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:31:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:32:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:32:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3b5a8f45-f02e-4e02-bb7f-2ccb2c081f25
01/31/2025 05:32:16:INFO:Received: evaluate message 3b5a8f45-f02e-4e02-bb7f-2ccb2c081f25
[92mINFO [0m:      Sent reply
01/31/2025 05:32:18:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:32:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:32:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a5373152-0672-456e-ad1f-d6fdab76d2e4
01/31/2025 05:32:50:INFO:Received: train message a5373152-0672-456e-ad1f-d6fdab76d2e4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:33:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:34:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:34:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message af6a28cb-aa11-40ba-ac0b-ba04ad10010c
01/31/2025 05:34:03:INFO:Received: evaluate message af6a28cb-aa11-40ba-ac0b-ba04ad10010c
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 1.0, target_epsilon: 1.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118], 'accuracy': [0.5175918686473807], 'auc': [0.737810384411014]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651], 'accuracy': [0.5175918686473807, 0.5215011727912432], 'auc': [0.737810384411014, 0.754622171691574]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:34:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:34:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:34:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4d706a7f-06d5-4bf2-8f73-0c1d0c0eea53
01/31/2025 05:34:20:INFO:Received: train message 4d706a7f-06d5-4bf2-8f73-0c1d0c0eea53
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:34:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:35:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:35:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6043a449-beac-4892-9cec-817b6dc19858
01/31/2025 05:35:54:INFO:Received: evaluate message 6043a449-beac-4892-9cec-817b6dc19858
[92mINFO [0m:      Sent reply
01/31/2025 05:35:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:36:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:36:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2bfd2976-412e-4fe9-a2d0-e9c3b55fa553
01/31/2025 05:36:42:INFO:Received: train message 2bfd2976-412e-4fe9-a2d0-e9c3b55fa553
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:36:57:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:37:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:37:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f06f8db7-68da-4327-a555-0068582824cb
01/31/2025 05:37:44:INFO:Received: evaluate message f06f8db7-68da-4327-a555-0068582824cb
[92mINFO [0m:      Sent reply
01/31/2025 05:37:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:38:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:38:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ba42ef6f-a5e6-4860-94ab-f3d569137e3c
01/31/2025 05:38:38:INFO:Received: train message ba42ef6f-a5e6-4860-94ab-f3d569137e3c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:38:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:39:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:39:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message be0c2858-42e0-48b7-a02a-01d8d7f6f90b
01/31/2025 05:39:44:INFO:Received: evaluate message be0c2858-42e0-48b7-a02a-01d8d7f6f90b
[92mINFO [0m:      Sent reply
01/31/2025 05:39:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:40:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:40:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e64ccacb-b99a-48af-943b-8498b7eb319e
01/31/2025 05:40:38:INFO:Received: train message e64ccacb-b99a-48af-943b-8498b7eb319e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:40:50:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:41:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:41:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message afbb88f1-73ec-4b47-ba1d-e37ab5ff7c37
01/31/2025 05:41:25:INFO:Received: evaluate message afbb88f1-73ec-4b47-ba1d-e37ab5ff7c37
[92mINFO [0m:      Sent reply
01/31/2025 05:41:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:42:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:42:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f13ff9cf-c7f4-4a84-8710-41227d2642dd
01/31/2025 05:42:22:INFO:Received: train message f13ff9cf-c7f4-4a84-8710-41227d2642dd
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:42:32:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:43:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:43:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f2ac2841-b6b4-4ca7-8cf9-2f8fc910c55d
01/31/2025 05:43:04:INFO:Received: evaluate message f2ac2841-b6b4-4ca7-8cf9-2f8fc910c55d
[92mINFO [0m:      Sent reply
01/31/2025 05:43:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:43:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:43:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6f7c0a65-8bfa-4ab0-aa4e-6fae123cfff1
01/31/2025 05:43:28:INFO:Received: train message 6f7c0a65-8bfa-4ab0-aa4e-6fae123cfff1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:43:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:44:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:44:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d45219f0-a635-4b02-96cd-b7e412c16a30
01/31/2025 05:44:46:INFO:Received: evaluate message d45219f0-a635-4b02-96cd-b7e412c16a30

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:44:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:45:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:45:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message dca7492d-f493-4d91-85ff-7b2eca0db43a
01/31/2025 05:45:21:INFO:Received: train message dca7492d-f493-4d91-85ff-7b2eca0db43a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:45:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:45:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:45:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c6901086-26bf-429c-9257-13cc2f5ada76
01/31/2025 05:45:53:INFO:Received: evaluate message c6901086-26bf-429c-9257-13cc2f5ada76
[92mINFO [0m:      Sent reply
01/31/2025 05:45:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:46:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:46:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7b7f367e-fb81-45e3-b91a-042b3747e7e1
01/31/2025 05:46:34:INFO:Received: train message 7b7f367e-fb81-45e3-b91a-042b3747e7e1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:46:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:47:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:47:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c287afdc-a74f-4810-a0b3-d66714489055
01/31/2025 05:47:20:INFO:Received: evaluate message c287afdc-a74f-4810-a0b3-d66714489055
[92mINFO [0m:      Sent reply
01/31/2025 05:47:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:48:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:48:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4345b96c-3cbf-416d-9c24-cf418e30c7f8
01/31/2025 05:48:07:INFO:Received: train message 4345b96c-3cbf-416d-9c24-cf418e30c7f8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:48:20:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:49:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:49:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1583f52a-ffe3-44a6-908b-f36733043eeb
01/31/2025 05:49:03:INFO:Received: evaluate message 1583f52a-ffe3-44a6-908b-f36733043eeb
[92mINFO [0m:      Sent reply
01/31/2025 05:49:05:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:49:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:49:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8387963f-e274-4b50-bbd8-5edb2b7d8b28
01/31/2025 05:49:29:INFO:Received: train message 8387963f-e274-4b50-bbd8-5edb2b7d8b28
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:49:41:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:50:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:50:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b9069606-7d1d-4a15-a0a5-aa4873115b87
01/31/2025 05:50:30:INFO:Received: evaluate message b9069606-7d1d-4a15-a0a5-aa4873115b87
[92mINFO [0m:      Sent reply
01/31/2025 05:50:32:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:51:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:51:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a1809cbb-e0eb-428e-8cc3-ef333b041eab
01/31/2025 05:51:04:INFO:Received: train message a1809cbb-e0eb-428e-8cc3-ef333b041eab
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:51:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:51:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:51:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 935419d9-ecf6-4b4d-ab28-dfcfd88a6d64
01/31/2025 05:51:40:INFO:Received: evaluate message 935419d9-ecf6-4b4d-ab28-dfcfd88a6d64

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:51:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:52:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:52:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 886bc311-8d50-406c-984d-eac4add6c22b
01/31/2025 05:52:28:INFO:Received: train message 886bc311-8d50-406c-984d-eac4add6c22b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:52:41:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:53:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:53:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8c92c5e0-752e-4926-8114-e85046084fd0
01/31/2025 05:53:19:INFO:Received: evaluate message 8c92c5e0-752e-4926-8114-e85046084fd0
[92mINFO [0m:      Sent reply
01/31/2025 05:53:22:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:53:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:53:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b2d9d62f-37dd-4936-a413-0ca3790b64be
01/31/2025 05:53:40:INFO:Received: train message b2d9d62f-37dd-4936-a413-0ca3790b64be
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:53:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:54:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:54:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d2bb24b4-b1b1-4cc4-8111-ee58ef149cf9
01/31/2025 05:54:57:INFO:Received: evaluate message d2bb24b4-b1b1-4cc4-8111-ee58ef149cf9
[92mINFO [0m:      Sent reply
01/31/2025 05:55:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:55:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:55:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e14cf3cc-b845-4761-bd5f-cf437dd2ae76
01/31/2025 05:55:38:INFO:Received: train message e14cf3cc-b845-4761-bd5f-cf437dd2ae76
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:55:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:56:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:56:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message dc56d75d-0ec7-4c7e-974b-6e3b2fcf7217
01/31/2025 05:56:16:INFO:Received: evaluate message dc56d75d-0ec7-4c7e-974b-6e3b2fcf7217
[92mINFO [0m:      Sent reply
01/31/2025 05:56:18:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:57:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:57:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c9af331b-7924-49fb-bb92-541b2c747ce4
01/31/2025 05:57:00:INFO:Received: train message c9af331b-7924-49fb-bb92-541b2c747ce4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:57:09:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:57:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:57:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6281e313-021e-4266-9947-de0a4abec84a
01/31/2025 05:57:54:INFO:Received: evaluate message 6281e313-021e-4266-9947-de0a4abec84a

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 05:57:56:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:58:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:58:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4a7406b9-5ae2-4899-bbfe-7fa35b32db5c
01/31/2025 05:58:52:INFO:Received: train message 4a7406b9-5ae2-4899-bbfe-7fa35b32db5c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 05:59:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 05:59:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 05:59:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5ec3cae1-64d6-43a3-b025-3934e18d3dd3
01/31/2025 05:59:43:INFO:Received: evaluate message 5ec3cae1-64d6-43a3-b025-3934e18d3dd3
[92mINFO [0m:      Sent reply
01/31/2025 05:59:45:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:00:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:00:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 99e49813-a43b-45d2-b5fc-d78c75bc8f22
01/31/2025 06:00:23:INFO:Received: train message 99e49813-a43b-45d2-b5fc-d78c75bc8f22
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:00:37:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:01:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:01:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fbc432d8-5a4f-4b78-8a54-ecc8b4eb646e
01/31/2025 06:01:05:INFO:Received: evaluate message fbc432d8-5a4f-4b78-8a54-ecc8b4eb646e
[92mINFO [0m:      Sent reply
01/31/2025 06:01:07:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:01:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:01:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a7d26c87-d447-4703-b567-4530229fc7ba
01/31/2025 06:01:49:INFO:Received: train message a7d26c87-d447-4703-b567-4530229fc7ba
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:01:59:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:02:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:02:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9c1a8882-104b-491f-9f81-13f7b4dc6180
01/31/2025 06:02:49:INFO:Received: evaluate message 9c1a8882-104b-491f-9f81-13f7b4dc6180
[92mINFO [0m:      Sent reply
01/31/2025 06:02:53:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:03:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:03:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message aca4744c-1d71-49f9-a387-528ab4b0edc1
01/31/2025 06:03:19:INFO:Received: train message aca4744c-1d71-49f9-a387-528ab4b0edc1

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:03:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:04:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:04:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 166c9785-c892-44da-a070-a88b15e00ca1
01/31/2025 06:04:26:INFO:Received: evaluate message 166c9785-c892-44da-a070-a88b15e00ca1
[92mINFO [0m:      Sent reply
01/31/2025 06:04:29:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:05:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:05:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7f49ee13-0d61-4f2c-80e4-d6ac97994ef9
01/31/2025 06:05:22:INFO:Received: train message 7f49ee13-0d61-4f2c-80e4-d6ac97994ef9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:05:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:06:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:06:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 938d3d32-d4a6-4e01-9fce-f3d008c6dce7
01/31/2025 06:06:26:INFO:Received: evaluate message 938d3d32-d4a6-4e01-9fce-f3d008c6dce7
[92mINFO [0m:      Sent reply
01/31/2025 06:06:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:07:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:07:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d3840842-ac03-4869-a796-fd8dec8daa79
01/31/2025 06:07:10:INFO:Received: train message d3840842-ac03-4869-a796-fd8dec8daa79
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 06:07:26:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:08:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:08:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d4e1dcca-326e-441c-8f82-f18926eb3a35
01/31/2025 06:08:17:INFO:Received: evaluate message d4e1dcca-326e-441c-8f82-f18926eb3a35
[92mINFO [0m:      Sent reply
01/31/2025 06:08:21:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 06:08:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 06:08:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message ca4cc693-5d94-4f31-8730-4879351e7ce4
01/31/2025 06:08:23:INFO:Received: reconnect message ca4cc693-5d94-4f31-8730-4879351e7ce4
01/31/2025 06:08:23:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 06:08:23:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 768, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678, 1.014726576626161], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409, 0.8129799795083197]}



Final client history:
{'loss': [1.0650320724177118, 1.1435031147092651, 1.14496373468493, 1.0871561519143356, 1.0580496810860145, 1.0860763859991174, 1.078478406238034, 1.075482842230629, 1.0735989590004331, 1.071916224156813, 1.008569647130601, 1.049823229997022, 1.032722747120846, 1.0393645761533115, 1.0436073726187283, 1.043382160499564, 1.0689515229591269, 1.0154109152617914, 1.0378118212843799, 1.105929083056148, 1.0370387514183725, 1.0404642454994386, 1.0359342383909635, 1.036139934952134, 0.9872238999516634, 1.0871558723457164, 1.0336675031563562, 1.006800597398145, 1.0072966768836678, 1.014726576626161], 'accuracy': [0.5175918686473807, 0.5215011727912432, 0.5340109460516028, 0.5433932759968726, 0.5543393275996873, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5856137607505864, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5895230648944488, 0.5777951524628616, 0.5840500390930414, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.737810384411014, 0.754622171691574, 0.7630398645800955, 0.7718321472507048, 0.777497085891427, 0.7804611864899138, 0.7828739786675091, 0.7847185316137854, 0.7860346211118455, 0.7884850994031911, 0.7928451880461926, 0.7949859176877196, 0.7949766829233569, 0.7937493853010754, 0.7958585238036657, 0.7975881541457897, 0.799110162433671, 0.8006139013113436, 0.8001750832077643, 0.8009661738399159, 0.8038719238804488, 0.8044155986611784, 0.8048619192047883, 0.8059240550589555, 0.8094196018912208, 0.809639705995446, 0.8109418186232445, 0.8121464706217649, 0.8107583221748409, 0.8129799795083197]}

