Initial Train Dataset Size: 768 Sample rate: 0.12
Global Epoch (Round): 1, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.5260, Epsilon: 1.00, Dynamic Noise Multiplier: 0.00
Loss: 1.0715, Accuracy: 0.5207, AUC: 0.7293
Initial Train Dataset Size: 768 Sample rate: 0.12
Global Epoch (Round): 1, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.5366, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0650, Accuracy: 0.5176, AUC: 0.7378
Global Epoch (Round): 2, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.4721, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.1435, Accuracy: 0.5215, AUC: 0.7546
Global Epoch (Round): 3, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.4069, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.1450, Accuracy: 0.5340, AUC: 0.7630
Global Epoch (Round): 4, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.4461, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0872, Accuracy: 0.5434, AUC: 0.7718
Global Epoch (Round): 5, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3576, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0580, Accuracy: 0.5543, AUC: 0.7775
Global Epoch (Round): 6, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3767, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0861, Accuracy: 0.5590, AUC: 0.7805
Global Epoch (Round): 7, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.4233, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0785, Accuracy: 0.5598, AUC: 0.7829
Global Epoch (Round): 8, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3941, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0755, Accuracy: 0.5590, AUC: 0.7847
Global Epoch (Round): 9, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3480, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0736, Accuracy: 0.5653, AUC: 0.7860
Global Epoch (Round): 10, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2785, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0719, Accuracy: 0.5622, AUC: 0.7885
Global Epoch (Round): 11, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3312, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0086, Accuracy: 0.5692, AUC: 0.7928
Global Epoch (Round): 12, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2915, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0498, Accuracy: 0.5770, AUC: 0.7950
Global Epoch (Round): 13, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2849, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0327, Accuracy: 0.5794, AUC: 0.7950
Global Epoch (Round): 14, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2870, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0394, Accuracy: 0.5731, AUC: 0.7937
Global Epoch (Round): 15, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3081, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0436, Accuracy: 0.5856, AUC: 0.7959
Global Epoch (Round): 16, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3114, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0434, Accuracy: 0.5848, AUC: 0.7976
Global Epoch (Round): 17, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2547, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0690, Accuracy: 0.5770, AUC: 0.7991
Global Epoch (Round): 18, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2893, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0154, Accuracy: 0.5825, AUC: 0.8006
Global Epoch (Round): 19, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2574, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0378, Accuracy: 0.5895, AUC: 0.8002
Global Epoch (Round): 20, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2284, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.1059, Accuracy: 0.5778, AUC: 0.8010
Global Epoch (Round): 21, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2648, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0370, Accuracy: 0.5841, AUC: 0.8039
Global Epoch (Round): 22, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2908, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0405, Accuracy: 0.5848, AUC: 0.8044
Global Epoch (Round): 23, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2683, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0359, Accuracy: 0.5911, AUC: 0.8049
Global Epoch (Round): 24, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2710, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0361, Accuracy: 0.5903, AUC: 0.8059
Global Epoch (Round): 25, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2582, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 0.9872, Accuracy: 0.5981, AUC: 0.8094
Global Epoch (Round): 26, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2563, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0872, Accuracy: 0.5864, AUC: 0.8096
Global Epoch (Round): 27, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2665, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0337, Accuracy: 0.5942, AUC: 0.8109
Global Epoch (Round): 28, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2390, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0068, Accuracy: 0.5966, AUC: 0.8121
Global Epoch (Round): 29, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2335, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0073, Accuracy: 0.5989, AUC: 0.8108
Global Epoch (Round): 30, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2358, Epsilon: 1.0000, Dynamic Noise Multiplier: 0.0005
Loss: 1.0147, Accuracy: 0.5989, AUC: 0.8130
