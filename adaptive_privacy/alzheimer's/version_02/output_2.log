nohup: ignoring input
01/30/2025 05:28:15:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/30/2025 05:28:15:DEBUG:ChannelConnectivity.IDLE
01/30/2025 05:28:15:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/30/2025 05:28:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:28:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: get_parameters message 9b6ec957-a83d-42d8-bc46-0145a7667cc4
01/30/2025 05:28:15:INFO:Received: get_parameters message 9b6ec957-a83d-42d8-bc46-0145a7667cc4
[92mINFO [0m:      Sent reply
01/30/2025 05:28:21:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:29:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:29:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d8b9d8a7-6ee8-4fbb-9950-c036cb2458e5
01/30/2025 05:29:07:INFO:Received: train message d8b9d8a7-6ee8-4fbb-9950-c036cb2458e5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:29:43:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:30:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:30:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 80449a0e-e828-4686-9eac-5c332b87c25f
01/30/2025 05:30:56:INFO:Received: evaluate message 80449a0e-e828-4686-9eac-5c332b87c25f
[92mINFO [0m:      Sent reply
01/30/2025 05:31:01:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:31:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:31:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5798f3ff-3677-4aa0-9f4d-3b27afa433dc
01/30/2025 05:31:55:INFO:Received: train message 5798f3ff-3677-4aa0-9f4d-3b27afa433dc
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:32:33:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:33:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:33:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e377f577-0b4c-4456-bee7-794fe8624f5c
01/30/2025 05:33:51:INFO:Received: evaluate message e377f577-0b4c-4456-bee7-794fe8624f5c
[92mINFO [0m:      Sent reply
01/30/2025 05:33:56:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:34:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:34:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1b1cd49c-c3a3-4f8b-a615-0209c5180251
01/30/2025 05:34:52:INFO:Received: train message 1b1cd49c-c3a3-4f8b-a615-0209c5180251
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:35:35:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:36:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:36:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 221df43e-8a57-47ef-836a-6932da503242
01/30/2025 05:36:42:INFO:Received: evaluate message 221df43e-8a57-47ef-836a-6932da503242
[92mINFO [0m:      Sent reply
01/30/2025 05:36:49:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:37:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:37:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2e1ef3dc-ba51-4076-8bdb-d092fcd6a4f3
01/30/2025 05:37:34:INFO:Received: train message 2e1ef3dc-ba51-4076-8bdb-d092fcd6a4f3
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:38:16:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:39:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:39:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 04907a55-7729-443d-8cc2-8578ca33f999
01/30/2025 05:39:17:INFO:Received: evaluate message 04907a55-7729-443d-8cc2-8578ca33f999
[92mINFO [0m:      Sent reply
01/30/2025 05:39:22:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:40:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:40:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f812f469-e804-48aa-826f-33a65b4d55f0
01/30/2025 05:40:07:INFO:Received: train message f812f469-e804-48aa-826f-33a65b4d55f0
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:40:43:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:42:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:42:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5556ff52-5b41-4b47-a9b0-c8ae992b71ca
01/30/2025 05:42:13:INFO:Received: evaluate message 5556ff52-5b41-4b47-a9b0-c8ae992b71ca
[92mINFO [0m:      Sent reply
01/30/2025 05:42:18:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:43:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:43:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6b53872b-6c66-48ff-ba5e-44a7781da0f5
01/30/2025 05:43:10:INFO:Received: train message 6b53872b-6c66-48ff-ba5e-44a7781da0f5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:43:50:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:45:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:45:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b639f57d-e0e9-4d0e-b184-8115f1452bef
01/30/2025 05:45:05:INFO:Received: evaluate message b639f57d-e0e9-4d0e-b184-8115f1452bef
[92mINFO [0m:      Sent reply
01/30/2025 05:45:10:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:45:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:45:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3f44cc2f-b365-4261-9f90-290213435772
01/30/2025 05:45:37:INFO:Received: train message 3f44cc2f-b365-4261-9f90-290213435772
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:46:14:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:47:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:47:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7e786832-1a9f-4994-9500-fc2b2de64468
01/30/2025 05:47:47:INFO:Received: evaluate message 7e786832-1a9f-4994-9500-fc2b2de64468
[92mINFO [0m:      Sent reply
01/30/2025 05:47:52:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:48:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:48:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7bc693aa-5ab1-4565-b18a-c7c2481b8ad2
01/30/2025 05:48:39:INFO:Received: train message 7bc693aa-5ab1-4565-b18a-c7c2481b8ad2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:49:19:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:50:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:50:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 35d3e7df-8a3f-48ea-84fb-230308537e76
01/30/2025 05:50:06:INFO:Received: evaluate message 35d3e7df-8a3f-48ea-84fb-230308537e76
[92mINFO [0m:      Sent reply
01/30/2025 05:50:11:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:50:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:50:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f6d6718c-072c-450c-9eed-14ccaa0ee871
01/30/2025 05:50:56:INFO:Received: train message f6d6718c-072c-450c-9eed-14ccaa0ee871
