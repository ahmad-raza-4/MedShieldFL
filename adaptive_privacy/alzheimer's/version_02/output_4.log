nohup: ignoring input
01/30/2025 05:28:22:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/30/2025 05:28:22:DEBUG:ChannelConnectivity.IDLE
01/30/2025 05:28:22:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/30/2025 05:29:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:29:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b4b7fd2e-2dd9-44a3-845e-37545a02eb50
01/30/2025 05:29:07:INFO:Received: train message b4b7fd2e-2dd9-44a3-845e-37545a02eb50
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:29:52:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:30:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:30:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 395fd7cb-5548-431b-83bf-7f7aadf388f7
01/30/2025 05:30:56:INFO:Received: evaluate message 395fd7cb-5548-431b-83bf-7f7aadf388f7
[92mINFO [0m:      Sent reply
01/30/2025 05:31:00:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:31:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:31:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c11c785d-7b0b-4a19-9669-d075d0010976
01/30/2025 05:31:51:INFO:Received: train message c11c785d-7b0b-4a19-9669-d075d0010976
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:32:42:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:33:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:33:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 37152c38-d4d5-435c-9fbb-af2af8ca1481
01/30/2025 05:33:41:INFO:Received: evaluate message 37152c38-d4d5-435c-9fbb-af2af8ca1481
[92mINFO [0m:      Sent reply
01/30/2025 05:33:47:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:34:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:34:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1c4a60f6-f055-41c6-b4f2-e40be7cf502b
01/30/2025 05:34:51:INFO:Received: train message 1c4a60f6-f055-41c6-b4f2-e40be7cf502b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:35:39:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:36:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:36:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4f9baa7b-be6d-4c33-8f85-ef31e9b74a9a
01/30/2025 05:36:46:INFO:Received: evaluate message 4f9baa7b-be6d-4c33-8f85-ef31e9b74a9a
[92mINFO [0m:      Sent reply
01/30/2025 05:36:51:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:37:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:37:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 937ad98e-894d-40b6-b851-e031fbb21399
01/30/2025 05:37:25:INFO:Received: train message 937ad98e-894d-40b6-b851-e031fbb21399
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:38:13:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:39:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:39:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8891f438-0449-49fe-a9a9-d8620fe8fe14
01/30/2025 05:39:34:INFO:Received: evaluate message 8891f438-0449-49fe-a9a9-d8620fe8fe14
[92mINFO [0m:      Sent reply
01/30/2025 05:39:40:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:40:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:40:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2a071a45-2010-4a54-8c0c-50d78adbe99e
01/30/2025 05:40:28:INFO:Received: train message 2a071a45-2010-4a54-8c0c-50d78adbe99e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:41:12:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:42:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:42:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e2f1ba49-2c49-41ed-85a4-055a4224211b
01/30/2025 05:42:18:INFO:Received: evaluate message e2f1ba49-2c49-41ed-85a4-055a4224211b
[92mINFO [0m:      Sent reply
01/30/2025 05:42:24:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:43:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:43:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 275755e2-cbeb-41c1-8ecc-3160d2c9ac47
01/30/2025 05:43:13:INFO:Received: train message 275755e2-cbeb-41c1-8ecc-3160d2c9ac47
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:44:02:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:44:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:44:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 182f511d-78c7-4ccc-b8ff-13c432737961
01/30/2025 05:44:37:INFO:Received: evaluate message 182f511d-78c7-4ccc-b8ff-13c432737961
[92mINFO [0m:      Sent reply
01/30/2025 05:44:41:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:45:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:45:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a6f97825-dd17-4fd9-b0c6-66c37247728c
01/30/2025 05:45:56:INFO:Received: train message a6f97825-dd17-4fd9-b0c6-66c37247728c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:46:40:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:47:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:47:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 026a540d-5d0f-46c4-8957-4ea882ada7ef
01/30/2025 05:47:40:INFO:Received: evaluate message 026a540d-5d0f-46c4-8957-4ea882ada7ef
[92mINFO [0m:      Sent reply
01/30/2025 05:47:45:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:48:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:48:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ef8a0e90-e060-4912-8046-ef757b7ad85c
01/30/2025 05:48:20:INFO:Received: train message ef8a0e90-e060-4912-8046-ef757b7ad85c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:49:09:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:50:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:50:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 020f44e6-152a-4a41-aab1-5e1e21050f22
01/30/2025 05:50:16:INFO:Received: evaluate message 020f44e6-152a-4a41-aab1-5e1e21050f22
[92mINFO [0m:      Sent reply
01/30/2025 05:50:21:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:51:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:51:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0925d2c7-1fa8-4b4b-9239-a4339c4d0cb7
01/30/2025 05:51:05:INFO:Received: train message 0925d2c7-1fa8-4b4b-9239-a4339c4d0cb7
