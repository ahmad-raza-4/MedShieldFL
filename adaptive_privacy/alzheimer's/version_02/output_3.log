nohup: ignoring input
01/30/2025 05:28:17:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/30/2025 05:28:17:DEBUG:ChannelConnectivity.IDLE
01/30/2025 05:28:17:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/30/2025 05:29:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:29:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 25d0c2a5-5294-4c73-b50a-4f215949cb21
01/30/2025 05:29:08:INFO:Received: train message 25d0c2a5-5294-4c73-b50a-4f215949cb21
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:29:49:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:30:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:30:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7547c972-b296-478a-84d1-2b169b99b237
01/30/2025 05:30:56:INFO:Received: evaluate message 7547c972-b296-478a-84d1-2b169b99b237
[92mINFO [0m:      Sent reply
01/30/2025 05:31:02:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:31:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:31:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 706c98aa-b014-4c78-8a35-18549caeac5c
01/30/2025 05:31:32:INFO:Received: train message 706c98aa-b014-4c78-8a35-18549caeac5c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:32:16:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:33:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:33:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6695f922-9af5-4557-ba27-1284d3f784fe
01/30/2025 05:33:42:INFO:Received: evaluate message 6695f922-9af5-4557-ba27-1284d3f784fe
[92mINFO [0m:      Sent reply
01/30/2025 05:33:47:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:34:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:34:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0c5082ce-9771-4595-aa9c-cc8d7c005a82
01/30/2025 05:34:26:INFO:Received: train message 0c5082ce-9771-4595-aa9c-cc8d7c005a82
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:35:16:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:36:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:36:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 432fadaa-c238-4ae3-b513-711a976f3474
01/30/2025 05:36:32:INFO:Received: evaluate message 432fadaa-c238-4ae3-b513-711a976f3474
[92mINFO [0m:      Sent reply
01/30/2025 05:36:36:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:37:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:37:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 12f7a775-3c7b-4ed1-93ed-014f5886a884
01/30/2025 05:37:34:INFO:Received: train message 12f7a775-3c7b-4ed1-93ed-014f5886a884
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:38:22:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:39:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:39:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f7213878-216b-48fd-b25e-46d5256575e1
01/30/2025 05:39:35:INFO:Received: evaluate message f7213878-216b-48fd-b25e-46d5256575e1
[92mINFO [0m:      Sent reply
01/30/2025 05:39:40:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:40:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:40:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f3653b0c-af43-4195-b412-1833bf208d4e
01/30/2025 05:40:15:INFO:Received: train message f3653b0c-af43-4195-b412-1833bf208d4e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:40:56:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:41:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:41:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0ef26d7f-7296-46b6-9642-5b18ba545d10
01/30/2025 05:41:49:INFO:Received: evaluate message 0ef26d7f-7296-46b6-9642-5b18ba545d10
[92mINFO [0m:      Sent reply
01/30/2025 05:41:54:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:42:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:42:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 72bf6c0e-8f48-4554-afb1-e0627f54695f
01/30/2025 05:42:52:INFO:Received: train message 72bf6c0e-8f48-4554-afb1-e0627f54695f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:43:32:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:44:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:44:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f9e262cf-b4bc-47c0-9850-e264c7171808
01/30/2025 05:44:55:INFO:Received: evaluate message f9e262cf-b4bc-47c0-9850-e264c7171808
[92mINFO [0m:      Sent reply
01/30/2025 05:45:01:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:45:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:45:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3309567c-855c-49f0-a33c-23bef85836d0
01/30/2025 05:45:56:INFO:Received: train message 3309567c-855c-49f0-a33c-23bef85836d0
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:46:31:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:47:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:47:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4b602b87-38c4-473e-9af4-694da2ce5193
01/30/2025 05:47:43:INFO:Received: evaluate message 4b602b87-38c4-473e-9af4-694da2ce5193
[92mINFO [0m:      Sent reply
01/30/2025 05:47:48:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:48:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:48:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6201ca12-40e6-49b0-8708-2dd99a148bda
01/30/2025 05:48:40:INFO:Received: train message 6201ca12-40e6-49b0-8708-2dd99a148bda
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/30/2025 05:49:18:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:50:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:50:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message cd6b5445-0894-42fc-923f-38b238d3e10a
01/30/2025 05:50:11:INFO:Received: evaluate message cd6b5445-0894-42fc-923f-38b238d3e10a
[92mINFO [0m:      Sent reply
01/30/2025 05:50:15:INFO:Sent reply
[92mINFO [0m:      
01/30/2025 05:50:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/30/2025 05:50:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 51287439-6b57-4595-b431-fb99f85dfd87
01/30/2025 05:50:54:INFO:Received: train message 51287439-6b57-4595-b431-fb99f85dfd87
