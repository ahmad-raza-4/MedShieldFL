nohup: ignoring input
01/31/2025 07:59:37:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/31/2025 07:59:37:DEBUG:ChannelConnectivity.IDLE
01/31/2025 07:59:37:DEBUG:ChannelConnectivity.CONNECTING
01/31/2025 07:59:37:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/31/2025 08:00:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:00:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 04d060ad-ced1-4ca4-84ee-3bafe05f1e4f
01/31/2025 08:00:10:INFO:Received: train message 04d060ad-ced1-4ca4-84ee-3bafe05f1e4f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:00:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:01:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:01:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6401f829-8636-42ce-bcd9-0f283780886f
01/31/2025 08:01:21:INFO:Received: evaluate message 6401f829-8636-42ce-bcd9-0f283780886f
[92mINFO [0m:      Sent reply
01/31/2025 08:01:23:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:02:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:02:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 89128d5f-1537-4950-a13b-80d5f19d5827
01/31/2025 08:02:00:INFO:Received: train message 89128d5f-1537-4950-a13b-80d5f19d5827
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:02:28:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:03:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:03:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b5a7ade5-4048-45ea-b1fe-b6dae0606920
01/31/2025 08:03:14:INFO:Received: evaluate message b5a7ade5-4048-45ea-b1fe-b6dae0606920
[92mINFO [0m:      Sent reply
01/31/2025 08:03:16:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:03:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:03:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0739b9f2-b715-4fa2-91ad-efc6e4964fa6
01/31/2025 08:03:41:INFO:Received: train message 0739b9f2-b715-4fa2-91ad-efc6e4964fa6
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:04:05:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:04:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:04:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e5268b5e-44e3-4c15-9b9c-d0ee918e01bb
01/31/2025 08:04:39:INFO:Received: evaluate message e5268b5e-44e3-4c15-9b9c-d0ee918e01bb
[92mINFO [0m:      Sent reply
01/31/2025 08:04:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:05:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:05:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fd2283c8-b378-4e2c-af0e-3d6982f5b299
01/31/2025 08:05:22:INFO:Received: train message fd2283c8-b378-4e2c-af0e-3d6982f5b299
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:05:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:06:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:06:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 27f93141-0035-4869-82d4-31cf8e44c486
01/31/2025 08:06:29:INFO:Received: evaluate message 27f93141-0035-4869-82d4-31cf8e44c486
[92mINFO [0m:      Sent reply
01/31/2025 08:06:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:07:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:07:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c9507fb2-dcb4-49ae-82a8-5b0758227a87
01/31/2025 08:07:13:INFO:Received: train message c9507fb2-dcb4-49ae-82a8-5b0758227a87
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:07:35:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:08:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:08:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 971c89bc-29aa-455b-ab1b-3037ce739ca2
01/31/2025 08:08:15:INFO:Received: evaluate message 971c89bc-29aa-455b-ab1b-3037ce739ca2
[92mINFO [0m:      Sent reply
01/31/2025 08:08:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:08:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:08:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b7fdadaf-ead2-4073-9ac6-b7931ef3f75f
01/31/2025 08:08:42:INFO:Received: train message b7fdadaf-ead2-4073-9ac6-b7931ef3f75f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:09:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:10:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:10:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1e9f229e-9800-4944-9ffc-7036d674d2cc
01/31/2025 08:10:03:INFO:Received: evaluate message 1e9f229e-9800-4944-9ffc-7036d674d2cc
[92mINFO [0m:      Sent reply
01/31/2025 08:10:08:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:10:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:10:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 57d3f3bf-1ea0-4784-afa4-c2ff328293a2
01/31/2025 08:10:39:INFO:Received: train message 57d3f3bf-1ea0-4784-afa4-c2ff328293a2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:11:00:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:11:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:11:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9d32a1e8-d771-4444-b2de-a22a46cf516d
01/31/2025 08:11:49:INFO:Received: evaluate message 9d32a1e8-d771-4444-b2de-a22a46cf516d
[92mINFO [0m:      Sent reply
01/31/2025 08:11:52:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:12:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:12:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9d9d544c-b420-44fe-bcbc-cbfa19ae851b
01/31/2025 08:12:27:INFO:Received: train message 9d9d544c-b420-44fe-bcbc-cbfa19ae851b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:12:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:13:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:13:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a0fb4c60-dd83-47b7-b14a-b32d7cd69273
01/31/2025 08:13:16:INFO:Received: evaluate message a0fb4c60-dd83-47b7-b14a-b32d7cd69273
[92mINFO [0m:      Sent reply
01/31/2025 08:13:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:14:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:14:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 673b6c93-6e67-4bed-9824-3830c1406e50
01/31/2025 08:14:09:INFO:Received: train message 673b6c93-6e67-4bed-9824-3830c1406e50
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:14:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:15:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:15:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5ba3ae63-4f80-4be1-aabd-90d21089d2c7
01/31/2025 08:15:12:INFO:Received: evaluate message 5ba3ae63-4f80-4be1-aabd-90d21089d2c7
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 6400, num_classes: 4

Privacy Params:
 epsilon: 20.0, target_epsilon: 20.0, target_delta: 1e-05

Device: cuda:0

Step 1: Client Initialized
Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969], 'accuracy': [0.5183737294761532], 'auc': [0.7379489183581498]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479], 'accuracy': [0.5183737294761532, 0.5222830336200156], 'auc': [0.7379489183581498, 0.7546630873005361]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:15:14:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:15:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:15:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4aee6433-b428-425c-90b4-e678c2d2782d
01/31/2025 08:15:45:INFO:Received: train message 4aee6433-b428-425c-90b4-e678c2d2782d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:16:11:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:16:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:16:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7f7043a5-2e5b-4e41-8f42-9b2da00bb1f1
01/31/2025 08:16:59:INFO:Received: evaluate message 7f7043a5-2e5b-4e41-8f42-9b2da00bb1f1
[92mINFO [0m:      Sent reply
01/31/2025 08:17:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:17:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:17:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3371090b-3b42-4efe-a1dc-203aabab84fd
01/31/2025 08:17:21:INFO:Received: train message 3371090b-3b42-4efe-a1dc-203aabab84fd
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:17:48:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:19:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:19:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message db1ee97b-527b-4e1c-8391-9a83d5d174d6
01/31/2025 08:19:08:INFO:Received: evaluate message db1ee97b-527b-4e1c-8391-9a83d5d174d6
[92mINFO [0m:      Sent reply
01/31/2025 08:19:11:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:19:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:19:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 64605c1c-3d62-4397-a0e6-dc89ef7bbfb9
01/31/2025 08:19:59:INFO:Received: train message 64605c1c-3d62-4397-a0e6-dc89ef7bbfb9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:20:26:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:21:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:21:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2c831bbe-e1a1-4c14-be62-7c6dbdecb856
01/31/2025 08:21:00:INFO:Received: evaluate message 2c831bbe-e1a1-4c14-be62-7c6dbdecb856
[92mINFO [0m:      Sent reply
01/31/2025 08:21:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:21:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:21:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d6efe59f-267f-4f24-ba5c-71973e7d1f39
01/31/2025 08:21:57:INFO:Received: train message d6efe59f-267f-4f24-ba5c-71973e7d1f39
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:22:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:22:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:22:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 22b74baa-1172-4dd5-aaca-b835ec6453a4
01/31/2025 08:22:45:INFO:Received: evaluate message 22b74baa-1172-4dd5-aaca-b835ec6453a4
[92mINFO [0m:      Sent reply
01/31/2025 08:22:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:23:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:23:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message edaacba6-49ec-456a-8bd4-d08056f1c60e
01/31/2025 08:23:32:INFO:Received: train message edaacba6-49ec-456a-8bd4-d08056f1c60e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:23:50:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:24:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:24:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3b22edf9-4bfd-410f-9fe8-f72d1173b345
01/31/2025 08:24:24:INFO:Received: evaluate message 3b22edf9-4bfd-410f-9fe8-f72d1173b345
[92mINFO [0m:      Sent reply
01/31/2025 08:24:27:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:24:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:24:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ba540e27-8b7e-45ed-997c-bc531d5ed4f2
01/31/2025 08:24:55:INFO:Received: train message ba540e27-8b7e-45ed-997c-bc531d5ed4f2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:25:15:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:26:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:26:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 03228d4d-0408-455a-a953-8409e5441466
01/31/2025 08:26:04:INFO:Received: evaluate message 03228d4d-0408-455a-a953-8409e5441466

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:26:06:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:26:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:26:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 45cf1806-4edb-4c61-afda-ab13c511e311
01/31/2025 08:26:27:INFO:Received: train message 45cf1806-4edb-4c61-afda-ab13c511e311
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:26:55:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:27:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:27:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 04954df3-5eae-4132-976d-a7326d74209a
01/31/2025 08:27:32:INFO:Received: evaluate message 04954df3-5eae-4132-976d-a7326d74209a
[92mINFO [0m:      Sent reply
01/31/2025 08:27:34:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:28:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:28:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 989ad8ed-68f8-410f-84a6-cd9590c2145b
01/31/2025 08:28:20:INFO:Received: train message 989ad8ed-68f8-410f-84a6-cd9590c2145b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:28:40:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:29:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:29:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 628f17b8-0265-443f-9c70-8a137f5b1428
01/31/2025 08:29:21:INFO:Received: evaluate message 628f17b8-0265-443f-9c70-8a137f5b1428
[92mINFO [0m:      Sent reply
01/31/2025 08:29:26:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:29:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:29:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message bb7e6f72-8c4f-4c7d-8743-350736b3286f
01/31/2025 08:29:43:INFO:Received: train message bb7e6f72-8c4f-4c7d-8743-350736b3286f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:30:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:31:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:31:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8d4e4010-1501-4dca-84dc-62c39d37636b
01/31/2025 08:31:01:INFO:Received: evaluate message 8d4e4010-1501-4dca-84dc-62c39d37636b
[92mINFO [0m:      Sent reply
01/31/2025 08:31:03:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:31:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:31:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8088ea45-6700-4591-b4a4-ac3dee685184
01/31/2025 08:31:28:INFO:Received: train message 8088ea45-6700-4591-b4a4-ac3dee685184
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:31:49:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:32:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:32:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ef867e3d-500b-4f66-ba5e-ce2213cada6a
01/31/2025 08:32:33:INFO:Received: evaluate message ef867e3d-500b-4f66-ba5e-ce2213cada6a
[92mINFO [0m:      Sent reply
01/31/2025 08:32:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:33:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:33:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4f5715c5-8cca-4f14-9af3-ad81548ee99e
01/31/2025 08:33:09:INFO:Received: train message 4f5715c5-8cca-4f14-9af3-ad81548ee99e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:33:35:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:34:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:34:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 19fb009e-2fe5-419e-9539-6f1418cee53e
01/31/2025 08:34:27:INFO:Received: evaluate message 19fb009e-2fe5-419e-9539-6f1418cee53e

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:34:30:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:35:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:35:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 58763b19-2771-466b-a567-bd1393557bd1
01/31/2025 08:35:36:INFO:Received: train message 58763b19-2771-466b-a567-bd1393557bd1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:36:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:36:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:36:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 57c0afeb-9962-443e-9f1b-a7f92a8d784f
01/31/2025 08:36:35:INFO:Received: evaluate message 57c0afeb-9962-443e-9f1b-a7f92a8d784f
[92mINFO [0m:      Sent reply
01/31/2025 08:36:37:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:37:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:37:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6a1e8d42-81d5-449d-baab-e73a916b30ea
01/31/2025 08:37:26:INFO:Received: train message 6a1e8d42-81d5-449d-baab-e73a916b30ea
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:37:46:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:38:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:38:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b0ff6ed1-a94d-48d6-be10-9d25519b4dc8
01/31/2025 08:38:34:INFO:Received: evaluate message b0ff6ed1-a94d-48d6-be10-9d25519b4dc8
[92mINFO [0m:      Sent reply
01/31/2025 08:38:36:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:39:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:39:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ef575b3b-0c6c-497a-b507-9f3aaff7d4ca
01/31/2025 08:39:14:INFO:Received: train message ef575b3b-0c6c-497a-b507-9f3aaff7d4ca
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:39:35:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:40:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:40:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1e6ec88e-700e-4c50-9704-4d1cdf02ea5f
01/31/2025 08:40:14:INFO:Received: evaluate message 1e6ec88e-700e-4c50-9704-4d1cdf02ea5f
[92mINFO [0m:      Sent reply
01/31/2025 08:40:17:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:40:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:40:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 643bec43-7bd4-41ae-8861-871b8d4c7909
01/31/2025 08:40:51:INFO:Received: train message 643bec43-7bd4-41ae-8861-871b8d4c7909
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:41:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:41:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:41:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2aad88e1-3470-46c5-ad62-051d28a9adf5
01/31/2025 08:41:40:INFO:Received: evaluate message 2aad88e1-3470-46c5-ad62-051d28a9adf5

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally
[92mINFO [0m:      Sent reply
01/31/2025 08:41:42:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:42:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:42:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3e739d0d-84f2-46f2-924b-cbbaeaece908
01/31/2025 08:42:28:INFO:Received: train message 3e739d0d-84f2-46f2-924b-cbbaeaece908
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:42:50:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:43:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:43:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7ba52dfa-4996-44b2-88e8-f1486fcd3d4b
01/31/2025 08:43:17:INFO:Received: evaluate message 7ba52dfa-4996-44b2-88e8-f1486fcd3d4b
[92mINFO [0m:      Sent reply
01/31/2025 08:43:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:44:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:44:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d491270d-c976-4e06-a029-4e6ae27cfd6e
01/31/2025 08:44:08:INFO:Received: train message d491270d-c976-4e06-a029-4e6ae27cfd6e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:44:27:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:45:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:45:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b90ecdbd-25a1-43cd-b7d4-38651028f4e7
01/31/2025 08:45:09:INFO:Received: evaluate message b90ecdbd-25a1-43cd-b7d4-38651028f4e7
[92mINFO [0m:      Sent reply
01/31/2025 08:45:12:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:45:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:45:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 01ff58f5-bbfb-4704-af7e-5d94dcba7430
01/31/2025 08:45:41:INFO:Received: train message 01ff58f5-bbfb-4704-af7e-5d94dcba7430
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:46:02:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:46:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:46:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message bd2ce189-2ae5-4b4d-a247-db8b92cb04a7
01/31/2025 08:46:35:INFO:Received: evaluate message bd2ce189-2ae5-4b4d-a247-db8b92cb04a7
[92mINFO [0m:      Sent reply
01/31/2025 08:46:37:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:47:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:47:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b15f41fc-8e31-4b97-9980-c03dab19d8dc
01/31/2025 08:47:06:INFO:Received: train message b15f41fc-8e31-4b97-9980-c03dab19d8dc

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:47:31:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:48:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:48:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8641105f-d8fe-454b-affb-5b94408e860d
01/31/2025 08:48:51:INFO:Received: evaluate message 8641105f-d8fe-454b-affb-5b94408e860d
[92mINFO [0m:      Sent reply
01/31/2025 08:48:54:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:49:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:49:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 146ca26a-0790-49ae-914a-75ba61bf2987
01/31/2025 08:49:53:INFO:Received: train message 146ca26a-0790-49ae-914a-75ba61bf2987
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:50:19:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:51:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:51:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1e0951b2-c677-4269-ab74-e5e5e3a34afc
01/31/2025 08:51:22:INFO:Received: evaluate message 1e0951b2-c677-4269-ab74-e5e5e3a34afc
[92mINFO [0m:      Sent reply
01/31/2025 08:51:24:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:51:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:51:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 51d0d82f-c083-4044-90d2-f77516b3c36c
01/31/2025 08:51:53:INFO:Received: train message 51d0d82f-c083-4044-90d2-f77516b3c36c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/31/2025 08:52:13:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:53:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:53:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message df1836b6-dc76-46f3-a466-dd9417a1213a
01/31/2025 08:53:02:INFO:Received: evaluate message df1836b6-dc76-46f3-a466-dd9417a1213a
[92mINFO [0m:      Sent reply
01/31/2025 08:53:04:INFO:Sent reply
[92mINFO [0m:      
01/31/2025 08:53:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/31/2025 08:53:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message e2380a8c-d801-4f9e-91b1-25c6a50c8e7e
01/31/2025 08:53:07:INFO:Received: reconnect message e2380a8c-d801-4f9e-91b1-25c6a50c8e7e
01/31/2025 08:53:07:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/31/2025 08:53:07:INFO:Disconnect and shut down
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817]}

Step 2a: Compute base noise multiplier
Step 2b: Update noise multiplier dynamically
Step 2c: Re-initialize PrivacyEngine
Step 2d: Make model private
Step 2e: Perform local DP training
Training the model with the following parameters:
Epochs: 3, Trainloader Size: 589, Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)

Step 2f: Log training details
Step 3: Evaluate the model locally

{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399, 1.0146706239891947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817, 0.8129905939058173]}



Final client history:
{'loss': [1.064968405056969, 1.143424023586479, 1.1448232881532598, 1.0869922246012118, 1.057983738915635, 1.085904567338602, 1.07825235923442, 1.0753258308271956, 1.0734578944259179, 1.071774921909359, 1.0084182970033575, 1.0496187529310386, 1.032506156051597, 1.0391733372369905, 1.0435534100032953, 1.0433790931205809, 1.0687411096153825, 1.015168486860602, 1.0375629482649564, 1.1057447312025468, 1.0368838819607429, 1.0403738920347498, 1.0356549616900155, 1.035876474686206, 0.9869848173330127, 1.0871801342788947, 1.0335426636279048, 1.0066990948357184, 1.0072884780993399, 1.0146706239891947], 'accuracy': [0.5183737294761532, 0.5222830336200156, 0.5340109460516028, 0.544175136825645, 0.5551211884284597, 0.5590304925723222, 0.5598123534010946, 0.5590304925723222, 0.565285379202502, 0.562157935887412, 0.5691946833463644, 0.5770132916340891, 0.5793588741204065, 0.5731039874902267, 0.5863956215793589, 0.584831899921814, 0.5770132916340891, 0.5824863174354965, 0.5903049257232212, 0.5777951524628616, 0.584831899921814, 0.584831899921814, 0.5910867865519938, 0.5903049257232212, 0.5981235340109461, 0.5863956215793589, 0.5942142298670836, 0.596559812353401, 0.5989053948397185, 0.5989053948397185], 'auc': [0.7379489183581498, 0.7546630873005361, 0.7631130250551742, 0.7719102168620879, 0.7776408559894529, 0.7804386268726486, 0.7829072761962275, 0.784628409367552, 0.7860178232000494, 0.7885159101710704, 0.7927181606166256, 0.7949546377789054, 0.7950435856227291, 0.7938107331116697, 0.7958251580437732, 0.7975262536933632, 0.7990436347815142, 0.8006268880018412, 0.8001856626611777, 0.8009040786877405, 0.8038256400927525, 0.8044059903580408, 0.8047467449463152, 0.8058870981715842, 0.8094334655940406, 0.8096226415787721, 0.8109623802384914, 0.8120829695942571, 0.8107866127940817, 0.8129905939058173]}

