Initial Train Dataset Size: 768 Sample rate: 0.12
Global Epoch (Round): 1, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.5577, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0612, Accuracy: 0.5160, AUC: 0.7097
Global Epoch (Round): 2, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.5293, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1627, Accuracy: 0.5066, AUC: 0.7280
Global Epoch (Round): 3, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.4626, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1313, Accuracy: 0.5207, AUC: 0.7378
Global Epoch (Round): 4, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.5032, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1363, Accuracy: 0.5324, AUC: 0.7445
Global Epoch (Round): 5, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.4253, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1077, Accuracy: 0.5340, AUC: 0.7500
Global Epoch (Round): 6, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.4516, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1004, Accuracy: 0.5403, AUC: 0.7542
Global Epoch (Round): 7, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.4707, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0959, Accuracy: 0.5434, AUC: 0.7582
Global Epoch (Round): 8, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.4421, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1248, Accuracy: 0.5356, AUC: 0.7610
Global Epoch (Round): 9, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.4079, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1048, Accuracy: 0.5504, AUC: 0.7636
Global Epoch (Round): 10, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3404, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1182, Accuracy: 0.5434, AUC: 0.7661
Global Epoch (Round): 11, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3883, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0493, Accuracy: 0.5598, AUC: 0.7702
Global Epoch (Round): 12, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3494, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1034, Accuracy: 0.5512, AUC: 0.7712
Global Epoch (Round): 13, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3541, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0756, Accuracy: 0.5590, AUC: 0.7733
Global Epoch (Round): 14, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3507, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0729, Accuracy: 0.5622, AUC: 0.7739
Global Epoch (Round): 15, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3670, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0868, Accuracy: 0.5614, AUC: 0.7755
Global Epoch (Round): 16, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3670, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0736, Accuracy: 0.5614, AUC: 0.7770
Global Epoch (Round): 17, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2981, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1040, Accuracy: 0.5582, AUC: 0.7782
Global Epoch (Round): 18, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3525, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0825, Accuracy: 0.5606, AUC: 0.7793
Global Epoch (Round): 19, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3328, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0958, Accuracy: 0.5590, AUC: 0.7793
Global Epoch (Round): 20, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2936, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1431, Accuracy: 0.5536, AUC: 0.7799
Global Epoch (Round): 21, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3158, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0871, Accuracy: 0.5668, AUC: 0.7825
Global Epoch (Round): 22, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3469, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0711, Accuracy: 0.5700, AUC: 0.7830
Global Epoch (Round): 23, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3252, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0961, Accuracy: 0.5645, AUC: 0.7833
Global Epoch (Round): 24, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3378, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0808, Accuracy: 0.5715, AUC: 0.7841
Global Epoch (Round): 25, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3251, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0706, Accuracy: 0.5715, AUC: 0.7857
Global Epoch (Round): 26, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3356, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.1242, Accuracy: 0.5614, AUC: 0.7856
Global Epoch (Round): 27, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3158, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0718, Accuracy: 0.5731, AUC: 0.7887
Global Epoch (Round): 28, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2777, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0639, Accuracy: 0.5794, AUC: 0.7897
Global Epoch (Round): 29, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.3040, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0340, Accuracy: 0.5801, AUC: 0.7897
Global Epoch (Round): 30, Train Size: 768, Sample Rate: 0.12, Train Loss: 1.2883, Epsilon: 1.00, Dynamic Noise Multiplier: 0.05
Loss: 1.0625, Accuracy: 0.5809, AUC: 0.7912
