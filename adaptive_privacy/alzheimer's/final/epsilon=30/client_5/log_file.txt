Initial Train Dataset Size: 1088 Sample rate: 0.17
Global Epoch (Round): 1, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0838, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0719, Accuracy: 0.5199, AUC: 0.7254
Global Epoch (Round): 2, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0435, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.1476, Accuracy: 0.5238, AUC: 0.7454
Global Epoch (Round): 3, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0970, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.1482, Accuracy: 0.5309, AUC: 0.7554
Global Epoch (Round): 4, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0728, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0952, Accuracy: 0.5403, AUC: 0.7649
Global Epoch (Round): 5, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0220, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0692, Accuracy: 0.5496, AUC: 0.7714
Global Epoch (Round): 6, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0500, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0887, Accuracy: 0.5598, AUC: 0.7750
Global Epoch (Round): 7, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0622, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0883, Accuracy: 0.5559, AUC: 0.7783
Global Epoch (Round): 8, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9827, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0831, Accuracy: 0.5536, AUC: 0.7811
Global Epoch (Round): 9, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0614, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0841, Accuracy: 0.5622, AUC: 0.7826
Global Epoch (Round): 10, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0176, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0823, Accuracy: 0.5559, AUC: 0.7855
Global Epoch (Round): 11, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0482, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0176, Accuracy: 0.5676, AUC: 0.7899
Global Epoch (Round): 12, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0011, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0593, Accuracy: 0.5708, AUC: 0.7916
Global Epoch (Round): 13, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0339, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0433, Accuracy: 0.5762, AUC: 0.7920
Global Epoch (Round): 14, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0124, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0454, Accuracy: 0.5715, AUC: 0.7915
Global Epoch (Round): 15, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9902, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0525, Accuracy: 0.5794, AUC: 0.7929
Global Epoch (Round): 16, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0488, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0490, Accuracy: 0.5825, AUC: 0.7947
Global Epoch (Round): 17, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9963, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0760, Accuracy: 0.5731, AUC: 0.7962
Global Epoch (Round): 18, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0385, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0288, Accuracy: 0.5825, AUC: 0.7979
Global Epoch (Round): 19, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0238, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0487, Accuracy: 0.5841, AUC: 0.7974
Global Epoch (Round): 20, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9500, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.1139, Accuracy: 0.5684, AUC: 0.7982
Global Epoch (Round): 21, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0249, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0474, Accuracy: 0.5762, AUC: 0.8015
Global Epoch (Round): 22, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9498, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0477, Accuracy: 0.5794, AUC: 0.8019
Global Epoch (Round): 23, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9681, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0485, Accuracy: 0.5872, AUC: 0.8021
Global Epoch (Round): 24, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0094, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0489, Accuracy: 0.5895, AUC: 0.8030
Global Epoch (Round): 25, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9594, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0008, Accuracy: 0.5911, AUC: 0.8061
Global Epoch (Round): 26, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9653, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0954, Accuracy: 0.5770, AUC: 0.8060
Global Epoch (Round): 27, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0160, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0398, Accuracy: 0.5895, AUC: 0.8077
Global Epoch (Round): 28, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9995, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0157, Accuracy: 0.5903, AUC: 0.8089
Global Epoch (Round): 29, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9525, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0122, Accuracy: 0.5942, AUC: 0.8079
Global Epoch (Round): 30, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9324, Epsilon: 30.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0185, Accuracy: 0.5919, AUC: 0.8099
