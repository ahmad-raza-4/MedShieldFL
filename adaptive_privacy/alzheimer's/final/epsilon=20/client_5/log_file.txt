Initial Train Dataset Size: 1088 Sample rate: 0.17
Global Epoch (Round): 1, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0905, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0663, Accuracy: 0.5160, AUC: 0.7330
Global Epoch (Round): 2, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0407, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.1491, Accuracy: 0.5192, AUC: 0.7509
Global Epoch (Round): 3, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0929, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.1505, Accuracy: 0.5324, AUC: 0.7598
Global Epoch (Round): 4, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0684, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0952, Accuracy: 0.5434, AUC: 0.7687
Global Epoch (Round): 5, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0207, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0675, Accuracy: 0.5536, AUC: 0.7742
Global Epoch (Round): 6, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0476, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0883, Accuracy: 0.5575, AUC: 0.7775
Global Epoch (Round): 7, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0609, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0863, Accuracy: 0.5575, AUC: 0.7805
Global Epoch (Round): 8, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9819, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0831, Accuracy: 0.5528, AUC: 0.7830
Global Epoch (Round): 9, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0626, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0828, Accuracy: 0.5653, AUC: 0.7844
Global Epoch (Round): 10, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0179, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0807, Accuracy: 0.5575, AUC: 0.7871
Global Epoch (Round): 11, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0486, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0171, Accuracy: 0.5684, AUC: 0.7914
Global Epoch (Round): 12, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0009, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0588, Accuracy: 0.5715, AUC: 0.7927
Global Epoch (Round): 13, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0334, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0433, Accuracy: 0.5762, AUC: 0.7930
Global Epoch (Round): 14, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0123, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0432, Accuracy: 0.5700, AUC: 0.7929
Global Epoch (Round): 15, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9885, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0514, Accuracy: 0.5747, AUC: 0.7941
Global Epoch (Round): 16, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0491, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0480, Accuracy: 0.5825, AUC: 0.7958
Global Epoch (Round): 17, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9959, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0757, Accuracy: 0.5731, AUC: 0.7971
Global Epoch (Round): 18, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0386, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0293, Accuracy: 0.5833, AUC: 0.7988
Global Epoch (Round): 19, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0252, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0482, Accuracy: 0.5809, AUC: 0.7984
Global Epoch (Round): 20, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9508, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.1144, Accuracy: 0.5715, AUC: 0.7991
Global Epoch (Round): 21, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0251, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0473, Accuracy: 0.5794, AUC: 0.8021
Global Epoch (Round): 22, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9494, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0472, Accuracy: 0.5848, AUC: 0.8026
Global Epoch (Round): 23, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9683, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0501, Accuracy: 0.5856, AUC: 0.8029
Global Epoch (Round): 24, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0113, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0492, Accuracy: 0.5919, AUC: 0.8036
Global Epoch (Round): 25, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9603, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0026, Accuracy: 0.5919, AUC: 0.8067
Global Epoch (Round): 26, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9673, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0959, Accuracy: 0.5786, AUC: 0.8063
Global Epoch (Round): 27, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0166, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0383, Accuracy: 0.5973, AUC: 0.8081
Global Epoch (Round): 28, Train Size: 1088, Sample Rate: 0.17, Train Loss: 1.0008, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0160, Accuracy: 0.5911, AUC: 0.8094
Global Epoch (Round): 29, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9525, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0108, Accuracy: 0.5942, AUC: 0.8081
Global Epoch (Round): 30, Train Size: 1088, Sample Rate: 0.17, Train Loss: 0.9329, Epsilon: 20.00, Dynamic Noise Multiplier: 0.02
Loss: 1.0181, Accuracy: 0.5927, AUC: 0.8101
