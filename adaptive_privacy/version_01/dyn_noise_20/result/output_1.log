nohup: ignoring input
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(mpl.__version__) >= "3.0":
/home/dgxuser16/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/cm.py:1582: MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.
  mpl_cm.register_cmap(_name, _cmap)
/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/raid/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_20/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
01/18/2025 08:24:55:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/18/2025 08:24:55:DEBUG:ChannelConnectivity.IDLE
01/18/2025 08:24:55:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/18/2025 08:25:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 08:25:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f20648de-d226-4a82-83c3-95eedd305277
01/18/2025 08:25:16:INFO:Received: train message f20648de-d226-4a82-83c3-95eedd305277
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 08:50:02:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 08:50:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 08:50:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8e041dce-30da-4840-9be2-9363cfa87537
01/18/2025 08:50:46:INFO:Received: evaluate message 8e041dce-30da-4840-9be2-9363cfa87537
[92mINFO [0m:      Sent reply
01/18/2025 08:55:09:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 08:55:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 08:55:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4e487f15-bba8-4df7-b595-21b14fc37d44
01/18/2025 08:55:39:INFO:Received: train message 4e487f15-bba8-4df7-b595-21b14fc37d44
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 09:20:25:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:21:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:21:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2207d1b8-13ac-4a04-bc7d-cd49a3363d3f
01/18/2025 09:21:11:INFO:Received: evaluate message 2207d1b8-13ac-4a04-bc7d-cd49a3363d3f
[92mINFO [0m:      Sent reply
01/18/2025 09:25:45:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:26:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:26:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5bcbf0c8-d39c-493a-9503-8ea8f63ec39a
01/18/2025 09:26:20:INFO:Received: train message 5bcbf0c8-d39c-493a-9503-8ea8f63ec39a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 09:50:16:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:50:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:50:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 90e34eda-32fc-4aeb-b1e8-6553b66291dc
01/18/2025 09:50:42:INFO:Received: evaluate message 90e34eda-32fc-4aeb-b1e8-6553b66291dc
[92mINFO [0m:      Sent reply
01/18/2025 09:54:55:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:56:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:56:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message aae93f99-9997-4b05-afc4-af42d6ec4c08
01/18/2025 09:56:13:INFO:Received: train message aae93f99-9997-4b05-afc4-af42d6ec4c08
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 10:19:45:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:20:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:20:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b717d143-b031-49d3-a0ea-3569d5d1f090
01/18/2025 10:20:30:INFO:Received: evaluate message b717d143-b031-49d3-a0ea-3569d5d1f090
[92mINFO [0m:      Sent reply
01/18/2025 10:25:18:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:25:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:25:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a8a4baba-9bd8-4815-b404-3422c64aa94e
01/18/2025 10:25:41:INFO:Received: train message a8a4baba-9bd8-4815-b404-3422c64aa94e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 10:49:11:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:49:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:49:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d59f1c38-25b5-4c48-a11a-81a53fe2b9fb
01/18/2025 10:49:38:INFO:Received: evaluate message d59f1c38-25b5-4c48-a11a-81a53fe2b9fb
[92mINFO [0m:      Sent reply
01/18/2025 10:54:30:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:55:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:55:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 48efdcc7-a5ec-45a9-8333-28c2c696efe5
01/18/2025 10:55:24:INFO:Received: train message 48efdcc7-a5ec-45a9-8333-28c2c696efe5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 11:20:59:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:21:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:21:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 43b13b35-24a7-43a2-972b-5edc94124200
01/18/2025 11:21:47:INFO:Received: evaluate message 43b13b35-24a7-43a2-972b-5edc94124200
[92mINFO [0m:      Sent reply
01/18/2025 11:26:32:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:26:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:26:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7499cfcf-3e35-4eda-b9df-032e1a09ade3
01/18/2025 11:26:58:INFO:Received: train message 7499cfcf-3e35-4eda-b9df-032e1a09ade3
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 11:57:26:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:57:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:57:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f0fdcb74-e002-40f8-a917-2bd4c3393903
01/18/2025 11:57:52:INFO:Received: evaluate message f0fdcb74-e002-40f8-a917-2bd4c3393903
[92mINFO [0m:      Sent reply
01/18/2025 12:02:19:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:03:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:03:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f982448e-38ce-48e5-9840-ac135a6fbc7d
01/18/2025 12:03:00:INFO:Received: train message f982448e-38ce-48e5-9840-ac135a6fbc7d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 12:31:00:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:31:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:31:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 43e28233-dbcf-444c-9eee-cfdf41be650b
01/18/2025 12:31:21:INFO:Received: evaluate message 43e28233-dbcf-444c-9eee-cfdf41be650b
[92mINFO [0m:      Sent reply
01/18/2025 12:35:42:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:37:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:37:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message eb048090-0534-409c-a33d-c69f91ed6a9b
01/18/2025 12:37:03:INFO:Received: train message eb048090-0534-409c-a33d-c69f91ed6a9b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 13:01:41:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:02:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:02:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1ea84d6e-5fb6-4cf3-ad4b-d56e408e96d0
01/18/2025 13:02:10:INFO:Received: evaluate message 1ea84d6e-5fb6-4cf3-ad4b-d56e408e96d0
[92mINFO [0m:      Sent reply
01/18/2025 13:07:06:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:07:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:07:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6499d19f-1dca-438e-8ced-6f5a48f2e48d
01/18/2025 13:07:46:INFO:Received: train message 6499d19f-1dca-438e-8ced-6f5a48f2e48d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 13:31:55:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:32:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:32:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b024bfee-c9ec-478e-b7d9-35e59a104849
01/18/2025 13:32:45:INFO:Received: evaluate message b024bfee-c9ec-478e-b7d9-35e59a104849
[92mINFO [0m:      Sent reply
01/18/2025 13:37:44:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:38:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:38:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 71e2b431-d910-48e4-beb1-ed1fb978b417
01/18/2025 13:38:06:INFO:Received: train message 71e2b431-d910-48e4-beb1-ed1fb978b417
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 14:03:07:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:03:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:03:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9f177a53-0b69-495c-889b-0016dbd15dcc
01/18/2025 14:03:49:INFO:Received: evaluate message 9f177a53-0b69-495c-889b-0016dbd15dcc
[92mINFO [0m:      Sent reply
01/18/2025 14:08:33:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:08:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:08:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 181be261-2c2a-4690-bb0d-20835780f410
01/18/2025 14:08:57:INFO:Received: train message 181be261-2c2a-4690-bb0d-20835780f410
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 14:34:56:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:35:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:35:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d0b3a7c8-db4f-4922-92bd-0724b4b7481e
01/18/2025 14:35:23:INFO:Received: evaluate message d0b3a7c8-db4f-4922-92bd-0724b4b7481e
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_20', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/.local/lib/python3.8/site-packages', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_20']
BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967], 'accuracy': [0.3415223519935562], 'auc': [0.5458924085168692]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536], 'accuracy': [0.3415223519935562, 0.3403141361256545], 'auc': [0.5458924085168692, 0.5872467305216424]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 14:39:58:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:40:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:40:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e1f20cd9-3da3-4471-9748-b0be447b1534
01/18/2025 14:40:47:INFO:Received: train message e1f20cd9-3da3-4471-9748-b0be447b1534
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 15:09:19:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:09:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:09:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a6c3bd9f-1f41-475e-afa2-e60b0ff3919f
01/18/2025 15:09:49:INFO:Received: evaluate message a6c3bd9f-1f41-475e-afa2-e60b0ff3919f
[92mINFO [0m:      Sent reply
01/18/2025 15:14:09:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:14:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:14:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a218af4c-35ba-4654-8625-6129de8a2dae
01/18/2025 15:14:45:INFO:Received: train message a218af4c-35ba-4654-8625-6129de8a2dae
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 15:41:24:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:41:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:41:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6adbc720-17f2-4574-8f87-ae104e38e1a3
01/18/2025 15:41:54:INFO:Received: evaluate message 6adbc720-17f2-4574-8f87-ae104e38e1a3
[92mINFO [0m:      Sent reply
01/18/2025 15:46:15:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:47:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:47:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 149b6a6d-afbc-498c-81d5-4236be34f14b
01/18/2025 15:47:06:INFO:Received: train message 149b6a6d-afbc-498c-81d5-4236be34f14b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 16:11:03:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:11:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:11:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8a08518e-ed9e-43d9-8438-d7c5afd12d94
01/18/2025 16:11:23:INFO:Received: evaluate message 8a08518e-ed9e-43d9-8438-d7c5afd12d94
[92mINFO [0m:      Sent reply
01/18/2025 16:15:38:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:16:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:16:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9cb21293-ba23-4455-8486-ffd67c469cc5
01/18/2025 16:16:46:INFO:Received: train message 9cb21293-ba23-4455-8486-ffd67c469cc5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 16:39:22:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:39:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:39:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6e9e8e0c-ae11-4125-80e7-6a81c971ded6
01/18/2025 16:39:53:INFO:Received: evaluate message 6e9e8e0c-ae11-4125-80e7-6a81c971ded6
[92mINFO [0m:      Sent reply
01/18/2025 16:44:25:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:45:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:45:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 77bfa8e0-7bd2-4107-affe-88d58c13b9d8
01/18/2025 16:45:09:INFO:Received: train message 77bfa8e0-7bd2-4107-affe-88d58c13b9d8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 17:07:24:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:07:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:07:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6c05c005-b881-4309-a460-52c948a31a10
01/18/2025 17:07:50:INFO:Received: evaluate message 6c05c005-b881-4309-a460-52c948a31a10
[92mINFO [0m:      Sent reply
01/18/2025 17:12:16:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:13:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:13:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d2821fb0-9bf6-4c99-8e58-f4106d3b488f
01/18/2025 17:13:24:INFO:Received: train message d2821fb0-9bf6-4c99-8e58-f4106d3b488f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 17:36:16:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:36:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:36:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fd7e8c65-1967-48be-8a6b-493fba05dc63
01/18/2025 17:36:41:INFO:Received: evaluate message fd7e8c65-1967-48be-8a6b-493fba05dc63

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3756426442414522
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.35059980129202206
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3255569583425919
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.3005141153931618
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 17:41:20:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:42:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:42:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e41e6321-206b-485e-a889-92551afeeac1
01/18/2025 17:42:37:INFO:Received: train message e41e6321-206b-485e-a889-92551afeeac1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 18:06:44:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:07:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:07:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 33ca0d6e-f35e-49cb-bc9a-38ff067b47e0
01/18/2025 18:07:30:INFO:Received: evaluate message 33ca0d6e-f35e-49cb-bc9a-38ff067b47e0
[92mINFO [0m:      Sent reply
01/18/2025 18:12:31:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:12:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:12:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 178509fb-8d5e-4581-aa5f-48a309d6d0d6
01/18/2025 18:12:54:INFO:Received: train message 178509fb-8d5e-4581-aa5f-48a309d6d0d6
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 18:40:34:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:41:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:41:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0ac5049b-1f6f-4335-9b1d-28af4d04acbf
01/18/2025 18:41:25:INFO:Received: evaluate message 0ac5049b-1f6f-4335-9b1d-28af4d04acbf
[92mINFO [0m:      Sent reply
01/18/2025 18:46:13:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:46:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:46:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b80414d1-d336-4663-83ee-d702982604d4
01/18/2025 18:46:49:INFO:Received: train message b80414d1-d336-4663-83ee-d702982604d4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 19:16:00:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:16:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:16:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 215fa3f7-9539-422f-9774-47688e4bd532
01/18/2025 19:16:30:INFO:Received: evaluate message 215fa3f7-9539-422f-9774-47688e4bd532
[92mINFO [0m:      Sent reply
01/18/2025 19:20:52:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:21:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:21:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 996d935d-122c-4db1-b059-1d7b17555b1c
01/18/2025 19:21:42:INFO:Received: train message 996d935d-122c-4db1-b059-1d7b17555b1c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 19:48:26:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:49:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:49:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3720d3f3-d3cd-4765-8c8e-c9c25eff5aac
01/18/2025 19:49:09:INFO:Received: evaluate message 3720d3f3-d3cd-4765-8c8e-c9c25eff5aac
[92mINFO [0m:      Sent reply
01/18/2025 19:53:50:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:54:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:54:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 242857cf-b06c-43b5-a8e2-727096755c5f
01/18/2025 19:54:18:INFO:Received: train message 242857cf-b06c-43b5-a8e2-727096755c5f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 20:18:59:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:19:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:19:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message bb157d33-0283-409c-8cbf-8324d487bea2
01/18/2025 20:19:32:INFO:Received: evaluate message bb157d33-0283-409c-8cbf-8324d487bea2

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.27547127244373165
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.2504284294943015
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.2253855865448713
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.2003427435954412
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.17529990064601103
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 20:24:17:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:24:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:24:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ec045acd-afd7-4516-943c-57c75a38c62a
01/18/2025 20:24:59:INFO:Received: train message ec045acd-afd7-4516-943c-57c75a38c62a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 20:46:43:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:47:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:47:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 991bfcd9-492e-40cb-8aa2-ad6899050d2f
01/18/2025 20:47:03:INFO:Received: evaluate message 991bfcd9-492e-40cb-8aa2-ad6899050d2f
[92mINFO [0m:      Sent reply
01/18/2025 20:51:18:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:52:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:52:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9096cfb3-6d4a-4d1c-a588-9041695e9334
01/18/2025 20:52:02:INFO:Received: train message 9096cfb3-6d4a-4d1c-a588-9041695e9334
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 21:14:14:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:14:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:14:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2e22be9e-1d12-44ba-8825-82117dbeb505
01/18/2025 21:14:49:INFO:Received: evaluate message 2e22be9e-1d12-44ba-8825-82117dbeb505
[92mINFO [0m:      Sent reply
01/18/2025 21:19:15:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:19:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:19:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 09f446ff-b0c4-46ec-8d88-5fdafe33731f
01/18/2025 21:19:42:INFO:Received: train message 09f446ff-b0c4-46ec-8d88-5fdafe33731f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 21:41:51:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:42:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:42:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f7780fd7-ab05-4e0a-8c57-0672ec6b997c
01/18/2025 21:42:27:INFO:Received: evaluate message f7780fd7-ab05-4e0a-8c57-0672ec6b997c
[92mINFO [0m:      Sent reply
01/18/2025 21:46:54:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:47:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:47:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0508aba1-73ad-43a5-99f0-ded62329e893
01/18/2025 21:47:12:INFO:Received: train message 0508aba1-73ad-43a5-99f0-ded62329e893
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 22:09:38:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:10:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:10:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 13585f8a-4f7f-4fee-b047-a8807c949ea0
01/18/2025 22:10:13:INFO:Received: evaluate message 13585f8a-4f7f-4fee-b047-a8807c949ea0

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.1502570576965809
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.12521421474715075
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.10017137179772061
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.07512852884829042
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 22:14:41:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:15:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:15:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c0db4ad8-d3d9-4d0f-993c-7552e716118f
01/18/2025 22:15:08:INFO:Received: train message c0db4ad8-d3d9-4d0f-993c-7552e716118f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 22:37:11:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:37:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:37:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 94d941d8-f9f0-45a2-a4b8-4e3dbd3cb9d5
01/18/2025 22:37:44:INFO:Received: evaluate message 94d941d8-f9f0-45a2-a4b8-4e3dbd3cb9d5
[92mINFO [0m:      Sent reply
01/18/2025 22:42:20:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:42:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:42:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e7e4ab02-0ead-485a-ad50-a47e2d66a35d
01/18/2025 22:42:55:INFO:Received: train message e7e4ab02-0ead-485a-ad50-a47e2d66a35d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 23:04:41:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:05:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:05:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1b211779-54bd-4da0-9bbb-ae8a2a738a5c
01/18/2025 23:05:08:INFO:Received: evaluate message 1b211779-54bd-4da0-9bbb-ae8a2a738a5c
[92mINFO [0m:      Sent reply
01/18/2025 23:09:43:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:10:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:10:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cd260293-0b22-4672-8cd5-8c432c088954
01/18/2025 23:10:05:INFO:Received: train message cd260293-0b22-4672-8cd5-8c432c088954
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 23:32:23:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:32:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:32:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 610803da-f92d-4bf9-97d9-e95b233173f5
01/18/2025 23:32:56:INFO:Received: evaluate message 610803da-f92d-4bf9-97d9-e95b233173f5
[92mINFO [0m:      Sent reply
01/18/2025 23:37:21:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:37:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:37:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message 6b8caea1-6893-4031-8517-d2b71d0f0ea3
01/18/2025 23:37:22:INFO:Received: reconnect message 6b8caea1-6893-4031-8517-d2b71d0f0ea3
01/18/2025 23:37:22:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/18/2025 23:37:22:INFO:Disconnect and shut down

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.05008568589886028
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.02504284294943014
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497, 117.29163300991058], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263, 0.5324204591220298], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543, 0.7210482541591376]}

BaseNM 0.509185791015625
noise multiplier 0.3756426442414522
Noise multiplier before  adjustment: 0.3756426442414522
Noise multiplier before convergence adjustment: 0.3756426442414522
Updated noise multiplier after convergence adjustment: 0.0
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497, 117.29163300991058, 117.4067069888115], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263, 0.5324204591220298, 0.5328231977446637], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543, 0.7210482541591376, 0.7225542326603682]}



Final client history:
{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497, 117.29163300991058, 117.4067069888115], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263, 0.5324204591220298, 0.5328231977446637], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543, 0.7210482541591376, 0.7225542326603682]}

