{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/raid/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "import torch\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(ViT, self).__init__()\n",
    "        self.model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        in_features = self.model.heads[-1].in_features\n",
    "        self.model.heads[-1] = nn.Linear(in_features, 8) \n",
    "        self.model.heads[-1].requires_grad = True  \n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "class ViT_GPU(nn.Module):\n",
    "    def __init__(self, device: torch.device) -> None:\n",
    "        super(ViT_GPU, self).__init__()  \n",
    "        self.device = device\n",
    "        self.model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1).to(device)\n",
    "        \n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        in_features = self.model.heads[-1].in_features\n",
    "        self.model.heads[-1] = nn.Linear(in_features, 8).to(device)\n",
    "        self.model.heads[-1].requires_grad = True\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x.to(self.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1612466/4100837152.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT_GPU(\n",
      "  (model): VisionTransformer(\n",
      "    (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (encoder): Encoder(\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (layers): Sequential(\n",
      "        (encoder_layer_0): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_1): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_2): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_3): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_4): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_5): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_6): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_7): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_8): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_9): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_10): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (encoder_layer_11): EncoderBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (self_attention): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): MLPBlock(\n",
      "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Dropout(p=0.0, inplace=False)\n",
      "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (4): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (heads): Sequential(\n",
      "      (head): Linear(in_features=768, out_features=8, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming the ViT model class is already defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "model = ViT_GPU(device)\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint_path = \"/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_1/result/model_checkpoint_round_30.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Print the model structure\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ihpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
