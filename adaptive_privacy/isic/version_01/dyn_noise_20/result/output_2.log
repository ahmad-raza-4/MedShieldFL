nohup: ignoring input
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(mpl.__version__) >= "3.0":
/home/dgxuser16/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/cm.py:1582: MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.
  mpl_cm.register_cmap(_name, _cmap)
/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/raid/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_20/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
01/18/2025 08:20:48:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/18/2025 08:20:48:DEBUG:ChannelConnectivity.IDLE
01/18/2025 08:20:48:DEBUG:ChannelConnectivity.CONNECTING
01/18/2025 08:20:48:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/18/2025 08:25:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 08:25:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 14fa62d1-860e-427d-a258-4e9ac5236368
01/18/2025 08:25:26:INFO:Received: train message 14fa62d1-860e-427d-a258-4e9ac5236368
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 08:40:09:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 08:50:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 08:50:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f2a55565-d686-4287-9956-20aa09f6fd15
01/18/2025 08:50:42:INFO:Received: evaluate message f2a55565-d686-4287-9956-20aa09f6fd15
[92mINFO [0m:      Sent reply
01/18/2025 08:55:00:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 08:55:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 08:55:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0e6dfd4c-44be-4abc-b2f3-a1578ac1407f
01/18/2025 08:55:35:INFO:Received: train message 0e6dfd4c-44be-4abc-b2f3-a1578ac1407f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 09:10:49:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:21:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:21:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 6237b105-7c3c-4f45-8913-afbffd861aaa
01/18/2025 09:21:01:INFO:Received: evaluate message 6237b105-7c3c-4f45-8913-afbffd861aaa
[92mINFO [0m:      Sent reply
01/18/2025 09:25:25:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:26:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:26:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0d29840d-76a8-486b-a9ec-9a8fc61a498a
01/18/2025 09:26:21:INFO:Received: train message 0d29840d-76a8-486b-a9ec-9a8fc61a498a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 09:41:42:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:50:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:50:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a207055c-a2f1-4482-9d53-086eea4fe896
01/18/2025 09:50:59:INFO:Received: evaluate message a207055c-a2f1-4482-9d53-086eea4fe896
[92mINFO [0m:      Sent reply
01/18/2025 09:55:31:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:56:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:56:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d6b0dd53-6e96-4368-b007-ba5f48cca5e9
01/18/2025 09:56:11:INFO:Received: train message d6b0dd53-6e96-4368-b007-ba5f48cca5e9
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 10:11:37:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:20:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:20:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7262ab12-c9e9-4acb-8a03-42aa86302372
01/18/2025 10:20:17:INFO:Received: evaluate message 7262ab12-c9e9-4acb-8a03-42aa86302372
[92mINFO [0m:      Sent reply
01/18/2025 10:24:48:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:25:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:25:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 676017b8-b90e-4dae-b424-0600f4201591
01/18/2025 10:25:55:INFO:Received: train message 676017b8-b90e-4dae-b424-0600f4201591
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 10:41:31:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:49:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:49:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ef95de31-dc8d-49d8-aa3c-461e6a4e1215
01/18/2025 10:49:57:INFO:Received: evaluate message ef95de31-dc8d-49d8-aa3c-461e6a4e1215
[92mINFO [0m:      Sent reply
01/18/2025 10:54:59:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:55:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:55:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fe9d3547-4316-4faa-b56e-837499458b67
01/18/2025 10:55:42:INFO:Received: train message fe9d3547-4316-4faa-b56e-837499458b67
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 11:09:53:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:21:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:21:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a27c9d72-e854-44d5-bb2f-a0d41fa13f9b
01/18/2025 11:21:52:INFO:Received: evaluate message a27c9d72-e854-44d5-bb2f-a0d41fa13f9b
[92mINFO [0m:      Sent reply
01/18/2025 11:26:18:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:26:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:26:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 547bf44b-774b-4c07-8886-eafc2221e266
01/18/2025 11:26:54:INFO:Received: train message 547bf44b-774b-4c07-8886-eafc2221e266
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 11:40:55:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:58:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:58:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 70918334-dbf2-4331-9e52-5732f0604139
01/18/2025 11:58:06:INFO:Received: evaluate message 70918334-dbf2-4331-9e52-5732f0604139
[92mINFO [0m:      Sent reply
01/18/2025 12:02:24:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:03:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:03:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d3b25711-0626-4c4e-9c14-88b115b78127
01/18/2025 12:03:04:INFO:Received: train message d3b25711-0626-4c4e-9c14-88b115b78127
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 12:18:54:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:31:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:31:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c1bceaba-dbab-46f8-ad11-be4693ca8f0c
01/18/2025 12:31:40:INFO:Received: evaluate message c1bceaba-dbab-46f8-ad11-be4693ca8f0c
[92mINFO [0m:      Sent reply
01/18/2025 12:36:26:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:37:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:37:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 970d2869-ff13-4f53-8d9c-3c081d0ff015
01/18/2025 12:37:04:INFO:Received: train message 970d2869-ff13-4f53-8d9c-3c081d0ff015
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 12:52:26:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:02:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:02:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message be11059c-8c4e-4112-ad86-9ea57001aa72
01/18/2025 13:02:19:INFO:Received: evaluate message be11059c-8c4e-4112-ad86-9ea57001aa72
[92mINFO [0m:      Sent reply
01/18/2025 13:06:50:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:07:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:07:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c3014020-3664-4f73-9fad-0bc263a5d55b
01/18/2025 13:07:46:INFO:Received: train message c3014020-3664-4f73-9fad-0bc263a5d55b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 13:22:25:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:32:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:32:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0a0fdea6-f040-4910-9cd2-545aa0b2bc25
01/18/2025 13:32:33:INFO:Received: evaluate message 0a0fdea6-f040-4910-9cd2-545aa0b2bc25
[92mINFO [0m:      Sent reply
01/18/2025 13:37:03:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:38:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:38:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6c4f44b6-6fba-4c9b-870f-8090cbb0ff3a
01/18/2025 13:38:21:INFO:Received: train message 6c4f44b6-6fba-4c9b-870f-8090cbb0ff3a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 13:52:08:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:03:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:03:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fbb3a854-e1aa-4ba1-a4b6-761693db1866
01/18/2025 14:03:36:INFO:Received: evaluate message fbb3a854-e1aa-4ba1-a4b6-761693db1866
[92mINFO [0m:      Sent reply
01/18/2025 14:08:05:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:09:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:09:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c4d293cd-0dd5-4fa7-989a-ce719c13fbfc
01/18/2025 14:09:05:INFO:Received: train message c4d293cd-0dd5-4fa7-989a-ce719c13fbfc
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 14:23:06:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:35:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:35:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7c6672f8-804e-4019-954a-a80ee54fa0fb
01/18/2025 14:35:40:INFO:Received: evaluate message 7c6672f8-804e-4019-954a-a80ee54fa0fb
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_20', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/.local/lib/python3.8/site-packages', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_20']
BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967], 'accuracy': [0.3415223519935562], 'auc': [0.5458924085168692]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536], 'accuracy': [0.3415223519935562, 0.3403141361256545], 'auc': [0.5458924085168692, 0.5872467305216424]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 14:40:03:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:40:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:40:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 329e82de-4e0c-424f-8d4d-3289e69cf898
01/18/2025 14:40:54:INFO:Received: train message 329e82de-4e0c-424f-8d4d-3289e69cf898
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 14:55:04:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:10:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:10:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d61a09ac-59dc-4922-a48e-a26dfe44c8df
01/18/2025 15:10:05:INFO:Received: evaluate message d61a09ac-59dc-4922-a48e-a26dfe44c8df
[92mINFO [0m:      Sent reply
01/18/2025 15:14:20:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:14:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:14:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f93b8b9d-ca75-4f11-9432-152c28424950
01/18/2025 15:14:59:INFO:Received: train message f93b8b9d-ca75-4f11-9432-152c28424950
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 15:29:12:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:42:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:42:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 41b1f435-cf3c-4738-9856-07506a32d83e
01/18/2025 15:42:07:INFO:Received: evaluate message 41b1f435-cf3c-4738-9856-07506a32d83e
[92mINFO [0m:      Sent reply
01/18/2025 15:46:28:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:46:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:46:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 40f76947-291b-4b06-9686-a2cfd975174b
01/18/2025 15:46:49:INFO:Received: train message 40f76947-291b-4b06-9686-a2cfd975174b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 16:00:30:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:11:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:11:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message aed671ca-fa42-4ab2-8b45-19febe59e4d5
01/18/2025 16:11:46:INFO:Received: evaluate message aed671ca-fa42-4ab2-8b45-19febe59e4d5
[92mINFO [0m:      Sent reply
01/18/2025 16:16:07:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:16:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:16:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message eaae2690-5908-4976-bf25-e51440ab82d5
01/18/2025 16:16:50:INFO:Received: train message eaae2690-5908-4976-bf25-e51440ab82d5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 16:30:22:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:40:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:40:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8268686f-edee-4bff-953b-32f1ffbe57b5
01/18/2025 16:40:02:INFO:Received: evaluate message 8268686f-edee-4bff-953b-32f1ffbe57b5
[92mINFO [0m:      Sent reply
01/18/2025 16:44:38:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:45:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:45:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d5c042ad-6059-4d10-a627-1baa7f8b45c6
01/18/2025 16:45:15:INFO:Received: train message d5c042ad-6059-4d10-a627-1baa7f8b45c6
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 16:59:05:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:08:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:08:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b079450d-198b-4c65-b5fc-ac92aaca7477
01/18/2025 17:08:02:INFO:Received: evaluate message b079450d-198b-4c65-b5fc-ac92aaca7477
[92mINFO [0m:      Sent reply
01/18/2025 17:12:48:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:13:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:13:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 979d6e58-f095-4a72-895d-7148ab722833
01/18/2025 17:13:33:INFO:Received: train message 979d6e58-f095-4a72-895d-7148ab722833
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 17:27:35:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:36:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:36:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4539218d-3714-4e8c-a53b-8170892c9ec3
01/18/2025 17:36:55:INFO:Received: evaluate message 4539218d-3714-4e8c-a53b-8170892c9ec3

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3626526682637632
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3384758237128456
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.3142989791619281
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.29012213461101055
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 17:41:51:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:42:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:42:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d30d390a-2123-4124-a511-050e68d23987
01/18/2025 17:42:31:INFO:Received: train message d30d390a-2123-4124-a511-050e68d23987
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 17:56:35:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:07:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:07:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b9116de3-3327-4eba-9d96-fc48aca079b1
01/18/2025 18:07:24:INFO:Received: evaluate message b9116de3-3327-4eba-9d96-fc48aca079b1
[92mINFO [0m:      Sent reply
01/18/2025 18:12:28:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:13:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:13:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 91d1d812-2ebf-4abf-898a-1daf0f7f9d3b
01/18/2025 18:13:07:INFO:Received: train message 91d1d812-2ebf-4abf-898a-1daf0f7f9d3b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 18:27:11:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:41:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:41:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d871f0aa-6132-45e4-822a-893b920c47b2
01/18/2025 18:41:25:INFO:Received: evaluate message d871f0aa-6132-45e4-822a-893b920c47b2
[92mINFO [0m:      Sent reply
01/18/2025 18:46:13:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:46:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:46:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 31a14121-6363-4cfd-be64-4161f89ebcb7
01/18/2025 18:46:46:INFO:Received: train message 31a14121-6363-4cfd-be64-4161f89ebcb7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 19:00:53:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:16:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:16:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 80abc010-dcb1-4b9d-bda4-d267e113897f
01/18/2025 19:16:44:INFO:Received: evaluate message 80abc010-dcb1-4b9d-bda4-d267e113897f
[92mINFO [0m:      Sent reply
01/18/2025 19:21:07:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:21:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:21:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 92542ec2-adbe-436a-a872-3c692334ea5c
01/18/2025 19:21:38:INFO:Received: train message 92542ec2-adbe-436a-a872-3c692334ea5c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 19:37:26:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:48:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:48:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 23735041-d21b-4765-a06d-8001623d4cb1
01/18/2025 19:48:56:INFO:Received: evaluate message 23735041-d21b-4765-a06d-8001623d4cb1
[92mINFO [0m:      Sent reply
01/18/2025 19:53:39:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:54:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:54:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f87ee481-b6c6-4211-8757-7bb16530491f
01/18/2025 19:54:16:INFO:Received: train message f87ee481-b6c6-4211-8757-7bb16530491f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 20:09:49:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:19:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:19:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message aac1b503-e350-4f06-bf68-ab7502971896
01/18/2025 20:19:43:INFO:Received: evaluate message aac1b503-e350-4f06-bf68-ab7502971896

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.26594529006009304
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.24176844550917548
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.2175916009582579
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.19341475640734038
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.1692379118564228
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 20:24:25:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:24:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:24:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4fef7927-2ac2-485c-acd2-61178c097768
01/18/2025 20:24:45:INFO:Received: train message 4fef7927-2ac2-485c-acd2-61178c097768
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 20:39:06:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:47:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:47:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4f42b988-6a89-4d9b-bc1c-76f44bed879b
01/18/2025 20:47:06:INFO:Received: evaluate message 4f42b988-6a89-4d9b-bc1c-76f44bed879b
[92mINFO [0m:      Sent reply
01/18/2025 20:51:27:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:52:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:52:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 32432834-5e73-44dd-880b-a99a270b6075
01/18/2025 20:52:11:INFO:Received: train message 32432834-5e73-44dd-880b-a99a270b6075
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 21:06:59:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:14:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:14:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b2af6f07-4007-467e-9e2e-c180f83ebfa5
01/18/2025 21:14:52:INFO:Received: evaluate message b2af6f07-4007-467e-9e2e-c180f83ebfa5
[92mINFO [0m:      Sent reply
01/18/2025 21:19:16:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:19:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:19:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b088af71-1f5e-47c5-943a-9cc0e5d59ca1
01/18/2025 21:19:46:INFO:Received: train message b088af71-1f5e-47c5-943a-9cc0e5d59ca1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 21:34:28:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:42:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:42:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ed587d92-c760-4be6-99fd-783b63c7e9c0
01/18/2025 21:42:27:INFO:Received: evaluate message ed587d92-c760-4be6-99fd-783b63c7e9c0
[92mINFO [0m:      Sent reply
01/18/2025 21:46:55:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:47:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:47:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9f678db1-ce5e-412c-9bfb-260a93f82376
01/18/2025 21:47:27:INFO:Received: train message 9f678db1-ce5e-412c-9bfb-260a93f82376
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 22:01:57:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:10:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:10:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 88fcb6e4-cbc9-4d81-9a6d-68c70e042233
01/18/2025 22:10:15:INFO:Received: evaluate message 88fcb6e4-cbc9-4d81-9a6d-68c70e042233

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.14506106730550528
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.12088422275458774
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.0967073782036702
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.07253053365275262
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 22:14:41:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:14:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:14:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 85549df8-1b88-4268-8b72-643260236336
01/18/2025 22:14:58:INFO:Received: train message 85549df8-1b88-4268-8b72-643260236336
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 22:29:12:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:37:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:37:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 666f7ded-5498-4202-85cd-ccdeed366282
01/18/2025 22:37:44:INFO:Received: evaluate message 666f7ded-5498-4202-85cd-ccdeed366282
[92mINFO [0m:      Sent reply
01/18/2025 22:42:21:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:42:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:42:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message bfedb739-7041-49c4-95d6-9b5e37f4600c
01/18/2025 22:42:48:INFO:Received: train message bfedb739-7041-49c4-95d6-9b5e37f4600c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 22:56:57:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:05:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:05:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 52d36472-6ef9-4e3f-939e-84bfbda102f6
01/18/2025 23:05:05:INFO:Received: evaluate message 52d36472-6ef9-4e3f-939e-84bfbda102f6
[92mINFO [0m:      Sent reply
01/18/2025 23:09:35:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:10:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:10:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3af4f9c8-0ffd-41dc-a49a-21c15d35d07d
01/18/2025 23:10:20:INFO:Received: train message 3af4f9c8-0ffd-41dc-a49a-21c15d35d07d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 23:24:45:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:32:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:32:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a847fb6e-9473-4ecf-9a97-4f000bc865d1
01/18/2025 23:32:40:INFO:Received: evaluate message a847fb6e-9473-4ecf-9a97-4f000bc865d1
[92mINFO [0m:      Sent reply
01/18/2025 23:36:39:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:37:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:37:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message 813ed636-5926-4fc7-baf1-b793055baf72
01/18/2025 23:37:22:INFO:Received: reconnect message 813ed636-5926-4fc7-baf1-b793055baf72
01/18/2025 23:37:22:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/18/2025 23:37:22:INFO:Disconnect and shut down

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.04835368910183508
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.02417684455091754
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497, 117.29163300991058], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263, 0.5324204591220298], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543, 0.7210482541591376]}

BaseNM 0.509185791015625
noise multiplier 0.3626526682637632
Noise multiplier before  adjustment: 0.3626526682637632
Noise multiplier before convergence adjustment: 0.3626526682637632
Updated noise multiplier after convergence adjustment: 0.0
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497, 117.29163300991058, 117.4067069888115], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263, 0.5324204591220298, 0.5328231977446637], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543, 0.7210482541591376, 0.7225542326603682]}



Final client history:
{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497, 117.29163300991058, 117.4067069888115], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263, 0.5324204591220298, 0.5328231977446637], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543, 0.7210482541591376, 0.7225542326603682]}

