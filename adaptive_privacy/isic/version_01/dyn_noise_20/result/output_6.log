nohup: ignoring input
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(mpl.__version__) >= "3.0":
/home/dgxuser16/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/cm.py:1582: MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.
  mpl_cm.register_cmap(_name, _cmap)
/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/raid/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_20/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
01/18/2025 08:17:09:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/18/2025 08:17:09:DEBUG:ChannelConnectivity.IDLE
01/18/2025 08:17:09:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/18/2025 08:17:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 08:17:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: get_parameters message 5e444424-ef4b-46fc-82d1-f1103b08d595
01/18/2025 08:17:09:INFO:Received: get_parameters message 5e444424-ef4b-46fc-82d1-f1103b08d595
[92mINFO [0m:      Sent reply
01/18/2025 08:17:14:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 08:25:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 08:25:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7ece56f1-92bc-4768-8140-ae13f14513c7
01/18/2025 08:25:32:INFO:Received: train message 7ece56f1-92bc-4768-8140-ae13f14513c7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 08:28:20:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 08:50:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 08:50:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f6e842de-7da1-4277-aa76-781ddcf0cc2a
01/18/2025 08:50:35:INFO:Received: evaluate message f6e842de-7da1-4277-aa76-781ddcf0cc2a
[92mINFO [0m:      Sent reply
01/18/2025 08:55:03:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 08:55:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 08:55:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ebbfc7cb-a508-4a6b-bdfb-4a396cfcb269
01/18/2025 08:55:42:INFO:Received: train message ebbfc7cb-a508-4a6b-bdfb-4a396cfcb269
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 08:58:41:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:21:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:21:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5cc989a1-81e2-4356-bfe0-2a9042d5f5e3
01/18/2025 09:21:01:INFO:Received: evaluate message 5cc989a1-81e2-4356-bfe0-2a9042d5f5e3
[92mINFO [0m:      Sent reply
01/18/2025 09:25:40:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:26:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:26:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d5f5810f-d41f-4254-b72a-5e134058e8ab
01/18/2025 09:26:09:INFO:Received: train message d5f5810f-d41f-4254-b72a-5e134058e8ab
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 09:28:50:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:51:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:51:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0de835e6-53e8-4280-9405-692b4b616b19
01/18/2025 09:51:00:INFO:Received: evaluate message 0de835e6-53e8-4280-9405-692b4b616b19
[92mINFO [0m:      Sent reply
01/18/2025 09:55:33:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 09:55:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 09:55:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 08fcba0f-680a-45b4-a14c-1b45e5353f44
01/18/2025 09:55:51:INFO:Received: train message 08fcba0f-680a-45b4-a14c-1b45e5353f44
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 09:58:36:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:20:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:20:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3401fee8-bc30-440a-a9a9-9d962607a737
01/18/2025 10:20:30:INFO:Received: evaluate message 3401fee8-bc30-440a-a9a9-9d962607a737
[92mINFO [0m:      Sent reply
01/18/2025 10:25:17:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:25:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:25:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c68c402b-04cd-45ba-b8f9-31032af83697
01/18/2025 10:25:49:INFO:Received: train message c68c402b-04cd-45ba-b8f9-31032af83697
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 10:28:45:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:49:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:49:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 43b7030f-6fd7-40a9-8f09-21f225c3bc4d
01/18/2025 10:49:52:INFO:Received: evaluate message 43b7030f-6fd7-40a9-8f09-21f225c3bc4d
[92mINFO [0m:      Sent reply
01/18/2025 10:54:54:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 10:55:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:55:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message bf4cbddf-7780-411e-953c-55182368ac78
01/18/2025 10:55:39:INFO:Received: train message bf4cbddf-7780-411e-953c-55182368ac78
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 10:58:34:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:21:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:21:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e9c4f8bc-dff3-4b96-90b7-42a41e42d4b9
01/18/2025 11:21:28:INFO:Received: evaluate message e9c4f8bc-dff3-4b96-90b7-42a41e42d4b9
[92mINFO [0m:      Sent reply
01/18/2025 11:26:27:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:27:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:27:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 01716ba4-f3ee-4a3b-814c-dad0cf81ceb2
01/18/2025 11:27:08:INFO:Received: train message 01716ba4-f3ee-4a3b-814c-dad0cf81ceb2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 11:30:06:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:58:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:58:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9d91a9fb-ab71-4fff-89b6-0099fc602908
01/18/2025 11:58:10:INFO:Received: evaluate message 9d91a9fb-ab71-4fff-89b6-0099fc602908
[92mINFO [0m:      Sent reply
01/18/2025 12:02:30:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:02:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:02:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8dc0345c-d3dd-4f1e-88c2-715234359d07
01/18/2025 12:02:44:INFO:Received: train message 8dc0345c-d3dd-4f1e-88c2-715234359d07
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 12:04:51:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:31:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:31:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 68c33117-ea85-4ad5-8277-7d8d40fd67b4
01/18/2025 12:31:33:INFO:Received: evaluate message 68c33117-ea85-4ad5-8277-7d8d40fd67b4
[92mINFO [0m:      Sent reply
01/18/2025 12:36:06:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:37:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:37:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message adeedbaf-d9e7-4d9f-9270-15200fc762dc
01/18/2025 12:37:03:INFO:Received: train message adeedbaf-d9e7-4d9f-9270-15200fc762dc
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 12:39:55:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:02:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:02:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c9302dbf-4cba-4815-acb8-1abd1b3b2af7
01/18/2025 13:02:02:INFO:Received: evaluate message c9302dbf-4cba-4815-acb8-1abd1b3b2af7
[92mINFO [0m:      Sent reply
01/18/2025 13:06:59:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:07:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:07:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message dd8a9643-9df5-4cce-8f98-857077b37098
01/18/2025 13:07:33:INFO:Received: train message dd8a9643-9df5-4cce-8f98-857077b37098
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 13:10:36:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:32:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:32:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 96cef4b8-dc5a-4a4d-b434-5210af5b79a0
01/18/2025 13:32:41:INFO:Received: evaluate message 96cef4b8-dc5a-4a4d-b434-5210af5b79a0
[92mINFO [0m:      Sent reply
01/18/2025 13:37:40:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:38:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:38:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d9250262-5c49-4dc5-ad82-15fd7082ed89
01/18/2025 13:38:10:INFO:Received: train message d9250262-5c49-4dc5-ad82-15fd7082ed89
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 13:40:56:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:03:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:03:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a109024f-cad8-49a8-a09d-7b368b6b7eae
01/18/2025 14:03:45:INFO:Received: evaluate message a109024f-cad8-49a8-a09d-7b368b6b7eae
[92mINFO [0m:      Sent reply
01/18/2025 14:08:32:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:09:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:09:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 711f1809-a434-4a94-ba68-9f7edc912576
01/18/2025 14:09:10:INFO:Received: train message 711f1809-a434-4a94-ba68-9f7edc912576
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 14:12:11:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:35:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:35:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ed60861c-944c-4571-8fff-7a88fbb70ed3
01/18/2025 14:35:44:INFO:Received: evaluate message ed60861c-944c-4571-8fff-7a88fbb70ed3
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_20', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/.local/lib/python3.8/site-packages', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_20']
BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967], 'accuracy': [0.3415223519935562], 'auc': [0.5458924085168692]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536], 'accuracy': [0.3415223519935562, 0.3403141361256545], 'auc': [0.5458924085168692, 0.5872467305216424]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 14:40:17:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:40:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:40:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 90066b18-ab95-42cc-a36c-844d68dc6057
01/18/2025 14:40:44:INFO:Received: train message 90066b18-ab95-42cc-a36c-844d68dc6057
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 14:43:32:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:10:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:10:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 47c76c45-7fad-4e50-9a4c-f8d17356ef7e
01/18/2025 15:10:05:INFO:Received: evaluate message 47c76c45-7fad-4e50-9a4c-f8d17356ef7e
[92mINFO [0m:      Sent reply
01/18/2025 15:14:23:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:14:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:14:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4f394b5f-a849-4d97-acd5-271cf24615e8
01/18/2025 15:14:41:INFO:Received: train message 4f394b5f-a849-4d97-acd5-271cf24615e8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 15:17:00:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:41:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:41:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 36c78d6e-2c32-49bb-8b68-4b9d70756157
01/18/2025 15:41:52:INFO:Received: evaluate message 36c78d6e-2c32-49bb-8b68-4b9d70756157
[92mINFO [0m:      Sent reply
01/18/2025 15:46:26:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:47:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:47:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c77cf275-23bb-4bd5-a9f8-56fdd623cd9f
01/18/2025 15:47:06:INFO:Received: train message c77cf275-23bb-4bd5-a9f8-56fdd623cd9f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 15:50:02:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:11:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:11:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 990b63ca-3673-4f59-8498-7d732cbcf9bb
01/18/2025 16:11:34:INFO:Received: evaluate message 990b63ca-3673-4f59-8498-7d732cbcf9bb
[92mINFO [0m:      Sent reply
01/18/2025 16:16:13:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:16:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:16:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cebe0b79-e3be-40d7-9b67-692697081721
01/18/2025 16:16:35:INFO:Received: train message cebe0b79-e3be-40d7-9b67-692697081721
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 16:19:17:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:40:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:40:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d2d1ccad-7821-4f7a-befe-3c4ec7ffdf3e
01/18/2025 16:40:02:INFO:Received: evaluate message d2d1ccad-7821-4f7a-befe-3c4ec7ffdf3e
[92mINFO [0m:      Sent reply
01/18/2025 16:44:39:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:45:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:45:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 97722cee-cb00-4109-9939-32f89fe73e87
01/18/2025 16:45:05:INFO:Received: train message 97722cee-cb00-4109-9939-32f89fe73e87
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 16:47:54:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:08:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:08:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 06d1fe99-0168-43c9-b3a6-002cffad9468
01/18/2025 17:08:06:INFO:Received: evaluate message 06d1fe99-0168-43c9-b3a6-002cffad9468
[92mINFO [0m:      Sent reply
01/18/2025 17:12:39:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:13:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:13:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fcea4bbf-5c0e-4d5d-9d7c-57f69fa6b626
01/18/2025 17:13:03:INFO:Received: train message fcea4bbf-5c0e-4d5d-9d7c-57f69fa6b626
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 17:14:52:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:36:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:36:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7642cfc5-2862-4aae-81f7-53957a2b317f
01/18/2025 17:36:55:INFO:Received: evaluate message 7642cfc5-2862-4aae-81f7-53957a2b317f

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.3848063279874623
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.35915257278829815
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.33349881758913397
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.30784506238996984
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 17:41:13:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:42:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:42:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2eea745c-116d-4b2c-b27f-77789927ca16
01/18/2025 17:42:39:INFO:Received: train message 2eea745c-116d-4b2c-b27f-77789927ca16
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 17:45:37:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:07:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:07:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e5ef9159-8201-4ff8-9336-3db6aa3def29
01/18/2025 18:07:20:INFO:Received: evaluate message e5ef9159-8201-4ff8-9336-3db6aa3def29
[92mINFO [0m:      Sent reply
01/18/2025 18:11:19:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:13:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:13:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 076d81bd-571b-427e-95b5-c2c6a4cbe233
01/18/2025 18:13:02:INFO:Received: train message 076d81bd-571b-427e-95b5-c2c6a4cbe233
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 18:15:37:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:41:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:41:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a6ae6fd8-d298-42c9-9e68-2403ddd8f219
01/18/2025 18:41:08:INFO:Received: evaluate message a6ae6fd8-d298-42c9-9e68-2403ddd8f219
[92mINFO [0m:      Sent reply
01/18/2025 18:45:09:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:46:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:46:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f2828ddb-843a-48d1-97da-385eab38a112
01/18/2025 18:46:46:INFO:Received: train message f2828ddb-843a-48d1-97da-385eab38a112
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 18:49:37:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:16:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:16:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5bc0fb7c-9698-47e4-83f7-9d5ca97cb8f6
01/18/2025 19:16:28:INFO:Received: evaluate message 5bc0fb7c-9698-47e4-83f7-9d5ca97cb8f6
[92mINFO [0m:      Sent reply
01/18/2025 19:20:45:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:21:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:21:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 16a276ad-b47c-4d3e-b057-37d3943013ab
01/18/2025 19:21:43:INFO:Received: train message 16a276ad-b47c-4d3e-b057-37d3943013ab
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 19:24:36:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:49:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:49:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d203af23-8b3d-4451-b2c9-6023bfdc7b91
01/18/2025 19:49:03:INFO:Received: evaluate message d203af23-8b3d-4451-b2c9-6023bfdc7b91
[92mINFO [0m:      Sent reply
01/18/2025 19:53:37:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:54:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:54:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9fa66cd1-7566-40df-ab59-84f78a8a56e1
01/18/2025 19:54:22:INFO:Received: train message 9fa66cd1-7566-40df-ab59-84f78a8a56e1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 19:57:02:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:19:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:19:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f76016da-c533-44ea-8631-6e0530fd942d
01/18/2025 20:19:38:INFO:Received: evaluate message f76016da-c533-44ea-8631-6e0530fd942d

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.2821913071908057
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.2565375519916416
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.23088379679247736
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.2052300415933132
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.17957628639414908
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 20:24:03:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:24:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:24:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2db7acd5-6785-4fa8-8417-17ed416de4cb
01/18/2025 20:24:57:INFO:Received: train message 2db7acd5-6785-4fa8-8417-17ed416de4cb
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 20:27:44:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:47:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:47:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 79772de3-6016-484e-be2f-156566efd6d2
01/18/2025 20:47:07:INFO:Received: evaluate message 79772de3-6016-484e-be2f-156566efd6d2
[92mINFO [0m:      Sent reply
01/18/2025 20:51:21:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:52:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:52:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 29bcecec-ed8f-4f9c-9acc-e9ef8c9ca1f8
01/18/2025 20:52:19:INFO:Received: train message 29bcecec-ed8f-4f9c-9acc-e9ef8c9ca1f8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 20:55:11:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:14:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:14:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 57296681-a703-48cd-986e-e650cc08838a
01/18/2025 21:14:34:INFO:Received: evaluate message 57296681-a703-48cd-986e-e650cc08838a
[92mINFO [0m:      Sent reply
01/18/2025 21:18:38:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:19:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:19:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b7abd369-944a-47d6-a442-baea3fa079fb
01/18/2025 21:19:43:INFO:Received: train message b7abd369-944a-47d6-a442-baea3fa079fb
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 21:22:26:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:42:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:42:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 42412c7f-a319-4e65-864e-4a0b7234209f
01/18/2025 21:42:28:INFO:Received: evaluate message 42412c7f-a319-4e65-864e-4a0b7234209f
[92mINFO [0m:      Sent reply
01/18/2025 21:46:52:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:47:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:47:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f74268e4-b830-4a74-8e5e-394a3ee5de60
01/18/2025 21:47:24:INFO:Received: train message f74268e4-b830-4a74-8e5e-394a3ee5de60
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 21:50:12:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:10:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:10:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 910e0845-d51e-4875-8d53-c005f41efe7a
01/18/2025 22:10:11:INFO:Received: evaluate message 910e0845-d51e-4875-8d53-c005f41efe7a

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.15392253119498492
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.1282687759958208
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.10261502079665663
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.07696126559749245
Epsilon = 20.00
[92mINFO [0m:      Sent reply
01/18/2025 22:14:35:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:15:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:15:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4d0925ba-1e97-4707-bcac-f4ef137e3520
01/18/2025 22:15:11:INFO:Received: train message 4d0925ba-1e97-4707-bcac-f4ef137e3520
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 22:18:06:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:37:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:37:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 02a40a97-7bcd-45f8-b692-aac6e8d1103e
01/18/2025 22:37:40:INFO:Received: evaluate message 02a40a97-7bcd-45f8-b692-aac6e8d1103e
[92mINFO [0m:      Sent reply
01/18/2025 22:42:13:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:42:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:42:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 20d576b4-6879-413b-a040-ee9399bfe921
01/18/2025 22:42:53:INFO:Received: train message 20d576b4-6879-413b-a040-ee9399bfe921
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 22:45:41:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:05:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:05:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0ab401e8-ae8c-4f64-8d8d-f2f2c2477292
01/18/2025 23:05:05:INFO:Received: evaluate message 0ab401e8-ae8c-4f64-8d8d-f2f2c2477292
[92mINFO [0m:      Sent reply
01/18/2025 23:09:29:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:10:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:10:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a24f5452-fe85-4c3d-a75e-a870d15dcabe
01/18/2025 23:10:22:INFO:Received: train message a24f5452-fe85-4c3d-a75e-a870d15dcabe
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 23:13:13:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:32:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:32:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 15bd8d90-c4ac-470f-b528-ef8b16d9d8d4
01/18/2025 23:32:59:INFO:Received: evaluate message 15bd8d90-c4ac-470f-b528-ef8b16d9d8d4
[92mINFO [0m:      Sent reply
01/18/2025 23:37:17:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:37:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:37:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message fddf6266-fbe9-441b-8578-c66be589ffec
01/18/2025 23:37:21:INFO:Received: reconnect message fddf6266-fbe9-441b-8578-c66be589ffec
01/18/2025 23:37:22:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/18/2025 23:37:22:INFO:Disconnect and shut down

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.051307510398328295
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.025653755199164147
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497, 117.29163300991058], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263, 0.5324204591220298], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543, 0.7210482541591376]}

BaseNM 0.509185791015625
noise multiplier 0.3848063279874623
Noise multiplier before  adjustment: 0.3848063279874623
Noise multiplier before convergence adjustment: 0.3848063279874623
Updated noise multiplier after convergence adjustment: 0.0
Epsilon = 20.00

{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497, 117.29163300991058, 117.4067069888115], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263, 0.5324204591220298, 0.5328231977446637], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543, 0.7210482541591376, 0.7225542326603682]}



Final client history:
{'loss': [141.91953432559967, 135.46572041511536, 137.1726440191269, 139.42472064495087, 140.47733008861542, 140.36735045909882, 138.68980038166046, 136.82366251945496, 133.8171820640564, 131.7890875339508, 129.9862903356552, 128.8842145204544, 127.46359467506409, 126.39147812128067, 125.14994525909424, 124.38939321041107, 123.23706209659576, 122.82756131887436, 122.16060239076614, 121.24904602766037, 120.82610058784485, 120.29219061136246, 119.58572542667389, 119.08070361614227, 118.53430676460266, 118.51938855648041, 118.10474199056625, 117.48184382915497, 117.29163300991058, 117.4067069888115], 'accuracy': [0.3415223519935562, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34716069271043093, 0.35440998791784134, 0.369311316955296, 0.38300443012484897, 0.40112766814337497, 0.4180426902939992, 0.43656866693515906, 0.44703987112364074, 0.4567055980668546, 0.46637132501006845, 0.4724124043495771, 0.47563431333064843, 0.4828836085380588, 0.4893274265002014, 0.49617398308497784, 0.5038260169150222, 0.5066451872734595, 0.5106725734997987, 0.5155054369714056, 0.5219492549335482, 0.5283930728956907, 0.527184857027789, 0.5296012887635925, 0.5300040273862263, 0.5324204591220298, 0.5328231977446637], 'auc': [0.5458924085168692, 0.5872467305216424, 0.6121252187038672, 0.6253057738175832, 0.6347226858098717, 0.6415258918986717, 0.647859325078698, 0.6532598534198434, 0.6585854035844673, 0.6630952212898362, 0.6678254159418557, 0.6717056724543276, 0.6755452905335515, 0.6792348681199802, 0.6828257407273998, 0.6864363488422669, 0.6899019876279757, 0.692614643181826, 0.6953600292974049, 0.6985492575599968, 0.7011633816061517, 0.7037986395800959, 0.7065279161811373, 0.7091798697886703, 0.7119411586626083, 0.7139051870281878, 0.7163760968065104, 0.719037486314543, 0.7210482541591376, 0.7225542326603682]}

