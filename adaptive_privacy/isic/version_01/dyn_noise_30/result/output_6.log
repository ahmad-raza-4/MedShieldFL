nohup: ignoring input
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(mpl.__version__) >= "3.0":
/home/dgxuser16/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/cm.py:1582: MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.
  mpl_cm.register_cmap(_name, _cmap)
/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/raid/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_30/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
01/18/2025 10:59:01:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/18/2025 10:59:01:DEBUG:ChannelConnectivity.IDLE
[92mINFO [0m:      
01/18/2025 10:59:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 10:59:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: get_parameters message b81cf6c1-a9e5-4103-98ef-a1e6b6737991
01/18/2025 10:59:01:INFO:Received: get_parameters message b81cf6c1-a9e5-4103-98ef-a1e6b6737991
01/18/2025 10:59:01:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      Sent reply
01/18/2025 10:59:10:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:09:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:09:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f65e2a3f-9c4b-49d3-928b-0fe48f06affc
01/18/2025 11:09:12:INFO:Received: train message f65e2a3f-9c4b-49d3-928b-0fe48f06affc
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 11:11:50:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:36:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:36:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b486496e-93cd-4a30-8b2a-11c2a1c3938b
01/18/2025 11:36:59:INFO:Received: evaluate message b486496e-93cd-4a30-8b2a-11c2a1c3938b
[92mINFO [0m:      Sent reply
01/18/2025 11:40:46:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 11:41:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 11:41:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1b5b7c42-ff89-41f9-9d1b-1cd5314acce4
01/18/2025 11:41:54:INFO:Received: train message 1b5b7c42-ff89-41f9-9d1b-1cd5314acce4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 11:44:37:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:06:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:06:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4c12034d-c26d-4680-a7cd-c127dc0be4fb
01/18/2025 12:06:01:INFO:Received: evaluate message 4c12034d-c26d-4680-a7cd-c127dc0be4fb
[92mINFO [0m:      Sent reply
01/18/2025 12:10:06:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:10:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:10:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a41a2cd5-7a65-45d6-81a3-b236f23c6956
01/18/2025 12:10:40:INFO:Received: train message a41a2cd5-7a65-45d6-81a3-b236f23c6956
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 12:13:37:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:33:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:33:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 057dae84-4ca9-42c4-a3ba-ee57b430b659
01/18/2025 12:33:18:INFO:Received: evaluate message 057dae84-4ca9-42c4-a3ba-ee57b430b659
[92mINFO [0m:      Sent reply
01/18/2025 12:38:09:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 12:38:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 12:38:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message efabfe8d-9806-417d-86bb-6003a0310808
01/18/2025 12:38:34:INFO:Received: train message efabfe8d-9806-417d-86bb-6003a0310808
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 12:41:09:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:02:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:02:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9b06c66b-a617-4eff-b83c-b9790f1719ad
01/18/2025 13:02:00:INFO:Received: evaluate message 9b06c66b-a617-4eff-b83c-b9790f1719ad
[92mINFO [0m:      Sent reply
01/18/2025 13:06:02:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:07:27:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:07:27:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ab0f7f32-623e-4cf8-acfb-df3abe11b912
01/18/2025 13:07:27:INFO:Received: train message ab0f7f32-623e-4cf8-acfb-df3abe11b912
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 13:10:04:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:31:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:31:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 93b3e281-b635-4820-b16c-f9645b4d75ff
01/18/2025 13:31:24:INFO:Received: evaluate message 93b3e281-b635-4820-b16c-f9645b4d75ff
[92mINFO [0m:      Sent reply
01/18/2025 13:36:04:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:36:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:36:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message bc850120-edae-49cc-b8bc-a21cee6a25ee
01/18/2025 13:36:40:INFO:Received: train message bc850120-edae-49cc-b8bc-a21cee6a25ee
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 13:38:57:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 13:59:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 13:59:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ef220411-b869-4396-b460-4c6908633c93
01/18/2025 13:59:18:INFO:Received: evaluate message ef220411-b869-4396-b460-4c6908633c93
[92mINFO [0m:      Sent reply
01/18/2025 14:03:27:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:04:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:04:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b066d9a8-4840-4258-90a2-03098e487238
01/18/2025 14:04:18:INFO:Received: train message b066d9a8-4840-4258-90a2-03098e487238
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 14:06:40:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:28:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:28:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e68b42f8-49be-4080-8c6c-a1e03fc3ea6b
01/18/2025 14:28:18:INFO:Received: evaluate message e68b42f8-49be-4080-8c6c-a1e03fc3ea6b
[92mINFO [0m:      Sent reply
01/18/2025 14:32:51:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:33:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:33:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 63b10295-1ca5-4b58-bb94-9ab34a6279c7
01/18/2025 14:33:44:INFO:Received: train message 63b10295-1ca5-4b58-bb94-9ab34a6279c7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 14:36:30:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 14:57:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 14:57:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2e094393-2d41-4466-ab3e-8b3bae38b233
01/18/2025 14:57:24:INFO:Received: evaluate message 2e094393-2d41-4466-ab3e-8b3bae38b233
[92mINFO [0m:      Sent reply
01/18/2025 15:02:05:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:02:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:02:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 84baff8a-4a4c-46a0-81e7-ee4bec94ec8c
01/18/2025 15:02:28:INFO:Received: train message 84baff8a-4a4c-46a0-81e7-ee4bec94ec8c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 15:04:39:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:28:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:28:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fc17db7e-9d9d-4a18-8844-3667d013a8fe
01/18/2025 15:28:15:INFO:Received: evaluate message fc17db7e-9d9d-4a18-8844-3667d013a8fe
[92mINFO [0m:      Sent reply
01/18/2025 15:32:49:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 15:33:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 15:33:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c58795bc-8d36-4619-918a-acefb47f1ce5
01/18/2025 15:33:44:INFO:Received: train message c58795bc-8d36-4619-918a-acefb47f1ce5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 15:36:30:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:02:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:02:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f438171c-fbc5-4839-8537-5b7126a966f4
01/18/2025 16:02:10:INFO:Received: evaluate message f438171c-fbc5-4839-8537-5b7126a966f4
[92mINFO [0m:      Sent reply
01/18/2025 16:06:19:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:07:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:07:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ac766829-f0cd-4f63-91d9-8c15b787c128
01/18/2025 16:07:04:INFO:Received: train message ac766829-f0cd-4f63-91d9-8c15b787c128
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 16:09:39:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:34:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:34:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ee3f11a9-f407-49e6-8cdd-ea18e7f4f14f
01/18/2025 16:34:16:INFO:Received: evaluate message ee3f11a9-f407-49e6-8cdd-ea18e7f4f14f
[92mINFO [0m:      Sent reply
01/18/2025 16:38:19:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 16:39:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 16:39:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 16d4ba70-d443-4aa4-8b99-82d0398e2326
01/18/2025 16:39:05:INFO:Received: train message 16d4ba70-d443-4aa4-8b99-82d0398e2326
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 16:41:43:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:04:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:04:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5f41f298-1fc6-420f-88ad-10783d755ff8
01/18/2025 17:04:54:INFO:Received: evaluate message 5f41f298-1fc6-420f-88ad-10783d755ff8
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_30', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/.local/lib/python3.8/site-packages', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/dyn_noise_30']
BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535], 'accuracy': [0.3419250906161901], 'auc': [0.5460484530250033]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187], 'accuracy': [0.3419250906161901, 0.3403141361256545], 'auc': [0.5460484530250033, 0.5873079809432222]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00
[92mINFO [0m:      Sent reply
01/18/2025 17:09:00:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:09:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:09:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2f8e4319-2a37-4c67-8393-8522b2a25450
01/18/2025 17:09:40:INFO:Received: train message 2f8e4319-2a37-4c67-8393-8522b2a25450
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 17:12:09:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:34:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:34:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message bc0fe87f-a419-4669-9e89-734b12564dde
01/18/2025 17:34:14:INFO:Received: evaluate message bc0fe87f-a419-4669-9e89-734b12564dde
[92mINFO [0m:      Sent reply
01/18/2025 17:38:24:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 17:39:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 17:39:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b7c50af7-0e7e-449b-bf30-4b4c8fe1b412
01/18/2025 17:39:18:INFO:Received: train message b7c50af7-0e7e-449b-bf30-4b4c8fe1b412
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 17:41:41:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:02:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:02:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 39f5278a-fee4-4d99-bd0f-86d10a76338d
01/18/2025 18:02:43:INFO:Received: evaluate message 39f5278a-fee4-4d99-bd0f-86d10a76338d
[92mINFO [0m:      Sent reply
01/18/2025 18:07:12:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:07:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:07:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 0d755b01-a2a7-4c71-aa65-2a979df23acc
01/18/2025 18:07:42:INFO:Received: train message 0d755b01-a2a7-4c71-aa65-2a979df23acc
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 18:10:38:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:30:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:30:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 14b0fc22-ed05-43d2-bee5-cea9420b3d50
01/18/2025 18:30:19:INFO:Received: evaluate message 14b0fc22-ed05-43d2-bee5-cea9420b3d50
[92mINFO [0m:      Sent reply
01/18/2025 18:34:40:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:35:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:35:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 76ea26d5-b9dd-4d30-b701-3a03511767b7
01/18/2025 18:35:08:INFO:Received: train message 76ea26d5-b9dd-4d30-b701-3a03511767b7
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 18:37:47:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 18:57:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 18:57:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5a63661a-4879-4e8d-b5ff-ba96bfba3220
01/18/2025 18:57:35:INFO:Received: evaluate message 5a63661a-4879-4e8d-b5ff-ba96bfba3220
[92mINFO [0m:      Sent reply
01/18/2025 19:02:10:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:02:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:02:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 68db2c76-157a-436a-acff-dac8bef60d7e
01/18/2025 19:02:47:INFO:Received: train message 68db2c76-157a-436a-acff-dac8bef60d7e
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 19:05:34:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:25:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:25:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1a91f061-f27c-4915-a709-fa9e0f7ddf56
01/18/2025 19:25:23:INFO:Received: evaluate message 1a91f061-f27c-4915-a709-fa9e0f7ddf56
[92mINFO [0m:      Sent reply
01/18/2025 19:30:08:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:30:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:30:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3cdbe651-5806-4db3-9e84-d80c12eb6b27
01/18/2025 19:30:47:INFO:Received: train message 3cdbe651-5806-4db3-9e84-d80c12eb6b27
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 19:33:46:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:53:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:53:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 0909360c-1599-457a-aa34-4c625164efee
01/18/2025 19:53:15:INFO:Received: evaluate message 0909360c-1599-457a-aa34-4c625164efee
[92mINFO [0m:      Sent reply
01/18/2025 19:58:09:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 19:58:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 19:58:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message aa90d2bf-bdfc-4971-bd2a-816bf0e5cba8
01/18/2025 19:58:46:INFO:Received: train message aa90d2bf-bdfc-4971-bd2a-816bf0e5cba8

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.31537246285006404
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.2943476319933931
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.2733228011367222
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.25229797028005124
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031]}

/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 20:01:23:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:20:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:20:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8567803c-0f3a-4305-8c83-c3428098536e
01/18/2025 20:20:59:INFO:Received: evaluate message 8567803c-0f3a-4305-8c83-c3428098536e
[92mINFO [0m:      Sent reply
01/18/2025 20:25:37:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:26:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:26:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 048873bb-39c8-4e8d-83fd-c3442a76039d
01/18/2025 20:26:24:INFO:Received: train message 048873bb-39c8-4e8d-83fd-c3442a76039d
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 20:28:53:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:45:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:45:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d620e6ee-3cc8-4f72-b1ec-503716e6d100
01/18/2025 20:45:37:INFO:Received: evaluate message d620e6ee-3cc8-4f72-b1ec-503716e6d100
[92mINFO [0m:      Sent reply
01/18/2025 20:49:34:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 20:50:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 20:50:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b170d4d3-e214-4b2c-b2af-842393d38384
01/18/2025 20:50:01:INFO:Received: train message b170d4d3-e214-4b2c-b2af-842393d38384
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 20:52:37:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:09:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:09:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a0471e2e-a976-4578-91e7-029a7b0fa60f
01/18/2025 21:09:24:INFO:Received: evaluate message a0471e2e-a976-4578-91e7-029a7b0fa60f
[92mINFO [0m:      Sent reply
01/18/2025 21:13:29:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:13:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:13:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2ea79fb9-2962-460c-b251-34e2166b26c0
01/18/2025 21:13:56:INFO:Received: train message 2ea79fb9-2962-460c-b251-34e2166b26c0
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 21:16:32:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:33:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:33:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 13f5d5e7-badc-4f9d-919c-ebbdc14598b2
01/18/2025 21:33:13:INFO:Received: evaluate message 13f5d5e7-badc-4f9d-919c-ebbdc14598b2
[92mINFO [0m:      Sent reply
01/18/2025 21:37:22:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:37:50:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:37:50:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3f85f73f-40a7-4038-ad0b-dc6b59480275
01/18/2025 21:37:50:INFO:Received: train message 3f85f73f-40a7-4038-ad0b-dc6b59480275
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 21:40:17:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 21:56:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 21:56:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1068a4e4-4ded-4c5c-9142-da77a60aebb6
01/18/2025 21:56:59:INFO:Received: evaluate message 1068a4e4-4ded-4c5c-9142-da77a60aebb6
[92mINFO [0m:      Sent reply
01/18/2025 22:01:05:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:01:19:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:01:19:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b117a7a9-f4dc-47b6-9c65-b4c55256d5e6
01/18/2025 22:01:19:INFO:Received: train message b117a7a9-f4dc-47b6-9c65-b4c55256d5e6
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 22:03:21:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:20:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:20:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d3be5a1d-b9a6-41ba-8f32-4e6fe09437bd
01/18/2025 22:20:41:INFO:Received: evaluate message d3be5a1d-b9a6-41ba-8f32-4e6fe09437bd
BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.23127313942338032
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.2102483085667094
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.18922347771003842
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473, 120.60332131385803], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561, 0.5066451872734595], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127, 0.701726967048038]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.1681986468533675
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473, 120.60332131385803, 120.17026662826538], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561, 0.5066451872734595, 0.5110753121224325], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127, 0.701726967048038, 0.7042518908730465]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.14717381599669654
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473, 120.60332131385803, 120.17026662826538, 119.4384194612503], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561, 0.5066451872734595, 0.5110753121224325, 0.5155054369714056], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127, 0.701726967048038, 0.7042518908730465, 0.7070529084088146]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.12614898514002562
Epsilon = 30.00
[92mINFO [0m:      Sent reply
01/18/2025 22:24:49:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:25:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:25:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 946fd0a3-106b-4036-994b-2df16b42d025
01/18/2025 22:25:12:INFO:Received: train message 946fd0a3-106b-4036-994b-2df16b42d025
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 22:27:05:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:44:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:44:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 8f4ec506-af74-4d68-b971-c52514bdee12
01/18/2025 22:44:41:INFO:Received: evaluate message 8f4ec506-af74-4d68-b971-c52514bdee12
[92mINFO [0m:      Sent reply
01/18/2025 22:48:47:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 22:49:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 22:49:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 387a3b08-7f4d-4bc7-8150-3eb247f6ff59
01/18/2025 22:49:09:INFO:Received: train message 387a3b08-7f4d-4bc7-8150-3eb247f6ff59
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 22:51:22:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:08:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:08:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e48dd882-1c82-4610-aa72-0281f095b879
01/18/2025 23:08:45:INFO:Received: evaluate message e48dd882-1c82-4610-aa72-0281f095b879
[92mINFO [0m:      Sent reply
01/18/2025 23:12:56:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:13:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:13:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 50a1032b-57e9-4bff-84d2-f5ed93d9a974
01/18/2025 23:13:26:INFO:Received: train message 50a1032b-57e9-4bff-84d2-f5ed93d9a974
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 23:15:58:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:32:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:32:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9f4e2140-e7ee-4128-a049-c68b7cebeace
01/18/2025 23:32:35:INFO:Received: evaluate message 9f4e2140-e7ee-4128-a049-c68b7cebeace
[92mINFO [0m:      Sent reply
01/18/2025 23:36:44:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:36:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:36:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message aa7a2848-9175-48ff-be64-366bf7798a48
01/18/2025 23:36:56:INFO:Received: train message aa7a2848-9175-48ff-be64-366bf7798a48
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/18/2025 23:38:40:INFO:Sent reply
[92mINFO [0m:      
01/18/2025 23:56:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/18/2025 23:56:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5cbf8e83-138c-4839-9ee3-dc600fea9f79
01/18/2025 23:56:24:INFO:Received: evaluate message 5cbf8e83-138c-4839-9ee3-dc600fea9f79

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473, 120.60332131385803, 120.17026662826538, 119.4384194612503, 119.05765295028687], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561, 0.5066451872734595, 0.5110753121224325, 0.5155054369714056, 0.5219492549335482], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127, 0.701726967048038, 0.7042518908730465, 0.7070529084088146, 0.7095426281970368]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.1051241542833547
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473, 120.60332131385803, 120.17026662826538, 119.4384194612503, 119.05765295028687, 118.52940011024475], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561, 0.5066451872734595, 0.5110753121224325, 0.5155054369714056, 0.5219492549335482, 0.5275875956504229], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127, 0.701726967048038, 0.7042518908730465, 0.7070529084088146, 0.7095426281970368, 0.7122546946207959]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.08409932342668376
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473, 120.60332131385803, 120.17026662826538, 119.4384194612503, 119.05765295028687, 118.52940011024475, 118.54788601398468], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561, 0.5066451872734595, 0.5110753121224325, 0.5155054369714056, 0.5219492549335482, 0.5275875956504229, 0.5279903342730567], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127, 0.701726967048038, 0.7042518908730465, 0.7070529084088146, 0.7095426281970368, 0.7122546946207959, 0.7141621364853833]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.0630744925700128
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473, 120.60332131385803, 120.17026662826538, 119.4384194612503, 119.05765295028687, 118.52940011024475, 118.54788601398468, 118.15519630908966], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561, 0.5066451872734595, 0.5110753121224325, 0.5155054369714056, 0.5219492549335482, 0.5275875956504229, 0.5279903342730567, 0.5296012887635925], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127, 0.701726967048038, 0.7042518908730465, 0.7070529084088146, 0.7095426281970368, 0.7122546946207959, 0.7141621364853833, 0.7165603094050297]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.04204966171334186
Epsilon = 30.00
[92mINFO [0m:      Sent reply
01/19/2025 00:00:24:INFO:Sent reply
[92mINFO [0m:      
01/19/2025 00:00:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/19/2025 00:00:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8a3943f2-e7dc-4a01-8b58-1bce6e9e31ee
01/19/2025 00:00:49:INFO:Received: train message 8a3943f2-e7dc-4a01-8b58-1bce6e9e31ee
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/19/2025 00:03:16:INFO:Sent reply
[92mINFO [0m:      
01/19/2025 00:19:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/19/2025 00:19:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message dde9cb77-07ee-4e7a-b27d-2626286fbf84
01/19/2025 00:19:46:INFO:Received: evaluate message dde9cb77-07ee-4e7a-b27d-2626286fbf84
[92mINFO [0m:      Sent reply
01/19/2025 00:23:50:INFO:Sent reply
[92mINFO [0m:      
01/19/2025 00:24:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/19/2025 00:24:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 3b10c9a0-04b3-4950-ba70-afecc851aea1
01/19/2025 00:24:12:INFO:Received: train message 3b10c9a0-04b3-4950-ba70-afecc851aea1
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/19/2025 00:26:03:INFO:Sent reply
[92mINFO [0m:      
01/19/2025 00:43:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/19/2025 00:43:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ff3bcb4a-bf31-4afa-9d3c-1e44052d57f6
01/19/2025 00:43:25:INFO:Received: evaluate message ff3bcb4a-bf31-4afa-9d3c-1e44052d57f6
[92mINFO [0m:      Sent reply
01/19/2025 00:46:41:INFO:Sent reply
[92mINFO [0m:      
01/19/2025 00:47:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/19/2025 00:47:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message fa8e538e-5d6a-4f9d-88f7-da03c44ca86e
01/19/2025 00:47:39:INFO:Received: reconnect message fa8e538e-5d6a-4f9d-88f7-da03c44ca86e
01/19/2025 00:47:39:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/19/2025 00:47:39:INFO:Disconnect and shut down

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473, 120.60332131385803, 120.17026662826538, 119.4384194612503, 119.05765295028687, 118.52940011024475, 118.54788601398468, 118.15519630908966, 117.42482489347458], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561, 0.5066451872734595, 0.5110753121224325, 0.5155054369714056, 0.5219492549335482, 0.5275875956504229, 0.5279903342730567, 0.5296012887635925, 0.5296012887635925], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127, 0.701726967048038, 0.7042518908730465, 0.7070529084088146, 0.7095426281970368, 0.7122546946207959, 0.7141621364853833, 0.7165603094050297, 0.7193555349179758]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.02102483085667093
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473, 120.60332131385803, 120.17026662826538, 119.4384194612503, 119.05765295028687, 118.52940011024475, 118.54788601398468, 118.15519630908966, 117.42482489347458, 117.25908535718918], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561, 0.5066451872734595, 0.5110753121224325, 0.5155054369714056, 0.5219492549335482, 0.5275875956504229, 0.5279903342730567, 0.5296012887635925, 0.5296012887635925, 0.5328231977446637], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127, 0.701726967048038, 0.7042518908730465, 0.7070529084088146, 0.7095426281970368, 0.7122546946207959, 0.7141621364853833, 0.7165603094050297, 0.7193555349179758, 0.7212846690688237]}

BaseNM 0.41748046875
noise multiplier 0.31537246285006404
Noise multiplier before  adjustment: 0.31537246285006404
Noise multiplier before convergence adjustment: 0.31537246285006404
Updated noise multiplier after convergence adjustment: 0.0
Epsilon = 30.00

{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473, 120.60332131385803, 120.17026662826538, 119.4384194612503, 119.05765295028687, 118.52940011024475, 118.54788601398468, 118.15519630908966, 117.42482489347458, 117.25908535718918, 117.31337916851044], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561, 0.5066451872734595, 0.5110753121224325, 0.5155054369714056, 0.5219492549335482, 0.5275875956504229, 0.5279903342730567, 0.5296012887635925, 0.5296012887635925, 0.5328231977446637, 0.5332259363672976], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127, 0.701726967048038, 0.7042518908730465, 0.7070529084088146, 0.7095426281970368, 0.7122546946207959, 0.7141621364853833, 0.7165603094050297, 0.7193555349179758, 0.7212846690688237, 0.7229776848061777]}



Final client history:
{'loss': [141.89181208610535, 135.49430978298187, 137.1008837223053, 139.42722713947296, 140.38146257400513, 140.1488618850708, 138.49389910697937, 136.6689555644989, 133.6193369626999, 131.62890231609344, 129.86334824562073, 128.8125473856926, 127.34060329198837, 126.31609010696411, 125.00594735145569, 124.22317373752594, 123.08636915683746, 122.69723302125931, 122.06729191541672, 121.11292892694473, 120.60332131385803, 120.17026662826538, 119.4384194612503, 119.05765295028687, 118.52940011024475, 118.54788601398468, 118.15519630908966, 117.42482489347458, 117.25908535718918, 117.31337916851044], 'accuracy': [0.3419250906161901, 0.3403141361256545, 0.3415223519935562, 0.34313330648409185, 0.34756343133306483, 0.35481272654047524, 0.3697140555779299, 0.38260169150221507, 0.4015304067660089, 0.4196536447845348, 0.43616592831252515, 0.4478453483689086, 0.4571083366894885, 0.46677406363270235, 0.4724124043495771, 0.47724526782118404, 0.4828836085380588, 0.48892468787756743, 0.49496576721707614, 0.5042287555376561, 0.5066451872734595, 0.5110753121224325, 0.5155054369714056, 0.5219492549335482, 0.5275875956504229, 0.5279903342730567, 0.5296012887635925, 0.5296012887635925, 0.5328231977446637, 0.5332259363672976], 'auc': [0.5460484530250033, 0.5873079809432222, 0.6123466175339257, 0.6255987195877803, 0.635134593630355, 0.6420977321827006, 0.6482744795069026, 0.6537858380055177, 0.6591302272665509, 0.6637053251581886, 0.6684711322983466, 0.6722962584776735, 0.6760643712103915, 0.679713381286971, 0.6834217381657681, 0.6869806688082736, 0.6904838307350867, 0.6931174504447031, 0.6958782406082653, 0.6990661484489127, 0.701726967048038, 0.7042518908730465, 0.7070529084088146, 0.7095426281970368, 0.7122546946207959, 0.7141621364853833, 0.7165603094050297, 0.7193555349179758, 0.7212846690688237, 0.7229776848061777]}

