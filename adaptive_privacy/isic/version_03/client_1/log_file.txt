Initial Train Dataset Size: 9930 Sample rate: 0.5339570898532021
Initial Train Dataset Size: 9930 Sample rate: 0.5339570898532021
Global Epoch (Round): 1, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.3873, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.3709, Accuracy: 0.6222, AUC: 0.8608
Global Epoch (Round): 2, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.2875, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.3394, Accuracy: 0.6387, AUC: 0.8777
Global Epoch (Round): 3, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.2255, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2831, Accuracy: 0.6524, AUC: 0.8883
Global Epoch (Round): 4, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.2135, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2534, Accuracy: 0.6569, AUC: 0.8950
Global Epoch (Round): 5, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.2004, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.3024, Accuracy: 0.6472, AUC: 0.8940
Global Epoch (Round): 6, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1755, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2844, Accuracy: 0.6641, AUC: 0.8991
Global Epoch (Round): 7, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1707, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2353, Accuracy: 0.6698, AUC: 0.9015
Global Epoch (Round): 8, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1806, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2791, Accuracy: 0.6673, AUC: 0.9001
Global Epoch (Round): 9, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1633, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2499, Accuracy: 0.6669, AUC: 0.8985
Global Epoch (Round): 10, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1524, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2290, Accuracy: 0.6673, AUC: 0.9043
Global Epoch (Round): 11, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1652, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2523, Accuracy: 0.6706, AUC: 0.9037
Global Epoch (Round): 12, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1385, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2765, Accuracy: 0.6758, AUC: 0.9049
Global Epoch (Round): 13, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1315, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2845, Accuracy: 0.6746, AUC: 0.9056
Global Epoch (Round): 14, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1535, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2610, Accuracy: 0.6689, AUC: 0.9073
Global Epoch (Round): 15, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1353, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2594, Accuracy: 0.6718, AUC: 0.9067
Global Epoch (Round): 16, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1188, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2562, Accuracy: 0.6694, AUC: 0.9086
Global Epoch (Round): 17, Train Size: 9930, Sample Rate: 0.5339570898532021, Train Loss: 1.1259, Epsilon: 30.00, Dynamic Noise Multiplier: 0.03
Loss: 1.2459, Accuracy: 0.6806, AUC: 0.9087
