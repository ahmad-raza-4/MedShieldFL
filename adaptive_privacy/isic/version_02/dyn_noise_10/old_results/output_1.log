nohup: ignoring input
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(mpl.__version__) >= "3.0":
/home/dgxuser16/.local/lib/python3.8/site-packages/setuptools/_distutils/version.py:345: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
/home/dgxuser16/.local/lib/python3.8/site-packages/seaborn/cm.py:1582: MatplotlibDeprecationWarning: The register_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps.register(name)`` instead.
  mpl_cm.register_cmap(_name, _cmap)
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/adaptive_privacy/isic/version_02/dyn_noise_10/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
01/23/2025 11:24:16:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/23/2025 11:24:16:DEBUG:ChannelConnectivity.IDLE
01/23/2025 11:24:16:DEBUG:ChannelConnectivity.CONNECTING
01/23/2025 11:24:16:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/23/2025 11:24:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 11:24:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8f9e4883-a7b5-4adb-8eba-8ef8ea65dc0a
01/23/2025 11:24:44:INFO:Received: train message 8f9e4883-a7b5-4adb-8eba-8ef8ea65dc0a
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 11:43:20:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 11:43:55:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 11:43:55:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 44e43855-145f-41d5-a13e-cad1c3792c5c
01/23/2025 11:43:55:INFO:Received: evaluate message 44e43855-145f-41d5-a13e-cad1c3792c5c
[92mINFO [0m:      Sent reply
01/23/2025 11:47:59:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 11:48:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 11:48:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1b0548d8-d849-4e9f-80ac-e4a65454a997
01/23/2025 11:48:25:INFO:Received: train message 1b0548d8-d849-4e9f-80ac-e4a65454a997
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 12:07:06:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 12:07:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 12:07:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 48300f68-8b20-4e06-b4c0-77b3c9df3379
01/23/2025 12:07:25:INFO:Received: evaluate message 48300f68-8b20-4e06-b4c0-77b3c9df3379
[92mINFO [0m:      Sent reply
01/23/2025 12:10:42:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 12:12:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 12:12:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f40cf267-e8db-41f9-a35f-4a599547e679
01/23/2025 12:12:03:INFO:Received: train message f40cf267-e8db-41f9-a35f-4a599547e679
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 12:30:35:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 12:31:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 12:31:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 51c52639-0af7-4532-a0ce-9045b9559aea
01/23/2025 12:31:09:INFO:Received: evaluate message 51c52639-0af7-4532-a0ce-9045b9559aea
[92mINFO [0m:      Sent reply
01/23/2025 12:35:14:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 12:35:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 12:35:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1cc974fa-5f53-4715-a359-540cb1c1fb58
01/23/2025 12:35:24:INFO:Received: train message 1cc974fa-5f53-4715-a359-540cb1c1fb58
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 12:54:18:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 12:54:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 12:54:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message cff113f4-c4ca-4e31-bdd7-a2106d102801
01/23/2025 12:54:48:INFO:Received: evaluate message cff113f4-c4ca-4e31-bdd7-a2106d102801
[92mINFO [0m:      Sent reply
01/23/2025 12:58:55:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 12:59:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 12:59:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 97edb441-40fd-49d4-902b-654af683cb15
01/23/2025 12:59:24:INFO:Received: train message 97edb441-40fd-49d4-902b-654af683cb15
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 13:18:12:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 13:18:30:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 13:18:30:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 45f346d2-415d-409a-b479-73c4ed0942ea
01/23/2025 13:18:30:INFO:Received: evaluate message 45f346d2-415d-409a-b479-73c4ed0942ea
[92mINFO [0m:      Sent reply
01/23/2025 13:21:53:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 13:22:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 13:22:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e02a3cdc-8923-4bb6-9ee0-efb135c53bd6
01/23/2025 13:22:59:INFO:Received: train message e02a3cdc-8923-4bb6-9ee0-efb135c53bd6
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 13:41:41:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 13:42:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 13:42:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2bb9e00f-a769-499b-974d-21627f726dcd
01/23/2025 13:42:12:INFO:Received: evaluate message 2bb9e00f-a769-499b-974d-21627f726dcd
[92mINFO [0m:      Sent reply
01/23/2025 13:46:12:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 13:46:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 13:46:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 964cd6cb-caf1-4800-8531-96cdb6a6f392
01/23/2025 13:46:43:INFO:Received: train message 964cd6cb-caf1-4800-8531-96cdb6a6f392
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 14:05:14:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 14:05:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 14:05:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 21878ef0-0b52-4d4d-b03e-4c3fae3aa591
01/23/2025 14:05:39:INFO:Received: evaluate message 21878ef0-0b52-4d4d-b03e-4c3fae3aa591
[92mINFO [0m:      Sent reply
01/23/2025 14:09:32:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 14:09:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 14:09:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e9d223ab-259a-4f5b-bdd3-fb78694443c3
01/23/2025 14:09:56:INFO:Received: train message e9d223ab-259a-4f5b-bdd3-fb78694443c3
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 14:28:54:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 14:29:16:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 14:29:16:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b911f2f9-71e4-4e67-ab39-5e9e4bfef449
01/23/2025 14:29:16:INFO:Received: evaluate message b911f2f9-71e4-4e67-ab39-5e9e4bfef449
[92mINFO [0m:      Sent reply
01/23/2025 14:32:59:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 14:33:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 14:33:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 4955c734-8285-4111-86ae-3accabf0c270
01/23/2025 14:33:58:INFO:Received: train message 4955c734-8285-4111-86ae-3accabf0c270
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 14:52:40:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 14:52:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 14:52:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 06f8160f-7449-4a22-8aa4-d85a5f4813c6
01/23/2025 14:52:59:INFO:Received: evaluate message 06f8160f-7449-4a22-8aa4-d85a5f4813c6
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/adaptive_privacy/isic/version_02/dyn_noise_10', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/.local/lib/python3.8/site-packages', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/adaptive_privacy/isic/version_02/dyn_noise_10']
Params:
 batch_size: 32, local_epochs: 3, full_dataset_size: 25331, num_classes: 8

Privacy Params:
 epsilon: 10, target_epsilon: 10, target_delta: 1e-05

Device: cuda:0

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.66

{'loss': [137.23898267745972], 'accuracy': [0.3383004430124849], 'auc': [0.5877396505618926]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.83

{'loss': [137.23898267745972, 134.08246445655823], 'accuracy': [0.3383004430124849, 0.3407168747482884], 'auc': [0.5877396505618926, 0.620088227094536]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.20

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.71

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.55

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.31

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.86

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.58

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.89
[92mINFO [0m:      Sent reply
01/23/2025 14:56:46:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 14:57:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 14:57:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d5a95a19-3557-49b9-ba2c-4850093abdce
01/23/2025 14:57:42:INFO:Received: train message d5a95a19-3557-49b9-ba2c-4850093abdce
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 15:16:12:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 15:16:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 15:16:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 086da973-e166-4904-b609-b5f6859c66fa
01/23/2025 15:16:45:INFO:Received: evaluate message 086da973-e166-4904-b609-b5f6859c66fa
[92mINFO [0m:      Sent reply
01/23/2025 15:20:48:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 15:21:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 15:21:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 48c1b1f7-35de-4839-b539-d55f88f87b81
01/23/2025 15:21:17:INFO:Received: train message 48c1b1f7-35de-4839-b539-d55f88f87b81
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 15:39:57:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 15:40:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 15:40:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message f897041a-0230-4218-91ed-37f697a37e6b
01/23/2025 15:40:28:INFO:Received: evaluate message f897041a-0230-4218-91ed-37f697a37e6b
[92mINFO [0m:      Sent reply
01/23/2025 15:44:28:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 15:44:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 15:44:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 21d30b36-268a-4c0b-9515-6aac59e922bf
01/23/2025 15:44:44:INFO:Received: train message 21d30b36-268a-4c0b-9515-6aac59e922bf
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 16:03:18:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 16:03:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 16:03:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3e34543e-0fdf-4edf-8536-26f5e7b2cce8
01/23/2025 16:03:52:INFO:Received: evaluate message 3e34543e-0fdf-4edf-8536-26f5e7b2cce8
[92mINFO [0m:      Sent reply
01/23/2025 16:07:51:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 16:08:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 16:08:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d711497b-a259-4d5a-aa04-b0d4e29abaad
01/23/2025 16:08:10:INFO:Received: train message d711497b-a259-4d5a-aa04-b0d4e29abaad
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 16:26:46:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 16:27:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 16:27:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 9b7cb41c-3c5a-4ac1-979d-8876532ae6b1
01/23/2025 16:27:08:INFO:Received: evaluate message 9b7cb41c-3c5a-4ac1-979d-8876532ae6b1
[92mINFO [0m:      Sent reply
01/23/2025 16:31:11:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 16:31:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 16:31:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message e990d67f-301b-40dd-a552-bd4f6e90055c
01/23/2025 16:31:31:INFO:Received: train message e990d67f-301b-40dd-a552-bd4f6e90055c
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 16:50:29:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 16:51:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 16:51:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 1230cd60-8e6f-456f-8c70-b1ed4e82f34e
01/23/2025 16:51:03:INFO:Received: evaluate message 1230cd60-8e6f-456f-8c70-b1ed4e82f34e
[92mINFO [0m:      Sent reply
01/23/2025 16:54:59:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 16:55:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 16:55:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9b2d1dbb-04a6-4901-9e89-c52463ee46d0
01/23/2025 16:55:29:INFO:Received: train message 9b2d1dbb-04a6-4901-9e89-c52463ee46d0
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 17:13:59:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 17:14:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 17:14:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b7f69873-ed0d-49b2-b440-45d62d24e8ea
01/23/2025 17:14:29:INFO:Received: evaluate message b7f69873-ed0d-49b2-b440-45d62d24e8ea

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.41

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.56

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.38

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.53

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 2.11

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.024460434075444938
Epsilon = 10.00 and Loss = 1.45
[92mINFO [0m:      Sent reply
01/23/2025 17:18:31:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 17:19:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 17:19:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a64d73e4-7015-4c56-931b-5c7537dc4da4
01/23/2025 17:19:02:INFO:Received: train message a64d73e4-7015-4c56-931b-5c7537dc4da4
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 17:37:48:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 17:38:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 17:38:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a74c6bee-5966-4c02-96bc-06d6f9b19612
01/23/2025 17:38:15:INFO:Received: evaluate message a74c6bee-5966-4c02-96bc-06d6f9b19612
[92mINFO [0m:      Sent reply
01/23/2025 17:42:11:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 17:42:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 17:42:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a5689b4e-fbff-4cfd-95d9-909e49fa8343
01/23/2025 17:42:41:INFO:Received: train message a5689b4e-fbff-4cfd-95d9-909e49fa8343
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 18:01:17:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 18:01:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 18:01:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a7157b14-a8ac-4095-9ea7-b66278381809
01/23/2025 18:01:47:INFO:Received: evaluate message a7157b14-a8ac-4095-9ea7-b66278381809
[92mINFO [0m:      Sent reply
01/23/2025 18:05:54:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 18:06:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 18:06:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 672c2d34-d5b7-484d-a2f2-895147199f8f
01/23/2025 18:06:26:INFO:Received: train message 672c2d34-d5b7-484d-a2f2-895147199f8f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 18:24:56:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 18:25:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 18:25:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 41b09e1f-6c45-4cb8-a062-6677ebd57867
01/23/2025 18:25:22:INFO:Received: evaluate message 41b09e1f-6c45-4cb8-a062-6677ebd57867
[92mINFO [0m:      Sent reply
01/23/2025 18:29:22:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 18:29:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 18:29:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8f39afd4-fd39-4f76-9ab9-e13ef1298c50
01/23/2025 18:29:52:INFO:Received: train message 8f39afd4-fd39-4f76-9ab9-e13ef1298c50
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 18:48:24:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 18:48:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 18:48:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d59173c1-2065-4d2a-a379-1f577481426d
01/23/2025 18:48:49:INFO:Received: evaluate message d59173c1-2065-4d2a-a379-1f577481426d
[92mINFO [0m:      Sent reply
01/23/2025 18:52:52:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 18:53:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 18:53:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 08c7a8d5-599d-483d-be85-b2cb601d0f87
01/23/2025 18:53:29:INFO:Received: train message 08c7a8d5-599d-483d-be85-b2cb601d0f87
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 19:11:55:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 19:12:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 19:12:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a94d03c0-00f0-48d9-b215-96368e9a9758
01/23/2025 19:12:24:INFO:Received: evaluate message a94d03c0-00f0-48d9-b215-96368e9a9758

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.022829738470415275
Epsilon = 10.00 and Loss = 1.84

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.021199042865385615
Epsilon = 10.00 and Loss = 1.79

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.019568347260355952
Epsilon = 10.00 and Loss = 1.50

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.01793765165532629
Epsilon = 10.00 and Loss = 1.64

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.01630695605029663
Epsilon = 10.00 and Loss = 1.40
[92mINFO [0m:      Sent reply
01/23/2025 19:16:30:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 19:16:47:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 19:16:47:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8501352a-307a-42b2-8a7a-f6f8b1b5345f
01/23/2025 19:16:47:INFO:Received: train message 8501352a-307a-42b2-8a7a-f6f8b1b5345f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 19:35:30:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 19:35:58:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 19:35:58:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 09f7679a-92c4-44b4-b6af-1ffd6cdf4871
01/23/2025 19:35:58:INFO:Received: evaluate message 09f7679a-92c4-44b4-b6af-1ffd6cdf4871
[92mINFO [0m:      Sent reply
01/23/2025 19:40:04:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 19:40:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 19:40:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 79959ff4-aa70-4fda-8a24-4dd6f7deef49
01/23/2025 19:40:33:INFO:Received: train message 79959ff4-aa70-4fda-8a24-4dd6f7deef49
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 19:59:00:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 19:59:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 19:59:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2be7b79d-8afc-4ac3-9f30-a4fe16dbac5b
01/23/2025 19:59:34:INFO:Received: evaluate message 2be7b79d-8afc-4ac3-9f30-a4fe16dbac5b
[92mINFO [0m:      Sent reply
01/23/2025 20:03:33:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 20:03:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 20:03:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6098f5d3-0a71-458c-9e67-963ce753ef3f
01/23/2025 20:03:51:INFO:Received: train message 6098f5d3-0a71-458c-9e67-963ce753ef3f
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 20:22:45:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 20:23:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 20:23:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message bab3ecf6-d3e3-40c8-9076-1ecee341fa49
01/23/2025 20:23:00:INFO:Received: evaluate message bab3ecf6-d3e3-40c8-9076-1ecee341fa49
[92mINFO [0m:      Sent reply
01/23/2025 20:26:44:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 20:27:36:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 20:27:36:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 51a2b98d-9c27-4627-9609-c4953001fee5
01/23/2025 20:27:36:INFO:Received: train message 51a2b98d-9c27-4627-9609-c4953001fee5
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 20:46:17:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 20:46:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 20:46:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 5cad86f9-f4f1-473b-9865-e85d6de8b9e1
01/23/2025 20:46:32:INFO:Received: evaluate message 5cad86f9-f4f1-473b-9865-e85d6de8b9e1

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.014676260445266962
Epsilon = 10.00 and Loss = 1.87

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226, 119.29281044006348], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263, 0.5118807893677003], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125, 0.7126418327786991]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.0130455648402373
Epsilon = 10.00 and Loss = 1.44

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226, 119.29281044006348, 118.69239163398743], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263, 0.5118807893677003, 0.5159081755940395], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125, 0.7126418327786991, 0.7152616297876564]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.011414869235207637
Epsilon = 10.00 and Loss = 1.57

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226, 119.29281044006348, 118.69239163398743, 118.04494619369507], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263, 0.5118807893677003, 0.5159081755940395, 0.5195328231977446], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125, 0.7126418327786991, 0.7152616297876564, 0.7178179842200959]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.009784173630177976
Epsilon = 10.00 and Loss = 1.31
[92mINFO [0m:      Sent reply
01/23/2025 20:50:18:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 20:51:14:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 20:51:14:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 74df91dc-14ce-4a99-a377-4a86a45a2cc2
01/23/2025 20:51:14:INFO:Received: train message 74df91dc-14ce-4a99-a377-4a86a45a2cc2
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 21:09:53:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 21:10:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 21:10:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 22da0a45-426e-45cf-bbec-e53d760e39db
01/23/2025 21:10:21:INFO:Received: evaluate message 22da0a45-426e-45cf-bbec-e53d760e39db
[92mINFO [0m:      Sent reply
01/23/2025 21:14:26:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 21:15:11:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 21:15:11:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message febe9d07-9402-4f5e-9afd-33ff71ff1274
01/23/2025 21:15:11:INFO:Received: train message febe9d07-9402-4f5e-9afd-33ff71ff1274
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 21:34:06:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 21:34:43:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 21:34:43:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 207ca29a-7ef3-44d6-89f7-75b3535fc783
01/23/2025 21:34:43:INFO:Received: evaluate message 207ca29a-7ef3-44d6-89f7-75b3535fc783
[92mINFO [0m:      Sent reply
01/23/2025 21:38:57:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 21:39:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 21:39:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ef7ef72c-b0bc-4675-a745-f41570713cc6
01/23/2025 21:39:25:INFO:Received: train message ef7ef72c-b0bc-4675-a745-f41570713cc6
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 22:04:46:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 22:05:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 22:05:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message eb92ca5a-b964-42e9-b95d-216c8726b45c
01/23/2025 22:05:20:INFO:Received: evaluate message eb92ca5a-b964-42e9-b95d-216c8726b45c
[92mINFO [0m:      Sent reply
01/23/2025 22:10:13:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 22:10:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 22:10:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b666bb09-f774-4ecb-881e-f75dd4e1472d
01/23/2025 22:10:49:INFO:Received: train message b666bb09-f774-4ecb-881e-f75dd4e1472d

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226, 119.29281044006348, 118.69239163398743, 118.04494619369507, 117.50876820087433], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263, 0.5118807893677003, 0.5159081755940395, 0.5195328231977446, 0.522754732178816], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125, 0.7126418327786991, 0.7152616297876564, 0.7178179842200959, 0.7203159641961545]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.008153478025148314
Epsilon = 10.00 and Loss = 1.38

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226, 119.29281044006348, 118.69239163398743, 118.04494619369507, 117.50876820087433, 117.10123109817505], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263, 0.5118807893677003, 0.5159081755940395, 0.5195328231977446, 0.522754732178816, 0.5247684252919855], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125, 0.7126418327786991, 0.7152616297876564, 0.7178179842200959, 0.7203159641961545, 0.7226743140632264]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.006522782420118651
Epsilon = 10.00 and Loss = 1.11

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226, 119.29281044006348, 118.69239163398743, 118.04494619369507, 117.50876820087433, 117.10123109817505, 117.10221004486084], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263, 0.5118807893677003, 0.5159081755940395, 0.5195328231977446, 0.522754732178816, 0.5247684252919855, 0.5255739025372533], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125, 0.7126418327786991, 0.7152616297876564, 0.7178179842200959, 0.7203159641961545, 0.7226743140632264, 0.7244231714217761]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.004892086815088986
Epsilon = 10.00 and Loss = 1.88

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226, 119.29281044006348, 118.69239163398743, 118.04494619369507, 117.50876820087433, 117.10123109817505, 117.10221004486084, 116.7288248538971], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263, 0.5118807893677003, 0.5159081755940395, 0.5195328231977446, 0.522754732178816, 0.5247684252919855, 0.5255739025372533, 0.5300040273862263], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125, 0.7126418327786991, 0.7152616297876564, 0.7178179842200959, 0.7203159641961545, 0.7226743140632264, 0.7244231714217761, 0.7264684107252344]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 22:37:19:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 22:37:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 22:37:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4a75f872-3238-40d3-9397-25ab16dd7bff
01/23/2025 22:37:53:INFO:Received: evaluate message 4a75f872-3238-40d3-9397-25ab16dd7bff
[92mINFO [0m:      Sent reply
01/23/2025 22:42:50:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 22:43:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 22:43:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 7f270fc3-e29d-4856-8f2d-421a4506393b
01/23/2025 22:43:12:INFO:Received: train message 7f270fc3-e29d-4856-8f2d-421a4506393b
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 23:14:44:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 23:15:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 23:15:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c3c89c4e-55c5-4ba7-bf2d-ba6a21af5411
01/23/2025 23:15:23:INFO:Received: evaluate message c3c89c4e-55c5-4ba7-bf2d-ba6a21af5411
[92mINFO [0m:      Sent reply
01/23/2025 23:20:06:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 23:20:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 23:20:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f1e5e879-d468-44c2-9159-a5b0ec7902d8
01/23/2025 23:20:28:INFO:Received: train message f1e5e879-d468-44c2-9159-a5b0ec7902d8
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/23/2025 23:48:24:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 23:48:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 23:48:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 182cc4a0-4ec5-4950-bfda-d86b2dc428f0
01/23/2025 23:48:44:INFO:Received: evaluate message 182cc4a0-4ec5-4950-bfda-d86b2dc428f0
[92mINFO [0m:      Sent reply
01/23/2025 23:53:26:INFO:Sent reply
[92mINFO [0m:      
01/23/2025 23:53:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/23/2025 23:53:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: reconnect message 0f195c40-6b63-43d1-b9b7-c048245a1211
01/23/2025 23:53:49:INFO:Received: reconnect message 0f195c40-6b63-43d1-b9b7-c048245a1211
01/23/2025 23:53:49:DEBUG:gRPC channel closed
[92mINFO [0m:      Disconnect and shut down
01/23/2025 23:53:49:INFO:Disconnect and shut down
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.0032613912100593243
Epsilon = 10.00 and Loss = 1.34

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226, 119.29281044006348, 118.69239163398743, 118.04494619369507, 117.50876820087433, 117.10123109817505, 117.10221004486084, 116.7288248538971, 116.15087568759918], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263, 0.5118807893677003, 0.5159081755940395, 0.5195328231977446, 0.522754732178816, 0.5247684252919855, 0.5255739025372533, 0.5300040273862263, 0.5308095046314941], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125, 0.7126418327786991, 0.7152616297876564, 0.7178179842200959, 0.7203159641961545, 0.7226743140632264, 0.7244231714217761, 0.7264684107252344, 0.7286912139793894]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.0016306956050296622
Epsilon = 10.00 and Loss = 1.51

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226, 119.29281044006348, 118.69239163398743, 118.04494619369507, 117.50876820087433, 117.10123109817505, 117.10221004486084, 116.7288248538971, 116.15087568759918, 116.01985085010529], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263, 0.5118807893677003, 0.5159081755940395, 0.5195328231977446, 0.522754732178816, 0.5247684252919855, 0.5255739025372533, 0.5300040273862263, 0.5308095046314941, 0.5344341522351993], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125, 0.7126418327786991, 0.7152616297876564, 0.7178179842200959, 0.7203159641961545, 0.7226743140632264, 0.7244231714217761, 0.7264684107252344, 0.7286912139793894, 0.730389215145808]}

Base Noise Multiplier Received:  0.8197021484375
Data Scaling Factor: 2.550956696878147 where Client Data Size: 9930
Noise Multiplier after Fisher Scaling:  [0.39626026153564453, 0.5964537858963013, 0.4014344811439514, 0.14097385108470917, 0.1780557632446289, 0.07782359421253204, 0.08872205764055252, 0.07711093127727509]
Noise Multiplier after list and tensor:  0.24460434075444937
Noise Multiplier after Epsilon Scaling:  0.024460434075444938
Noise Multiplier after Convergence: 0.0
Epsilon = 10.00 and Loss = 1.10

{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226, 119.29281044006348, 118.69239163398743, 118.04494619369507, 117.50876820087433, 117.10123109817505, 117.10221004486084, 116.7288248538971, 116.15087568759918, 116.01985085010529, 116.09026396274567], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263, 0.5118807893677003, 0.5159081755940395, 0.5195328231977446, 0.522754732178816, 0.5247684252919855, 0.5255739025372533, 0.5300040273862263, 0.5308095046314941, 0.5344341522351993, 0.5372533225936368], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125, 0.7126418327786991, 0.7152616297876564, 0.7178179842200959, 0.7203159641961545, 0.7226743140632264, 0.7244231714217761, 0.7264684107252344, 0.7286912139793894, 0.730389215145808, 0.731616827854312]}



Final client history:
{'loss': [137.23898267745972, 134.08246445655823, 136.50129997730255, 138.68937921524048, 139.77128911018372, 139.64172565937042, 137.6421983242035, 135.82592260837555, 132.65138185024261, 130.51821053028107, 128.63891410827637, 127.28007924556732, 125.9071455001831, 124.84411978721619, 123.52748727798462, 122.66383385658264, 121.6530350446701, 121.15643334388733, 120.60817646980286, 119.69176495075226, 119.29281044006348, 118.69239163398743, 118.04494619369507, 117.50876820087433, 117.10123109817505, 117.10221004486084, 116.7288248538971, 116.15087568759918, 116.01985085010529, 116.09026396274567], 'accuracy': [0.3383004430124849, 0.3407168747482884, 0.342327829238824, 0.34353604510672575, 0.3495771244462344, 0.3568264196536448, 0.37535239629480466, 0.39428111155859846, 0.41522351993556184, 0.4309303262182843, 0.44703987112364074, 0.4587192911800242, 0.4671768022553363, 0.47362062021747886, 0.4816753926701571, 0.4877164720096657, 0.49295207410390657, 0.4973821989528796, 0.5026178010471204, 0.509061619009263, 0.5118807893677003, 0.5159081755940395, 0.5195328231977446, 0.522754732178816, 0.5247684252919855, 0.5255739025372533, 0.5300040273862263, 0.5308095046314941, 0.5344341522351993, 0.5372533225936368], 'auc': [0.5877396505618926, 0.620088227094536, 0.634044103019688, 0.6416926486242707, 0.647897844942319, 0.6532735014964851, 0.6585939920688253, 0.6636922400708751, 0.6692355450490037, 0.6739765691828631, 0.6787644661574044, 0.6830271542360524, 0.6871049544939689, 0.6907218374514706, 0.694736098121962, 0.6981423781026579, 0.7015472651555668, 0.7043517911808491, 0.7071334455651364, 0.7101973643929125, 0.7126418327786991, 0.7152616297876564, 0.7178179842200959, 0.7203159641961545, 0.7226743140632264, 0.7244231714217761, 0.7264684107252344, 0.7286912139793894, 0.730389215145808, 0.731616827854312]}

