nohup: ignoring input
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.2 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/fixed_dp/isic/version_02/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
01/28/2025 02:50:17:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/28/2025 02:50:17:DEBUG:ChannelConnectivity.IDLE
01/28/2025 02:50:17:DEBUG:ChannelConnectivity.CONNECTING
01/28/2025 02:50:17:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/28/2025 02:50:17:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 02:50:17:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: get_parameters message 4c068af1-a69e-4c99-8388-b6c26083003a
01/28/2025 02:50:17:INFO:Received: get_parameters message 4c068af1-a69e-4c99-8388-b6c26083003a
[92mINFO [0m:      Sent reply
01/28/2025 02:50:20:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 02:50:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 02:50:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 46846ca3-442f-4e62-a902-918a11bf75f9
01/28/2025 02:50:52:INFO:Received: train message 46846ca3-442f-4e62-a902-918a11bf75f9
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 03:04:16:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 03:12:42:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 03:12:42:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a0106fc7-115c-4616-a1db-e9c0fafc389e
01/28/2025 03:12:42:INFO:Received: evaluate message a0106fc7-115c-4616-a1db-e9c0fafc389e
[92mINFO [0m:      Sent reply
01/28/2025 03:16:46:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 03:17:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 03:17:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cd487215-372a-40c2-9231-83b812d56bca
01/28/2025 03:17:28:INFO:Received: train message cd487215-372a-40c2-9231-83b812d56bca
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 03:31:15:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 03:41:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 03:41:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 387960ed-34e2-4f57-ac74-543278c32e0e
01/28/2025 03:41:37:INFO:Received: evaluate message 387960ed-34e2-4f57-ac74-543278c32e0e
[92mINFO [0m:      Sent reply
01/28/2025 03:45:43:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 03:46:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 03:46:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6eb6cd48-3d4b-4ed2-b1f5-e9c44fc2fad3
01/28/2025 03:46:59:INFO:Received: train message 6eb6cd48-3d4b-4ed2-b1f5-e9c44fc2fad3
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 04:00:37:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 04:10:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 04:10:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message e6414c21-f7ed-4466-a918-5ecbe57b3a51
01/28/2025 04:10:38:INFO:Received: evaluate message e6414c21-f7ed-4466-a918-5ecbe57b3a51
[92mINFO [0m:      Sent reply
01/28/2025 04:14:42:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 04:15:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 04:15:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message dbd8026c-6afe-4aa8-b325-ab37e2535ce0
01/28/2025 04:15:09:INFO:Received: train message dbd8026c-6afe-4aa8-b325-ab37e2535ce0
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 04:28:33:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 04:36:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 04:36:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message bb4b1913-de25-41d6-831a-441d8e3934a1
01/28/2025 04:36:56:INFO:Received: evaluate message bb4b1913-de25-41d6-831a-441d8e3934a1
[92mINFO [0m:      Sent reply
01/28/2025 04:41:05:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 04:41:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 04:41:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a17b153a-c632-46ed-81ac-174d7ee602c6
01/28/2025 04:41:33:INFO:Received: train message a17b153a-c632-46ed-81ac-174d7ee602c6
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 04:54:49:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 05:03:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 05:03:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c4c4e471-7dc8-4fa4-acc3-38f08a28e228
01/28/2025 05:03:13:INFO:Received: evaluate message c4c4e471-7dc8-4fa4-acc3-38f08a28e228
[92mINFO [0m:      Sent reply
01/28/2025 05:07:32:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 05:08:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 05:08:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message fdea817a-a751-428d-99cb-63ec75c2a601
01/28/2025 05:08:10:INFO:Received: train message fdea817a-a751-428d-99cb-63ec75c2a601
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 05:21:19:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 05:29:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 05:29:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message c3f10e01-2226-4bc2-83ff-7534f7c8df90
01/28/2025 05:29:13:INFO:Received: evaluate message c3f10e01-2226-4bc2-83ff-7534f7c8df90
[92mINFO [0m:      Sent reply
01/28/2025 05:33:17:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 05:33:48:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 05:33:48:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2f56afb1-8256-4969-aec0-e0ddc6057b5e
01/28/2025 05:33:48:INFO:Received: train message 2f56afb1-8256-4969-aec0-e0ddc6057b5e
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 05:47:06:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 05:55:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 05:55:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7f4ff93e-0cf8-4de7-8c1b-ef2d45bc9527
01/28/2025 05:55:29:INFO:Received: evaluate message 7f4ff93e-0cf8-4de7-8c1b-ef2d45bc9527
[92mINFO [0m:      Sent reply
01/28/2025 05:59:44:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 06:00:15:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 06:00:15:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f4ca1c06-6d49-4e15-b760-06a4b749137c
01/28/2025 06:00:15:INFO:Received: train message f4ca1c06-6d49-4e15-b760-06a4b749137c
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 06:13:25:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 06:22:10:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 06:22:10:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ad416c5a-34a0-4177-bc02-6fdf3da42757
01/28/2025 06:22:10:INFO:Received: evaluate message ad416c5a-34a0-4177-bc02-6fdf3da42757
[92mINFO [0m:      Sent reply
01/28/2025 06:26:26:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 06:26:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 06:26:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 6902bab6-ca16-474d-957a-1434a25f8480
01/28/2025 06:26:53:INFO:Received: train message 6902bab6-ca16-474d-957a-1434a25f8480
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 06:40:10:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 06:47:57:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 06:47:57:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4294cf65-9e71-4863-8752-55de444e8c5a
01/28/2025 06:47:57:INFO:Received: evaluate message 4294cf65-9e71-4863-8752-55de444e8c5a
[92mINFO [0m:      Sent reply
01/28/2025 06:52:05:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 06:52:26:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 06:52:26:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 5b56f860-0c42-4751-89a4-cd8266e5c2ae
01/28/2025 06:52:26:INFO:Received: train message 5b56f860-0c42-4751-89a4-cd8266e5c2ae
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 07:05:34:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 07:14:04:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 07:14:04:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 90e04fa5-0c34-4a12-b5e4-500e7f1996db
01/28/2025 07:14:04:INFO:Received: evaluate message 90e04fa5-0c34-4a12-b5e4-500e7f1996db
[92mINFO [0m:      Sent reply
01/28/2025 07:18:11:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 07:18:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 07:18:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message d71c246a-637e-45d0-ae86-36be981e5980
01/28/2025 07:18:37:INFO:Received: train message d71c246a-637e-45d0-ae86-36be981e5980
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 07:31:53:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 07:40:51:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 07:40:51:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message afacaa01-86a5-4e29-8f32-16d6439f1dbe
01/28/2025 07:40:51:INFO:Received: evaluate message afacaa01-86a5-4e29-8f32-16d6439f1dbe
[92mINFO [0m:      Sent reply
01/28/2025 07:45:03:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 07:45:34:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 07:45:34:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message f6d97e92-3c15-4c11-ae34-73d2b01bc484
01/28/2025 07:45:34:INFO:Received: train message f6d97e92-3c15-4c11-ae34-73d2b01bc484
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 07:59:25:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 08:07:09:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 08:07:09:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message ca72d4a1-367b-43ed-9fdc-28ec546ce594
01/28/2025 08:07:09:INFO:Received: evaluate message ca72d4a1-367b-43ed-9fdc-28ec546ce594
[92mINFO [0m:      Sent reply
01/28/2025 08:11:11:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 08:12:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 08:12:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 67d7f148-ad01-4e59-ae53-9f48d40b877d
01/28/2025 08:12:01:INFO:Received: train message 67d7f148-ad01-4e59-ae53-9f48d40b877d
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 08:25:02:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 08:33:39:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 08:33:39:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3010cf78-d096-41f9-8912-237fd8a502d1
01/28/2025 08:33:39:INFO:Received: evaluate message 3010cf78-d096-41f9-8912-237fd8a502d1
[92mINFO [0m:      Sent reply
01/28/2025 08:37:52:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 08:38:21:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 08:38:21:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 8cbbdaa0-b3d0-419d-a221-0fc1c85b8440
01/28/2025 08:38:21:INFO:Received: train message 8cbbdaa0-b3d0-419d-a221-0fc1c85b8440
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 08:51:15:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 09:00:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 09:00:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 06486eb6-5ee5-44fe-a184-1d2c4a4f45ee
01/28/2025 09:00:03:INFO:Received: evaluate message 06486eb6-5ee5-44fe-a184-1d2c4a4f45ee
[92mINFO [0m:      Sent reply
01/28/2025 09:04:09:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 09:04:29:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 09:04:29:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 10a22fd5-8abb-4ad7-9ecb-63a92195c206
01/28/2025 09:04:29:INFO:Received: train message 10a22fd5-8abb-4ad7-9ecb-63a92195c206
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 09:17:29:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 09:25:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 09:25:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 4253130b-9aa1-4694-8195-c363d4c68614
01/28/2025 09:25:33:INFO:Received: evaluate message 4253130b-9aa1-4694-8195-c363d4c68614
['/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/fixed_dp/isic/version_02', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python38.zip', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/lib-dynload', '/home/dgxuser16/.local/lib/python3.8/site-packages', '/home/dgxuser16/anaconda3/envs/ihpc/lib/python3.8/site-packages', '/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/fixed_dp/isic/version_02']
Device: cuda:0
Params: {'batch_size': 32, 'local_epochs': 3, 'full_dataset_size': 18597, 'number_of_classes': 8}
Privacy Params: {'target_delta': 1e-05, 'noise_multiplier': 1.8, 'max_grad_norm': 1.0}
Epsilon = 0.40

{'loss': [1.6900447713623017], 'accuracy': [0.4289166331051148], 'auc': [0.6836437826488786]}

Epsilon = 0.56

{'loss': [1.6900447713623017, 1.6200207814640255], 'accuracy': [0.4289166331051148, 0.49697946033024565], 'auc': [0.6836437826488786, 0.7193702350502433]}

Epsilon = 0.69

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546]}

Epsilon = 0.80

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464, 1.5503206903109663], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603, 0.5501409585179219], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546, 0.7591763445479134]}

Epsilon = 0.90

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464, 1.5503206903109663, 1.531454744667379], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603, 0.5501409585179219, 0.5614176399516714], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546, 0.7591763445479134, 0.7698641286799174]}

Epsilon = 1.00

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464, 1.5503206903109663, 1.531454744667379, 1.495392064341508], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603, 0.5501409585179219, 0.5614176399516714, 0.5698751510269835], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546, 0.7591763445479134, 0.7698641286799174, 0.7772493072393372]}

Epsilon = 1.08

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464, 1.5503206903109663, 1.531454744667379, 1.495392064341508, 1.4951688798742337], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603, 0.5501409585179219, 0.5614176399516714, 0.5698751510269835, 0.5775271848570278], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546, 0.7591763445479134, 0.7698641286799174, 0.7772493072393372, 0.7844971780330663]}

Epsilon = 1.16

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464, 1.5503206903109663, 1.531454744667379, 1.495392064341508, 1.4951688798742337, 1.4937441075851587], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603, 0.5501409585179219, 0.5614176399516714, 0.5698751510269835, 0.5775271848570278, 0.5803463552154652], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546, 0.7591763445479134, 0.7698641286799174, 0.7772493072393372, 0.7844971780330663, 0.7922772055040708]}

Epsilon = 1.24

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464, 1.5503206903109663, 1.531454744667379, 1.495392064341508, 1.4951688798742337, 1.4937441075851587, 1.5138965205132264], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603, 0.5501409585179219, 0.5614176399516714, 0.5698751510269835, 0.5775271848570278, 0.5803463552154652, 0.5819573097060008], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546, 0.7591763445479134, 0.7698641286799174, 0.7772493072393372, 0.7844971780330663, 0.7922772055040708, 0.7944170434063611]}

Epsilon = 1.31

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464, 1.5503206903109663, 1.531454744667379, 1.495392064341508, 1.4951688798742337, 1.4937441075851587, 1.5138965205132264, 1.4726980906842555], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603, 0.5501409585179219, 0.5614176399516714, 0.5698751510269835, 0.5775271848570278, 0.5803463552154652, 0.5819573097060008, 0.5884011276681433], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546, 0.7591763445479134, 0.7698641286799174, 0.7772493072393372, 0.7844971780330663, 0.7922772055040708, 0.7944170434063611, 0.8006586339919941]}

Epsilon = 1.38

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464, 1.5503206903109663, 1.531454744667379, 1.495392064341508, 1.4951688798742337, 1.4937441075851587, 1.5138965205132264, 1.4726980906842555, 1.4792252174078626], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603, 0.5501409585179219, 0.5614176399516714, 0.5698751510269835, 0.5775271848570278, 0.5803463552154652, 0.5819573097060008, 0.5884011276681433, 0.5920257752718485], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546, 0.7591763445479134, 0.7698641286799174, 0.7772493072393372, 0.7844971780330663, 0.7922772055040708, 0.7944170434063611, 0.8006586339919941, 0.7995045072414405]}

Epsilon = 1.44

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464, 1.5503206903109663, 1.531454744667379, 1.495392064341508, 1.4951688798742337, 1.4937441075851587, 1.5138965205132264, 1.4726980906842555, 1.4792252174078626, 1.47882433389878], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603, 0.5501409585179219, 0.5614176399516714, 0.5698751510269835, 0.5775271848570278, 0.5803463552154652, 0.5819573097060008, 0.5884011276681433, 0.5920257752718485, 0.5936367297623842], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546, 0.7591763445479134, 0.7698641286799174, 0.7772493072393372, 0.7844971780330663, 0.7922772055040708, 0.7944170434063611, 0.8006586339919941, 0.7995045072414405, 0.801438904597928]}

Epsilon = 1.51

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464, 1.5503206903109663, 1.531454744667379, 1.495392064341508, 1.4951688798742337, 1.4937441075851587, 1.5138965205132264, 1.4726980906842555, 1.4792252174078626, 1.47882433389878, 1.4742726371310384], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603, 0.5501409585179219, 0.5614176399516714, 0.5698751510269835, 0.5775271848570278, 0.5803463552154652, 0.5819573097060008, 0.5884011276681433, 0.5920257752718485, 0.5936367297623842, 0.5948449456302859], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546, 0.7591763445479134, 0.7698641286799174, 0.7772493072393372, 0.7844971780330663, 0.7922772055040708, 0.7944170434063611, 0.8006586339919941, 0.7995045072414405, 0.801438904597928, 0.8024453735221511]}

Epsilon = 1.57

{'loss': [1.6900447713623017, 1.6200207814640255, 1.5653510015912464, 1.5503206903109663, 1.531454744667379, 1.495392064341508, 1.4951688798742337, 1.4937441075851587, 1.5138965205132264, 1.4726980906842555, 1.4792252174078626, 1.47882433389878, 1.4742726371310384, 1.4762130140826148], 'accuracy': [0.4289166331051148, 0.49697946033024565, 0.5304067660088603, 0.5501409585179219, 0.5614176399516714, 0.5698751510269835, 0.5775271848570278, 0.5803463552154652, 0.5819573097060008, 0.5884011276681433, 0.5920257752718485, 0.5936367297623842, 0.5948449456302859, 0.5916230366492147], 'auc': [0.6836437826488786, 0.7193702350502433, 0.7411763249990546, 0.7591763445479134, 0.7698641286799174, 0.7772493072393372, 0.7844971780330663, 0.7922772055040708, 0.7944170434063611, 0.8006586339919941, 0.7995045072414405, 0.801438904597928, 0.8024453735221511, 0.7999357316614879]}

Epsilon = 1.63
[92mINFO [0m:      Sent reply
01/28/2025 09:29:35:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 09:30:05:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 09:30:05:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ace0d46b-4389-4ac7-943d-214f5fac63e6
01/28/2025 09:30:05:INFO:Received: train message ace0d46b-4389-4ac7-943d-214f5fac63e6
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/28/2025 09:43:02:INFO:Sent reply
[92mINFO [0m:      
01/28/2025 09:51:38:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/28/2025 09:51:38:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b7e8fcc8-0b62-427a-9181-ee12092da62a
01/28/2025 09:51:38:INFO:Received: evaluate message b7e8fcc8-0b62-427a-9181-ee12092da62a
