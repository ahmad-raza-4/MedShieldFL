nohup: ignoring input
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/raid/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/fixed_dp/version_01/1.8/flamby/datasets/fed_isic2019/dataset.py:222: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.
  albumentations.Flip(p=0.5),
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_holes` is deprecated. Use num_holes_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_height` is deprecated. Use hole_height_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/pydantic/main.py:214: DeprecationWarning: `max_width` is deprecated. Use hole_width_range instead.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/.local/lib/python3.8/site-packages/albumentations/core/validation.py:45: DeprecationWarning: always_apply is deprecated. Use `p=1` if you want to always apply the transform. self.p will be set to 1.
  original_init(self, **validated_kwargs)
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
01/20/2025 02:23:28:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/20/2025 02:23:28:DEBUG:ChannelConnectivity.IDLE
01/20/2025 02:23:28:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/20/2025 02:23:28:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 02:23:28:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: get_parameters message ab650767-6333-4138-8b3e-9bbb44fd10e5
01/20/2025 02:23:28:INFO:Received: get_parameters message ab650767-6333-4138-8b3e-9bbb44fd10e5
[92mINFO [0m:      Sent reply
01/20/2025 02:23:32:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 02:24:02:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 02:24:02:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b9a950ce-5dd5-4ef1-89c2-84f121a22d29
01/20/2025 02:24:02:INFO:Received: train message b9a950ce-5dd5-4ef1-89c2-84f121a22d29
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 02:36:56:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 02:43:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 02:43:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 35fb5b83-faee-4ea5-98e8-f17ba9510692
01/20/2025 02:43:54:INFO:Received: evaluate message 35fb5b83-faee-4ea5-98e8-f17ba9510692
[92mINFO [0m:      Sent reply
01/20/2025 02:47:54:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 02:48:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 02:48:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9aad300e-0ff5-4011-b44c-b2fe8533ba09
01/20/2025 02:48:20:INFO:Received: train message 9aad300e-0ff5-4011-b44c-b2fe8533ba09
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 03:01:08:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 03:08:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 03:08:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3a53e5f4-2b51-4c87-8282-d3ab19be623d
01/20/2025 03:08:53:INFO:Received: evaluate message 3a53e5f4-2b51-4c87-8282-d3ab19be623d
[92mINFO [0m:      Sent reply
01/20/2025 03:13:04:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 03:13:24:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 03:13:24:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 20bd666e-214e-443d-956d-7359255c31c1
01/20/2025 03:13:24:INFO:Received: train message 20bd666e-214e-443d-956d-7359255c31c1
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 03:26:08:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 03:33:25:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 03:33:25:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 40c59392-f564-48e4-a0cf-6fcc9d32bf11
01/20/2025 03:33:25:INFO:Received: evaluate message 40c59392-f564-48e4-a0cf-6fcc9d32bf11
[92mINFO [0m:      Sent reply
01/20/2025 03:37:36:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 03:38:00:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 03:38:00:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1b59a71a-414f-41bf-a5cc-d6e05f6a4886
01/20/2025 03:38:00:INFO:Received: train message 1b59a71a-414f-41bf-a5cc-d6e05f6a4886
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 03:50:40:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 03:57:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 03:57:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 88a324ff-3223-47cf-9d5b-24b3085f06c0
01/20/2025 03:57:18:INFO:Received: evaluate message 88a324ff-3223-47cf-9d5b-24b3085f06c0
[92mINFO [0m:      Sent reply
01/20/2025 04:01:19:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 04:01:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 04:01:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1b3a44bc-d462-4b5f-a2c2-2ad35cab758b
01/20/2025 04:01:49:INFO:Received: train message 1b3a44bc-d462-4b5f-a2c2-2ad35cab758b
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 04:14:37:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 04:21:01:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 04:21:01:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message abae25b8-975b-482d-a389-753071e40f04
01/20/2025 04:21:01:INFO:Received: evaluate message abae25b8-975b-482d-a389-753071e40f04
[92mINFO [0m:      Sent reply
01/20/2025 04:25:15:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 04:25:33:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 04:25:33:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a66c0dec-25b6-4ed2-a713-34f9b2657e3e
01/20/2025 04:25:33:INFO:Received: train message a66c0dec-25b6-4ed2-a713-34f9b2657e3e
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 04:38:22:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 04:46:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 04:46:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3d609bc1-c9d6-4c5f-ab20-a6bb9a4393be
01/20/2025 04:46:07:INFO:Received: evaluate message 3d609bc1-c9d6-4c5f-ab20-a6bb9a4393be
[92mINFO [0m:      Sent reply
01/20/2025 04:50:11:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 04:50:52:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 04:50:52:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b9cf1347-6249-40f1-a01b-5777360e6054
01/20/2025 04:50:52:INFO:Received: train message b9cf1347-6249-40f1-a01b-5777360e6054
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 05:03:36:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 05:09:59:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 05:09:59:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message cbc3155e-2277-4080-a693-5f7ffc8a9046
01/20/2025 05:09:59:INFO:Received: evaluate message cbc3155e-2277-4080-a693-5f7ffc8a9046
[92mINFO [0m:      Sent reply
01/20/2025 05:14:02:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 05:14:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 05:14:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message a6286105-554b-464d-8866-9a05050740d8
01/20/2025 05:14:31:INFO:Received: train message a6286105-554b-464d-8866-9a05050740d8
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 05:27:11:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 05:33:22:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 05:33:22:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 67d70dde-eb10-409a-ac65-27de66d99d2e
01/20/2025 05:33:22:INFO:Received: evaluate message 67d70dde-eb10-409a-ac65-27de66d99d2e
[92mINFO [0m:      Sent reply
01/20/2025 05:37:40:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 05:38:32:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 05:38:32:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 88d9a577-aef7-4d7d-83fb-af70bedd6bef
01/20/2025 05:38:32:INFO:Received: train message 88d9a577-aef7-4d7d-83fb-af70bedd6bef
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 05:51:29:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 06:05:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 06:05:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 2ed179d2-c9f0-4384-a3e9-95c2d09c134d
01/20/2025 06:05:40:INFO:Received: evaluate message 2ed179d2-c9f0-4384-a3e9-95c2d09c134d
[92mINFO [0m:      Sent reply
01/20/2025 06:10:42:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 06:11:20:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 06:11:20:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 9f82b237-a8a5-4ee2-8c8b-d6b3c3c47612
01/20/2025 06:11:20:INFO:Received: train message 9f82b237-a8a5-4ee2-8c8b-d6b3c3c47612
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 06:27:20:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 06:42:13:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 06:42:13:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 7d6da8a6-8408-4816-84ad-e38aa2e45f6f
01/20/2025 06:42:13:INFO:Received: evaluate message 7d6da8a6-8408-4816-84ad-e38aa2e45f6f
[92mINFO [0m:      Sent reply
01/20/2025 06:47:13:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 06:47:41:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 06:47:41:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cbbf49a8-b65f-4573-b3e2-56e108220c8b
01/20/2025 06:47:41:INFO:Received: train message cbbf49a8-b65f-4573-b3e2-56e108220c8b
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 07:03:43:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 07:18:23:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 07:18:23:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message dcf9155b-5a2b-4f8c-951f-e63a9328ebb4
01/20/2025 07:18:23:INFO:Received: evaluate message dcf9155b-5a2b-4f8c-951f-e63a9328ebb4
[92mINFO [0m:      Sent reply
01/20/2025 07:23:28:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 07:24:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 07:24:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ed14b46f-38a4-4a9a-af93-b870925736ff
01/20/2025 07:24:03:INFO:Received: train message ed14b46f-38a4-4a9a-af93-b870925736ff
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 07:40:02:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 07:54:44:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 07:54:44:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message cde58bd2-cf09-4e0f-9cb0-c5443a0b2db8
01/20/2025 07:54:44:INFO:Received: evaluate message cde58bd2-cf09-4e0f-9cb0-c5443a0b2db8
[92mINFO [0m:      Sent reply
01/20/2025 07:59:41:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 08:00:06:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 08:00:06:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 80956044-1c26-4993-aed7-ce5de8f062ef
01/20/2025 08:00:06:INFO:Received: train message 80956044-1c26-4993-aed7-ce5de8f062ef
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 08:16:03:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 08:30:56:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 08:30:56:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message fdb09e95-eb1c-4ed0-8100-3745e367a4c2
01/20/2025 08:30:56:INFO:Received: evaluate message fdb09e95-eb1c-4ed0-8100-3745e367a4c2
[92mINFO [0m:      Sent reply
01/20/2025 08:35:53:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 08:36:12:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 08:36:12:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 07e6872b-0558-491a-a729-6bdc1a1b8549
01/20/2025 08:36:12:INFO:Received: train message 07e6872b-0558-491a-a729-6bdc1a1b8549
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1640: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)
[92mINFO [0m:      Sent reply
01/20/2025 08:52:21:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 09:07:07:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 09:07:07:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 64ea860b-6aa1-403b-b778-f6010c734c0f
01/20/2025 09:07:07:INFO:Received: evaluate message 64ea860b-6aa1-403b-b778-f6010c734c0f
[92mINFO [0m:      Sent reply
01/20/2025 09:12:06:INFO:Sent reply
[92mINFO [0m:      
01/20/2025 09:12:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/20/2025 09:12:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 82720d9b-f99b-4b4d-b9f3-9dbba8745a15
01/20/2025 09:12:40:INFO:Received: train message 82720d9b-f99b-4b4d-b9f3-9dbba8745a15
