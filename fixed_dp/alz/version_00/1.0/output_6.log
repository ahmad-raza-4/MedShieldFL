nohup: ignoring input
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
01/22/2025 11:29:18:WARNING:Ignoring drop_last as it is not compatible with DPDataLoader.
01/22/2025 11:29:18:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/22/2025 11:29:18:DEBUG:ChannelConnectivity.IDLE
01/22/2025 11:29:18:DEBUG:ChannelConnectivity.CONNECTING
01/22/2025 11:29:18:DEBUG:ChannelConnectivity.READY
nohup: ignoring input
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
01/22/2025 11:30:20:WARNING:Ignoring drop_last as it is not compatible with DPDataLoader.
01/22/2025 11:30:20:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/22/2025 11:30:20:DEBUG:ChannelConnectivity.IDLE
01/22/2025 11:30:20:DEBUG:ChannelConnectivity.CONNECTING
01/22/2025 11:30:20:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/22/2025 11:30:35:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/22/2025 11:30:35:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message ff14deb0-c7f5-4333-af88-413cdd85debb
01/22/2025 11:30:35:INFO:Received: train message ff14deb0-c7f5-4333-af88-413cdd85debb
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/22/2025 11:32:05:INFO:Sent reply
[92mINFO [0m:      
01/22/2025 11:35:40:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/22/2025 11:35:40:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message 3e38a236-be9c-46f5-87d5-9a066c5dbc4c
01/22/2025 11:35:40:INFO:Received: evaluate message 3e38a236-be9c-46f5-87d5-9a066c5dbc4c
[92mINFO [0m:      Sent reply
01/22/2025 11:36:13:INFO:Sent reply
[92mINFO [0m:      
01/22/2025 11:36:46:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/22/2025 11:36:46:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message b9718b3c-d3e6-4065-a9fc-81eaddbb1d36
01/22/2025 11:36:46:INFO:Received: train message b9718b3c-d3e6-4065-a9fc-81eaddbb1d36
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/22/2025 11:38:44:INFO:Sent reply
[92mINFO [0m:      
01/22/2025 11:41:49:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/22/2025 11:41:49:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message a8787175-a1e6-490d-9453-2b886bdc1676
01/22/2025 11:41:49:INFO:Received: evaluate message a8787175-a1e6-490d-9453-2b886bdc1676
[92mINFO [0m:      Sent reply
01/22/2025 11:42:30:INFO:Sent reply
[92mINFO [0m:      
01/22/2025 11:42:54:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/22/2025 11:42:54:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 98e5a16c-3a43-484b-a613-eb63d8c557f5
01/22/2025 11:42:54:INFO:Received: train message 98e5a16c-3a43-484b-a613-eb63d8c557f5
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/22/2025 11:44:53:INFO:Sent reply
