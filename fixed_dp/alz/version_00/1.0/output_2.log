nohup: ignoring input
/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.
  warnings.warn(
01/21/2025 10:04:46:WARNING:Ignoring drop_last as it is not compatible with DPDataLoader.
01/21/2025 10:04:46:DEBUG:Opened insecure gRPC connection (no certificates were passed)
01/21/2025 10:04:46:DEBUG:ChannelConnectivity.IDLE
01/21/2025 10:04:46:DEBUG:ChannelConnectivity.CONNECTING
01/21/2025 10:04:46:DEBUG:ChannelConnectivity.READY
[92mINFO [0m:      
01/21/2025 10:05:18:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/21/2025 10:05:18:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 1439bda6-d2ff-442d-a290-f3bc2ae42c11
01/21/2025 10:05:18:INFO:Received: train message 1439bda6-d2ff-442d-a290-f3bc2ae42c11
Error importing huggingface_hub.hf_api: No module named 'tqdm'
Error importing huggingface_hub.hf_api: No module named 'tqdm'
/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/21/2025 10:10:07:INFO:Sent reply
[92mINFO [0m:      
01/21/2025 10:14:45:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/21/2025 10:14:45:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b8f2673c-2a04-41b7-a596-e9f32ea3a2a2
01/21/2025 10:14:45:INFO:Received: evaluate message b8f2673c-2a04-41b7-a596-e9f32ea3a2a2
Epsilon = 1.11
[92mINFO [0m:      Sent reply
01/21/2025 10:16:31:INFO:Sent reply
[92mINFO [0m:      
01/21/2025 10:17:03:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/21/2025 10:17:03:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message cadfa2e9-0fd5-436d-9138-2565b4e1b0e4
01/21/2025 10:17:03:INFO:Received: train message cadfa2e9-0fd5-436d-9138-2565b4e1b0e4

{'loss': [183.56197291612625], 'accuracy': [0.49648162627052383], 'auc': [0.5590802922012008]}

/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/21/2025 10:21:53:INFO:Sent reply
[92mINFO [0m:      
01/21/2025 10:26:31:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/21/2025 10:26:31:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message d87bafdf-95a8-4089-be8e-4cd2eebc9d60
01/21/2025 10:26:31:INFO:Received: evaluate message d87bafdf-95a8-4089-be8e-4cd2eebc9d60
Epsilon = 1.49
[92mINFO [0m:      Sent reply
01/21/2025 10:28:19:INFO:Sent reply
[92mINFO [0m:      
01/21/2025 10:28:53:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/21/2025 10:28:53:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message 2c1b966e-0331-469e-8234-04c3135be92e
01/21/2025 10:28:53:INFO:Received: train message 2c1b966e-0331-469e-8234-04c3135be92e

{'loss': [183.56197291612625, 174.04597514867783], 'accuracy': [0.49648162627052383, 0.49569976544175137], 'auc': [0.5590802922012008, 0.5831169002518957]}

/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[92mINFO [0m:      Sent reply
01/21/2025 10:33:42:INFO:Sent reply
[92mINFO [0m:      
01/21/2025 10:38:08:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/21/2025 10:38:08:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: evaluate message b91f0c47-2135-4887-b61a-6b6840d4a90b
01/21/2025 10:38:08:INFO:Received: evaluate message b91f0c47-2135-4887-b61a-6b6840d4a90b
Epsilon = 1.79
[92mINFO [0m:      Sent reply
01/21/2025 10:39:53:INFO:Sent reply
[92mINFO [0m:      
01/21/2025 10:40:37:INFO:
[92mINFO [0m:      [RUN 0, ROUND ]
01/21/2025 10:40:37:INFO:[RUN 0, ROUND ]
[92mINFO [0m:      Received: train message c085cb41-c50e-4e68-8e74-843604d1e526
01/21/2025 10:40:37:INFO:Received: train message c085cb41-c50e-4e68-8e74-843604d1e526

{'loss': [183.56197291612625, 174.04597514867783, 171.55733466148376], 'accuracy': [0.49648162627052383, 0.49569976544175137, 0.4910086004691165], 'auc': [0.5590802922012008, 0.5831169002518957, 0.5971922107095]}

/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
[91mERROR [0m:     Client raised an exception.
Traceback (most recent call last):
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/app.py", line 496, in _start_client_internal
    reply_message = client_app(message=message, context=context)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/client_app.py", line 98, in __call__
    return self._call(message, context)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/client_app.py", line 81, in ffn
    out_message = handle_legacy_message_from_msgtype(
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/message_handler/message_handler.py", line 130, in handle_legacy_message_from_msgtype
    fit_res = maybe_call_fit(
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/client.py", line 234, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/numpy_client.py", line 238, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "client_2.py", line 142, in fit
    epsilon = train(
  File "client_2.py", line 78, in train
    loss = criterion(net(images), labels)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/grad_sample/grad_sample_module.py", line 149, in forward
    return self._module(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/fixed_dp/alz/version_00/1.0/main.py", line 52, in forward
    return self.model(x.to(self.device))
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/models/vision_transformer.py", line 298, in forward
    x = self.encoder(x)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/models/vision_transformer.py", line 157, in forward
    return self.ln(self.layers(self.dropout(input)))
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/models/vision_transformer.py", line 113, in forward
    x, _ = self.self_attention(x, x, x, need_weights=False)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 5440, in multi_head_attention_forward
    attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
RuntimeError: CUDA error: invalid configuration argument
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

01/21/2025 10:43:40:ERROR:Client raised an exception.
Traceback (most recent call last):
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/app.py", line 496, in _start_client_internal
    reply_message = client_app(message=message, context=context)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/client_app.py", line 98, in __call__
    return self._call(message, context)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/client_app.py", line 81, in ffn
    out_message = handle_legacy_message_from_msgtype(
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/message_handler/message_handler.py", line 130, in handle_legacy_message_from_msgtype
    fit_res = maybe_call_fit(
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/client.py", line 234, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/numpy_client.py", line 238, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "client_2.py", line 142, in fit
    epsilon = train(
  File "client_2.py", line 78, in train
    loss = criterion(net(images), labels)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/grad_sample/grad_sample_module.py", line 149, in forward
    return self._module(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/fixed_dp/alz/version_00/1.0/main.py", line 52, in forward
    return self.model(x.to(self.device))
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/models/vision_transformer.py", line 298, in forward
    x = self.encoder(x)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/models/vision_transformer.py", line 157, in forward
    return self.ln(self.layers(self.dropout(input)))
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/models/vision_transformer.py", line 113, in forward
    x, _ = self.self_attention(x, x, x, need_weights=False)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 5440, in multi_head_attention_forward
    attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
RuntimeError: CUDA error: invalid configuration argument
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

01/21/2025 10:43:40:DEBUG:gRPC channel closed
Traceback (most recent call last):
  File "client_2.py", line 178, in <module>
    fl.client.start_client(
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/app.py", line 291, in start_client
    _start_client_internal(
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/app.py", line 503, in _start_client_internal
    raise ex
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/app.py", line 496, in _start_client_internal
    reply_message = client_app(message=message, context=context)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/client_app.py", line 98, in __call__
    return self._call(message, context)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/client_app.py", line 81, in ffn
    out_message = handle_legacy_message_from_msgtype(
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/message_handler/message_handler.py", line 130, in handle_legacy_message_from_msgtype
    fit_res = maybe_call_fit(
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/client.py", line 234, in maybe_call_fit
    return client.fit(fit_ins)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/flwr/client/numpy_client.py", line 238, in _fit
    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore
  File "client_2.py", line 142, in fit
    epsilon = train(
  File "client_2.py", line 78, in train
    loss = criterion(net(images), labels)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/opacus/grad_sample/grad_sample_module.py", line 149, in forward
    return self._module(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/raid/home/dgxuser16/NTL/mccarthy/ahmad/github/adaptive_privacy_fl/fixed_dp/alz/version_00/1.0/main.py", line 52, in forward
    return self.model(x.to(self.device))
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/models/vision_transformer.py", line 298, in forward
    x = self.encoder(x)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/models/vision_transformer.py", line 157, in forward
    return self.ln(self.layers(self.dropout(input)))
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torchvision/models/vision_transformer.py", line 113, in forward
    x, _ = self.self_attention(x, x, x, need_weights=False)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/dgxuser16/.local/lib/python3.8/site-packages/torch/nn/functional.py", line 5440, in multi_head_attention_forward
    attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
RuntimeError: CUDA error: invalid configuration argument
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

